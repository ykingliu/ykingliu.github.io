[{"title":"HBase 集群监控","date":"2017-10-21T06:49:14.105Z","path":"2017/10/21/HBase-metrics/","text":"为什么需要监控？为了保证系统的稳定性，可靠性，可运维性。 掌控集群的核心性能指标，了解集群的性能表现。 集群出现问题时及时报警，便于运维同学及时修复问题。 集群重要指标值异常时进行预警，将问题扼杀在摇篮中，不用等集群真正不可用时才采取行动。 当集群出现问题时，监控系统可以帮助我们更快的定位问题和解决问题 如何构建 HBase 集群监控系统？公司有自己的监控系统，我们所要做的就是将 HBase 中我们关心的指标项发送到监控系统去，问题就转换为我们开发，采集并返回哪些 HBase 集群监控指标项。 HBase 集群监控指标采集的监控数据主要包括以下几个方面：某台机器 OS 层面上的数据，例如 CPU、内存、磁盘、网络、load、网络流量等；某台 regionserver（或master）机器 jvm 的状态，例如关于线程的信息，GC 的次数和时间，内存使用状况，以及 ERROR、WARN、Fatal 事件出现的次数；regionserver（或 master）进程中的统计信息。 可以通过以下地址获取 HBase 提供的 JMX 信息的 web 页面 1http://your_master:60010/jmx //所有的bean JMX web 页面的数据格式是json格式，信息很多！ OS 监控数据HBase 中对于 OS 的监控数据，主要是 OperatingSystem 的对象来进行的，如下就是我提取出来的 JSON 信息， 1234567891011121314151617181920&#123; \"name\" : \"java.lang:type=OperatingSystem\", \"modelerType\" : \"com.sun.management.UnixOperatingSystem\", \"MaxFileDescriptorCount\" : 1000000, \"OpenFileDescriptorCount\" : 413, \"CommittedVirtualMemorySize\" : 1892225024, \"FreePhysicalMemorySize\" : 284946432, \"FreeSwapSpaceSize\" : 535703552, \"ProcessCpuLoad\" : 0.0016732901066722444, \"ProcessCpuTime\" : 59306210000000, \"SystemCpuLoad\" : 0.018197029910060655, \"TotalPhysicalMemorySize\" : 16660848640, \"TotalSwapSpaceSize\" : 536862720, \"AvailableProcessors\" : 8, \"Arch\" : \"amd64\", \"SystemLoadAverage\" : 0.0, \"Name\" : \"Linux\", \"Version\" : \"2.6.32-431.11.7.el6.ucloud.x86_64\", \"ObjectName\" : \"java.lang:type=OperatingSystem\" &#125; 其中比较重要的指标有 OpenFileDescriptorCount , FreePhysicalMemorySize , ProcessCpuLoad , SystemCpuLoad , AvailableProcessors , SystemLoadAverage JVM 监控数据Hbase 中对于 JVM 的监控数据，主要是 JvmMetrics 的对象来进行的，如下就是我提取出来的 JSON 信息， 12345678910111213141516171819202122232425262728293031&#123; \"name\" : \"Hadoop:service=HBase,name=JvmMetrics\", \"modelerType\" : \"JvmMetrics\", \"tag.Context\" : \"jvm\", \"tag.ProcessName\" : \"Master\", \"tag.SessionId\" : \"\", \"tag.Hostname\" : \"uhadoop-qrljqo-master2\", \"MemNonHeapUsedM\" : 53.846107, \"MemNonHeapCommittedM\" : 85.84375, \"MemNonHeapMaxM\" : 130.0, \"MemHeapUsedM\" : 79.05823, \"MemHeapCommittedM\" : 240.125, \"MemHeapMaxM\" : 989.875, \"MemMaxM\" : 989.875, \"GcCountParNew\" : 15190, \"GcTimeMillisParNew\" : 72300, \"GcCountConcurrentMarkSweep\" : 2, \"GcTimeMillisConcurrentMarkSweep\" : 319, \"GcCount\" : 15192, \"GcTimeMillis\" : 72619, \"ThreadsNew\" : 0, \"ThreadsRunnable\" : 21, \"ThreadsBlocked\" : 0, \"ThreadsWaiting\" : 144, \"ThreadsTimedWaiting\" : 18, \"ThreadsTerminated\" : 0, \"LogFatal\" : 0, \"LogError\" : 0, \"LogWarn\" : 0, \"LogInfo\" : 0 &#125; JvmMetrics 主要统计的信息包括：内存的使用状态信息；GC的统计信息；线程的统计信息；以及事件的统计信息。 内存的统计信息主要是：JVM 当前已经使用的 NonHeapMemory 的大小、以及配置的 NonHeapMemory 的大小；JVM 当前已经使用的 HeapMemory 的大小、以及配置的 HeapMemory 的大小； JVM 运行时的可以使用的最大的内存的大小。 GC 的统计较为简单，仅统计了进程在固定间隔内 GC 的次数和花费的总时间。 线程的统计，主要是统计进程内当前线程的处于 NEW 、RUNNABLE、BLOCKED、WAITING、TIMED_WAITING、TERMINATED 这六种状态下的线程数量。 对于事件的统计，主要统计固定时间间隔内的 Fatal、Error、Warn 以及 Info 的数量。(这块好像不怎么重要) Region Servers 健康你也可以通过如下地址： 1http://your_master:60010/jmx?qry=Hadoop:service=HBase,name=Master,sub=Server 获得到 Region Servers 健康值： 123456789101112131415161718&#123; \"name\" : \"Hadoop:service=HBase,name=Master,sub=Server\", \"modelerType\" : \"Master,sub=Server\", \"tag.liveRegionServers\" : \"xxx\", \"tag.deadRegionServers\" : \"\", \"tag.zookeeperQuorum\" : \"xxx\", \"tag.serverName\" : \"xxx2,60000,1495683310213\", \"tag.clusterId\" : \"e5e044a3-ef9f-48f7-ba63-637376f5fa90\", \"tag.isActiveMaster\" : \"true\", \"tag.Context\" : \"master\", \"tag.Hostname\" : \"xxx\", \"masterActiveTime\" : 1495683312239, \"masterStartTime\" : 1495683310213, \"averageLoad\" : 143.66666666666666, \"numRegionServers\" : 3, \"numDeadRegionServers\" : 0, \"clusterRequests\" : 1297834323 &#125; MemoryPool从全部的 JSON 值中你会看到很多种 MemoryPool 值，比如 Par Eden Space 、CMS Perm Gen、Par Survivor Space、CMS Old Gen、Code Cache ，按需获取吧。 总结任何一个服务的监控系统都是一个不断迭代，不断优化的过程，不可能一开始就做到最好。监控总是比问题发生来的更早一些，而每一次出问题，又进一步加强相应方面的监控，我们需要让监控系统从出问题时才报警到可能出现问题时就预警逐渐过渡，最终让监控系统成为我们保证系统稳定性的一个有力工具。 最后监控指标有很多，但请按需获取 ! 转载文章请注明原出处，谢谢支持！ http://www.54tianzhisheng.cn/2017/10/21/HBase-metrics/ 参考资料1、hbase性能监控（一） 2、hbase性能监控（二） 3、hbase性能监控（三） 4、HBase 集群监控系统构建 5、hbase jmx常用监控指标 推荐相关文章1、ElasticSearch 单个节点监控 2、ElasticSearch 集群监控","tags":[{"name":"HBase","slug":"HBase","permalink":"http://yoursite.com/tags/HBase/"}]},{"title":"ElasticSearch 单个节点监控","date":"2017-10-18T07:09:05.837Z","path":"2017/10/18/ElasticSearch-nodes-metrics/","text":"集群健康监控是对集群信息进行高度的概括，节点统计值 API 提供了集群中每个节点的统计值。节点统计值很多，在监控的时候仍需要我们清楚哪些指标是最值得关注的。 集群健康监控可以参考这篇文章：ElasticSearch 集群监控 节点信息 Node Info :1curl -XGET &apos;http://localhost:9200/_nodes&apos; 执行上述命令可以获取所有 node 的信息 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071_nodes: &#123; total: 2, successful: 2, failed: 0&#125;,cluster_name: \"elasticsearch\",nodes: &#123; MSQ_CZ7mTNyOSlYIfrvHag: &#123; name: \"node0\", transport_address: \"192.168.180.110:9300\", host: \"192.168.180.110\", ip: \"192.168.180.110\", version: \"5.5.0\", build_hash: \"260387d\", total_indexing_buffer: 103887667, roles:&#123;...&#125;, settings: &#123;...&#125;, os: &#123; refresh_interval_in_millis: 1000, name: \"Linux\", arch: \"amd64\", version: \"3.10.0-229.el7.x86_64\", available_processors: 4, allocated_processors: 4 &#125;, process: &#123; refresh_interval_in_millis: 1000, id: 3022, mlockall: false &#125;, jvm: &#123; pid: 3022, version: \"1.8.0_121\", vm_name: \"Java HotSpot(TM) 64-Bit Server VM\", vm_version: \"25.121-b13\", vm_vendor: \"Oracle Corporation\", start_time_in_millis: 1507515225302, mem: &#123; heap_init_in_bytes: 1073741824, heap_max_in_bytes: 1038876672, non_heap_init_in_bytes: 2555904, non_heap_max_in_bytes: 0, direct_max_in_bytes: 1038876672 &#125;, gc_collectors: [], memory_pools: [], using_compressed_ordinary_object_pointers: \"true\", input_arguments:&#123;&#125; &#125; thread_pool:&#123; force_merge: &#123;&#125;, fetch_shard_started: &#123;&#125;, listener: &#123;&#125;, index: &#123;&#125;, refresh: &#123;&#125;, generic: &#123;&#125;, warmer: &#123;&#125;, search: &#123;&#125;, flush: &#123;&#125;, fetch_shard_store: &#123;&#125;, management: &#123;&#125;, get: &#123;&#125;, bulk: &#123;&#125;, snapshot: &#123;&#125; &#125; transport: &#123;...&#125;, http: &#123;...&#125;, plugins: [], modules: [], ingest: &#123;...&#125; &#125; 上面是我已经简写了很多数据之后的返回值，但是指标还是很多，有些是一些常规的指标，对于监控来说，没必要拿取。从上面我们可以主要关注以下这些指标: 1os, process, jvm, thread_pool, transport, http, ingest and indices 节点统计 nodes-statistics节点统计值 API 可通过如下命令获取： 1GET /_nodes/stats 得到： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158_nodes: &#123; total: 2, successful: 2, failed: 0&#125;,cluster_name: \"elasticsearch\",nodes: &#123; MSQ_CZ7mTNyOSlYI0yvHag: &#123; timestamp: 1508312932354, name: \"node0\", transport_address: \"192.168.180.110:9300\", host: \"192.168.180.110\", ip: \"192.168.180.110:9300\", roles: [], indices: &#123; docs: &#123; count: 6163666, deleted: 0 &#125;, store: &#123; size_in_bytes: 2301398179, throttle_time_in_millis: 122850 &#125;, indexing: &#123;&#125;, get: &#123;&#125;, search: &#123;&#125;, merges: &#123;&#125;, refresh: &#123;&#125;, flush: &#123;&#125;, warmer: &#123;&#125;, query_cache: &#123;&#125;, fielddata: &#123;&#125;, completion: &#123;&#125;, segments: &#123;&#125;, translog: &#123;&#125;, request_cache: &#123;&#125;, recovery: &#123;&#125; &#125;, os: &#123; timestamp: 1508312932369, cpu: &#123; percent: 0, load_average: &#123; 1m: 0.09, 5m: 0.12, 15m: 0.08 &#125; &#125;, mem: &#123; total_in_bytes: 8358301696, free_in_bytes: 1381613568, used_in_bytes: 6976688128, free_percent: 17, used_percent: 83 &#125;, swap: &#123; total_in_bytes: 8455712768, free_in_bytes: 8455299072, used_in_bytes: 413696 &#125;, cgroup: &#123; cpuacct: &#123;&#125;, cpu: &#123; control_group: \"/user.slice\", cfs_period_micros: 100000, cfs_quota_micros: -1, stat: &#123;&#125; &#125; &#125;&#125;,process: &#123; timestamp: 1508312932369, open_file_descriptors: 228, max_file_descriptors: 65536, cpu: &#123; percent: 0, total_in_millis: 2495040 &#125;, mem: &#123; total_virtual_in_bytes: 5002465280 &#125;&#125;,jvm: &#123; timestamp: 1508312932369, uptime_in_millis: 797735804, mem: &#123; heap_used_in_bytes: 318233768, heap_used_percent: 30, heap_committed_in_bytes: 1038876672, heap_max_in_bytes: 1038876672, non_heap_used_in_bytes: 102379784, non_heap_committed_in_bytes: 108773376, pools: &#123; young: &#123; used_in_bytes: 62375176, max_in_bytes: 279183360, peak_used_in_bytes: 279183360, peak_max_in_bytes: 279183360 &#125;, survivor: &#123; used_in_bytes: 175384, max_in_bytes: 34865152, peak_used_in_bytes: 34865152, peak_max_in_bytes: 34865152 &#125;, old: &#123; used_in_bytes: 255683208, max_in_bytes: 724828160, peak_used_in_bytes: 255683208, peak_max_in_bytes: 724828160 &#125; &#125; &#125;, threads: &#123;&#125;, gc: &#123;&#125;, buffer_pools: &#123;&#125;, classes: &#123;&#125;&#125;, thread_pool: &#123; bulk: &#123;&#125;, fetch_shard_started: &#123;&#125;, fetch_shard_store: &#123;&#125;, flush: &#123;&#125;, force_merge: &#123;&#125;, generic: &#123;&#125;, get: &#123;&#125;, index: &#123; threads: 1, queue: 0, active: 0, rejected: 0, largest: 1, completed: 1 &#125; listener: &#123;&#125;, management: &#123;&#125;, refresh: &#123;&#125;, search: &#123;&#125;, snapshot: &#123;&#125;, warmer: &#123;&#125; &#125;, fs: &#123;&#125;, transport: &#123; server_open: 13, rx_count: 11696, rx_size_in_bytes: 1525774, tx_count: 10282, tx_size_in_bytes: 1440101928 &#125;, http: &#123; current_open: 4, total_opened: 23 &#125;, breakers: &#123;&#125;, script: &#123;&#125;, discovery: &#123;&#125;, ingest: &#123;&#125;&#125; 节点名是一个 UUID，上面列举了很多指标，下面讲解下： 索引部分 indices这部分列出了这个节点上所有索引的聚合过的统计值 ： docs 展示节点内存有多少文档，包括还没有从段里清除的已删除文档数量。 store 部分显示节点耗用了多少物理存储。这个指标包括主分片和副本分片在内。如果限流时间很大，那可能表明你的磁盘限流设置得过低。 indexing 显示已经索引了多少文档。这个值是一个累加计数器。在文档被删除的时候，数值不会下降。还要注意的是，在发生内部 索引操作的时候，这个值也会增加，比如说文档更新。 还列出了索引操作耗费的时间，正在索引的文档数量，以及删除操作的类似统计值。 get 显示通过 ID 获取文档的接口相关的统计值。包括对单个文档的 GET 和 HEAD 请求。 search 描述在活跃中的搜索（ open_contexts ）数量、查询的总数量、以及自节点启动以来在查询上消耗的总时间。用 query_time_in_millis / query_total 计算的比值，可以用来粗略的评价你的查询有多高效。比值越大，每个查询花费的时间越多，你应该要考虑调优了。 fetch 统计值展示了查询处理的后一半流程（query-then-fetch 里的 fetch ）。如果 fetch 耗时比 query 还多，说明磁盘较慢，或者获取了太多文档，或者可能搜索请求设置了太大的分页（比如， size: 10000 ）。 merges 包括了 Lucene 段合并相关的信息。它会告诉你目前在运行几个合并，合并涉及的文档数量，正在合并的段的总大小，以及在合并操作上消耗的总时间。 filter_cache 展示了已缓存的过滤器位集合所用的内存数量，以及过滤器被驱逐出内存的次数。过多的驱逐数 可能 说明你需要加大过滤器缓存的大小，或者你的过滤器不太适合缓存（比如它们因为高基数而在大量产生，就像是缓存一个 now 时间表达式）。 不过，驱逐数是一个很难评定的指标。过滤器是在每个段的基础上缓存的，而从一个小的段里驱逐过滤器，代价比从一个大的段里要廉价的多。有可能你有很大的驱逐数，但是它们都发生在小段上，也就意味着这些对查询性能只有很小的影响。 把驱逐数指标作为一个粗略的参考。如果你看到数字很大，检查一下你的过滤器，确保他们都是正常缓存的。不断驱逐着的过滤器，哪怕都发生在很小的段上，效果也比正确缓存住了的过滤器差很多。 field_data 显示 fielddata 使用的内存， 用以聚合、排序等等。这里也有一个驱逐计数。和 filter_cache 不同的是，这里的驱逐计数是很有用的：这个数应该或者至少是接近于 0。因为 fielddata 不是缓存，任何驱逐都消耗巨大，应该避免掉。如果你在这里看到驱逐数，你需要重新评估你的内存情况，fielddata 限制，请求语句，或者这三者。 segments 会展示这个节点目前正在服务中的 Lucene 段的数量。 这是一个重要的数字。大多数索引会有大概 50–150 个段，哪怕它们存有 TB 级别的数十亿条文档。段数量过大表明合并出现了问题（比如，合并速度跟不上段的创建）。注意这个统计值是节点上所有索引的汇聚总数。记住这点。 memory 统计值展示了 Lucene 段自己用掉的内存大小。 这里包括底层数据结构，比如倒排表，字典，和布隆过滤器等。太大的段数量会增加这些数据结构带来的开销，这个内存使用量就是一个方便用来衡量开销的度量值。 操作系统和进程部分OS 和 Process 部分基本是自描述的，不会在细节中展开讲解。它们列出来基础的资源统计值，比如 CPU 和负载。OS 部分描述了整个操作系统，而 Process 部分只显示 Elasticsearch 的 JVM 进程使用的资源情况。 这些都是非常有用的指标，不过通常在你的监控技术栈里已经都测量好了。统计值包括下面这些： CPU 负载 内存使用率 （mem.used_percent） Swap 使用率 打开的文件描述符 （open_file_descriptors） JVM 部分jvm 部分包括了运行 Elasticsearch 的 JVM 进程一些很关键的信息。 最重要的，它包括了垃圾回收的细节，这对你的 Elasticsearch 集群的稳定性有着重大影响。 123456789101112jvm: &#123; timestamp: 1508312932369, uptime_in_millis: 797735804, mem: &#123; heap_used_in_bytes: 318233768, heap_used_percent: 30, heap_committed_in_bytes: 1038876672, heap_max_in_bytes: 1038876672, non_heap_used_in_bytes: 102379784, non_heap_committed_in_bytes: 108773376, &#125;&#125; jvm 部分首先列出一些和 heap 内存使用有关的常见统计值。你可以看到有多少 heap 被使用了，多少被指派了（当前被分配给进程的），以及 heap 被允许分配的最大值。理想情况下，heap_committed_in_bytes 应该等于 heap_max_in_bytes 。如果指派的大小更小，JVM 最终会被迫调整 heap 大小——这是一个非常昂贵的操作。如果你的数字不相等，阅读 堆内存:大小和交换 学习如何正确的配置它。 heap_used_percent 指标是值得关注的一个数字。Elasticsearch 被配置为当 heap 达到 75% 的时候开始 GC。如果你的节点一直 &gt;= 75%，你的节点正处于 内存压力 状态。这是个危险信号，不远的未来可能就有慢 GC 要出现了。 如果 heap 使用率一直 &gt;=85%，你就麻烦了。Heap 在 90–95% 之间，则面临可怕的性能风险，此时最好的情况是长达 10–30s 的 GC，最差的情况就是内存溢出（OOM）异常。 线程池部分Elasticsearch 在内部维护了线程池。 这些线程池相互协作完成任务，有必要的话相互间还会传递任务。通常来说，你不需要配置或者调优线程池，不过查看它们的统计值有时候还是有用的，可以洞察你的集群表现如何。 每个线程池会列出已配置的线程数量（ threads ），当前在处理任务的线程数量（ active ），以及在队列中等待处理的任务单元数量（ queue ）。 如果队列中任务单元数达到了极限，新的任务单元会开始被拒绝，你会在 rejected 统计值上看到它反映出来。这通常是你的集群在某些资源上碰到瓶颈的信号。因为队列满意味着你的节点或集群在用最高速度运行，但依然跟不上工作的蜂拥而入。 这里的一系列的线程池，大多数你可以忽略，但是有一小部分还是值得关注的： indexing 普通的索引请求的线程池 bulk 批量请求，和单条的索引请求不同的线程池 get Get-by-ID 操作 search 所有的搜索和查询请求 merging 专用于管理 Lucene 合并的线程池 网络部分 transport 显示和 传输地址 相关的一些基础统计值。包括节点间的通信（通常是 9300 端口）以及任意传输客户端或者节点客户端的连接。如果看到这里有很多连接数不要担心；Elasticsearch 在节点之间维护了大量的连接。 http 显示 HTTP 端口（通常是 9200）的统计值。如果你看到 total_opened 数很大而且还在一直上涨，这是一个明确信号，说明你的 HTTP 客户端里有没启用 keep-alive 长连接的。持续的 keep-alive 长连接对性能很重要，因为连接、断开套接字是很昂贵的（而且浪费文件描述符）。请确认你的客户端都配置正确。 参考资料1、nodes-info 2、nodes-stats 3、ES监控指标 最后：转载请注明地址：http://www.54tianzhisheng.cn/2017/10/18/ElasticSearch-nodes-metrics/","tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"http://yoursite.com/tags/ElasticSearch/"}]},{"title":"ElasticSearch 集群监控","date":"2017-10-15T12:35:47.137Z","path":"2017/10/15/ElasticSearch-cluster-health-metrics/","text":"最近在做 ElasticSearch 的信息（集群和节点）监控，特此稍微整理下学到的东西。这篇文章主要介绍集群的监控。 要监控哪些 ElasticSearch metrics Elasticsearch 提供了大量的 Metric，可以帮助您检测到问题的迹象，在遇到节点不可用、out-of-memory、long garbage collection times 的时候采取相应措施。但是指标太多了，有时我们并不需要这么多，这就需要我们进行筛选。 集群健康一个 Elasticsearch 集群至少包括一个节点和一个索引。或者它 可能有一百个数据节点、三个单独的主节点，以及一小打客户端节点——这些共同操作一千个索引（以及上万个分片）。 不管集群扩展到多大规模，你都会想要一个快速获取集群状态的途径。Cluster Health API 充当的就是这个角色。你可以把它想象成是在一万英尺的高度鸟瞰集群。它可以告诉你安心吧一切都好，或者警告你集群某个地方有问题。 让我们执行一下 cluster-health API 然后看看响应体是什么样子的： 1GET _cluster/health 和 Elasticsearch 里其他 API 一样，cluster-health 会返回一个 JSON 响应。这对自动化和告警系统来说，非常便于解析。响应中包含了和你集群有关的一些关键信息： 123456789101112&#123; \"cluster_name\": \"elasticsearch_zach\", \"status\": \"green\", \"timed_out\": false, \"number_of_nodes\": 1, \"number_of_data_nodes\": 1, \"active_primary_shards\": 10, \"active_shards\": 10, \"relocating_shards\": 0, \"initializing_shards\": 0, \"unassigned_shards\": 0&#125; 响应信息中最重要的一块就是 status 字段。状态可能是下列三个值之一 : status 含义 green 所有的主分片和副本分片都已分配。你的集群是 100% 可用的。 yellow 所有的主分片已经分片了，但至少还有一个副本是缺失的。不会有数据丢失，所以搜索结果依然是完整的。不过，你的高可用性在某种程度上被弱化。如果 更多的 分片消失，你就会丢数据了。把 yellow 想象成一个需要及时调查的警告。 red 至少一个主分片（以及它的全部副本）都在缺失中。这意味着你在缺少数据：搜索只能返回部分数据，而分配到这个分片上的写入请求会返回一个异常。 number_of_nodes 和 number_of_data_nodes 这个命名完全是自描述的。 active_primary_shards 指出你集群中的主分片数量。这是涵盖了所有索引的汇总值。 active_shards 是涵盖了所有索引的所有分片的汇总值，即包括副本分片。 relocating_shards 显示当前正在从一个节点迁往其他节点的分片的数量。通常来说应该是 0，不过在 Elasticsearch 发现集群不太均衡时，该值会上涨。比如说：添加了一个新节点，或者下线了一个节点。 initializing_shards 是刚刚创建的分片的个数。比如，当你刚创建第一个索引，分片都会短暂的处于 initializing 状态。这通常会是一个临时事件，分片不应该长期停留在 initializing状态。你还可能在节点刚重启的时候看到 initializing 分片：当分片从磁盘上加载后，它们会从initializing 状态开始。 unassigned_shards 是已经在集群状态中存在的分片，但是实际在集群里又找不着。通常未分配分片的来源是未分配的副本。比如，一个有 5 分片和 1 副本的索引，在单节点集群上，就会有 5 个未分配副本分片。如果你的集群是 red 状态，也会长期保有未分配分片（因为缺少主分片）。 集群统计集群统计信息包含 集群的分片数，文档数，存储空间，缓存信息，内存作用率，插件内容，文件系统内容，JVM 作用状况，系统 CPU，OS 信息，段信息。 查看全部统计信息命令： 1curl -XGET &apos;http://localhost:9200/_cluster/stats?human&amp;pretty&apos; 返回 JSON 结果： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177&#123; \"timestamp\": 1459427693515, \"cluster_name\": \"elasticsearch\", \"status\": \"green\", \"indices\": &#123; \"count\": 2, \"shards\": &#123; \"total\": 10, \"primaries\": 10, \"replication\": 0, \"index\": &#123; \"shards\": &#123; \"min\": 5, \"max\": 5, \"avg\": 5 &#125;, \"primaries\": &#123; \"min\": 5, \"max\": 5, \"avg\": 5 &#125;, \"replication\": &#123; \"min\": 0, \"max\": 0, \"avg\": 0 &#125; &#125; &#125;, \"docs\": &#123; \"count\": 10, \"deleted\": 0 &#125;, \"store\": &#123; \"size\": \"16.2kb\", \"size_in_bytes\": 16684, \"throttle_time\": \"0s\", \"throttle_time_in_millis\": 0 &#125;, \"fielddata\": &#123; \"memory_size\": \"0b\", \"memory_size_in_bytes\": 0, \"evictions\": 0 &#125;, \"query_cache\": &#123; \"memory_size\": \"0b\", \"memory_size_in_bytes\": 0, \"total_count\": 0, \"hit_count\": 0, \"miss_count\": 0, \"cache_size\": 0, \"cache_count\": 0, \"evictions\": 0 &#125;, \"completion\": &#123; \"size\": \"0b\", \"size_in_bytes\": 0 &#125;, \"segments\": &#123; \"count\": 4, \"memory\": \"8.6kb\", \"memory_in_bytes\": 8898, \"terms_memory\": \"6.3kb\", \"terms_memory_in_bytes\": 6522, \"stored_fields_memory\": \"1.2kb\", \"stored_fields_memory_in_bytes\": 1248, \"term_vectors_memory\": \"0b\", \"term_vectors_memory_in_bytes\": 0, \"norms_memory\": \"384b\", \"norms_memory_in_bytes\": 384, \"doc_values_memory\": \"744b\", \"doc_values_memory_in_bytes\": 744, \"index_writer_memory\": \"0b\", \"index_writer_memory_in_bytes\": 0, \"version_map_memory\": \"0b\", \"version_map_memory_in_bytes\": 0, \"fixed_bit_set\": \"0b\", \"fixed_bit_set_memory_in_bytes\": 0, \"file_sizes\": &#123;&#125; &#125;, \"percolator\": &#123; \"num_queries\": 0 &#125; &#125;, \"nodes\": &#123; \"count\": &#123; \"total\": 1, \"data\": 1, \"coordinating_only\": 0, \"master\": 1, \"ingest\": 1 &#125;, \"versions\": [ \"5.6.3\" ], \"os\": &#123; \"available_processors\": 8, \"allocated_processors\": 8, \"names\": [ &#123; \"name\": \"Mac OS X\", \"count\": 1 &#125; ], \"mem\" : &#123; \"total\" : \"16gb\", \"total_in_bytes\" : 17179869184, \"free\" : \"78.1mb\", \"free_in_bytes\" : 81960960, \"used\" : \"15.9gb\", \"used_in_bytes\" : 17097908224, \"free_percent\" : 0, \"used_percent\" : 100 &#125; &#125;, \"process\": &#123; \"cpu\": &#123; \"percent\": 9 &#125;, \"open_file_descriptors\": &#123; \"min\": 268, \"max\": 268, \"avg\": 268 &#125; &#125;, \"jvm\": &#123; \"max_uptime\": \"13.7s\", \"max_uptime_in_millis\": 13737, \"versions\": [ &#123; \"version\": \"1.8.0_74\", \"vm_name\": \"Java HotSpot(TM) 64-Bit Server VM\", \"vm_version\": \"25.74-b02\", \"vm_vendor\": \"Oracle Corporation\", \"count\": 1 &#125; ], \"mem\": &#123; \"heap_used\": \"57.5mb\", \"heap_used_in_bytes\": 60312664, \"heap_max\": \"989.8mb\", \"heap_max_in_bytes\": 1037959168 &#125;, \"threads\": 90 &#125;, \"fs\": &#123; \"total\": \"200.6gb\", \"total_in_bytes\": 215429193728, \"free\": \"32.6gb\", \"free_in_bytes\": 35064553472, \"available\": \"32.4gb\", \"available_in_bytes\": 34802409472 &#125;, \"plugins\": [ &#123; \"name\": \"analysis-icu\", \"version\": \"5.6.3\", \"description\": \"The ICU Analysis plugin integrates Lucene ICU module into elasticsearch, adding ICU relates analysis components.\", \"classname\": \"org.elasticsearch.plugin.analysis.icu.AnalysisICUPlugin\", \"has_native_controller\": false &#125;, &#123; \"name\": \"ingest-geoip\", \"version\": \"5.6.3\", \"description\": \"Ingest processor that uses looksup geo data based on ip adresses using the Maxmind geo database\", \"classname\": \"org.elasticsearch.ingest.geoip.IngestGeoIpPlugin\", \"has_native_controller\": false &#125;, &#123; \"name\": \"ingest-user-agent\", \"version\": \"5.6.3\", \"description\": \"Ingest processor that extracts information from a user agent\", \"classname\": \"org.elasticsearch.ingest.useragent.IngestUserAgentPlugin\", \"has_native_controller\": false &#125; ] &#125;&#125; 内存使用和 GC 指标在运行 Elasticsearch 时，内存是您要密切监控的关键资源之一。 Elasticsearch 和 Lucene 以两种方式利用节点上的所有可用 RAM：JVM heap 和文件系统缓存。 Elasticsearch 运行在Java虚拟机（JVM）中，这意味着JVM垃圾回收的持续时间和频率将成为其他重要的监控领域。 上面返回的 JSON监控的指标有我个人觉得有这些： nodes.successful nodes.failed nodes.total nodes.mem.used_percent nodes.process.cpu.percent nodes.jvm.mem.heap_used 可以看到 JSON 文件是很复杂的，如果从这复杂的 JSON 中获取到对应的指标（key）的值呢，这里请看文章 ：JsonPath —— JSON 解析神器 最后这里主要讲下 ES 集群的一些监控信息，有些监控指标是个人觉得需要监控的，但是具体情况还是得看需求了。下篇文章主要讲节点的监控信息。转载请注明地址：http://www.54tianzhisheng.cn/2017/10/15/ElasticSearch-cluster-health-metrics/ 参考资料1、How to monitor Elasticsearch performance 2、ElasticSearch 性能监控 3、cluster-health 4、cluster-stats 相关阅读1、Elasticsearch 默认分词器和中分分词器之间的比较及使用方法 2、全文搜索引擎 Elasticsearch 集群搭建入门教程","tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"http://yoursite.com/tags/ElasticSearch/"}]},{"title":"Centos7 搭建最新 Nexus3 Maven 私服","date":"2017-10-13T17:37:00.733Z","path":"2017/10/14/Nexus3-Maven/","text":"Maven 介绍Apache Maven 是一个创新的软件项目管理和综合工具。Maven 提供了一个基于项目对象模型（POM）文件的新概念来管理项目的构建，可以从一个中心资料片管理项目构建，报告和文件。Maven 最强大的功能就是能够自动下载项目依赖库。Maven 提供了开发人员构建一个完整的生命周期框架。开发团队可以自动完成项目的基础工具建设，Maven 使用标准的目录结构和默认构建生命周期。在多个开发团队环境时，Maven 可以设置按标准在非常短的时间里完成配置工作。由于大部分项目的设置都很简单，并且可重复使用，Maven 让开发人员的工作更轻松，同时创建报表，检查，构建和测试自动化设置。Maven 项目的结构和内容在一个 XML 文件中声明，pom.xml 项目对象模型（POM），这是整个 Maven 系统的基本单元。 Maven 提供了开发人员的方式来管理：1）Builds2）Documentation3）Reporting4）Dependencies5）SCMs6）Releases7）Distribution8）mailing list概括地说，Maven 简化和标准化项目建设过程。处理编译，分配，文档，团队协作和其他任务的无缝连接。Maven 增加可重用性并负责建立相关的任务。Maven 最初设计，是以简化 Jakarta Turbine 项目的建设。在几个项目，每个项目包含了不同的 Ant 构建文件。 JAR 检查到 CVS。Apache 组织开发 Maven 可以建立多个项目，发布项目信息，项目部署，在几个项目中 JAR 文件提供团队合作和帮助。 Maven 主要目标是提供给开发人员：1）项目是可重复使用，易维护，更容易理解的一个综合模型。2）插件或交互的工具，这种声明性的模式。 私服介绍私服是指私有服务器，是架设在局域网的一种特殊的远程仓库，目的是代理远程仓库及部署第三方构建。有了私服之后，当 Maven 需要下载构件时，直接请求私服，私服上存在则下载到本地仓库；否则，私服请求外部的远程仓库，将构件下载到私服，再提供给本地仓库下载。 Nexus 介绍Nexus 是一个强大的 Maven 仓库管理器，它极大地简化了本地内部仓库的维护和外部仓库的访问。如果使用了公共的 Maven 仓库服务器，可以从 Maven 中央仓库下载所需要的构件（Artifact），但这通常不是一个好的做法。正常做法是在本地架设一个 Maven 仓库服务器，即利用 Nexus 私服可以只在一个地方就能够完全控制访问和部署在你所维护仓库中的每个 Artifact。Nexus 在代理远程仓库的同时维护本地仓库，以降低中央仓库的负荷, 节省外网带宽和时间，Nexus 私服就可以满足这样的需要。Nexus 是一套 “开箱即用” 的系统不需要数据库，它使用文件系统加 Lucene 来组织数据。Nexus 使用 ExtJS 来开发界面，利用 Restlet 来提供完整的 REST APIs，通过 m2eclipse 与 Eclipse 集成使用。Nexus 支持 WebDAV 与 LDAP 安全身份认证。Nexus 还提供了强大的仓库管理功能，构件搜索功能，它基于 REST，友好的 UI 是一个 extjs 的 REST 客户端，它占用较少的内存，基于简单文件系统而非数据库。 为什么要构建 Nexus 私服？如果没有 Nexus 私服，我们所需的所有构件都需要通过 maven 的中央仓库和第三方的 Maven 仓库下载到本地，而一个团队中的所有人都重复的从 maven 仓库下载构件无疑加大了仓库的负载和浪费了外网带宽，如果网速慢的话，还会影响项目的进程。很多情况下项目的开发都是在内网进行的，连接不到 maven 仓库怎么办呢？开发的公共构件怎么让其它项目使用？这个时候我们不得不为自己的团队搭建属于自己的 maven 私服，这样既节省了网络带宽也会加速项目搭建的进程，当然前提条件就是你的私服中拥有项目所需的所有构件。 总之，在本地构建 nexus 私服的好处有：1）加速构建；2）节省带宽；3）节省中央 maven 仓库的带宽；4）稳定（应付一旦中央服务器出问题的情况）；5）控制和审计；6）能够部署第三方构件；7）可以建立本地内部仓库；8）可以建立公共仓库这些优点使得 Nexus 日趋成为最流行的 Maven 仓库管理器。 1. 安装 jdk1.8关于 jdk1.8 的安装, 在这里就不做赘述了 2. 安装 maven关于 maven 的安装, 本文在这里就不详细写了 3. 安装 nexus31. 下载 nexus-3.6.0-02-unix.tar.gz官网链接地址：https://www.sonatype.com/download-oss-sonatype 下载 linux 最新版本，直接下载速度可能很慢，建议用迅雷下载会快很多的。 2. 解压1tar -zxvf nexus-3.6.0-02-unix.tar.gz -C /usr/local/ 3. 启动 nexus312cd /usr/local/nexus-3.6.0-02/bin/./nexus run &amp; 稍等一会 (首次启动会比较慢), 当出现以下日志的时候表示启动成功! 12345-------------------------------------------------Started Sonatype Nexus OSS 3.6.0-02------------------------------------------------- 4. 开启远程访问端口关闭防火墙，并开启远程访问端口 8081 123vim /etc/sysconfig/iptables添加：-A INPUT -p tcp -m state --state NEW -m tcp --dport 8081 -j ACCEPT 5. 测试 123nexus3默认端口是:8081nexus3默认账号是:adminnexus3默认密码是:admin123 6. 设置开机自启动123ln -s /usr/local/nexus-3.6.0-02/bin/nexus /etc/init.d/nexus3chkconfig --add nexus3chkconfig nexus3 on 7. 修改 nexus3 的运行用户为 root1vim nexus.rc 12//设置run_as_user=&quot;root&quot; 8. 修改 nexus3 启动时要使用的 jdk 版本1vim nexus 第 14 行: 1INSTALL4J_JAVA_HOME_OVERRIDE=/usr/local/java/jdk1.8.0_144 9. 修改 nexus3 默认端口 (可选)12cd /usr/local/nexus-3.6.0-02/etc/vim nexus-default.properties 默认端口: 8081 1application-port=8081 10. 修改 nexus3 数据以及相关日志的存储位置 (可选)：12[root@MiWiFi-R3-srv bin]# cd /usr/local/nexus-3.6.0-02/bin/[root@MiWiFi-R3-srv bin]# vim nexus.vmoptions 123-XX:LogFile=./sonatype-work/nexus3/log/jvm.log-Dkaraf.data=./sonatype-work/nexus3-Djava.io.tmpdir=./sonatype-work/nexus3/tmp 出现上面 5 中的测试页面，说明配置 nexus 成功！ 点击右上角 “Log in”， 输入默认用户名 (admin) 和默认密码（admin123）登录 至此, nexus3_maven 的私服就搭建完成了!!! 可以点击上面的 “设置” 图标，在 “设置” 里可以添加用户、角色，对接 LDAP 等的设置，如下： 可以在 “管理” 里查看 nexus 的系统信息 注意：1.component name 的一些说明： 1）maven-central：maven 中央库，默认从 https://repo1.maven.org/maven2 / 拉取 jar 2）maven-releases：私库发行版 jar 3）maven-snapshots：私库快照（调试版本）jar 4）maven-public：仓库分组，把上面三个仓库组合在一起对外提供服务，在本地 maven 基础配置 settings.xml 中使用。 2.Nexus 默认的仓库类型有以下四种： 1）group(仓库组类型)：又叫组仓库，用于方便开发人员自己设定的仓库； 2）hosted(宿主类型)：内部项目的发布仓库（内部开发人员，发布上去存放的仓库）； 3）proxy(代理类型)：从远程中央仓库中寻找数据的仓库（可以点击对应的仓库的 Configuration 页签下 Remote Storage Location 属性的值即被代理的远程仓库的路径）； 4）virtual(虚拟类型)：虚拟仓库（这个基本用不到，重点关注上面三个仓库的使用）； 3.Policy(策略): 表示该仓库为发布 (Release) 版本仓库还是快照 (Snapshot) 版本仓库； 4.Public Repositories 下的仓库 1）3rd party: 无法从公共仓库获得的第三方发布版本的构件仓库，即第三方依赖的仓库，这个数据通常是由内部人员自行下载之后发布上去； 2）Apache Snapshots: 用了代理 ApacheMaven 仓库快照版本的构件仓库 3）Central: 用来代理 maven 中央仓库中发布版本构件的仓库 4）Central M1 shadow: 用于提供中央仓库中 M1 格式的发布版本的构件镜像仓库 5）Codehaus Snapshots: 用来代理 CodehausMaven 仓库的快照版本构件的仓库 6）Releases: 内部的模块中 release 模块的发布仓库，用来部署管理内部的发布版本构件的宿主类型仓库；release 是发布版本； 7）Snapshots: 发布内部的 SNAPSHOT 模块的仓库，用来部署管理内部的快照版本构件的宿主类型仓库；snapshots 是快照版本，也就是不稳定版本所以自定义构建的仓库组代理仓库的顺序为：Releases，Snapshots，3rd party，Central。也可以使用 oschina 放到 Central 前面，下载包会更快。 5.Nexus 默认的端口是 8081，可以在 etc/nexus-default.properties 配置中修改。 6.Nexus 默认的用户名密码是 admin/admin123 当遇到奇怪问题时，重启 nexus，重启后 web 界面要 1 分钟左右后才能访问。 8.Nexus 的工作目录是 sonatype-work（路径一般在 nexus 同级目录下）12345678[root@master-node local]# pwd/usr/local[root@master-node local]# ls nexus/bin deploy etc lib LICENSE.txt NOTICE.txt public system[root@master-node local]# ls sonatype-work/nexus3[root@master-node local]# ls sonatype-work/nexus3/backup blobs cache db elasticsearch etc generated-bundles health-check instances keystores lock log orient port tmp Nexus 仓库分类的概念：1）Maven 可直接从宿主仓库下载构件, 也可以从代理仓库下载构件, 而代理仓库间接的从远程仓库下载并缓存构件2）为了方便, Maven 可以从仓库组下载构件, 而仓库组并没有时间的内容 (下图中用虚线表示, 它会转向包含的宿主仓库或者代理仓库获得实际构件的内容). Nexus 的 web 界面功能介绍1.Browse Server Content 1.1 Search这个就是类似 Maven 仓库上的搜索功能，就是从私服上查找是否有哪些包。注意：1）在 Search 这级是支持模糊搜索的，如图所示： 2）如果进入具体的目录，好像不支持模糊搜索，如图所示： 1.2 Browse 1）Assets这是能看到所有的资源，包含 Jar，已经对 Jar 的一些描述信息。2）Components这里只能看到 Jar 包。 2.Server Adminstration And configuration看到这个选项的前提是要进行登录的，如上面已经介绍登陆方法，右上角点击 “Sign In” 的登录按钮，输入 admin/admin123, 登录成功之后，即可看到此功能，如图所示： 2.1 Blob Stores文件存储的地方，创建一个目录的话，对应文件系统的一个目录，如图所示： 2.2 Repositories 1）Proxy这里就是代理的意思，代理中央 Maven 仓库，当 PC 访问中央库的时候，先通过 Proxy 下载到 Nexus 仓库，然后再从 Nexus 仓库下载到 PC 本地。这样的优势只要其中一个人从中央库下来了，以后大家都是从 Nexus 私服上进行下来，私服一般部署在内网，这样大大节约的宽带。创建 Proxy 的具体步骤1 点击 “Create Repositories” 按钮 2 选择要创建的类型 3 填写详细信息Name：就是为代理起个名字Remote Storage: 代理的地址，Maven 的地址为: https://repo1.maven.org/maven2/Blob Store: 选择代理下载包的存放路径 2）HostedHosted 是宿主机的意思，就是怎么把第三方的 Jar 放到私服上。Hosted 有三种方式，Releases、SNAPSHOT、MixedReleases: 一般是已经发布的 Jar 包Snapshot: 未发布的版本Mixed：混合的Hosted 的创建和 Proxy 是一致的，具体步骤和上面基本一致。如下： 注意事项：Deployment Pollcy: 需要把策略改成 “Allow redeploy”。 3）Group能把两个仓库合成一个仓库来使用，目前没使用过，所以没做详细的研究。 2.3 Security这里主要是用户、角色、权限的配置（上面已经提到了在这里添加用户和角色等） 2.4 Support包含日志及数据分析。 2.5 System主要是邮件服务器，调度的设置地方这部分主要讲怎么和 Maven 做集成, 集成的方式主要分以下种情况：代理中央仓库、Snapshot 包的管理、Release 包的管理、第三方 Jar 上传到 Nexus 上。 代理中央仓库只要在 PMO 文件中配置私服的地址（比如 http://192.168.1.14:8081）即可，配置如下： 12345678910111213&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;maven-central&lt;/id&gt; &lt;name&gt;maven-central&lt;/name&gt; &lt;url&gt;http://192.168.1.14:8081/repository/maven-central/&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;/repository&gt;&lt;/repositories&gt; Snapshot 包的管理1）修改 Maven 的 settings.xml 文件，加入认证机制 12345&lt;servers&gt; &lt;server&gt;&lt;id&gt;nexus&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt;&lt;/server&gt; 2）修改工程的 Pom 文件 123456789101112&lt;distributionManagement&gt; &lt;snapshotRepository&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;name&gt;Nexus Snapshot&lt;/name&gt; &lt;url&gt;http://192.168.1.14:8081/repository/maven-snapshots/&lt;/url&gt; &lt;/snapshotRepository&gt; &lt;site&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;name&gt;Nexus Sites&lt;/name&gt; &lt;url&gt;dav:http://192.168.1.14:8081/repository/maven-snapshots/&lt;/url&gt; &lt;/site&gt;&lt;/distributionManagement&gt; 注意事项: 上面修改的 Pom 文件如截图中的名字要跟 / usr/local/maven/conf/settings.xml 文件中的名字一定要对应上。 3）上传到 Nexus 上 1– 项目编译成的 jar 是 Snapshot(POM 文件的头部) 1234&lt;groupId&gt;com.zhisheng&lt;/groupId&gt;&lt;artifactId&gt;test-nexus&lt;/artifactId&gt;&lt;version&gt;1.0.0-SHAPSHOT&lt;/version&gt;&lt;packaging&gt;jar&lt;/packaging&gt; 2– 使用 mvn deploy 命令运行即可（运行结果在此略过） 3– 因为 Snapshot 是快照版本，默认他每次会把 Jar 加一个时间戳，做为历史备份版本。 Releases 包的管理1）与 Snapshot 大同小异，只是上传到私服上的 Jar 包不会自动带时间戳2）与 Snapshot 配置不同的地方，就是工程的 PMO 文件，加入 repository 配置 1234567&lt;distributionManagement&gt; &lt;repository&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;name&gt;Nexus Snapshot&lt;/name&gt; &lt;url&gt;http://192.168.1.14:8081/repository/maven-releases/&lt;/url&gt; &lt;/repository&gt;&lt;/distributionManagement&gt; 3）打包的时候需要把 Snapshot 去掉 1234&lt;groupId&gt;com.zhisheng&lt;/groupId&gt;&lt;artifactId&gt;test-nexus&lt;/artifactId&gt;&lt;version&gt;1.0.0&lt;/version&gt;&lt;packaging&gt;jar&lt;/packaging&gt; | 第三方 Jar 上传到 Nexus[root@master-node src]# mvn deploy:deploy-file -DgroupId=org.jasig.cas.client -DartifactId=cas-client-core -Dversion=3.1.3 -Dpackag注意事项：-DrepositoryId=nexus 对应的就是 Maven 中 settings.xml 的认证配的名字。 最后搭建的时候是参考网上博客，写篇完整的博客再回馈给网上。转载请注明地址：http://www.54tianzhisheng.cn/2017/10/14/Nexus3-Maven/","tags":[{"name":"Maven","slug":"Maven","permalink":"http://yoursite.com/tags/Maven/"}]},{"title":"JsonPath —— JSON 解析神器","date":"2017-10-13T15:59:12.727Z","path":"2017/10/13/JsonPath/","text":"真乃神器也，再复杂的 Json 都能给你解析出来，非常方便的获取 JSON 的内容，很强大！语法简介 JsonPath 描述 $ 根节点 @ 当前节点 .or[] 子节点 .. 选择所有符合条件的节点 * 所有节点 [] 迭代器标示，如数组下标 [,] 支持迭代器中做多选 [start:end:step] 数组切片运算符 ?() 支持过滤操作 () 支持表达式计算 JSON 值： 1234567891011121314151617181920&#123; \"store\": &#123; \"book\": [ &#123; \"category\": \"reference\", \"author\": \"Nigel Rees\", \"title\": \"Sayings of the Century\", \"price\": 8.95 &#125;, &#123; \"category\": \"fiction\", \"author\": \"Evelyn Waugh\", \"title\": \"Sword of Honour\", \"price\": 12.99, \"isbn\": \"0-553-21311-3\" &#125; ], \"bicycle\": &#123; \"color\": \"red\", \"price\": 19.95 &#125; &#125;&#125; 导包：import com.jayway.jsonpath.JsonPath 解析代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344//输出book[0]的author值String author = JsonPath.read(json, \"$.store.book[0].author\");System.out.println(\"author\\t\"+author);//输出全部author的值，使用Iterator迭代List&lt;String&gt; authors = JsonPath.read(json, \"$.store.book[*].author\");System.out.println(\"authors\\t\"+authors);//输出book[*]中category == 'reference'的bookList&lt;Object&gt; books = JsonPath.read(json, \"$.store.book[?(@.category == 'reference')]\");System.out.println(\"books\\t\"+books);//输出book[*]中category == 'reference'的book或者List&lt;Object&gt; books2 = JsonPath.read(json, \"$.store.book[?(@.category == 'reference' || @.price&gt;10)]\");System.out.println(\"books2\\t\"+books2);//输出book[*]中category == 'reference'的book的authorList&lt;Object&gt; books1 = JsonPath.read(json, \"$.store.book[?(@.category == 'reference')].author\");System.out.println(\"books1\\t\"+books1);//输出book[*]中price&gt;10的bookList&lt;Object&gt; b1 = JsonPath.read(json, \"$.store.book[?(@.price&gt;10)]\");System.out.println(\"b1\"+b1);//输出book[*]中含有isbn元素的bookList&lt;Object&gt; b2 = JsonPath.read(json, \"$.store.book[?(@.isbn)]\");System.out.println(\"b2\"+b2);//输出该json中所有price的值List&lt;Double&gt; prices = JsonPath.read(json, \"$..price\");System.out.println(\"prices\"+prices);//输出该json中所有title的值List&lt;Double&gt; title = JsonPath.read(json, \"$..title\");System.out.println(\"title\"+title);//输出该json中book 0,1的值List&lt;Double&gt; book01 = JsonPath.read(json, \"$..book[0,1]\");System.out.println(\"book01\"+book01);/* //输出该json中book 0,1的值List&lt;Double&gt; book012 = JsonPath.read(json, \"$..book[-2:]\");System.out.println(\"book012\"+book012);*///可以提前编辑一个路径，并多次使用它JsonPath path = JsonPath.compile(\"$.store.book[*]\");List&lt;Object&gt; b3 = path.read(json);System.out.println(\"path\\t\"+path+\"\\n\"+b3); 用法比较简单，多使用几次就会使用了！文章主要参考网上！原谅很多天不跟博的我现在竟然这样水了这么一篇文章，哈哈！实在是忙！","tags":[{"name":"JSON","slug":"JSON","permalink":"http://yoursite.com/tags/JSON/"}]},{"title":"Google Guava 缓存实现接口的限流","date":"2017-09-23T07:30:59.463Z","path":"2017/09/23/Guava-limit/","text":"项目背景最近项目中需要进行接口保护，防止高并发的情况把系统搞崩，因此需要对一个查询接口进行限流，主要的目的就是限制单位时间内请求此查询的次数，例如 1000 次，来保护接口。参考了 开涛的博客聊聊高并发系统限流特技 ，学习了其中利用 Google Guava 缓存实现限流的技巧，在网上也查到了很多关于 Google Guava 缓存的博客，学到了好多，推荐一个博客文章：http://ifeve.com/google-guava-cachesexplained/, 关于 Google Guava 缓存的更多细节或者技术，这篇文章讲的很详细；这里我们并不是用缓存来优化查询，而是利用缓存，存储一个计数器，然后用这个计数器来实现限流。 效果实验1234567static LoadingCache&lt;Long, AtomicLong&gt; count = CacheBuilder.newBuilder().expireAfterWrite(1, TimeUnit.SECONDS).build(new CacheLoader&lt;Long, AtomicLong&gt;() &#123; @Override public AtomicLong load(Long o) throws Exception &#123; //System.out.println(\"Load call!\"); return new AtomicLong(0L); &#125; &#125;); 上面，我们通过 CacheBuilder 来新建一个 LoadingCache 缓存对象 count，然后设置其有效时间为 1 秒，即每 1 秒钟刷新一次；缓存中，key 为一个 long 型的时间戳类型，value 是一个计数器，使用原子性的 AtomicLong 保证自增和自减操作的原子性， 每次查询缓存时如果不能命中，即查询的时间戳不在缓存中，则重新加载缓存，执行 load 将当前的时间戳的计数值初始化为 0。这样对于每一秒的时间戳，能计算这一秒内执行的次数，从而达到限流的目的；这是要执行的一个 getCounter 方法： 123456public class Counter &#123; static int counter = 0; public static int getCounter() throws Exception&#123; return counter++; &#125;&#125; 现在我们创建多个线程来执行这个方法： 12345678910111213141516171819202122public class Test &#123; public static void main(String args[]) throws Exception &#123; for(int i = 0;i&lt;100;i++) &#123; new Thread()&#123; @Override public void run() &#123; try &#123; System.out.println(Counter.getCounter()); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125;.start(); &#125; &#125;&#125; 这样执行的话，执行结果很简单，就是很快地执行这个 for 循环，迅速打印 0 到 99 折 100 个数，不再贴出。这里的 for 循环执行 100 个进程时间是很快的，那么现在我们要限制每秒只能有 10 个线程来执行 getCounter() 方法，该怎么办呢，上面讲的限流方法就派上用场了： 12345678910111213141516171819202122public class Counter &#123; static LoadingCache&lt;Long, AtomicLong&gt; count = CacheBuilder.newBuilder().expireAfterWrite(1, TimeUnit.SECONDS).build(new CacheLoader&lt;Long, AtomicLong&gt;() &#123; @Override public AtomicLong load(Long o) throws Exception &#123; System.out.println(\"Load call!\"); return new AtomicLong(0L); &#125; &#125;); static long limits = 10; static int counter = 0; public static synchronized int getCounter() throws Exception&#123; while (true) &#123; //获取当前的时间戳作为key Long currentSeconds = System.currentTimeMillis() / 1000; if (count.get(currentSeconds).getAndIncrement() &gt; limits) &#123; continue; &#125; return counter++; &#125; &#125;&#125; 这样一来，就可以限制每秒的执行数了。对于每个线程，获取当前时间戳，如果当前时间 (当前这 1 秒) 内有超过 10 个线程正在执行，那么这个进程一直在这里循环，直到下一秒，或者更靠后的时间，重新加载，执行 load，将新的时间戳的计数值重新为 0。执行结果：每秒执行 11 个（因为从 0 开始），每一秒之后，load 方法会执行一次； 12345678910111213141516171819202122232425为了更加直观，我们可以让每个for循环sleep一段时间：public class Test &#123; public static void main(String args[]) throws Exception &#123; for(int i = 0;i&lt;100;i++) &#123; new Thread()&#123; @Override public void run() &#123; try &#123; System.out.println(Counter.getCounter()); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125;.start(); Thread.sleep(100); &#125; &#125;&#125; 在上述这样的情况下，一个线程如果遇到当前时间正在执行的线程超过 limit 值就会一直在 while 循环，这样会浪费大量的资源，我们在做限流的时候，如果出现这种情况，可以不进行 while 循环，而是直接抛出异常或者返回，来拒绝这次执行（查询），这样便可以节省资源。 最后本篇文章地址： http://www.54tianzhisheng.cn/2017/09/23/Guava-limit/","tags":[{"name":"Guava","slug":"Guava","permalink":"http://yoursite.com/tags/Guava/"}]},{"title":"面试过阿里等互联网大公司，我知道了这些套路","date":"2017-09-16T17:28:43.398Z","path":"2017/09/17/Interview-summary/","text":"前面感谢一波因为看到掘金在做秋招求职征文大赛，赞助商也有牛客网，自己前段时间也稍微写了篇博客总结我的大学生活，那些年我看过的书 —— 致敬我的大学生活 —— Say Good Bye ！ 博客中稍微简单的介绍了下自己的求职，重点是推荐了下我自己看过的那些书籍，对我帮助真的很大。 如今借这么个机会，回馈掘金和牛客网，想想自己这一年在掘金也写过不少文章，从 0 个粉丝到如今被 11047 人（截止写此篇文章时）关注，有点小激动，竟然这么多粉，也不知道真正活跃的用户有多少。不管怎样，这一年在掘金还是收获很多的，不仅可以阅读到很多大神的文章，学习新的知识，而且还遇到了好几个不错的哥们，如今平常也有和他们交流，比如 ：芋道源码 老哥人就很不错，在上海还和老哥见过面，吃过饭，平常对我帮助也很大，会推荐一些很有用的书籍给我看。欢迎大家关注他的博客：芋道源码的博客 ，里面有好几系列的源码分析博客文章呢。至于牛客网，我就更是老用户了，印象中好像是大一的时候注册的，那时有空的话就会去上面刷几道基础题，写写题解，坚持了好久了，如今早已是红名了。（其实是水出来的，哈哈）在牛客网遇到的大神也是超多，好多朋友几乎都是通过牛客网认识的，那时早的时候一起在一群讨论问题，别提那场面了，震惊，我等弱渣瑟瑟发抖。感谢叶神，左神，牛妹！ 说着说着，好像偏题了。 正式进入话题吧！ 正文开始本篇秋招求职征文主要分享如下几方面：招聘职位需求套路 、招聘面试的套路、简历撰写套路、简历投递套路 、找工作经历 、自己面试面经 、实习感悟、书籍推荐 、优秀网站推荐 、优秀博客推荐 、求职资料放送。 招聘职位需求套路摘举下几个公司的招聘需求：（from lagou） 1、Java开发校招生( 有赞 ) 职位诱惑：福利好待遇佳，技术氛围浓，有大牛带成长快职位描述： 有赞2018校招官方网申地址（请在官网投递，勿直接在Lagou上投递）：https://job.youzan.com/campus岗位职责 我们拥有世界级的 SaaS 电商解决方案，每天处理几百万订单、几亿条消息，并且量级不断攀升； 我们开放了有赞云，连接了数十万开发者，大大提升了 SaaS 对商家产生的价值； 我们正在新零售的潮流中激流勇进、开疆拓土，用产品技术撬动巨大的市场； 而你的工作，就是参与这些大流量系统的研发，哪怕提升1%的性能和稳定性都将是激动人心的时刻。 岗位要求 2018届本科及以上学历应届毕业生，计算机或者软件工程相关专业； 具备扎实的计算机基础知识，至少熟练使用一门主流开发语言； 积极参与开发实践，如果拥有引以为豪的项目经历则加分； 热衷数据结构与算法，如果一不小心在 ACM 赛场摘过金，夺过银则加分； 能在 Linux 上写任何脚本，比王者荣耀上手还快则加分； 快速学习新鲜事物，自我驱动追求卓越，积极应对问题和变化。 2、京东居家生活事业部-汽车用品招聘实习生（2018届） 职位诱惑：京东商城 职位描述：京东商城-汽车用品部门招聘实习生 我们需要这样的你： 2018届毕业生（本科或硕士均可） 学习能力强 担当、抗压、接受变化 能长期实习（优秀者有转正机会） 需要一个大的平台来展示和发挥自己的能力 你将收获： 重新认识快速成长的自己 一份世界500强的实习经历 一群优秀的伙伴 3、爱奇艺 Java 实习生 - 游戏事业部 要求：至少 6 个月以上每周三天以上实习。 本科以上学历，计算机、软件工程相关专业； 基础扎实，熟悉 Java 编程，熟悉 Spring、MyBatis 等框架优先； 熟悉 SQL 语句，熟练使用 MySQL 数据库； 良好的沟通、表达、协调能力，富有激情，学习能力强； 有 GitHub 账号或者技术博客优先； 热爱游戏行业优先。 这里随便找了三个，从招聘需求里看，好多公司目前招聘的话在招聘需求中并不怎么会写的很清楚，有的也不会说明要求的技术栈，这其实有时会对我们这种新人来说，有点不好的，这样的话我们就没有明确的目标去复习，还有就是一些加分项，其实也是有点帮助的。就比如有些招聘上面的说有优秀博客和 GitHub 者优先，这两点的话我们其实可以在大学慢慢积累出来的，对面试确实有帮助，我好些面试机会都是靠这两个的。还有套路就是，别光信他这招聘需求，进去面试可能就不问你这些方面的问题了，那些公司几乎都是这么个套路：面试造火箭，入职拧螺丝 ！ 进去公司之前可能需要你懂很多东西，但是进去的话还只是专门做一方面的东西。不管怎样，如果你有机会进去大公司的话（而且适合去），还是去大公司吧，出来大厂光环不少。 认真耐心地拧螺丝钉，说不定有机会去造大火箭——正规大公司的节奏。 短时间把螺丝拧出花，说不定有机会造小火箭——上升中创业公司的节奏。 招聘面试的套路参考：https://mp.weixin.qq.com/s/qRwDowetBkJqpeMeAZsIpA 一个在掘金上认识的老哥，在京东工作，写的不错，干脆分享下。大家可以去看他的博客，http://mindwind.me/ 当时我求职的时候通过作者博客也学到不少东西。 一次集中的扩招需求，有点像每年一度的晋升评审，都需要对大量的候选人进行定级评审，因为每一个新招聘的人员都会对其有一个定级的过程。 维度： 通用能力：考察其沟通表达、学习成长等 专业知识：考察其知识的掌握、深度、广度等 专业能力：考察其技能应用的能力和结果 工作业绩：考察其工作成果、产出、创新点等 价值观：考察其认知、理解、行为等 整个面试过程会包括下面几个部分： 自我介绍一开始的简短自我介绍，考察点在于对自我的总结、归纳和认知能力。观察其表达的逻辑性和清晰性，有个整体印象。 项目经历一般我不会专门问一些比较死的专业技术点之类的知识，都是套在候选人的项目经历和过往经验中穿插。通过其描述，来判断其掌握知识点的范围和深度，以及在实际的案例中如何运用这些知识与技能解决真正的问题的。 所以，不会有所谓的题库。每一个我决定面试的候选人，都是提前细读其简历，提炼场景和发掘需要问的问题，相当于面试前有个二三十分钟的备课过程，组织好面试时的交互过程与场景，以顺利达到我想要了解的点。 团队合作通常还会问候选人其所在团队中的角色，他们的工作模式、协作方式，并给出一些真实的场景化案例观察其应对的反应。评价一下关于他周围的同事、下属或领导，了解他在团队中的自我定位。这里的考察点是沟通协作方面的通用能力。 学习成长这个维度考察的关键点包括：成长潜力、职业生涯规划的清晰度。人与人之间成长速度的关键差距，我自己观察得出的结论在于：自驱力。而路径的清晰性，也是产生自驱的一个源动力，否则可能会感觉迷茫，而陷于困顿。 文化匹配这算是价值观的一部分吧。其实，这是最难考核的，我没有什么好方法，基本靠感觉。曾经有过好几次碰到经历和技能都不错的人，但总是感觉哪里不对，但又着急要人，就放进来了。但最终感觉是对的，合作很快就结束了，人也走了。 综合评价总结点评候选人的优势、劣势并进行技术定级，定级也没有绝对标准，而是相对的。我一般就是和周围觉得差不多级别的人的平均水准比较下，大概就会有一个技术级别的判断。 套路 招聘面试，其实是一个对人的筛选，而筛选的本质是匹配 —— 匹配人与职位。第一，你得非常清楚地理解，这个职位需要什么样属性的人。第二，确定你的候选人是否拥有这个职位要求的必须属性。那么，首先回答第一个问题，一般的职位需要什么样的属性？ 属性，又可以进一步拆解为三个层次。第一层次是「技能（Skills）」，技能是你习得的一种工具，就像程序员会用某种语言和框架来编写某类应用程序。第二层次是「能力（Abilities）」，能力是你运用工具的思考和行为方式，用同样的语言和框架编写同样程序的程序员能力可以差别很大。而第三层次是「价值观（Values）」，价值观是一个人根深蒂固的信念以及驱动行为的原因与动力所在。 简历撰写套路参考：https://mp.weixin.qq.com/s/3f8hGAQ-auLdkxkQ8XG3CQ 简历，是如此重要，它是获得一份满意工作的敲门砖，但不同的简历敲门的声响可不同。 但很多时候简历给人的感觉也似乎微不足道，因为没有人会真正细致的去读一份简历。而仅仅是快速的浏览一遍，就几乎同时对一个候选人形成了一种要么强烈，要么无感的印象。现实中的真实情况是，你的简历只有十几二十秒的时间窗口机会会被浏览到，然后就决定了能否进入下一步。 要让面试官看了你的简历后：知道你做过什么？看看技能、经历与岗位需求的匹配度，然后再问问你是谁？你通过简历散发出来的味道是什么感觉，我愿意和这样的人一起共事么？ 一份简历的最少必要内容包括： 个人信息 姓名 年龄 手机 邮箱 教育经历 博士（硕士、本科） 有多个全部写出来，最高学历写在上面 工作经历（最匹配职位需求的，挑选出来的 TOP3 的项目） 项目1 项目背景上下文（场景、问题） 你在其中的角色（职责、发挥的作用、结果度量） 与此项经历有关的知识与技能（技术栈） 项目2 项目3 附加信息 博客：持续有内容，不碎碎念 开源：GitHub 持续 commit 社区：有一定专业影响力的 书籍：用心写的 演讲：行业大会级别的 专利：凑数的就算了 论文：学术界比较有影响力的 爱好：真正的兴趣点 对于我们学生，缺乏工作经历，那就写写独特的学习或实习经历。同学们大家都共有的经历就不要随便写上去凑数了。对于学生，看重的是通用能力，学习能力，适应能力以及对工作的态度和热情。如果没有区分度高的经历，那么有作品也是很好的。比如将你的做的网站部署出来，把地址写在简历上。 关于技术栈部分的技术术语，很多程序员不太注意。比如，把 Java 写成 java 或 JAVA，Java 已是一个专有品牌名词，大小写要完全符合，这一点和 iOS 类似（i 小写，OS 大写）。另外，像 HTML，CSS 则全部大写，因为这是多个单词的缩写。一些小小的细节就能读出你的专业性和散发出来的味道。最后，技术术语不是罗列得多就好，不是真正熟练的技能，不要轻易写进简历。因为这将给你自己挖坑。你可以将你自己擅长的或者很熟的知识点写进去，有时想着重就加粗或者打个括号，这样可以挖坑给面试官，让他去问你熟悉的（前提要确保你真的能讲清楚，我试过这个方法很有效的）。 然后就是简历格式了，最好是 PDF 了，Word 在不同的电脑上的打开效果可能不一样，格式可能会变，况且有些人的电脑不一定装了 Word，不过我喜欢用 Markdown 写简历，简洁，适合程序员，然后把 Markdown 转换成 PDF 出来。 简历投递套路内推 有内推通道尽量走内推通道，不知道方便多少，而且成功几率也很大！找熟人，找学长学姐吧！牛客网讨论区很多内推帖子，可以去找找。不过今年的好多公司的内推通道都不咋管用了，套路越来越多了。记得去年好多公司内推都是免笔试，直接进入面试阶段，今年直接变成内推免简历筛选，进入笔试。因为现在的内推越来越不靠谱，直接面试的话，会增加公司的面试成本，干脆笔试再筛选一部分人。 拉勾网 拉勾上还是算不错的。 Boss 直聘 虽说前段时间出现了程序员找工作进入传销最后导致死亡的惨事发生，但是里面总比智联招聘和前程无忧靠谱点。因为智联招聘和前程无忧几乎被广告党和培训机构给占领了。 脉脉 里面招应届生和实习生比较少，但是也有，可以试试。 总之，简历投递给公司之前，请确认下这家公司到底咋样，先去百度了解下，别被坑了，每个平台都有一些居心不良的广告党等着你上钩，千万别上当！！！ 找工作经历这段经历，算是自己很难忘记的经历吧。既辛酸既充实的日子！也很感谢自己在这段时间的系统复习，感觉把自己的基础知识再次聚集在一起了，自己的能力在这一段时间提升的也很快。后面有机会的话我也想写一系列的相关文章，为后来准备工作（面试）的同学提供一些自己的帮助。自己在找工作的这段时间面过的公司也有几家大厂，但是结果都不是很好，对我自己有很大的压力，当时心里真的感觉 ：“自己真的有这么差”，为什么一直被拒，当时很怀疑自己的能力，自己也有总结原因。一是面试的时候自己准备的还不够充分，虽说自己脑子里对这些基础有点印象，但是面试的时候自己稍紧张下就描述不怎么清楚了，导致面试官觉得你可能广度够了，深度还不够（这是阿里面试官电话面试说的）；二是自己的表达能力还是有所欠缺，不能够将自己所要表达的东西说出来，这可能我要在后面加强的地方；三是我的学校问题。在面了几家公司失败后，终于面了家公司要我了，我也确定在这家公司了。很幸运，刚出来，就有一个很好（很负责）的架构师带我，这周就给了我一个很牛逼的项目给我看，里面新东西很多，说吃透了这个项目，以后绝对可以拿出去吹逼（一脸正经.jpg）。找工作期间，自己也经常去收集一些博客，并把它保存下来，这样能够让自己下次更好的系统复习，还在牛客网整理了很多面经，每天看几篇面经，知道面试一般问什么问题，都有啥套路，其实你看多了面经就会发现，面试考的题目几乎都差不多，区别不是很大。目前我的找工作经历就简短的介绍到这里了，如果感兴趣的话，可以加群：528776268 期待志同道合的你。 自己面试面经亚信地址：http://www.54tianzhisheng.cn/2017/08/04/yaxin/ 1）自我介绍（说到一个亮点：长期坚持写博客，面试官觉得这个习惯很好，算加分项吧） 2）看到简历项目中用到 Solr，详细的问了下 Solr（自己介绍了下 Solr 的使用场景和建立索引等东西） 3）项目里面写了一个 “ 敏感词和 JS 标签过滤防 XSS 攻击”，面试官让我讲了下这个 XSS 攻击，并且是怎样实现的 4）项目里写了支持 Markdown，问是不是自己写的解析代码，（回答不是，自己引用的是 GitHub上的一个开源项目解析的） 5）想问我前端的知识，我回复到：自己偏后端开发，前端只是了解，然后面试官就不问了 6）问我考不考研？ 7）觉得杭州怎么样？是打算就呆在杭州还是把杭州作为一个跳板？ 8）有啥小目标？以后是打算继续技术方向，还是先技术后管理（还开玩笑的说：是不是赚他几个亿，当时我笑了笑） 9）有啥兴趣爱好？ 总结：面试问的问题不算多，主要是通过简历上项目所涉及的东西提问的，如果自己不太会的切记不要写上去。面试主要考察你回答问题来判断你的逻辑是否很清楚。 爱奇艺地址：http://www.54tianzhisheng.cn/2017/08/04/iqiyi/ 笔试（半个小时）题目：（记得一些） 1、重载重写的区别？ 2、转发和重定向的区别？ 3、画下 HashMap 的结构图？HashMap 、 HashTable 和 ConcurrentHashMap 的区别？ 4、statement 和 preparedstatement 区别？ 5、JSP 中一个 中取值与直接取值的区别？会有什么安全问题？ 6、实现一个线程安全的单例模式 7、一个写 sql 语句的题目 8、自己实现一个 List，（主要实现 add等常用方法） 9、Spring 中 IOC 和 AOP 的理解？ 10、两个对象的 hashcode 相同，是否对象相同？equal() 相同呢？ 11、@RequestBody 和 @ResponseBody 区别？ 12、JVM 一个错误，什么情况下会发生？ 13、常用的 Linux 命令？ 第一轮面试（80 分钟）1、自我介绍 2、介绍你最熟悉的一个项目 3、讲下这个 XSS 攻击 4、HashMap 的结构？HashMap 、 HashTable 和 ConcurrentHashMap 的区别？ 5、HashMap 中怎么解决冲突的？（要我详细讲下） 6、ConcurrentHashMap 和 HashTable 中线程安全的区别？为啥建议用 ConcurrentHashMap ？能把 ConcurrentHashMap 里面的实现详细的讲下吗？ 7、Session 和 Cookie 的区别？ 8、你项目中登录是怎样做的，用的 Cookie 和 Session？ 9、讲讲你对 Spring 中的 IOC 和 AOP 的理解？ 10、问了好几个注解的作用？ 11、statement 和 preparedstatement 区别？ 12、$ 和 # 的区别？以及这两个在哪些地方用？ 13、前面项目介绍了数据是爬虫爬取过来的，那你讲讲你的爬虫是多线程的吧？ 14、讲讲 Python 中的多线程和 Java 中的多线程区别？ 15、自己刚好前几天在看线程池，立马就把面试官带到我熟悉的线程池，和面试官讲了下 JDK 自带的四种线程池、ThreadPoolExecutor 类中的最重要的构造器里面的七个参数，然后再讲了下线程任务进入线程池和核心线程数、缓冲队列、最大线程数量比较。 16、线程同步，你了解哪几种方式？ 17、讲下 Synchronized？ 18、讲下 RecentLock 可重入锁？ 什么是可重入锁？为什么要设计可重入锁？ 19、讲下 Volatile 吧？他是怎样做到同步的？ 20、Volatile 为什么不支持原子性？举个例子 21、Atomic 怎么设计的？（没看过源码，当时回答错了，后来才发现里面全部用 final 修饰的属性和方法） 22、问几个前端的标签吧？（问了一个不会，直接说明我偏后端，前端只是了解，后面就不问了） 23、SpringBoot 的了解？ 24、Linux 常用命令？ 25、JVM 里的几个问题？ 26、事务的特性？ 27、隔离级别？ 28、网络状态码？以 2、3、4、5 开头的代表什么意思。 29、并发和并行的区别？ 30、你有什么问题想问我的？ 一面面完后面试官和说这份试卷是用来考 1~3 年开发工作经验的，让我准备一下，接下来的二面。 第二轮面试（半个小时）1、一上来就问怎么简历名字都没有，我指了简历第一行的我的名字，还特意大写了，然后就问学校是不是在上海，我回答在南昌（感觉被鄙视了一波，后面我在回答问题的时候面试官就一直在玩手机，估计后面对我的印象就不是很好了） 2、自我介绍 3、说一说数据库建表吧（从范式讲） 4、讲讲多态？（这个我答出来了，可是面试官竟然说不是这样吧，可能面试官没听请，后面还说我是不是平时写多态比较少，感觉这个也让面试官对我印象减分） 5、将两个数转换（不借助第三个参数） 6、手写个插入排序吧（写完了和面试官讲了下执行流程） 7、讲讲你对 Spring 中的 IOC 和 AOP 的理解？ 8、问了几个常用的 Linux 命令？ 9、也问到多线程？和一面一样把自己最近看的线程池也讲了一遍 10、学 Java 多久了？ 11、你有什么想问的？ 总结：面试题目大概就是这么多了，有些问题自己也忘记了，面试题目顺序不一定是按照上面所写的。再次感谢爱奇艺的第一面面试官了，要不是他帮忙内推的，我可能还没有机会收到面试机会。自己接到爱奇艺面试邀请电话是星期一晚上快7点中的，之后加了面试官微信约好了星期四面试的（时间准备较短，之前没系统的复习过）。星期四一大早（5点就起床了），然后就收拾了下，去等公交车，转了两次车，然后再做地铁去爱奇艺公司的，总共路上花费时间四个多小时。总的来说，这次面试准备的时间不是很充裕，所以准备的个人觉得不是很好，通过这次的面试，发现面试还是比较注重基础和深度的，我也知道了自己的一些弱处，还需要在哪里加强，面试技巧上也要掌握些。为后面的其他公司继续做好充足的准备。加油！！！ 阿里地址：http://www.54tianzhisheng.cn/2017/08/04/alibaba/ （菜鸟网络部门）（49 分钟） 2017.08.02 晚上9点21打电话过来，预约明天什么时候有空面试，约好第二天下午两点。 2017.08.03 下午两点10分打过来了。 说看了我的博客和 GitHub，觉得我学的还行，知识广度都还不错，但是还是要问问具体情况，为什么没看到你春招的记录，什么原因没投阿里？非得说一个原因，那就是：我自己太菜了，不敢投。 1、先自我介绍 2、什么是多态？哪里体现了多态的概念？ 3、HashMap 源码分析，把里面的东西问了个遍？最后问是不是线程安全？引出 ConcurrentHashMap 4、ConcurrentHashMap 源码分析 5、类加载，双亲委托机制 6、Java内存模型（一开始说的不是他想要的，主要想问我堆和栈的细节） 7、垃圾回收算法 8、线程池，自己之前看过，所以说的比较多，最后面试官说了句：看你对线程池了解还是很深了 9、事务的四种特性 10、什么是死锁？ 11、乐观锁和悲观锁的策略 12、高可用网站的设计（有什么技术实现） 13、低耦合高内聚 14、设计模式了解不？你用过哪几种，为什么用，单例模式帮我们做什么东西？有什么好处？ 15、你参与什么项目中成长比较快？学到了什么东西，以前是没有学过的？ 16、项目中遇到的最大困难是怎样的？是怎么解决的？ 17、智力题（两根不均匀的香，点一头烧完要一个小时，怎么确定15分钟） 18、你有什么问题想要问我的？ 19、问了菜鸟网络他们部门主要做什么？ 20、对我这次面试做个评价：看了你博客和 GitHub，知道你对学习的热情还是很高的，花了不少功夫，后面有通知！ 总结：面试总的来说，第一次电话面试，感觉好紧张，好多问题自己会点，但是其中的细节没弄清楚，自己准备的也不够充分。面试官很友好，看到我紧张，也安慰我说不要紧，不管以后出去面试啥的，不需要紧张，公司问的问题可能很广，你只需要把你知道的说出来就行，不会的直接说不会就行。之前一直不敢投阿里，因为自己准备的完全不够充分，但是在朋友磊哥的帮助下，还是试了下，不管结果怎么样，经历过总比没有的好。 后面说有通知，结果并没有，只看到官网的投递按钮变灰了。在掘金上一个朋友（我隔壁学校的），当时看我挂了说要不要让他租一起的隔壁邻居再内推下淘宝，我想想还是算了，自己目前能力真的是有限，达不到进阿里的要求！不过还是要感谢那个哥们，人真的超级好，虽然我们未曾谋面，但是有机会的话，我一定会请你吃饭的。 哔哩哔哩首先直接根据简历项目开问，自我介绍都没有。 1、登录从前端到后端整个过程描述一遍？越详细越好，说到密码加密，网络传输，后台验证用户名和密码，Cookie 设置等。具体问我密码加密是前台还是后台加密，说了在后台加密？面试官说，那你做这个项目有什么意思？密码传输都是明文的，默认 HTTP 传递是明文传输，当时被面试官带进前台加密还是后台加密的沟里去了，没想到用 HTTPS ，后来后来的路上查了些资料才知道的，面试过程中他很想我说前台加密，但是前台加密算法那代码就摆在那里，很容易就给破解了吧，也没给点提示说 HTTPS，我只好投降 2、写一个查询的 sql 语句 3、线程同步的方法？Synchronized、Volatile、（面试官好像觉得 Volatile 不可以做到同步，我和他说了半天的 Volatile 原理 ，他竟然不认同，我开始怀疑他的实力了）、ThreadLocal、Atomic。 说到这些了，我当时竟然没把他带进我我给他挖的坑里去（线程池，之前好好研究过呢，可惜了） 4、Spring IOC 和 AOP 的理解？叫我写 AOP 的代码，我没写 5、JDK 动态代理和 Cglib 代理区别？ 5、你觉得项目里面你觉得哪些技术比较好？我指了两个，然后他也没有问下去。 6、解释下 XSS 攻击 7、Spring 和 SpringBoot 的区别？ 8、JVM 垃圾回收算法？分代中为什么要分三层？ 9、OOM 是什么？什么情况会发生？ 10、你觉得你有啥优点？ 然后就叫我等一会，一会有人事来通知我，结果过了一会人事叫我可以回去等通知了。 总结：到公司的时候已经一点多钟了，面试直接在一个很多人的地方（吃饭的地方）直接面的，周围还有人再吃饭，场景有点尴尬，面试过程感觉很随意，想到什么问题就问什么，完全没有衔接，问到的有些地方感觉面试官自己都不清楚，还怀疑我所说的，另外就是问题比较刁钻，总体技术也就那样吧！ 目前所在公司当时是我现在的老大（架构师）面的，先是电话面试过一次，问的问题也比较难，不过最后还是觉得我基础还是不错的。最后叫我去公司面试下，来到公司面试问的问题那就更难了，几乎好多都回答不出来，但是简单的说了下思路，最后再叫主任面试了下，问的问题就很简单了，最后就是 HR 面了，主要说了下工资问题和什么时候能报道！这几次面试的问题当时由于时间比较紧，也没去整理，现在也记不清楚了！目前自己已经工作了快一个月了，给的项目也完全是新东西，对我的挑战也很大，有时自己也确实不怎么知道，不过我老大很耐心的教我，对我也很不错，这也是我打算留在这里的原因，碰到个好老大不易！必须好好珍惜！ 实习感悟进公司是架构运维组中的 Java 实习开发，目前实习已经快一个月了，说实话，实习后才发现一天真的很忙，写下这篇征文也是在周末整理大晚上写的。刚进公司就给了一个 Consul 的服务发现与注册和健康检查的项目，里面涉及的东西有 Consul、Docker、Nginx、Lua、ElasticSearch 还有几个很轻量级的框架，对我来说几乎都是新东西，确实需要时间去了解，再优化和改里面的 bug 的过程中，幸好我老大和我理了几次思路，才让我对整个项目有所进展，后续继续是在优化这项目（可能以后这个项目的所有东西都是我来做）。在上海，住的地方离公司有一定的距离，上班几乎要一个小时，每天花在上班路上的时间很多，这也导致我每天感觉很忙。公司上班时间比较弹性，无打卡，虽说公司不加班，但是每天自己都不怎么会按点下班，自己也想在实习阶段多学点东西！这段时间也是最关键的时间，碰到个问题，要花好久时间才能解决，也有可能未必解决得了，有时觉得自己啥都不会，这么点东西都做不好，有点否定自己。这也确实是自己的技术知识栈缺乏，和自己学的 SSM、Spring Boot 这些都不相关，也不怎么写业务逻辑代码。所以感觉很痛苦，不像自己以前写的代码那样顺畅，当然可能是自己以前自己写的项目太 low 了。 看到掘金-凯伦征文中写到： 公司其实并不期望刚刚进来的你，能够创造多少价值。新人是要成长的，在成长期难免会遇到各种各样的小问题，这可能是大多数人的必经之路，因为你所看到的同事，他们都比你在工作领域待的时间更久，有更多的经验，可以把他们作为目标，但不要把他们作为现在自己的标准，那样会压力太大。 感觉这段话对我现在很受用！ 加油，好好挺过这个阶段，别轻易说放弃！ 书籍推荐大学，我不怎么喜欢玩游戏，自己也还算不怎么堕落吧，看了以下的一些书籍，算是对我后面写博客、找工作也有很大的帮助。如果你是大神，请忽略，如果你还是还在大学，和我一样不想把时间浪费在游戏上，可以看看我推荐的一些书籍，有想讨论的请在评论下留下你的评论或者加上面给的群号。 Java1、《Java 核心技术》卷一 、卷二 两本书，算是入门比较好的书籍了 2、《疯狂 Java 讲义》 很厚的一本书，里面的内容也是很注重基础了 3、《Java 并发编程的艺术》—— 方腾飞 、魏鹏、程晓明著 方腾飞 是并发编程网的创始人，里面的文章确实还不错，可以多看看里面的文章，收获绝对很大。 4、《 Java多线程编程核心技术》—— 高洪岩著 这本书也算是入门多线程编程的不错书籍，我之前还写了一篇读书笔记呢，《Java 多线程编程核心技术》学习笔记及总结 , 大家如果不想看书的可以去看我的笔记。 5、《Java 并发编程实战》 这本书讲的有点难懂啊，不过确实也是一本很好的书，以上三本书籍如果都弄懂了，我觉得你并发编程这块可能大概就 OK 了，然后再去看看线程池的源码，了解下线程池，我觉得那就更棒了。不想看的话，请看我的博客：Java 线程池艺术探索 我个人觉得还是写的很不错，那些大厂面试也几乎都会问线程池的东西，然后大概内容也就是我这博客写的 6、《Effective Java》中文版 第二版 算是 Java 的进阶书籍了，面试好多问题也是从这出来的 7、《深入理解 Java 虚拟机——JVM高级特性与最佳实践》第二版 这算是国内讲 JVM 最清楚的书了吧，目前还是只看了一遍，后面继续啃，大厂面试几乎也是都会考 JVM 的，阿里面 JVM 特别多，想进阿里的同学请一定要买这本书去看。 8、《深入分析Java Web技术内幕 修订版》许令波著 里面知识很广，每一章都是一个不同的知识，可见作者的优秀，不愧是阿里大神。 9、《大型网站系统与 Java 中间件实践》—— 曽宪杰 著 作者是前淘宝技术总监，见证了淘宝网的发展，里面的讲的内容也是很好，看完能让自己也站在高处去思考问题。 10、《大型网站技术架构 —— 核心原理与案例分析》 —— 李智慧 著 最好和上面那本书籍一起看，效果更好，两本看完了，提升思想的高度！ 11、《疯狂Java.突破程序员基本功的16课》 李刚 著 书中很注重 Java 的一些细节，讲的很深入，但是书中的错别字特多，可以看看我的读书笔记：《疯狂 Java 突破程序员基本功的 16 课》读书笔记 12、《Spring 实战》 Spring 入门书籍 13、《Spring 揭秘》—— 王福强 著 这本书别提多牛了，出版时期为 2009 年，豆瓣评分为 9.0 分，写的是真棒！把 Spring 的 IOC 和 AOP 特性写的很清楚，把 Spring 的来龙去脉讲的很全。墙裂推荐这本书籍，如果你想看 Spring，作者很牛，资深架构师，很有幸和作者有过一次交流，当时因为自己的一篇博客 Pyspider框架 —— Python爬虫实战之爬取 V2EX 网站帖子，竟然找到我想叫我去实习，可惜了，当时差点就跟着他混了。作者还有一本书 《Spring Boot 揭秘》。 14、《Spring 技术内幕》—— 深入解析 Spring 架构与设计原理 讲解 Spring 源码，深入了内部机制，个人觉得还是不错的。 15、Spring 官方的英文文档 这个别提了，很好，能看英文尽量看英文 16、《跟开涛学 Spring 3》 《跟开涛学 Spring MVC》 京东大神，膜 17、《看透springMvc源代码分析与实践》 算是把 Spring MVC 源码讲的很好的了 见我的笔记： 1、通过源码详解 Servlet 2 、看透 Spring MVC 源代码分析与实践 —— 网站基础知识 3 、看透 Spring MVC 源代码分析与实践 —— 俯视 Spring MVC 4 、看透 Spring MVC 源代码分析与实践 —— Spring MVC 组件分析 18、《Spring Boot 实战》 19、Spring Boot 官方 Reference Guide 网上好多写 SpringBoot 的博客，几乎和这个差不多。 20、《JavaEE开发的颠覆者: Spring Boot实战》 21、MyBatis 当然是官方的文档最好了，而且还是中文的。 自己也写过几篇文章，帮助过很多人入门，传送门： 1、通过项目逐步深入了解Mybatis（一）/) 2、通过项目逐步深入了解Mybatis（二）/) 3、通过项目逐步深入了解Mybatis（三）/) 4、通过项目逐步深入了解Mybatis（四）/) 22、《深入理解 Java 内存模型》—— 程晓明 著 我觉得每个 Java 程序员都应该了解下 Java 的内存模型，该书籍我看的是电子版的，不多，但是讲的却很清楚，把重排序、顺序一致性、Volatile、锁、final等写的很清楚。 Linux《鸟哥的Linux私房菜 基础学习篇(第三版) 》 鸟哥的Linux私房菜：服务器架设篇(第3版) 鸟哥的书 计算机网络《计算机网络第六版——谢希仁 编》 《计算机网络自顶向下方法》 计算机系统《代码揭秘：从C／C.的角度探秘计算机系统 —— 左飞》 《深入理解计算机系统》 《计算机科学导论_佛罗赞》 数据库《高性能MySQL》 《Mysql技术内幕InnoDB存储引擎》 Python这门语言语法很简单，上手快，不过我目前好久没用了，都忘得差不多了。当时是看的廖雪峰的 Python 博客 自己也用 Python 做爬虫写过几篇博客，不过有些是在前人的基础上写的。感谢那些栽树的人！ 工具Git ： 廖雪峰的 Git 教程 IDEA：IntelliJ IDEA 简体中文专题教程 Maven：《Maven实战》 其他《如何高效学习-斯科特杨》 教你怎样高效学习的 《软技能：代码之外的生存指南》 程序员除了写代码，还得懂点其他的软技能。 《提问的智慧“中文版”》 《How-To-Ask-Questions-The-Smart-Way》 作为程序员的你，一定要学会咋提问，不然别人都不想鸟你。 优秀网站推荐1、GitHub 别和我说不知道 2、InfoQ 文章很不错 3、CSDN 经常看博客专家的博客，里面大牛很多，传送门：zhisheng 4、知乎 多关注些大牛，看他们吹逼 5、掘金 自己也在上面写专栏，粉丝已经超过一万了，传送门 ：zhisheng 6、并发编程网 前面已经介绍 7、developerworks 上面的博客也很好 8、博客园 里面应该大牛也很多，不过自己没在上面写过博客 9、微信公众号 关注了很多人，有些人的文章确实很好，平时也经常看。 10、牛客网 刷笔试题不错的地方，里面大牛超多，怀念叶神和左神讲课的时候，还有很有爱的牛妹。 优秀博客推荐廖雪峰 Git 和 Python 入门文章就是从他博客看的 阮一峰的网络日志 酷壳-陈皓 RednaxelaFX R大，牛逼的不得了 江南白衣 老司机 stormzhang 人称帅逼张，微信公众号写的不错 你假笨 阿里搞 JVM 的，很厉害 占小狼 泥瓦匠BYSocket 崔庆才 写了好多 Python 爬虫相关的文章 纯洁的微笑 SpringBoot 系列不错，其他的文章自己看了感觉是自己喜欢的那种文笔 程序猿DD 周立 芋道源码的博客 好多系列的源码分析 zhisheng 这个是我不要脸，竟然把自己博客地址的写上去了 求职资料放送自己在准备找工作那段时间，系统的复习了下大学所学的知识，期间在网上参考了很多不错的博客，并收集下来了，个人觉得还是不错的，因为这是包含了自己的心血，所以一直没怎么送出来，只给过我的几个同学，还有就是一些学习视频和实战项目视频。借着这次征文的机会，我想送给那些有缘人，希望你或许是那种在求职道路上正在艰难走着的人；或许是大一大二的学弟学妹们却想好好学习，有个奋斗的目标，不堪在大学堕落的；或许是工作一两年后感觉基础还比较薄弱的。要资料的时候期望你能简单的介绍下自己，期望你！联系方式请看文章最下面。 最后送一句话，越努力，越幸运，祝早日成为大神！ 这些地方可以找到我： blog: http://www.54tianzhisheng.cn/ GitHub: https://github.com/zhisheng17 QQ 群：528776268","tags":[{"name":"面经","slug":"面经","permalink":"http://yoursite.com/tags/面经/"}]},{"title":"Linux 下 lua 开发环境安装及安装 luafilesystem","date":"2017-09-15T15:17:26.540Z","path":"2017/09/15/linux-lua-lfs-install/","text":"火云邪神语录：天下武功，无坚不破，唯快不破！Nginx 的看家本领就是速度，Lua 的拿手好戏亦是速度，这两者的结合在速度上无疑有基因上的优势。 最近一直再折腾这个，干脆就稍微整理下。以防后面继续跳坑！ 安装： 1.先安装 lua 的相关依赖安装 C 开发环境由于 gcc 包需要依赖 binutils 和 cpp 包，另外 make 包也是在编译中常用的，所以一共需要 9 个包来完成安装，因此我们只需要执行 9 条指令即可： 12345678910gcc：命令未找到（解决方法）yum install cppyum install binutilsyum install glibcyum install glibc-kernheadersyum install glibc-commonyum install glibc-develyum install gccyum install makeyum install readline-devel 2.安装 lua5.1.5下载地址：http://www.lua.org/ftp/ 1234567891011121314151617181920tar -zxvf lua-5.1.5.tar.gzcd lua-5.1.5vi Makefile设置 INSTALL_TOP= /usr/local/luamake linuxmake testmake installrm -rf /usr/bin/lualn -s /usr/local/lua/bin/lua /usr/bin/lualn -s /usr/local/lua/share/lua /usr/share/lua设置环境变量：vim /etc/profile添加：export LUA_HOME=/usr/local/luaexport PATH=$PATH:$LUA_HOME/bin环境变量生效：source /etc/profile 3、安装 luarocks是一个 Lua 包管理器，基于 Lua 语言开发，提供一个命令行的方式来管理 Lua 包依赖、安装第三方 Lua 包等。 地址： https://github.com/luarocks/luarocks 12345678910111213141516使用 luarocks-2.2.1 版本在我机器上没有问题，但是使用 luarocks-2.4.2 出现问题wget http://luarocks.org/releases/luarocks-2.2.1.tar.gztar -zxvf luarocks-2.2.1.tar.gzcd luarocks-2.2.1./configure --with-lua=/usr/local --with-lua-include=/usr/local/lua/include设置环境变量：export LUA_LUAROCKS_PATH=/usr/local/luarocks-2.2.1export PATH=$PATH:$LUA_LUAROCKS_PATHmake &amp; make install 4、安装 luafilesystem是一个用于 lua 进行文件访问的库，可以支持 lua 5.1 和 lua5.2，且是跨平台的，在为 lua 安装 lfs 之前需要先安装luarocks。因为自己的需求刚好需要这模块。 地址：https://github.com/keplerproject/luafilesystem 文档： http://keplerproject.github.io/luafilesystem/index.html 1luarocks install luafilesystem 5、测试测试 lua 是否安装成功 lua -v 结果： 1Lua 5.1.5 Copyright (C) 1994-2012 Lua.org, PUC-Rio 测试 luafilesystem 是否安装成功 a.lua 123456789local lfs = require&quot;lfs&quot;function Rreturn(filePath) local time = os.date(&quot;%a, %d %b %Y %X GMT&quot;, lfs.attributes(filePath).modification) --打印文件的修改时间 print(time)endRreturn(&quot;/opt/lua/a.txt&quot;) a.txt 123abc 运行： 1lua a.lua 结果： 1Tue, 12 Sep 2017 18:43:13 GMT 出现打印出时间的结果就意味着已经安装好了。 当然以上这是在 Linux 安装的， Windows 上的其实比这还简单了，但是安装 luafilesystem 的话需要自己去下载个 lfs.dll ，然后把这个放到 lua 的安装路径去。很简单的，这里就不细说了。 出现过的错误：123456789101112[root@n1 lua-5.1.5]# make linux testcd src &amp;&amp; make linuxmake[1]: Entering directory `/opt/lua-5.1.5/src&apos;make all MYCFLAGS=-DLUA_USE_LINUX MYLIBS=&quot;-Wl,-E -ldl -lreadline -lhistory -lncurses&quot;make[2]: Entering directory `/opt/lua-5.1.5/src&apos;gcc -O2 -Wall -DLUA_USE_LINUX -c -o lapi.o lapi.cmake[2]: gcc：命令未找到make[2]: *** [lapi.o] 错误 127make[2]: Leaving directory `/opt/lua-5.1.5/src&apos;make[1]: *** [linux] 错误 2make[1]: Leaving directory `/opt/lua-5.1.5/src&apos;make: *** [linux] 错误 2 原因：最开始的那些依赖没安装","tags":[{"name":"lua","slug":"lua","permalink":"http://yoursite.com/tags/lua/"}]},{"title":"全文搜索引擎 Elasticsearch 集群搭建入门教程","date":"2017-09-09T03:56:42.374Z","path":"2017/09/09/Elasticsearch-install/","text":"介绍ElasticSearch 是一个基于 Lucene 的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，基于 RESTful web 接口。Elasticsearch 是用 Java 开发的，并作为 Apache 许可条款下的开放源码发布，是当前流行的企业级搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。基百科、Stack Overflow、Github 都采用它。 本文从零开始，讲解如何使用 Elasticsearch 搭建自己的全文搜索引擎。每一步都有详细的说明，大家跟着做就能学会。 环境1、VMware 2、Centos 6.6 3、Elasticsearch 5.5.2 4、JDK 1.8 VMware 安装以及在 VMware 中安装 Centos 这个就不说了，环境配置直接默认就好，不过分配给机器的内存最好设置大点（建议 2G）， 使用 dhclient 命令来自动获取 IP 地址，查看获取的 IP 地址则使用命令 ip addr 或者 ifconfig ，则会看到网卡信息和 lo 卡信息。 给虚拟机额中的 linux 设置固定的 ip（因为后面发现每次机器重启后又要重新使用 dhclient 命令来自动获取 IP 地址） 1vim /etc/sysconfig/network-scripts/ifcfg-eth0 修改： 12onboot=yesbootproto=static 增加：（下面可设置可不设置） 123IPADDR=192.168.1.113 网卡IP地址GATEWAY=192.168.1.1NETMASK=255.255.255.0 设置好之后，把网络服务重启一下， service network restart 修改 ip 地址参考： http://jingyan.baidu.com/article/e4d08ffdd417660fd3f60d70.html 大环境都准备好了，下面开始安装步骤： 安装 JDK 1.8先卸载自带的 openjdk，查找 openjdk 1rpm -qa | grep java 卸载 openjdk 12yum -y remove java-1.7.0-openjdk-1.7.0.65-2.5.1.2.el65.x8664yum -y remove java-1.6.0-openjdk-1.6.0.0-11.1.13.4.el6.x86_64 解压 JDK 安装包： 附上jdk1.8的下载地址：http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html 解压完成后配置一下环境变量就 ok 1、在/usr/local/下创建Java文件夹 12cd /usr/local/ 进入目录mkdir java 新建java目录 2、文件夹创建完毕，把安装包拷贝到 Java 目录中，然后解压 jdk 到当前目录 12cp /usr/jdk-8u144-linux-x64.tar.gz /usr/local/java/ **注意匹配你自己的文件名** 拷贝到java目录tar -zxvf jdk-8u144-linux-x64.tar.gz 解压到当前目录（Java目录） 3、解压完之后，Java目录中会出现一个jdk1.8.0_144的目录，这就解压完成了。之后配置一下环境变量。编辑/etc/下的profile文件，配置环境变量 12345678vi /etc/profile 进入profile文件的编辑模式在最后边追加一下内容(**配置的时候一定要根据自己的目录情况而定哦！**) JAVA_HOME=/usr/local/java/jdk1.8.0_144 CLASSPATH=$JAVA_HOME/lib/ PATH=$PATH:$JAVA_HOME/bin export PATH JAVA_HOME CLASSPATH 之后保存并退出文件之后。 让文件生效：source /etc/profile 在控制台输入Java 和 Java -version 看有没有信息输出，如下： java -version 123java version &quot;1.8.0_144&quot; Java(TM) SE Runtime Environment (build 1.8.0_60-b27) Java HotSpot(TM) Client VM (build 25.60-b23, mixed mode) 能显示以上信息，就说明 JDK 安装成功啦 安装 Maven因为后面可能会用到 maven ，先装上这个。 1、下载 maven 1wget http://mirrors.hust.edu.cn/apache/maven/maven-3/3.2.5/binaries/apache-maven-3.2.5-bin.tar.gz 2、解压至 /usr/local 目录 1tar -zxvf apache-maven-3.2.5-bin.tar.gz 3、配置公司给的配置 替换成公司给的 setting.xml 文件，修改关于本地仓库的位置, 默认位置: ${user.home}/.m2/repository 4、配置环境变量etc/profile 最后添加以下两行 12export MAVEN_HOME=/usr/local/apache-maven-3.2.5export PATH=$&#123;PATH&#125;:$&#123;MAVEN_HOME&#125;/bin 5、测试 123[root@localhost ~]# mvn -vApache Maven 3.2.5 (12a6b3acb947671f09b81f49094c53f426d8cea1; 2014-12-14T09:29:23-08:00)Maven home: /usr/local/apache-maven-3.2.5 VMware 虚拟机里面的三台机器 IP 分别是： 123192.168.153.133192.168.153.134192.168.153.132 配置 hosts在 /etc/hosts下面编写：ip node 节点的名字（域名解析） 1vim /etc/hosts 新增： 123192.168.153.133 es1192.168.153.134 es2192.168.153.132 es3 设置 SSH 免密码登录安装expect命令 ： yum -y install expect 将 ssh_p2p.jar 随便解压到任何目录下： (这个 jar 包可以去网上下载) 1unzip ssh_p2p.zip 修改 resource 的 ip 值 1vim /ssh_p2p/deploy_data/resource （各个节点和账户名，密码，free代表相互都可以无密码登陆） 123456#设置为你每台虚拟机的ip地址，用户名，密码address=(&quot;192.168.153.133,root,123456,free&quot;&quot;192.168.153,134,root,123456,free&quot;&quot;192.168.153.132,root,123456,free&quot;) 修改 start.sh 的运行权限 1chmod u+x start.sh 运行 1./start.sh 测试： ssh ip地址 （测试是否可以登录） 安装 ElasticSearch下载地址： https://www.elastic.co/downloads/elasticsearch 123wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.5.2.tar.gzcd /usr/localtar -zxvf elasticsearch-5.5.2.tar.gz su tzs 切换到 tzs 用户下 ( 默认不支持 root 用户) sh /usr/local/elasticsearch/bin/elasticsearch -d 其中 -d 表示后台启动 在 vmware 上测试是否成功：curl http://localhost:9200/ 出现如上图这样的效果，就代表已经装好了。 elasticsearch 默认 restful-api 的端口是 9200 不支持 IP 地址，也就是说无法从主机访问虚拟机中的服务，只能在本机用 http://localhost:9200 来访问。如果需要改变，需要修改配置文件 /usr/local/elasticsearch/config/elasticsearch.yml 文件，加入以下两行： 12network.bind_host: 0.0.0.0network.publish_host: _nonloopback:ipv4 或去除 network.host 和 http.port 之前的注释，并将 network.host 的 IP 地址修改为本机外网 IP。然后重启，Elasticsearch 关闭方法（输入命令：ps -ef | grep elasticsearch ，找到进程，然后 kill 掉就行了。 如果外网还是不能访问，则有可能是防火墙设置导致的 ( 关闭防火墙：service iptables stop ) 修改配置文件：vim config/elasticsearch.yml cluster.name : my-app (集群的名字，名字相同的就是一个集群) node.name : es1 （节点的名字, 和前面配置的 hosts 中的 name 要一致） path.data: /data/elasticsearch/data （数据的路径。没有要创建（mkdir -p /data/elasticsearch/{data,logs}），并且给执行用户权限 chown tzs /data/elasticsearch/{data,logs} -R ）path.logs: /data/elasticsearch/logs （数据 log 信息的路径，同上）network.host: 0.0.0.0 //允许外网访问，也可以是自己的ip地址http.port: 9200 //访问的端口discovery.zen.ping.unicast.hosts: [“192.168.153.133”, “192.168.153.134”, “192.168.153.132”] //各个节点的ip地址 记得需要添加上：（这个是安装 head 插件要用的， 目前不需要）http.cors.enabled: truehttp.cors.allow-origin: “*” 最后在外部浏览器的效果如下图： 安装 IK 中文分词可以自己下载源码使用 maven 编译，当然如果怕麻烦可以直接下载编译好的 https://github.com/medcl/elasticsearch-analysis-ik/releases/tag/v5.5.2 注意下载对应的版本放在 plugins 目录下 解压 unzip elasticsearch-analysis-ik-5.5.2.zip 在 es 的 plugins 下新建 ik 目录 mkdir ik 将刚才解压的复制到ik目录下 cp -r elasticsearch/* ik 删除刚才解压后的 12rm -rf elasticsearchrm -rf elasticsearch-analysis-ik-5.5.2.zip IK 带有两个分词器ik_max_word ：会将文本做最细粒度的拆分；尽可能多的拆分出词语 ik_smart：会做最粗粒度的拆分；已被分出的词语将不会再次被其它词语占有 安装完 IK 中文分词器后（当然不止这种中文分词器，还有其他的，可以参考我的文章 Elasticsearch 默认分词器和中分分词器之间的比较及使用方法），测试区别如下： ik_max_wordcurl -XGET ‘http://192.168.153.134:9200/_analyze?pretty&amp;analyzer=ik_max_word‘ -d ‘联想是全球最大的笔记本厂商’ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667&#123; &quot;tokens&quot; : [ &#123; &quot;token&quot; : &quot;联想&quot;, &quot;start_offset&quot; : 0, &quot;end_offset&quot; : 2, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 0 &#125;, &#123; &quot;token&quot; : &quot;是&quot;, &quot;start_offset&quot; : 2, &quot;end_offset&quot; : 3, &quot;type&quot; : &quot;CN_CHAR&quot;, &quot;position&quot; : 1 &#125;, &#123; &quot;token&quot; : &quot;全球&quot;, &quot;start_offset&quot; : 3, &quot;end_offset&quot; : 5, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 2 &#125;, &#123; &quot;token&quot; : &quot;最大&quot;, &quot;start_offset&quot; : 5, &quot;end_offset&quot; : 7, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 3 &#125;, &#123; &quot;token&quot; : &quot;的&quot;, &quot;start_offset&quot; : 7, &quot;end_offset&quot; : 8, &quot;type&quot; : &quot;CN_CHAR&quot;, &quot;position&quot; : 4 &#125;, &#123; &quot;token&quot; : &quot;笔记本&quot;, &quot;start_offset&quot; : 8, &quot;end_offset&quot; : 11, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 5 &#125;, &#123; &quot;token&quot; : &quot;笔记&quot;, &quot;start_offset&quot; : 8, &quot;end_offset&quot; : 10, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 6 &#125;, &#123; &quot;token&quot; : &quot;本厂&quot;, &quot;start_offset&quot; : 10, &quot;end_offset&quot; : 12, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 7 &#125;, &#123; &quot;token&quot; : &quot;厂商&quot;, &quot;start_offset&quot; : 11, &quot;end_offset&quot; : 13, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 8 &#125; ]&#125; ik_smartcurl -XGET ‘http://localhost:9200/_analyze?pretty&amp;analyzer=ik_smart‘ -d ‘联想是全球最大的笔记本厂商’ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&#123; &quot;tokens&quot; : [ &#123; &quot;token&quot; : &quot;联想&quot;, &quot;start_offset&quot; : 0, &quot;end_offset&quot; : 2, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 0 &#125;, &#123; &quot;token&quot; : &quot;是&quot;, &quot;start_offset&quot; : 2, &quot;end_offset&quot; : 3, &quot;type&quot; : &quot;CN_CHAR&quot;, &quot;position&quot; : 1 &#125;, &#123; &quot;token&quot; : &quot;全球&quot;, &quot;start_offset&quot; : 3, &quot;end_offset&quot; : 5, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 2 &#125;, &#123; &quot;token&quot; : &quot;最大&quot;, &quot;start_offset&quot; : 5, &quot;end_offset&quot; : 7, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 3 &#125;, &#123; &quot;token&quot; : &quot;的&quot;, &quot;start_offset&quot; : 7, &quot;end_offset&quot; : 8, &quot;type&quot; : &quot;CN_CHAR&quot;, &quot;position&quot; : 4 &#125;, &#123; &quot;token&quot; : &quot;笔记本&quot;, &quot;start_offset&quot; : 8, &quot;end_offset&quot; : 11, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 5 &#125;, &#123; &quot;token&quot; : &quot;厂商&quot;, &quot;start_offset&quot; : 11, &quot;end_offset&quot; : 13, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 6 &#125; ]&#125; 安装 head 插件elasticsearch-head 是一个 elasticsearch 的集群管理工具，它是完全由 html5 编写的独立网页程序，你可以通过插件把它集成到 es。 效果如下图：（图片来自网络） 安装 git123yum remove gityum install gitgit clone git://github.com/mobz/elasticsearch-head.git 拉取 head 插件到本地，或者直接在 GitHub 下载 压缩包下来 安装nodejs先去官网下载 node-v8.4.0-linux-x64.tar.xz 12tar -Jxv -f node-v8.4.0-linux-x64.tar.xzmv node-v8.4.0-linux-x64 node 环境变量设置： 1vim /etc/profile 新增： 123export NODE_HOME=/opt/nodeexport PATH=$PATH:$NODE_HOME/binexport NODE_PATH=$NODE_HOME/lib/node_modules 使配置文件生效（这步很重要，自己要多注意这步） 1source /etc/profile 测试是否全局可用了： 1node -v 然后 12345mv elasticsearch-head headcd head/npm install -g grunt-clinpm installgrunt server 再 es 的配置文件中加： 12http.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot; 在浏览器打开 http://192.168.153.133:9100/ 就可以看到效果了， 遇到问题把坑都走了一遍，防止以后再次入坑，特此记录下来 1、ERROR Could not register mbeans java.security.AccessControlException: access denied (“javax.management.MBeanTrustPermission” “register”) 改变 elasticsearch 文件夹所有者到当前用户 sudo chown -R noroot:noroot elasticsearch 这是因为 elasticsearch 需要读写配置文件，我们需要给予 config 文件夹权限，上面新建了 elsearch 用户，elsearch 用户不具备读写权限，因此还是会报错，解决方法是切换到管理员账户，赋予权限即可： sudo -i chmod -R 775 config 2、[WARN ][o.e.b.ElasticsearchUncaughtExceptionHandler] [] uncaught exception in thread [main]org.elasticsearch.bootstrap.StartupException: java.lang.RuntimeException: can not run elasticsearch as root 原因是elasticsearch默认是不支持用root用户来启动的。 解决方案一：Des.insecure.allow.root=true 修改/usr/local/elasticsearch-2.4.0/bin/elasticsearch， 添加 ES_JAVA_OPTS=”-Des.insecure.allow.root=true” 或执行时添加： sh /usr/local/elasticsearch-2.4.0/bin/elasticsearch -d -Des.insecure.allow.root=true 注意：正式环境用root运行可能会有安全风险，不建议用root来跑。 解决方案二：添加专门的用户 1234useradd elasticchown -R elastic:elastic elasticsearch-2.4.0su elasticsh /usr/local/elasticsearch-2.4.0/bin/elasticsearch -d 3、UnsupportedOperationException: seccomp unavailable: requires kernel 3.5+ with CONFIG_SECCOMP and CONFIG_SECCOMP_FILTER compiled in 只是警告，使用新的linux版本，就不会出现此类问题了。 4、ERROR: [4] bootstrap checks failed[1]: max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536] 原因：无法创建本地文件问题,用户最大可创建文件数太小 解决方案：切换到 root 用户，编辑 limits.conf 配置文件， 添加类似如下内容： vim /etc/security/limits.conf 添加如下内容: 1234* soft nofile 65536* hard nofile 131072* soft nproc 2048* hard nproc 4096 [2]: max number of threads [1024] for user [tzs] is too low, increase to at least [2048] 原因：无法创建本地线程问题,用户最大可创建线程数太小 解决方案：切换到root用户，进入limits.d目录下，修改90-nproc.conf 配置文件。 vim /etc/security/limits.d/90-nproc.conf 找到如下内容： soft nproc 1024 修改为 soft nproc 2048 [3]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] 原因：最大虚拟内存太小 root用户执行命令： sysctl -w vm.max_map_count=262144 或者修改 /etc/sysctl.conf 文件，添加 “vm.max_map_count”设置设置后，可以使用$ sysctl -p [4]: system call filters failed to install; check the logs and fix your configuration or disable system call filters at your own risk 原因：Centos6不支持SecComp，而ES5.4.1默认bootstrap.system_call_filter为true进行检测，所以导致检测失败，失败后直接导致ES不能启动。详见 ：https://github.com/elastic/elasticsearch/issues/22899 解决方法：在elasticsearch.yml中新增配置bootstrap.system_call_filter，设为false，注意要在Memory下面:bootstrap.memory_lock: falsebootstrap.system_call_filter: false 5、 java.lang.IllegalArgumentException: property [elasticsearch.version] is missing for plugin [head] 再 es 的配置文件中加： 12http.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot; 最后整个搭建的过程全程自己手动安装，不易，如果安装很多台机器，是否可以写个脚本之类的自动搭建呢？可以去想想的。首发于：http://www.54tianzhisheng.cn/2017/09/09/Elasticsearch-install/ ，转载请注明出处，谢谢配合！","tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://yoursite.com/tags/Elasticsearch/"}]},{"title":"Elasticsearch 默认分词器和中分分词器之间的比较及使用方法","date":"2017-09-07T01:50:46.000Z","path":"2017/09/07/Elasticsearch-analyzers/","text":"介绍：ElasticSearch 是一个基于 Lucene 的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，基于 RESTful web 接口。Elasticsearch 是用 Java 开发的，并作为Apache许可条款下的开放源码发布，是当前流行的企业级搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。 Elasticsearch中，内置了很多分词器（analyzers）。下面来进行比较下系统默认分词器和常用的中文分词器之间的区别。 系统默认分词器：1、standard 分词器https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-standard-analyzer.html 如何使用：http://www.yiibai.com/lucene/lucene_standardanalyzer.html 英文的处理能力同于StopAnalyzer.支持中文采用的方法为单字切分。他会将词汇单元转换成小写形式，并去除停用词和标点符号。 12345/**StandardAnalyzer分析器*/public void standardAnalyzer(String msg)&#123; StandardAnalyzer analyzer = new StandardAnalyzer(Version.LUCENE_36); this.getTokens(analyzer, msg);&#125; 2、simple 分词器https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-simple-analyzer.html 如何使用: http://www.yiibai.com/lucene/lucene_simpleanalyzer.html 功能强于WhitespaceAnalyzer, 首先会通过非字母字符来分割文本信息，然后将词汇单元统一为小写形式。该分析器会去掉数字类型的字符。 12345/**SimpleAnalyzer分析器*/ public void simpleAnalyzer(String msg)&#123; SimpleAnalyzer analyzer = new SimpleAnalyzer(Version.LUCENE_36); this.getTokens(analyzer, msg); &#125; 3、Whitespace 分词器https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-whitespace-analyzer.html 如何使用：http://www.yiibai.com/lucene/lucene_whitespaceanalyzer.html 仅仅是去除空格，对字符没有lowcase化,不支持中文；并且不对生成的词汇单元进行其他的规范化处理。 12345/**WhitespaceAnalyzer分析器*/ public void whitespaceAnalyzer(String msg)&#123; WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer(Version.LUCENE_36); this.getTokens(analyzer, msg); &#125; 4、Stop 分词器https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-stop-analyzer.html 如何使用：http://www.yiibai.com/lucene/lucene_stopanalyzer.html StopAnalyzer的功能超越了SimpleAnalyzer，在SimpleAnalyzer的基础上增加了去除英文中的常用单词（如the，a等），也可以更加自己的需要设置常用单词；不支持中文 12345/**StopAnalyzer分析器*/ public void stopAnalyzer(String msg)&#123; StopAnalyzer analyzer = new StopAnalyzer(Version.LUCENE_36); this.getTokens(analyzer, msg); &#125; 5、keyword 分词器KeywordAnalyzer把整个输入作为一个单独词汇单元，方便特殊类型的文本进行索引和检索。针对邮政编码，地址等文本信息使用关键词分词器进行索引项建立非常方便。 6、pattern 分词器https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-pattern-analyzer.html 一个pattern类型的analyzer可以通过正则表达式将文本分成”terms”(经过token Filter 后得到的东西 )。接受如下设置: 一个 pattern analyzer 可以做如下的属性设置: lowercase terms是否是小写. 默认为 true 小写. pattern 正则表达式的pattern, 默认是 \\W+. flags 正则表达式的flags stopwords 一个用于初始化stop filter的需要stop 单词的列表.默认单词是空的列表 7、language 分词器https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-lang-analyzer.html 一个用于解析特殊语言文本的analyzer集合。（ arabic,armenian, basque, brazilian, bulgarian, catalan, cjk, czech, danish, dutch, english, finnish, french,galician, german, greek, hindi, hungarian, indonesian, irish, italian, latvian, lithuanian, norwegian,persian, portuguese, romanian, russian, sorani, spanish, swedish, turkish, thai.）可惜没有中文。不予考虑 8、snowball 分词器一个snowball类型的analyzer是由standard tokenizer和standard filter、lowercase filter、stop filter、snowball filter这四个filter构成的。 snowball analyzer 在Lucene中通常是不推荐使用的。 9、Custom 分词器是自定义的analyzer。允许多个零到多个tokenizer，零到多个 Char Filters. custom analyzer 的名字不能以 “_”开头. The following are settings that can be set for a custom analyzer type: Setting Description tokenizer 通用的或者注册的tokenizer. filter 通用的或者注册的token filters char_filter 通用的或者注册的 character filters position_increment_gap 距离查询时，最大允许查询的距离，默认是100 自定义的模板： 1234567891011121314151617181920212223242526index : analysis : analyzer : myAnalyzer2 : type : custom tokenizer : myTokenizer1 filter : [myTokenFilter1, myTokenFilter2] char_filter : [my_html] position_increment_gap: 256 tokenizer : myTokenizer1 : type : standard max_token_length : 900 filter : myTokenFilter1 : type : stop stopwords : [stop1, stop2, stop3, stop4] myTokenFilter2 : type : length min : 0 max : 2000 char_filter : my_html : type : html_strip escaped_tags : [xxx, yyy] read_ahead : 1024 10、fingerprint 分词器https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-fingerprint-analyzer.html 中文分词器：1、ik-analyzerhttps://github.com/wks/ik-analyzer IKAnalyzer是一个开源的，基于java语言开发的轻量级的中文分词工具包。 采用了特有的“正向迭代最细粒度切分算法“，支持细粒度和最大词长两种切分模式；具有83万字/秒（1600KB/S）的高速处理能力。 采用了多子处理器分析模式，支持：英文字母、数字、中文词汇等分词处理，兼容韩文、日文字符 优化的词典存储，更小的内存占用。支持用户词典扩展定义 针对Lucene全文检索优化的查询分析器IKQueryParser(作者吐血推荐)；引入简单搜索表达式，采用歧义分析算法优化查询关键字的搜索排列组合，能极大的提高Lucene检索的命中率。 Maven用法： 12345&lt;dependency&gt; &lt;groupId&gt;org.wltea.ik-analyzer&lt;/groupId&gt; &lt;artifactId&gt;ik-analyzer&lt;/artifactId&gt; &lt;version&gt;3.2.8&lt;/version&gt;&lt;/dependency&gt; 在IK Analyzer加入Maven Central Repository之前，你需要手动安装，安装到本地的repository，或者上传到自己的Maven repository服务器上。 要安装到本地Maven repository，使用如下命令，将自动编译，打包并安装：mvn install -Dmaven.test.skip=true Elasticsearch添加中文分词安装IK分词插件https://github.com/medcl/elasticsearch-analysis-ik 进入elasticsearch-analysis-ik-master 更多安装请参考博客： 1、为elastic添加中文分词 ： http://blog.csdn.net/dingzfang/article/details/42776693 2、如何在Elasticsearch中安装中文分词器(IK+pinyin) ：http://www.cnblogs.com/xing901022/p/5910139.html 3、Elasticsearch 中文分词器 IK 配置和使用 ： http://blog.csdn.net/jam00/article/details/52983056 ik 带有两个分词器ik_max_word ：会将文本做最细粒度的拆分；尽可能多的拆分出词语 ik_smart：会做最粗粒度的拆分；已被分出的词语将不会再次被其它词语占有 区别： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133# ik_max_wordcurl -XGET &apos;http://localhost:9200/_analyze?pretty&amp;analyzer=ik_max_word&apos; -d &apos;联想是全球最大的笔记本厂商&apos;#返回&#123; &quot;tokens&quot; : [ &#123; &quot;token&quot; : &quot;联想&quot;, &quot;start_offset&quot; : 0, &quot;end_offset&quot; : 2, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 0 &#125;, &#123; &quot;token&quot; : &quot;是&quot;, &quot;start_offset&quot; : 2, &quot;end_offset&quot; : 3, &quot;type&quot; : &quot;CN_CHAR&quot;, &quot;position&quot; : 1 &#125;, &#123; &quot;token&quot; : &quot;全球&quot;, &quot;start_offset&quot; : 3, &quot;end_offset&quot; : 5, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 2 &#125;, &#123; &quot;token&quot; : &quot;最大&quot;, &quot;start_offset&quot; : 5, &quot;end_offset&quot; : 7, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 3 &#125;, &#123; &quot;token&quot; : &quot;的&quot;, &quot;start_offset&quot; : 7, &quot;end_offset&quot; : 8, &quot;type&quot; : &quot;CN_CHAR&quot;, &quot;position&quot; : 4 &#125;, &#123; &quot;token&quot; : &quot;笔记本&quot;, &quot;start_offset&quot; : 8, &quot;end_offset&quot; : 11, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 5 &#125;, &#123; &quot;token&quot; : &quot;笔记&quot;, &quot;start_offset&quot; : 8, &quot;end_offset&quot; : 10, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 6 &#125;, &#123; &quot;token&quot; : &quot;本厂&quot;, &quot;start_offset&quot; : 10, &quot;end_offset&quot; : 12, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 7 &#125;, &#123; &quot;token&quot; : &quot;厂商&quot;, &quot;start_offset&quot; : 11, &quot;end_offset&quot; : 13, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 8 &#125; ]&#125;# ik_smartcurl -XGET &apos;http://localhost:9200/_analyze?pretty&amp;analyzer=ik_smart&apos; -d &apos;联想是全球最大的笔记本厂商&apos;# 返回&#123; &quot;tokens&quot; : [ &#123; &quot;token&quot; : &quot;联想&quot;, &quot;start_offset&quot; : 0, &quot;end_offset&quot; : 2, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 0 &#125;, &#123; &quot;token&quot; : &quot;是&quot;, &quot;start_offset&quot; : 2, &quot;end_offset&quot; : 3, &quot;type&quot; : &quot;CN_CHAR&quot;, &quot;position&quot; : 1 &#125;, &#123; &quot;token&quot; : &quot;全球&quot;, &quot;start_offset&quot; : 3, &quot;end_offset&quot; : 5, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 2 &#125;, &#123; &quot;token&quot; : &quot;最大&quot;, &quot;start_offset&quot; : 5, &quot;end_offset&quot; : 7, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 3 &#125;, &#123; &quot;token&quot; : &quot;的&quot;, &quot;start_offset&quot; : 7, &quot;end_offset&quot; : 8, &quot;type&quot; : &quot;CN_CHAR&quot;, &quot;position&quot; : 4 &#125;, &#123; &quot;token&quot; : &quot;笔记本&quot;, &quot;start_offset&quot; : 8, &quot;end_offset&quot; : 11, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 5 &#125;, &#123; &quot;token&quot; : &quot;厂商&quot;, &quot;start_offset&quot; : 11, &quot;end_offset&quot; : 13, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 6 &#125; ]&#125; 下面我们来创建一个索引，使用 ik创建一个名叫 iktest 的索引，设置它的分析器用 ik ，分词器用 ik_max_word，并创建一个 article 的类型，里面有一个 subject 的字段，指定其使用 ik_max_word 分词器 12345678910111213141516171819202122curl -XPUT &apos;http://localhost:9200/iktest?pretty&apos; -d &apos;&#123; &quot;settings&quot; : &#123; &quot;analysis&quot; : &#123; &quot;analyzer&quot; : &#123; &quot;ik&quot; : &#123; &quot;tokenizer&quot; : &quot;ik_max_word&quot; &#125; &#125; &#125; &#125;, &quot;mappings&quot; : &#123; &quot;article&quot; : &#123; &quot;dynamic&quot; : true, &quot;properties&quot; : &#123; &quot;subject&quot; : &#123; &quot;type&quot; : &quot;string&quot;, &quot;analyzer&quot; : &quot;ik_max_word&quot; &#125; &#125; &#125; &#125;&#125;&apos; 批量添加几条数据，这里我指定元数据 _id 方便查看，subject 内容为我随便找的几条新闻的标题 123456789101112curl -XPOST http://localhost:9200/iktest/article/_bulk?pretty -d &apos;&#123; &quot;index&quot; : &#123; &quot;_id&quot; : &quot;1&quot; &#125; &#125;&#123;&quot;subject&quot; : &quot;＂闺蜜＂崔顺实被韩检方传唤 韩总统府促彻查真相&quot; &#125;&#123; &quot;index&quot; : &#123; &quot;_id&quot; : &quot;2&quot; &#125; &#125;&#123;&quot;subject&quot; : &quot;韩举行＂护国训练＂ 青瓦台:决不许国家安全出问题&quot; &#125;&#123; &quot;index&quot; : &#123; &quot;_id&quot; : &quot;3&quot; &#125; &#125;&#123;&quot;subject&quot; : &quot;媒体称FBI已经取得搜查令 检视希拉里电邮&quot; &#125;&#123; &quot;index&quot; : &#123; &quot;_id&quot; : &quot;4&quot; &#125; &#125;&#123;&quot;subject&quot; : &quot;村上春树获安徒生奖 演讲中谈及欧洲排外问题&quot; &#125;&#123; &quot;index&quot; : &#123; &quot;_id&quot; : &quot;5&quot; &#125; &#125;&#123;&quot;subject&quot; : &quot;希拉里团队炮轰FBI 参院民主党领袖批其“违法”&quot; &#125;&apos; 查询 “希拉里和韩国” 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071curl -XPOST http://localhost:9200/iktest/article/_search?pretty -d&apos;&#123; &quot;query&quot; : &#123; &quot;match&quot; : &#123; &quot;subject&quot; : &quot;希拉里和韩国&quot; &#125;&#125;, &quot;highlight&quot; : &#123; &quot;pre_tags&quot; : [&quot;&lt;font color=&apos;red&apos;&gt;&quot;], &quot;post_tags&quot; : [&quot;&lt;/font&gt;&quot;], &quot;fields&quot; : &#123; &quot;subject&quot; : &#123;&#125; &#125; &#125;&#125;&apos;#返回&#123; &quot;took&quot; : 113, &quot;timed_out&quot; : false, &quot;_shards&quot; : &#123; &quot;total&quot; : 5, &quot;successful&quot; : 5, &quot;failed&quot; : 0 &#125;, &quot;hits&quot; : &#123; &quot;total&quot; : 4, &quot;max_score&quot; : 0.034062363, &quot;hits&quot; : [ &#123; &quot;_index&quot; : &quot;iktest&quot;, &quot;_type&quot; : &quot;article&quot;, &quot;_id&quot; : &quot;2&quot;, &quot;_score&quot; : 0.034062363, &quot;_source&quot; : &#123; &quot;subject&quot; : &quot;韩举行＂护国训练＂ 青瓦台:决不许国家安全出问题&quot; &#125;, &quot;highlight&quot; : &#123; &quot;subject&quot; : [ &quot;&lt;font color=red&gt;韩&lt;/font&gt;举行＂护&lt;font color=red&gt;国&lt;/font&gt;训练＂ 青瓦台:决不许国家安全出问题&quot; ] &#125; &#125;, &#123; &quot;_index&quot; : &quot;iktest&quot;, &quot;_type&quot; : &quot;article&quot;, &quot;_id&quot; : &quot;3&quot;, &quot;_score&quot; : 0.0076681254, &quot;_source&quot; : &#123; &quot;subject&quot; : &quot;媒体称FBI已经取得搜查令 检视希拉里电邮&quot; &#125;, &quot;highlight&quot; : &#123; &quot;subject&quot; : [ &quot;媒体称FBI已经取得搜查令 检视&lt;font color=red&gt;希拉里&lt;/font&gt;电邮&quot; ] &#125; &#125;, &#123; &quot;_index&quot; : &quot;iktest&quot;, &quot;_type&quot; : &quot;article&quot;, &quot;_id&quot; : &quot;5&quot;, &quot;_score&quot; : 0.006709609, &quot;_source&quot; : &#123; &quot;subject&quot; : &quot;希拉里团队炮轰FBI 参院民主党领袖批其“违法”&quot; &#125;, &quot;highlight&quot; : &#123; &quot;subject&quot; : [ &quot;&lt;font color=red&gt;希拉里&lt;/font&gt;团队炮轰FBI 参院民主党领袖批其“违法”&quot; ] &#125; &#125;, &#123; &quot;_index&quot; : &quot;iktest&quot;, &quot;_type&quot; : &quot;article&quot;, &quot;_id&quot; : &quot;1&quot;, &quot;_score&quot; : 0.0021509775, &quot;_source&quot; : &#123; &quot;subject&quot; : &quot;＂闺蜜＂崔顺实被韩检方传唤 韩总统府促彻查真相&quot; &#125;, &quot;highlight&quot; : &#123; &quot;subject&quot; : [ &quot;＂闺蜜＂崔顺实被&lt;font color=red&gt;韩&lt;/font&gt;检方传唤 &lt;font color=red&gt;韩&lt;/font&gt;总统府促彻查真相&quot; ] &#125; &#125; ] &#125;&#125; 这里用了高亮属性 highlight，直接显示到 html 中，被匹配到的字或词将以红色突出显示。若要用过滤搜索，直接将 match 改为 term 即可 热词更新配置网络词语日新月异，如何让新出的网络热词（或特定的词语）实时的更新到我们的搜索当中呢 先用 ik 测试一下 12345678910111213141516171819202122232425262728293031323334353637curl -XGET &apos;http://localhost:9200/_analyze?pretty&amp;analyzer=ik_max_word&apos; -d &apos;成龙原名陈港生&apos;#返回&#123; &quot;tokens&quot; : [ &#123; &quot;token&quot; : &quot;成龙&quot;, &quot;start_offset&quot; : 1, &quot;end_offset&quot; : 3, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 0 &#125;, &#123; &quot;token&quot; : &quot;原名&quot;, &quot;start_offset&quot; : 3, &quot;end_offset&quot; : 5, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 1 &#125;, &#123; &quot;token&quot; : &quot;陈&quot;, &quot;start_offset&quot; : 5, &quot;end_offset&quot; : 6, &quot;type&quot; : &quot;CN_CHAR&quot;, &quot;position&quot; : 2 &#125;, &#123; &quot;token&quot; : &quot;港&quot;, &quot;start_offset&quot; : 6, &quot;end_offset&quot; : 7, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 3 &#125;, &#123; &quot;token&quot; : &quot;生&quot;, &quot;start_offset&quot; : 7, &quot;end_offset&quot; : 8, &quot;type&quot; : &quot;CN_CHAR&quot;, &quot;position&quot; : 4 &#125; ]&#125; ik 的主词典中没有”陈港生” 这个词，所以被拆分了。现在我们来配置一下 修改 IK 的配置文件 ：ES 目录/plugins/ik/config/ik/IKAnalyzer.cfg.xml 修改如下： 12345678910111213&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE properties SYSTEM &quot;http://java.sun.com/dtd/properties.dtd&quot;&gt;&lt;properties&gt; &lt;comment&gt;IK Analyzer 扩展配置&lt;/comment&gt; &lt;!--用户可以在这里配置自己的扩展字典 --&gt; &lt;entry key=&quot;ext_dict&quot;&gt;custom/mydict.dic;custom/single_word_low_freq.dic&lt;/entry&gt; &lt;!--用户可以在这里配置自己的扩展停止词字典--&gt; &lt;entry key=&quot;ext_stopwords&quot;&gt;custom/ext_stopword.dic&lt;/entry&gt; &lt;!--用户可以在这里配置远程扩展字典 --&gt; &lt;entry key=&quot;remote_ext_dict&quot;&gt;http://192.168.1.136/hotWords.php&lt;/entry&gt; &lt;!--用户可以在这里配置远程扩展停止词字典--&gt; &lt;!-- &lt;entry key=&quot;remote_ext_stopwords&quot;&gt;words_location&lt;/entry&gt; --&gt;&lt;/properties&gt; 这里我是用的是远程扩展字典，因为可以使用其他程序调用更新，且不用重启 ES，很方便；当然使用自定义的 mydict.dic 字典也是很方便的，一行一个词，自己加就可以了 既然是远程词典，那么就要是一个可访问的链接，可以是一个页面，也可以是一个txt的文档，但要保证输出的内容是 utf-8 的格式 hotWords.php 的内容 12345678$s = &lt;&lt;&lt;'EOF'陈港生元楼蓝瘦EOF;header('Last-Modified: '.gmdate('D, d M Y H:i:s', time()).' GMT', true, 200);header('ETag: \"5816f349-19\"');echo $s; ik 接收两个返回的头部属性 Last-Modified 和 ETag，只要其中一个有变化，就会触发更新，ik 会每分钟获取一次重启 Elasticsearch ，查看启动记录，看到了三个词已被加载进来 再次执行上面的请求，返回, 就可以看到 ik 分词器已经匹配到了 “陈港生” 这个词，同理一些关于我们公司的专有名字（例如：永辉、永辉超市、永辉云创、云创 …. ）也可以自己手动添加到字典中去。 2、结巴中文分词特点：1、支持三种分词模式： 精确模式，试图将句子最精确地切开，适合文本分析； 全模式，把句子中所有的可以成词的词语都扫描出来, 速度非常快，但是不能解决歧义； 搜索引擎模式，在精确模式的基础上，对长词再次切分，提高召回率，适合用于搜索引擎分词。 2、支持繁体分词 3、支持自定义词典 3、THULACTHULAC（THU Lexical Analyzer for Chinese）由清华大学自然语言处理与社会人文计算实验室研制推出的一套中文词法分析工具包，具有中文分词和词性标注功能。THULAC具有如下几个特点： 能力强。利用我们集成的目前世界上规模最大的人工分词和词性标注中文语料库（约含5800万字）训练而成，模型标注能力强大。 准确率高。该工具包在标准数据集Chinese Treebank（CTB5）上分词的F1值可达97.3％，词性标注的F1值可达到92.9％，与该数据集上最好方法效果相当。 速度较快。同时进行分词和词性标注速度为300KB/s，每秒可处理约15万字。只进行分词速度可达到1.3MB/s。 中文分词工具thulac4j发布 1、规范化分词词典，并去掉一些无用词； 2、重写DAT（双数组Trie树）的构造算法，生成的DAT size减少了8%左右，从而节省了内存； 3、优化分词算法，提高了分词速率。 12345&lt;dependency&gt; &lt;groupId&gt;io.github.yizhiru&lt;/groupId&gt; &lt;artifactId&gt;thulac4j&lt;/artifactId&gt; &lt;version&gt;$&#123;thulac4j.version&#125;&lt;/version&gt;&lt;/dependency&gt; http://www.cnblogs.com/en-heng/p/6526598.html thulac4j支持两种分词模式： SegOnly模式，只分词没有词性标注； SegPos模式，分词兼有词性标注。 12345678910// SegOnly modeString sentence = \"滔滔的流水，向着波士顿湾无声逝去\";SegOnly seg = new SegOnly(\"models/seg_only.bin\");System.out.println(seg.segment(sentence));// [滔滔, 的, 流水, ，, 向着, 波士顿湾, 无声, 逝去]// SegPos modeSegPos pos = new SegPos(\"models/seg_pos.bin\");System.out.println(pos.segment(sentence));//[滔滔/a, 的/u, 流水/n, ，/w, 向着/p, 波士顿湾/ns, 无声/v, 逝去/v] 4、NLPIR中科院计算所 NLPIR：http://ictclas.nlpir.org/nlpir/ (可直接在线分析中文) 下载地址：https://github.com/NLPIR-team/NLPIR 中科院分词系统(NLPIR)JAVA简易教程: http://www.cnblogs.com/wukongjiuwo/p/4092480.html 5、ansj分词器https://github.com/NLPchina/ansj_seg 这是一个基于n-Gram+CRF+HMM的中文分词的java实现. 分词速度达到每秒钟大约200万字左右（mac air下测试），准确率能达到96%以上 目前实现了.中文分词. 中文姓名识别 . 用户自定义词典,关键字提取，自动摘要，关键字标记等功能可以应用到自然语言处理等方面,适用于对分词效果要求高的各种项目. maven 引入： 12345&lt;dependency&gt; &lt;groupId&gt;org.ansj&lt;/groupId&gt; &lt;artifactId&gt;ansj_seg&lt;/artifactId&gt; &lt;version&gt;5.1.1&lt;/version&gt;&lt;/dependency&gt; 调用demo 1234String str = \"欢迎使用ansj_seg,(ansj中文分词)在这里如果你遇到什么问题都可以联系我.我一定尽我所能.帮助大家.ansj_seg更快,更准,更自由!\" ; System.out.println(ToAnalysis.parse(str)); 欢迎/v,使用/v,ansj/en,_,seg/en,,,(,ansj/en,中文/nz,分词/n,),在/p,这里/r,如果/c,你/r,遇到/v,什么/r,问题/n,都/d,可以/v,联系/v,我/r,./m,我/r,一定/d,尽我所能/l,./m,帮助/v,大家/r,./m,ansj/en,_,seg/en,更快/d,,,更/d,准/a,,,更/d,自由/a,! 6、哈工大的LTPhttps://link.zhihu.com/?target=https%3A//github.com/HIT-SCIR/ltp LTP制定了基于XML的语言处理结果表示，并在此基础上提供了一整套自底向上的丰富而且高效的中文语言处理模块（包括词法、句法、语义等6项中文处理核心技术），以及基于动态链接库（Dynamic Link Library, DLL）的应用程序接口、可视化工具，并且能够以网络服务（Web Service）的形式进行使用。 关于LTP的使用，请参考: http://ltp.readthedocs.io/zh_CN/latest/ 7、庖丁解牛下载地址：http://pan.baidu.com/s/1eQ88SZS 使用分为如下几步： 配置dic文件：修改paoding-analysis.jar中的paoding-dic-home.properties文件，将“#paoding.dic.home=dic”的注释去掉，并配置成自己dic文件的本地存放路径。eg：/home/hadoop/work/paoding-analysis-2.0.4-beta/dic 把Jar包导入到项目中：将paoding-analysis.jar、commons-logging.jar、lucene-analyzers-2.2.0.jar和lucene-core-2.2.0.jar四个包导入到项目中，这时就可以在代码片段中使用庖丁解牛工具提供的中文分词技术，例如： 123456789101112Analyzer analyzer = new PaodingAnalyzer(); //定义一个解析器String text = \"庖丁系统是个完全基于lucene的中文分词系统，它就是重新建了一个analyzer，叫做PaodingAnalyzer，这个analyer的核心任务就是生成一个可以切词TokenStream。\"; &lt;span style=\"font-family: Arial, Helvetica, sans-serif;\"&gt;//待分词的内容&lt;/span&gt;TokenStream tokenStream = analyzer.tokenStream(text, new StringReader(text)); //得到token序列的输出流try &#123; Token t; while ((t = tokenStream.next()) != null) &#123; System.out.println(t); //输出每个token &#125;&#125; catch (IOException e) &#123; e.printStackTrace();&#125; 8、sogo在线分词sogo在线分词采用了基于汉字标注的分词方法，主要使用了线性链链CRF（Linear-chain CRF）模型。词性标注模块主要基于结构化线性模型（Structured Linear Model） 在线使用地址为：http://www.sogou.com/labs/webservice/ 9、word分词地址： https://github.com/ysc/word word分词是一个Java实现的分布式的中文分词组件，提供了多种基于词典的分词算法，并利用ngram模型来消除歧义。能准确识别英文、数字，以及日期、时间等数量词，能识别人名、地名、组织机构名等未登录词。能通过自定义配置文件来改变组件行为，能自定义用户词库、自动检测词库变化、支持大规模分布式环境，能灵活指定多种分词算法，能使用refine功能灵活控制分词结果，还能使用词频统计、词性标注、同义标注、反义标注、拼音标注等功能。提供了10种分词算法，还提供了10种文本相似度算法，同时还无缝和Lucene、Solr、ElasticSearch、Luke集成。注意：word1.3需要JDK1.8 maven 中引入依赖： 1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apdplat&lt;/groupId&gt; &lt;artifactId&gt;word&lt;/artifactId&gt; &lt;version&gt;1.3&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; ElasticSearch插件： 1234567891011121314151617181920212223242526272829303132333435363738394041424344451、打开命令行并切换到elasticsearch的bin目录cd elasticsearch-2.1.1/bin2、运行plugin脚本安装word分词插件：./plugin install http://apdplat.org/word/archive/v1.4.zip安装的时候注意： 如果提示： ERROR: failed to download 或者 Failed to install word, reason: failed to download 或者 ERROR: incorrect hash (SHA1) 则重新再次运行命令，如果还是不行，多试两次如果是elasticsearch1.x系列版本，则使用如下命令：./plugin -u http://apdplat.org/word/archive/v1.3.1.zip -i word3、修改文件elasticsearch-2.1.1/config/elasticsearch.yml，新增如下配置：index.analysis.analyzer.default.type : &quot;word&quot;index.analysis.tokenizer.default.type : &quot;word&quot;4、启动ElasticSearch测试效果，在Chrome浏览器中访问：http://localhost:9200/_analyze?analyzer=word&amp;text=杨尚川是APDPlat应用级产品开发平台的作者5、自定义配置修改配置文件elasticsearch-2.1.1/plugins/word/word.local.conf6、指定分词算法修改文件elasticsearch-2.1.1/config/elasticsearch.yml，新增如下配置：index.analysis.analyzer.default.segAlgorithm : &quot;ReverseMinimumMatching&quot;index.analysis.tokenizer.default.segAlgorithm : &quot;ReverseMinimumMatching&quot;这里segAlgorithm可指定的值有：正向最大匹配算法：MaximumMatching逆向最大匹配算法：ReverseMaximumMatching正向最小匹配算法：MinimumMatching逆向最小匹配算法：ReverseMinimumMatching双向最大匹配算法：BidirectionalMaximumMatching双向最小匹配算法：BidirectionalMinimumMatching双向最大最小匹配算法：BidirectionalMaximumMinimumMatching全切分算法：FullSegmentation最少词数算法：MinimalWordCount最大Ngram分值算法：MaxNgramScore如不指定，默认使用双向最大匹配算法：BidirectionalMaximumMatching 10、jcseg分词器https://code.google.com/archive/p/jcseg/ 11、stanford分词器Stanford大学的一个开源分词工具，目前已支持汉语。 首先，去【1】下载Download Stanford Word Segmenter version 3.5.2，取得里面的 data 文件夹，放在maven project的 src/main/resources 里。 然后，maven依赖添加： 123456789101112131415161718192021222324&lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;corenlp.version&gt;3.6.0&lt;/corenlp.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;edu.stanford.nlp&lt;/groupId&gt; &lt;artifactId&gt;stanford-corenlp&lt;/artifactId&gt; &lt;version&gt;$&#123;corenlp.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;edu.stanford.nlp&lt;/groupId&gt; &lt;artifactId&gt;stanford-corenlp&lt;/artifactId&gt; &lt;version&gt;$&#123;corenlp.version&#125;&lt;/version&gt; &lt;classifier&gt;models&lt;/classifier&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;edu.stanford.nlp&lt;/groupId&gt; &lt;artifactId&gt;stanford-corenlp&lt;/artifactId&gt; &lt;version&gt;$&#123;corenlp.version&#125;&lt;/version&gt; &lt;classifier&gt;models-chinese&lt;/classifier&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 测试： 12345678910111213141516171819202122232425262728293031323334353637383940414243import java.util.Properties;import edu.stanford.nlp.ie.crf.CRFClassifier;public class CoreNLPSegment &#123; private static CoreNLPSegment instance; private CRFClassifier classifier; private CoreNLPSegment()&#123; Properties props = new Properties(); props.setProperty(\"sighanCorporaDict\", \"data\"); props.setProperty(\"serDictionary\", \"data/dict-chris6.ser.gz\"); props.setProperty(\"inputEncoding\", \"UTF-8\"); props.setProperty(\"sighanPostProcessing\", \"true\"); classifier = new CRFClassifier(props); classifier.loadClassifierNoExceptions(\"data/ctb.gz\", props); classifier.flags.setProperties(props); &#125; public static CoreNLPSegment getInstance() &#123; if (instance == null) &#123; instance = new CoreNLPSegment(); &#125; return instance; &#125; public String[] doSegment(String data) &#123; return (String[]) classifier.segmentString(data).toArray(); &#125; public static void main(String[] args) &#123; String sentence = \"他和我在学校里常打桌球。\"; String ret[] = CoreNLPSegment.getInstance().doSegment(sentence); for (String str : ret) &#123; System.out.println(str); &#125; &#125;&#125; 博客： https://blog.sectong.com/blog/corenlp_segment.html http://blog.csdn.net/lightty/article/details/51766602 12、SmartcnSmartcn为Apache2.0协议的开源中文分词系统，Java语言编写，修改的中科院计算所ICTCLAS分词系统。很早以前看到Lucene上多了一个中文分词的contribution，当时只是简单的扫了一下.class文件的文件名，通过文件名可以看得出又是一个改的ICTCLAS的分词系统。 http://lucene.apache.org/core/5_1_0/analyzers-smartcn/org/apache/lucene/analysis/cn/smart/SmartChineseAnalyzer.html 13、pinyin 分词器pinyin分词器可以让用户输入拼音，就能查找到相关的关键词。比如在某个商城搜索中，输入 yonghui，就能匹配到 永辉。这样的体验还是非常好的。 pinyin分词器的安装与IK是一样的。下载地址：https://github.com/medcl/elasticsearch-analysis-pinyin 一些参数请参考 GitHub 的 readme 文档。 这个分词器在1.8版本中，提供了两种分词规则： pinyin,就是普通的把汉字转换成拼音； pinyin_first_letter，提取汉字的拼音首字母 使用： 1.Create a index with custom pinyin analyzer 1234567891011121314151617181920212223curl -XPUT http://localhost:9200/medcl/ -d&apos;&#123; &quot;index&quot; : &#123; &quot;analysis&quot; : &#123; &quot;analyzer&quot; : &#123; &quot;pinyin_analyzer&quot; : &#123; &quot;tokenizer&quot; : &quot;my_pinyin&quot; &#125; &#125;, &quot;tokenizer&quot; : &#123; &quot;my_pinyin&quot; : &#123; &quot;type&quot; : &quot;pinyin&quot;, &quot;keep_separate_first_letter&quot; : false, &quot;keep_full_pinyin&quot; : true, &quot;keep_original&quot; : true, &quot;limit_first_letter_length&quot; : 16, &quot;lowercase&quot; : true, &quot;remove_duplicated_term&quot; : true &#125; &#125; &#125; &#125;&#125;&apos; 2.Test Analyzer, analyzing a chinese name, such as 刘德华 1http://localhost:9200/medcl/_analyze?text=%e5%88%98%e5%be%b7%e5%8d%8e&amp;analyzer=pinyin_analyzer 123456789101112131415161718192021222324252627282930313233343536373839&#123; &quot;tokens&quot; : [ &#123; &quot;token&quot; : &quot;liu&quot;, &quot;start_offset&quot; : 0, &quot;end_offset&quot; : 1, &quot;type&quot; : &quot;word&quot;, &quot;position&quot; : 0 &#125;, &#123; &quot;token&quot; : &quot;de&quot;, &quot;start_offset&quot; : 1, &quot;end_offset&quot; : 2, &quot;type&quot; : &quot;word&quot;, &quot;position&quot; : 1 &#125;, &#123; &quot;token&quot; : &quot;hua&quot;, &quot;start_offset&quot; : 2, &quot;end_offset&quot; : 3, &quot;type&quot; : &quot;word&quot;, &quot;position&quot; : 2 &#125;, &#123; &quot;token&quot; : &quot;刘德华&quot;, &quot;start_offset&quot; : 0, &quot;end_offset&quot; : 3, &quot;type&quot; : &quot;word&quot;, &quot;position&quot; : 3 &#125;, &#123; &quot;token&quot; : &quot;ldh&quot;, &quot;start_offset&quot; : 0, &quot;end_offset&quot; : 3, &quot;type&quot; : &quot;word&quot;, &quot;position&quot; : 4 &#125; ]&#125; 3.Create mapping 12345678910111213141516171819curl -XPOST http://localhost:9200/medcl/folks/_mapping -d&apos;&#123; &quot;folks&quot;: &#123; &quot;properties&quot;: &#123; &quot;name&quot;: &#123; &quot;type&quot;: &quot;keyword&quot;, &quot;fields&quot;: &#123; &quot;pinyin&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;store&quot;: &quot;no&quot;, &quot;term_vector&quot;: &quot;with_offsets&quot;, &quot;analyzer&quot;: &quot;pinyin_analyzer&quot;, &quot;boost&quot;: 10 &#125; &#125; &#125; &#125; &#125;&#125;&apos; 4.Indexing 1curl -XPOST http://localhost:9200/medcl/folks/andy -d&apos;&#123;&quot;name&quot;:&quot;刘德华&quot;&#125;&apos; 5.Let’s search 12345http://localhost:9200/medcl/folks/_search?q=name:%E5%88%98%E5%BE%B7%E5%8D%8Ecurl http://localhost:9200/medcl/folks/_search?q=name.pinyin:%e5%88%98%e5%be%b7curl http://localhost:9200/medcl/folks/_search?q=name.pinyin:liucurl http://localhost:9200/medcl/folks/_search?q=name.pinyin:ldhcurl http://localhost:9200/medcl/folks/_search?q=name.pinyin:de+hua 6.Using Pinyin-TokenFilter 123456789101112131415161718192021222324252627curl -XPUT http://localhost:9200/medcl1/ -d&apos;&#123; &quot;index&quot; : &#123; &quot;analysis&quot; : &#123; &quot;analyzer&quot; : &#123; &quot;user_name_analyzer&quot; : &#123; &quot;tokenizer&quot; : &quot;whitespace&quot;, &quot;filter&quot; : &quot;pinyin_first_letter_and_full_pinyin_filter&quot; &#125; &#125;, &quot;filter&quot; : &#123; &quot;pinyin_first_letter_and_full_pinyin_filter&quot; : &#123; &quot;type&quot; : &quot;pinyin&quot;, &quot;keep_first_letter&quot; : true, &quot;keep_full_pinyin&quot; : false, &quot;keep_none_chinese&quot; : true, &quot;keep_original&quot; : false, &quot;limit_first_letter_length&quot; : 16, &quot;lowercase&quot; : true, &quot;trim_whitespace&quot; : true, &quot;keep_none_chinese_in_first_letter&quot; : true &#125; &#125; &#125; &#125;&#125;&apos; Token Test:刘德华 张学友 郭富城 黎明 四大天王 1curl -XGET http://localhost:9200/medcl1/_analyze?text=%e5%88%98%e5%be%b7%e5%8d%8e+%e5%bc%a0%e5%ad%a6%e5%8f%8b+%e9%83%ad%e5%af%8c%e5%9f%8e+%e9%bb%8e%e6%98%8e+%e5%9b%9b%e5%a4%a7%e5%a4%a9%e7%8e%8b&amp;analyzer=user_name_analyzer 12345678910111213141516171819202122232425262728293031323334353637383940&#123; &quot;tokens&quot; : [ &#123; &quot;token&quot; : &quot;ldh&quot;, &quot;start_offset&quot; : 0, &quot;end_offset&quot; : 3, &quot;type&quot; : &quot;word&quot;, &quot;position&quot; : 0 &#125;, &#123; &quot;token&quot; : &quot;zxy&quot;, &quot;start_offset&quot; : 4, &quot;end_offset&quot; : 7, &quot;type&quot; : &quot;word&quot;, &quot;position&quot; : 1 &#125;, &#123; &quot;token&quot; : &quot;gfc&quot;, &quot;start_offset&quot; : 8, &quot;end_offset&quot; : 11, &quot;type&quot; : &quot;word&quot;, &quot;position&quot; : 2 &#125;, &#123; &quot;token&quot; : &quot;lm&quot;, &quot;start_offset&quot; : 12, &quot;end_offset&quot; : 14, &quot;type&quot; : &quot;word&quot;, &quot;position&quot; : 3 &#125;, &#123; &quot;token&quot; : &quot;sdtw&quot;, &quot;start_offset&quot; : 15, &quot;end_offset&quot; : 19, &quot;type&quot; : &quot;word&quot;, &quot;position&quot; : 4 &#125; ]&#125; 7.Used in phrase query (1)、 123456789101112131415161718192021222324252627282930PUT /medcl/ &#123; &quot;index&quot; : &#123; &quot;analysis&quot; : &#123; &quot;analyzer&quot; : &#123; &quot;pinyin_analyzer&quot; : &#123; &quot;tokenizer&quot; : &quot;my_pinyin&quot; &#125; &#125;, &quot;tokenizer&quot; : &#123; &quot;my_pinyin&quot; : &#123; &quot;type&quot; : &quot;pinyin&quot;, &quot;keep_first_letter&quot;:false, &quot;keep_separate_first_letter&quot; : false, &quot;keep_full_pinyin&quot; : true, &quot;keep_original&quot; : false, &quot;limit_first_letter_length&quot; : 16, &quot;lowercase&quot; : true &#125; &#125; &#125; &#125; &#125; GET /medcl/folks/_search &#123; &quot;query&quot;: &#123;&quot;match_phrase&quot;: &#123; &quot;name.pinyin&quot;: &quot;刘德华&quot; &#125;&#125; &#125; (2)、 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647PUT /medcl/ &#123; &quot;index&quot; : &#123; &quot;analysis&quot; : &#123; &quot;analyzer&quot; : &#123; &quot;pinyin_analyzer&quot; : &#123; &quot;tokenizer&quot; : &quot;my_pinyin&quot; &#125; &#125;, &quot;tokenizer&quot; : &#123; &quot;my_pinyin&quot; : &#123; &quot;type&quot; : &quot;pinyin&quot;, &quot;keep_first_letter&quot;:false, &quot;keep_separate_first_letter&quot; : true, &quot;keep_full_pinyin&quot; : false, &quot;keep_original&quot; : false, &quot;limit_first_letter_length&quot; : 16, &quot;lowercase&quot; : true &#125; &#125; &#125; &#125; &#125; POST /medcl/folks/andy &#123;&quot;name&quot;:&quot;刘德华&quot;&#125; GET /medcl/folks/_search &#123; &quot;query&quot;: &#123;&quot;match_phrase&quot;: &#123; &quot;name.pinyin&quot;: &quot;刘德h&quot; &#125;&#125; &#125; GET /medcl/folks/_search &#123; &quot;query&quot;: &#123;&quot;match_phrase&quot;: &#123; &quot;name.pinyin&quot;: &quot;刘dh&quot; &#125;&#125; &#125; GET /medcl/folks/_search &#123; &quot;query&quot;: &#123;&quot;match_phrase&quot;: &#123; &quot;name.pinyin&quot;: &quot;dh&quot; &#125;&#125; &#125; 14、Mmseg 分词器也支持 Elasticsearch 下载地址：https://github.com/medcl/elasticsearch-analysis-mmseg/releases 根据对应的版本进行下载 如何使用： 1、创建索引： 1curl -XPUT http://localhost:9200/index 2、创建 mapping 123456789101112curl -XPOST http://localhost:9200/index/fulltext/_mapping -d&apos;&#123; &quot;properties&quot;: &#123; &quot;content&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;term_vector&quot;: &quot;with_positions_offsets&quot;, &quot;analyzer&quot;: &quot;mmseg_maxword&quot;, &quot;search_analyzer&quot;: &quot;mmseg_maxword&quot; &#125; &#125;&#125;&apos; 3.Indexing some docs 123456789101112131415curl -XPOST http://localhost:9200/index/fulltext/1 -d&apos;&#123;&quot;content&quot;:&quot;美国留给伊拉克的是个烂摊子吗&quot;&#125;&apos;curl -XPOST http://localhost:9200/index/fulltext/2 -d&apos;&#123;&quot;content&quot;:&quot;公安部：各地校车将享最高路权&quot;&#125;&apos;curl -XPOST http://localhost:9200/index/fulltext/3 -d&apos;&#123;&quot;content&quot;:&quot;中韩渔警冲突调查：韩警平均每天扣1艘中国渔船&quot;&#125;&apos;curl -XPOST http://localhost:9200/index/fulltext/4 -d&apos;&#123;&quot;content&quot;:&quot;中国驻洛杉矶领事馆遭亚裔男子枪击 嫌犯已自首&quot;&#125;&apos; 4.Query with highlighting(查询高亮) 123456789101112curl -XPOST http://localhost:9200/index/fulltext/_search -d&apos;&#123; &quot;query&quot; : &#123; &quot;term&quot; : &#123; &quot;content&quot; : &quot;中国&quot; &#125;&#125;, &quot;highlight&quot; : &#123; &quot;pre_tags&quot; : [&quot;&lt;tag1&gt;&quot;, &quot;&lt;tag2&gt;&quot;], &quot;post_tags&quot; : [&quot;&lt;/tag1&gt;&quot;, &quot;&lt;/tag2&gt;&quot;], &quot;fields&quot; : &#123; &quot;content&quot; : &#123;&#125; &#125; &#125;&#125;&apos; 5、结果： 12345678910111213141516171819202122232425262728293031323334353637383940414243&#123; &quot;took&quot;: 14, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 2, &quot;max_score&quot;: 2, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;index&quot;, &quot;_type&quot;: &quot;fulltext&quot;, &quot;_id&quot;: &quot;4&quot;, &quot;_score&quot;: 2, &quot;_source&quot;: &#123; &quot;content&quot;: &quot;中国驻洛杉矶领事馆遭亚裔男子枪击 嫌犯已自首&quot; &#125;, &quot;highlight&quot;: &#123; &quot;content&quot;: [ &quot;&lt;tag1&gt;中国&lt;/tag1&gt;驻洛杉矶领事馆遭亚裔男子枪击 嫌犯已自首 &quot; ] &#125; &#125;, &#123; &quot;_index&quot;: &quot;index&quot;, &quot;_type&quot;: &quot;fulltext&quot;, &quot;_id&quot;: &quot;3&quot;, &quot;_score&quot;: 2, &quot;_source&quot;: &#123; &quot;content&quot;: &quot;中韩渔警冲突调查：韩警平均每天扣1艘中国渔船&quot; &#125;, &quot;highlight&quot;: &#123; &quot;content&quot;: [ &quot;均每天扣1艘&lt;tag1&gt;中国&lt;/tag1&gt;渔船 &quot; ] &#125; &#125; ] &#125;&#125; 参考博客： 为elastic添加中文分词: http://blog.csdn.net/dingzfang/article/details/42776693 15、bosonnlp （玻森数据中文分析器）下载地址：https://github.com/bosondata/elasticsearch-analysis-bosonnlp 如何使用： 运行 ElasticSearch 之前需要在 config 文件夹中修改 elasticsearch.yml 来定义使用玻森中文分析器，并填写玻森 API_TOKEN 以及玻森分词 API 的地址，即在该文件结尾处添加： 12345678910111213141516171819202122index: analysis: analyzer: bosonnlp: type: bosonnlp API_URL: http://api.bosonnlp.com/tag/analysis # You MUST give the API_TOKEN value, otherwise it doesn&apos;t work API_TOKEN: *PUT YOUR API TOKEN HERE* # Please uncomment if you want to specify ANY ONE of the following # areguments, otherwise the DEFAULT value will be used, i.e., # space_mode is 0, # oov_level is 3, # t2s is 0, # special_char_conv is 0. # More detials can be found in bosonnlp docs: # http://docs.bosonnlp.com/tag.html # # # space_mode: put your value here(range from 0-3) # oov_level: put your value here(range from 0-4) # t2s: put your value here(range from 0-1) # special_char_conv: put your value here(range from 0-1) 需要注意的是 必须在 API_URL 填写给定的分词地址以及在API_TOKEN：PUT YOUR API TOKEN HERE 中填写给定的玻森数据API_TOKEN，否则无法使用玻森中文分析器。该 API_TOKEN 是注册玻森数据账号所获得。 如果配置文件中已经有配置过其他的 analyzer，请直接在 analyzer 下如上添加 bosonnlp analyzer。 如果有多个 node 并且都需要 BosonNLP 的分词插件，则每个 node 下的 yaml 文件都需要如上安装和设置。 另外，玻森中文分词还提供了4个参数（space_mode，oov_level，t2s，special_char_conv）可满足不同的分词需求。如果取默认值，则无需任何修改；否则，可取消对应参数的注释并赋值。 测试： 建立 index 1curl -XPUT &apos;localhost:9200/test&apos; 测试分析器是否配置成功 1curl -XGET &apos;localhost:9200/test/_analyze?analyzer=bosonnlp&amp;pretty&apos; -d &apos;这是玻森数据分词的测试&apos; 结果 123456789101112131415161718192021222324252627282930313233343536373839404142434445&#123; &quot;tokens&quot; : [ &#123; &quot;token&quot; : &quot;这&quot;, &quot;start_offset&quot; : 0, &quot;end_offset&quot; : 1, &quot;type&quot; : &quot;word&quot;, &quot;position&quot; : 0 &#125;, &#123; &quot;token&quot; : &quot;是&quot;, &quot;start_offset&quot; : 1, &quot;end_offset&quot; : 2, &quot;type&quot; : &quot;word&quot;, &quot;position&quot; : 1 &#125;, &#123; &quot;token&quot; : &quot;玻森&quot;, &quot;start_offset&quot; : 2, &quot;end_offset&quot; : 4, &quot;type&quot; : &quot;word&quot;, &quot;position&quot; : 2 &#125;, &#123; &quot;token&quot; : &quot;数据&quot;, &quot;start_offset&quot; : 4, &quot;end_offset&quot; : 6, &quot;type&quot; : &quot;word&quot;, &quot;position&quot; : 3 &#125;, &#123; &quot;token&quot; : &quot;分词&quot;, &quot;start_offset&quot; : 6, &quot;end_offset&quot; : 8, &quot;type&quot; : &quot;word&quot;, &quot;position&quot; : 4 &#125;, &#123; &quot;token&quot; : &quot;的&quot;, &quot;start_offset&quot; : 8, &quot;end_offset&quot; : 9, &quot;type&quot; : &quot;word&quot;, &quot;position&quot; : 5 &#125;, &#123; &quot;token&quot; : &quot;测试&quot;, &quot;start_offset&quot; : 9, &quot;end_offset&quot; : 11, &quot;type&quot; : &quot;word&quot;, &quot;position&quot; : 6 &#125; ]&#125; 配置 Token Filter 现有的 BosonNLP 分析器没有内置 token filter，如果有过滤 Token 的需求，可以利用 BosonNLP Tokenizer 和 ES 提供的 token filter 搭建定制分析器。 步骤 配置定制的 analyzer 有以下三个步骤： 添加 BosonNLP tokenizer在 elasticsearch.yml 文件中 analysis 下添加 tokenizer， 并在 tokenizer 中添加 BosonNLP tokenizer 的配置： 123456789101112131415161718192021222324index: analysis: analyzer: ... tokenizer: bosonnlp: type: bosonnlp API_URL: http://api.bosonnlp.com/tag/analysis # You MUST give the API_TOKEN value, otherwise it doesn&apos;t work API_TOKEN: *PUT YOUR API TOKEN HERE* # Please uncomment if you want to specify ANY ONE of the following # areguments, otherwise the DEFAULT value will be used, i.e., # space_mode is 0, # oov_level is 3, # t2s is 0, # special_char_conv is 0. # More detials can be found in bosonnlp docs: # http://docs.bosonnlp.com/tag.html # # # space_mode: put your value here(range from 0-3) # oov_level: put your value here(range from 0-4) # t2s: put your value here(range from 0-1) # special_char_conv: put your value here(range from 0-1) 添加 token filter 在 elasticsearch.yml 文件中 analysis 下添加 filter， 并在 filter 中添加所需 filter 的配置（下面例子中，我们以 lowercase filter 为例）： 123456789index: analysis: analyzer: ... tokenizer: ... filter: lowercase: type: lowercase 添加定制的 analyzer 在 elasticsearch.yml 文件中 analysis 下添加 analyzer， 并在 analyzer 中添加定制的 analyzer 的配置（下面例子中，我们把定制的 analyzer 命名为 filter_bosonnlp）： 12345678index: analysis: analyzer: ... filter_bosonnlp: type: custom tokenizer: bosonnlp filter: [lowercase] 自定义分词器虽然Elasticsearch带有一些现成的分析器，然而在分析器上Elasticsearch真正的强大之处在于，你可以通过在一个适合你的特定数据的设置之中组合字符过滤器、分词器、词汇单元过滤器来创建自定义的分析器。 字符过滤器： 字符过滤器 用来 整理 一个尚未被分词的字符串。例如，如果我们的文本是HTML格式的，它会包含像 &lt;p&gt; 或者 &lt;div&gt; 这样的HTML标签，这些标签是我们不想索引的。我们可以使用 html清除 字符过滤器 来移除掉所有的HTML标签，并且像把 &amp;Aacute; 转换为相对应的Unicode字符 Á 这样，转换HTML实体。 一个分析器可能有0个或者多个字符过滤器。 分词器: 一个分析器 必须 有一个唯一的分词器。 分词器把字符串分解成单个词条或者词汇单元。 标准 分析器里使用的 标准 分词器 把一个字符串根据单词边界分解成单个词条，并且移除掉大部分的标点符号，然而还有其他不同行为的分词器存在。 词单元过滤器: 经过分词，作为结果的 词单元流 会按照指定的顺序通过指定的词单元过滤器 。 词单元过滤器可以修改、添加或者移除词单元。我们已经提到过 lowercase 和 stop 词过滤器 ，但是在 Elasticsearch 里面还有很多可供选择的词单元过滤器。 词干过滤器 把单词 遏制 为 词干。 ascii_folding 过滤器移除变音符，把一个像 “très” 这样的词转换为 “tres” 。 ngram 和 edge_ngram 词单元过滤器 可以产生 适合用于部分匹配或者自动补全的词单元。 创建一个自定义分析器我们可以在 analysis 下的相应位置设置字符过滤器、分词器和词单元过滤器: 1234567891011PUT /my_index&#123; &quot;settings&quot;: &#123; &quot;analysis&quot;: &#123; &quot;char_filter&quot;: &#123; ... custom character filters ... &#125;, &quot;tokenizer&quot;: &#123; ... custom tokenizers ... &#125;, &quot;filter&quot;: &#123; ... custom token filters ... &#125;, &quot;analyzer&quot;: &#123; ... custom analyzers ... &#125; &#125; &#125;&#125; 这个分析器可以做到下面的这些事: 1、使用 html清除 字符过滤器移除HTML部分。 2、使用一个自定义的 映射 字符过滤器把 &amp; 替换为 “和” ： 123456&quot;char_filter&quot;: &#123; &quot;&amp;_to_and&quot;: &#123; &quot;type&quot;: &quot;mapping&quot;, &quot;mappings&quot;: [ &quot;&amp;=&gt; and &quot;] &#125;&#125; 3、使用 标准 分词器分词。 4、小写词条，使用 小写 词过滤器处理。 5、使用自定义 停止 词过滤器移除自定义的停止词列表中包含的词： 123456&quot;filter&quot;: &#123; &quot;my_stopwords&quot;: &#123; &quot;type&quot;: &quot;stop&quot;, &quot;stopwords&quot;: [ &quot;the&quot;, &quot;a&quot; ] &#125;&#125; 我们的分析器定义用我们之前已经设置好的自定义过滤器组合了已经定义好的分词器和过滤器： 12345678&quot;analyzer&quot;: &#123; &quot;my_analyzer&quot;: &#123; &quot;type&quot;: &quot;custom&quot;, &quot;char_filter&quot;: [ &quot;html_strip&quot;, &quot;&amp;_to_and&quot; ], &quot;tokenizer&quot;: &quot;standard&quot;, &quot;filter&quot;: [ &quot;lowercase&quot;, &quot;my_stopwords&quot; ] &#125;&#125; 汇总起来，完整的 创建索引 请求 看起来应该像这样： 1234567891011121314151617181920212223PUT /my_index&#123; &quot;settings&quot;: &#123; &quot;analysis&quot;: &#123; &quot;char_filter&quot;: &#123; &quot;&amp;_to_and&quot;: &#123; &quot;type&quot;: &quot;mapping&quot;, &quot;mappings&quot;: [ &quot;&amp;=&gt; and &quot;] &#125;&#125;, &quot;filter&quot;: &#123; &quot;my_stopwords&quot;: &#123; &quot;type&quot;: &quot;stop&quot;, &quot;stopwords&quot;: [ &quot;the&quot;, &quot;a&quot; ] &#125;&#125;, &quot;analyzer&quot;: &#123; &quot;my_analyzer&quot;: &#123; &quot;type&quot;: &quot;custom&quot;, &quot;char_filter&quot;: [ &quot;html_strip&quot;, &quot;&amp;_to_and&quot; ], &quot;tokenizer&quot;: &quot;standard&quot;, &quot;filter&quot;: [ &quot;lowercase&quot;, &quot;my_stopwords&quot; ] &#125;&#125;&#125;&#125;&#125; 索引被创建以后，使用 analyze API 来 测试这个新的分析器： 12GET /my_index/_analyze?analyzer=my_analyzerThe quick &amp; brown fox 下面的缩略结果展示出我们的分析器正在正确地运行： 12345678&#123; &quot;tokens&quot; : [ &#123; &quot;token&quot; : &quot;quick&quot;, &quot;position&quot; : 2 &#125;, &#123; &quot;token&quot; : &quot;and&quot;, &quot;position&quot; : 3 &#125;, &#123; &quot;token&quot; : &quot;brown&quot;, &quot;position&quot; : 4 &#125;, &#123; &quot;token&quot; : &quot;fox&quot;, &quot;position&quot; : 5 &#125; ]&#125; 这个分析器现在是没有多大用处的，除非我们告诉 Elasticsearch在哪里用上它。我们可以像下面这样把这个分析器应用在一个 string 字段上： 123456789PUT /my_index/_mapping/my_type&#123; &quot;properties&quot;: &#123; &quot;title&quot;: &#123; &quot;type&quot;: &quot;string&quot;, &quot;analyzer&quot;: &quot;my_analyzer&quot; &#125; &#125;&#125; 最后整理参考网上资料，如有不正确的地方还请多多指教！","tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://yoursite.com/tags/Elasticsearch/"}]},{"title":"那些年我看过的书 —— 致敬我的大学生活 —— Say Good Bye ！","date":"2017-08-26T05:38:47.267Z","path":"2017/08/26/recommend-books/","text":"开头2017.08.21 正式开启我入职的里程，现在已是工作了一个星期了，这个星期算是我入职的过渡期，算是知道了学校生活和工作的差距了，总之，尽快习惯这种生活吧。下面讲下自己的找工作经历和大学阅读的书籍，算是一种书籍推荐，为还在迷茫的你指引方向，同时为我三年的大学生活致敬！也激励我大四在公司实习能更上一层楼！ 找工作经历这段经历，算是自己很难忘记的经历吧。既辛酸既充实的日子！也很感谢自己在这段时间的系统复习，感觉把自己的基础知识再次聚集在一起了，自己的能力在这一段时间提升的也很快。后面有机会的话我也想写一系列的相关文章，为后来准备工作（面试）的同学提供一些自己的帮助。自己在找工作的这段时间面过的公司也有几家大厂，但是结果都不是很好，对我自己有很大的压力，当时心里真的感觉 ：“自己真的有这么差”，为什么一直被拒，当时很怀疑自己的能力，自己也有总结原因。一是面试的时候自己准备的还不够充分，虽说自己脑子里对这些基础有点印象，但是面试的时候自己稍紧张下就描述不怎么清楚了，导致面试官觉得你可能广度够了，深度还不够（这是阿里面试官电话面试说的）；二是自己的表达能力还是有所欠缺，不能够将自己所要表达的东西说出来，这可能我要在后面加强的地方；三是我的学校问题。在面了几家公司失败后，终于面了家公司要我了，我也确定在这家公司了。很幸运，刚出来，就有一个很好（很负责）的架构师带我，这周就给了我一个很牛逼的项目给我看（虽然自己目前还没有思路改里面的代码），里面新东西很多，说吃透了这个项目，以后绝对可以拿出去吹逼（一脸正经.jpg）。目前我的找工作经历就简短的介绍到这里了，如果感兴趣的话，可以加群：528776268 进来和我讨论交流。 书籍推荐大学，我不怎么喜欢玩游戏，自己也还算不怎么堕落吧，看了以下的一些书籍，算是对我后面写博客、找工作也有很大的帮助。如果你是大神，请忽略，如果你还是还在大学，和我一样不想把时间浪费在游戏上，可以看看我推荐的一些书籍，有想讨论的请在评论下留下你的评论或者加上面给的群号。 Java1、《Java 核心技术》卷一 、卷二 两本书，算是入门比较好的书籍了 2、《疯狂 Java 讲义》 很厚的一本书，里面的内容也是很注重基础了 3、《Java 并发编程的艺术》—— 方腾飞 、魏鹏、程晓明著 方腾飞 是并发编程网的创始人，里面的文章确实还不错，可以多看看里面的文章，收获绝对很大。 4、《 Java多线程编程核心技术》—— 高洪岩著 这本书也算是入门多线程编程的不错书籍，我之前还写了一篇读书笔记呢，《Java 多线程编程核心技术》学习笔记及总结 , 大家如果不想看书的可以去看我的笔记。 5、《Java 并发编程实战》 这本书讲的有点难懂啊，不过确实也是一本很好的书，以上三本书籍如果都弄懂了，我觉得你并发编程这块可能大概就 OK 了，然后再去看看线程池的源码，了解下线程池，我觉得那就更棒了。不想看的话，请看我的博客：Java 线程池艺术探索 我个人觉得还是写的很不错，那些大厂面试也几乎都会问线程池的东西，然后大概内容也就是我这博客写的 6、《Effective Java》中文版 第二版 算是 Java 的进阶书籍了，面试好多问题也是从这出来的 7、《深入理解 Java 虚拟机——JVM高级特性与最佳实践》第二版 这算是国内讲 JVM 最清楚的书了吧，目前还是只看了一遍，后面继续啃，大厂面试几乎也是都会考 JVM 的，阿里面 JVM 特别多，想进阿里的同学请一定要买这本书去看。 8、《深入分析Java Web技术内幕 修订版》许令波著 里面知识很广，每一章都是一个不同的知识，可见作者的优秀，不愧是阿里大神。 9、《大型网站系统与 Java 中间件实践》—— 曽宪杰 著 作者是前淘宝技术总监，见证了淘宝网的发展，里面的讲的内容也是很好，看完能让自己也站在高处去思考问题。 10、《大型网站技术架构 —— 核心原理与案例分析》 —— 李智慧 著 最好和上面那本书籍一起看，效果更好，两本看完了，提升思想的高度！ 11、《疯狂Java.突破程序员基本功的16课》 李刚 著 书中很注重 Java 的一些细节，讲的很深入，但是书中的错别字特多，可以看看我的读书笔记：《疯狂 Java 突破程序员基本功的 16 课》读书笔记 12、《Spring 实战》 Spring 入门书籍 13、《Spring 揭秘》—— 王福强 著 这本书别提多牛了，出版时期为 2009 年，豆瓣评分为 9.0 分，写的是真棒！把 Spring 的 IOC 和 AOP 特性写的很清楚，把 Spring 的来龙去脉讲的很全。墙裂推荐这本书籍，如果你想看 Spring，作者很牛，资深架构师，很有幸和作者有过一次交流，当时因为自己的一篇博客 Pyspider框架 —— Python爬虫实战之爬取 V2EX 网站帖子，竟然找到我想叫我去实习，可惜了，当时差点就跟着他混了。作者还有一本书 《Spring Boot 揭秘》。 14、《Spring 技术内幕》—— 深入解析 Spring 架构与设计原理 讲解 Spring 源码，深入了内部机制，个人觉得还是不错的。 15、Spring 官方的英文文档 这个别提了，很好，能看英文尽量看英文 16、《跟开涛学 Spring 3》 《跟开涛学 Spring MVC》 京东大神，膜 17、《看透springMvc源代码分析与实践》 算是把 Spring MVC 源码讲的很好的了 见我的笔记： 1、通过源码详解 Servlet 2 、看透 Spring MVC 源代码分析与实践 —— 网站基础知识 3 、看透 Spring MVC 源代码分析与实践 —— 俯视 Spring MVC 4 、看透 Spring MVC 源代码分析与实践 —— Spring MVC 组件分析 18、《Spring Boot 实战》 19、Spring Boot 官方 Reference Guide 网上好多写 SpringBoot 的博客，几乎和这个差不多。 20、《JavaEE开发的颠覆者: Spring Boot实战》 21、MyBatis 当然是官方的文档最好了，而且还是中文的。 自己也写过几篇文章，帮助过很多人入门，传送门： 1、通过项目逐步深入了解Mybatis（一）/) 2、通过项目逐步深入了解Mybatis（二）/) 3、通过项目逐步深入了解Mybatis（三）/) 4、通过项目逐步深入了解Mybatis（四）/) 22、《深入理解 Java 内存模型》—— 程晓明 著 我觉得每个 Java 程序员都应该了解下 Java 的内存模型，该书籍我看的是电子版的，不多，但是讲的却很清楚，把重排序、顺序一致性、Volatile、锁、final等写的很清楚。 Linux《鸟哥的Linux私房菜 基础学习篇(第三版) 》 鸟哥的Linux私房菜：服务器架设篇(第3版) 鸟哥的书 计算机网络《计算机网络第六版——谢希仁 编》 《计算机网络自顶向下方法》 计算机系统《代码揭秘：从C／C.的角度探秘计算机系统 —— 左飞》 《深入理解计算机系统》 《计算机科学导论_佛罗赞》 数据库《高性能MySQL》 《Mysql技术内幕InnoDB存储引擎》 Python这门语言语法很简单，上手快，不过我目前好久没用了，都忘得差不多了。当时是看的廖雪峰的 Python 博客 自己也用 Python 做爬虫写过几篇博客，不过有些是在前人的基础上写的。感谢那些栽树的人！ 工具Git ： 廖雪峰的 Git 教程 IDEA：IntelliJ IDEA 简体中文专题教程 Maven：《Maven实战》 其他《如何高效学习-斯科特杨》 教你怎样高效学习的 《软技能：代码之外的生存指南》 程序员除了写代码，还得懂点其他的软技能。 《提问的智慧“中文版”》 《How-To-Ask-Questions-The-Smart-Way》 作为程序员的你，一定要学会咋提问，不然别人都不想鸟你。 优秀网站推荐1、GitHub 别和我说不知道 2、InfoQ 文章很不错 3、CSDN 经常看博客专家的博客，里面大牛很多，传送门：zhisheng 4、知乎 多关注些大牛，看他们吹逼 5、掘金 自己也在上面写专栏，粉丝已经超过一万了，传送门 ：zhisheng 6、并发编程网 前面已经介绍 7、developerworks 上面的博客也很好 8、博客园 里面应该大牛也很多，不过自己没在上面写过博客 9、微信公众号 关注了很多人，有些人的文章确实很好。 10、牛客网 刷笔试题不错的地方，里面大牛超多，怀念叶神和左神讲课的时候，还有很有爱的牛妹。 11、优秀博主的博客地址了 优秀博客推荐廖雪峰 Git 和 Python 入门文章就是从他博客看的 阮一峰的网络日志 酷壳-陈皓 RednaxelaFX R大，牛逼的不得了 江南白衣 老司机 stormzhang 人称帅逼张，微信公众号写的不错 你假笨 阿里搞 JVM 的，很厉害 占小狼 泥瓦匠BYSocket 崔庆才 写了好多 Python 爬虫相关的文章 纯洁的微笑 SpringBoot 系列不错，其他的文章自己看了感觉是自己喜欢的那种文笔 程序猿DD 周立 芋艿V的博客 好多系列的源码分析 zhisheng 这个是我不要脸，竟然把自己博客地址的写上去了 最后送一句话，越努力，越幸运，祝早日成为大神！ 这些地方可以找到我： blog: http://www.54tianzhisheng.cn/ GitHub: https://github.com/zhisheng17 QQ 群：528776268","tags":[{"name":"随笔","slug":"随笔","permalink":"http://yoursite.com/tags/随笔/"}]},{"title":"Ubuntu16.10 安装 Nginx","date":"2017-08-18T05:52:20.764Z","path":"2017/08/18/Ubuntu-install-Nginx/","text":"安装 Nginx 依赖库安装 gcc g++ 的依赖库Ubuntu 平台使用： 12apt-get install build-essentialapt-get install libtool CentOS 平台使用： 12345centos平台编译环境使用如下指令安装make：yum -y install gcc automake autoconf libtool make安装g++:yum install gcc gcc-c++ 安装 pcre 依赖库12sudo apt-get updatesudo apt-get install libpcre3 libpcre3-dev 安装 zlib 依赖库1apt-get install zlib1g-dev 安装 ssl 依赖库1apt-get install openssl 安装 Nginx在网上下载了 nginx-1.8.1.tar.gz 版本。 1234567891011121314151617#解压：tar -zxvf nginx-1.8.1.tar.gz#进入解压目录：cd nginx-1.8.1#配置：./configure --prefix=/usr/local/nginx#编辑nginx：make注意：这里可能会报错，提示“pcre.h No such file or directory”,具体详见：http://stackoverflow.com/questions/22555561/error-building-fatal-error-pcre-h-no-such-file-or-directory需要安装 libpcre3-dev,命令为：sudo apt-get install libpcre3-dev#安装nginx：sudo make install#启动nginx：sudo /usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf注意：-c 指定配置文件的路径，不加的话，nginx会自动加载默认路径的配置文件，可以通过 -h查看帮助命令。#查看nginx进程：ps -ef|grep nginx Nginx 常用命令启动 Nginx切换到 /usr/local/nginx/sbin/ 目录下，执行命令 1./nginx 查看效果： 停止 Nginx12./nginx -s stop./nginx -s quit -s 都是采用向 Nginx 发送信号的方式。 Nginx 重新加载配置文件1./nginx -s reload 指定配置文件1./nginx -c /usr/local/nginx/conf/nginx.conf -c 表示 configuration，指定配置文件 查看 Nginx 版本12./nginx -v //查看 Nginx 版本信息的参数./nginx -V //查看 Nginx 详细的版本信息 检查配置文件是否正确1./nginx -t 如果出现测试失败，表示没有访问错误日志文件和进程，可以 sudo 一下。配置正确的话会有相关的提示。 显示帮助信息123./nginx -h或者./nginx -? Nginx 的特点和应用场合见文章：Nginx 基本知识快速入门 最后文章首发地址：zhisheng的博客 ，转载请注明地址 http://www.54tianzhisheng.cn/2017/08/18/Ubuntu-install-Nginx/","tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://yoursite.com/tags/Nginx/"}]},{"title":"马云热血励志演讲《最伟大的成功》","date":"2017-08-11T13:56:34.713Z","path":"2017/08/11/most-success/","text":"当你乐观的时候，总是会有机会的。那么你可能要问了“机会在哪呢？”你可能没有特别想实现的事，没有迫切要成功的欲望，没有勇攀高峰的决心，没有水滴石穿的毅力，也没有一颗所向披靡的强大心脏。那么，让来自马云的这段演讲来告诉你，你有什么。你有年轻的身体，你有奇妙的想法，你有乐观的心态，你有无限的可能性。 我想，马云的这段励志演讲为我们提供了一面镜子可以用于自照。上面“你有什么”说完了，接下来让我讨论一下“你可能没有什么”。 你总爱抱怨，机会却总是躲在人们抱怨的地方。你没有仔细想想怎么能把事情做得不一样。你没有行动力，你缺少坚持下去的长劲儿。你抗压能力差，你动不动就玻璃心。你不相信自己也不相信别人，你怕犯错。现在是不是觉得这碗鸡汤有点难以下咽了？如果认识到差距，不如从今天开始改变。明天的你只要比今天的你多迈出0.1步，也是进步。 为自己而工作。停止抱怨，用抱怨的时间多做事。把那些夜里冒出来的好点子在白天付诸行动，既然有了设想，那就行动起来。行动是你迈出的第一步，后面可能会更难，历经无数次动摇，面临无数次诱惑，感受无数次失败的苦味和难以为继的辛酸。顶住这一切，比常人更勇敢地去面对，并且坚持下去。排除万难，别被来自世人的非议和质疑影响。相信你自己，相信你的团队。服务好你的客户，之后再想怎么回馈社会。犯足够多的错，年轻时走过的弯路是最棒的收获。 马云还曾经说过“今天很艰难，明天比今天更难，后天可能是美好的，但更多的人死在了明天”。是不是感到膝盖中箭了？不妨干了这碗“毒鸡汤”。成功的法则本就并非千篇一律，你会有你自己向上的学问。那不如从明天开始，去摸索，去践行，哪怕只比昨天的你多迈出0.01步。 送给正在找实习工作的自己！加油！！！","tags":[{"name":"励志","slug":"励志","permalink":"http://yoursite.com/tags/励志/"}]},{"title":"Nginx 基本知识快速入门","date":"2017-08-05T12:41:33.497Z","path":"2017/08/05/Nginx/","text":"什么是 Nginx？Nginx 是一个高性能的 HTTP 和反向代理服务器，以高稳定性、丰富的功能集、示例配置文件和低系统资源的消耗而闻名。 Nginx 特点 处理静态文件，索引文件以及自动索引；打开文件描述符缓冲． 无缓存的反向代理加速，简单的负载均衡和容错． FastCGI，简单的负载均衡和容错． 模块化的结构。包括 gzipping, byte ranges, chunked responses,以及 SSI-filter 等 filter。如果由 FastCGI 或其它代理服务器处理单页中存在的多个 SSI，则这项处理可以并行运行，而不需要相互等待。 支持 SSL 和 TLSSNI． 主要应用场合1、静态 HTTP 服务器首先，Nginx是一个 HTTP 服务器，可以将服务器上的静态文件（如 HTML、图片）通过 HTTP 协议展现给客户端。 配置： 123456server &#123; listen 80; # 端口号 location / &#123; root /usr/share/nginx/html; # 静态文件路径 &#125;&#125; 2、反向代理服务器什么是反向代理？ 客户端本来可以直接通过 HTTP 协议访问某网站应用服务器，如果网站管理员在中间加上一个 Nginx，客户端请求Nginx，Nginx 请求应用服务器，然后将结果返回给客户端，此时 Nginx 就是反向代理服务器。 配置： 123456server &#123; listen 80; location / &#123; proxy_pass http://192.168.20.1:8080; # 应用服务器HTTP地址 &#125;&#125; 既然服务器可以直接 HTTP 访问，为什么要在中间加上一个反向代理，不是多此一举吗？反向代理有什么作用？继续往下看，下面的负载均衡、虚拟主机，都基于反向代理实现，当然反向代理的功能也不仅仅是这些。 3、负载均衡当网站访问量非常大，网站站长开心赚钱的同时，也摊上事儿了。因为网站越来越慢，一台服务器已经不够用了。于是将相同的应用部署在多台服务器上，将大量用户的请求分配给多台机器处理。同时带来的好处是，其中一台服务器万一挂了，只要还有其他服务器正常运行，就不会影响用户使用。 当我们网站进行大的升级更新时，我们不可能直接将所有的服务器都关掉，然后再升级的。通常我们都是批量的关掉一些服务器，去升级网站，当有用户的请求时则分配给其他还在运作的机器处理。当之前关掉的机器更新完成后，再次开启，然后又批量关掉部分机器，如上循环，直到最后全部机器都更新完成。这样就不会影响用户使用。 Nginx 可以通过反向代理来实现负载均衡。 配置： 12345678910upstream myapp &#123; server 192.168.20.1:8080; # 应用服务器1 server 192.168.20.2:8080; # 应用服务器2&#125;server &#123; listen 80; location / &#123; proxy_pass http://myapp; &#125;&#125; 4、虚拟主机网站访问量大，需要负载均衡。然而并不是所有网站都如此出色，有的网站，由于访问量太小，需要节省成本，将多个网站部署在同一台服务器上。 例如将 www.aaa.com 和 www.bbb.com 两个网站部署在同一台服务器上，两个域名解析到同一个 IP 地址，但是用户通过两个域名却可以打开两个完全不同的网站，互相不影响，就像访问两个服务器一样，所以叫两个虚拟主机。 配置： 12345678910111213141516171819server &#123; listen 80 default_server; server_name _; return 444; # 过滤其他域名的请求，返回444状态码&#125;server &#123; listen 80; server_name www.aaa.com; # www.aaa.com域名 location / &#123; proxy_pass http://localhost:8080; # 对应端口号8080 &#125;&#125;server &#123; listen 80; server_name www.bbb.com; # www.bbb.com域名 location / &#123; proxy_pass http://localhost:8081; # 对应端口号8081 &#125;&#125; 在服务器 8080 和 8081 两个端口分别开了一个应用，客户端通过不同的域名访问，根据 server_name 可以反向代理到对应的应用服务器。 虚拟主机的原理是通过 HTTP 请求头中的 Host 是否匹配 server_name 来实现的，有兴趣的同学可以研究一下 HTTP 协议。 另外，server_name 配置还可以过滤有人恶意将某些域名指向你的主机服务器。 5、FastCGINginx 本身不支持 PHP 等语言，但是它可以通过 FastCGI 来将请求扔给某些语言或框架处理（例如 PHP、Python、Perl）。 123456789server &#123; listen 80; location ~ \\.php$ &#123; include fastcgi_params; fastcgi_param SCRIPT_FILENAME /PHP文件路径$fastcgi_script_name; # PHP文件路径 fastcgi_pass 127.0.0.1:9000; # PHP-FPM地址和端口号 # 另一种方式：fastcgi_pass unix:/var/run/php5-fpm.sock; &#125;&#125; 配置中将 .php 结尾的请求通过 FashCGI 交给 PHP-FPM 处理，PHP-FPM 是 PHP 的一个 FastCGI 管理器。有关FashCGI 可以查阅其他资料，本文不再介绍。 fastcgi_pass 和 proxy_pass 有什么区别？下面一张图带你看明白： 参考资料1、Nginx基本功能极速入门 2、Nginx 学习笔记","tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://yoursite.com/tags/Nginx/"}]},{"title":"秋招第三站 —— 内推阿里（一面）","date":"2017-08-04T03:36:52.742Z","path":"2017/08/04/alibaba/","text":"3、阿里巴巴（菜鸟网络部门）（一面 49 分钟）2017.08.02 晚上9点21打电话过来，预约明天什么时候有空面试，约好第二天下午两点。 2017.08.03 下午两点10分打过来了。 说看了我的博客和 GitHub，觉得我学的还行，知识广度都还不错，但是还是要问问具体情况，为什么没看到你春招的记录，什么原因没投阿里？非得说一个原因，那就是：我自己太菜了，不敢投。1、先自我介绍 2、什么是多态？哪里体现了多态的概念？ 3、HashMap 源码分析，把里面的东西问了个遍？最后问是不是线程安全？引出 ConcurrentHashMap 4、ConcurrentHashMap 源码分析 5、类加载，双亲委托机制 6、Java内存模型（一开始说的不是他想要的，主要想问我堆和栈的细节） 7、垃圾回收算法 8、线程池，自己之前看过，所以说的比较多，最后面试官说了句：看你对线程池了解还是很深了 9、事务的四种特性 10、什么是死锁？ 11、乐观锁和悲观锁的策略 12、高可用网站的设计（有什么技术实现） 13、低耦合高内聚 14、设计模式了解不？你用过哪几种，为什么用，单例模式帮我们做什么东西？有什么好处？ 15、你参与什么项目中成长比较快？学到了什么东西，以前是没有学过的？ 16、项目中遇到的最大困难是怎样的？是怎么解决的？ 17、智力题（两根不均匀的香，点一头烧完要一个小时，怎么确定15分钟） 18、你有什么问题想要问我的？ 19、问了菜鸟网络他们部门主要做什么？ 20、对我这次面试做个评价：看了你博客和 GitHub，知道你对学习的热情还是很高的，花了不少功夫，但是有些东西还是需要加强深度，阿里需要那种对技术有深度，有自己独到见解的人才。意思就是 GG 了。 总结：面试总的来说，第一次电话面试，感觉好紧张，好多问题自己会点，但是其中的细节没弄清楚，自己准备的也不够充分。面试官很友好，看到我紧张，也安慰我说不要紧，不管以后出去面试啥的，不需要紧张，公司问的问题可能很广，你只需要把你知道的说出来就行，不会的直接说不会就行。之前一直不敢投阿里，因为自己准备的完全不够充分，但是在朋友磊哥的帮助下，还是试了下，不管结果怎么样，经历过总比没有的好。","tags":[{"name":"面经","slug":"面经","permalink":"http://yoursite.com/tags/面经/"}]},{"title":"秋招第二站 —— 内推爱奇艺（一面二面）","date":"2017-08-04T03:34:33.403Z","path":"2017/08/04/iqiyi/","text":"第 2 站 、爱奇艺 后端 Java 开发实习生笔试（半个小时）题目：（记得一些） 1、重载重写的区别？ 2、转发和重定向的区别？3、画下 HashMap 的结构图？HashMap 、 HashTable 和 ConcurrentHashMap 的区别？ 4、statement 和 preparedstatement 区别？ 5、JSP 中一个 中取值与直接取值的区别？会有什么安全问题？ 6、实现一个线程安全的单例模式 7、一个写 sql 语句的题目 8、自己实现一个 List，（主要实现 add等常用方法） 9、Spring 中 IOC 和 AOP 的理解？ 10、两个对象的 hashcode 相同，是否对象相同？equal() 相同呢？ 11、@RequestBody 和 @ResponseBody 区别？ 12、JVM 一个错误，什么情况下会发生？ 13、常用的 Linux 命令？ 第一轮面试（80 分钟）1、自我介绍 2、介绍你最熟悉的一个项目 3、讲下这个 XSS 攻击 4、HashMap 的结构？HashMap 、 HashTable 和 ConcurrentHashMap 的区别？ 5、HashMap 中怎么解决冲突的？（要我详细讲下） 6、ConcurrentHashMap 和 HashTable 中线程安全的区别？为啥建议用 ConcurrentHashMap ？能把 ConcurrentHashMap 里面的实现详细的讲下吗？ 7、Session 和 Cookie 的区别？ 8、你项目中登录是怎样做的，用的 Cookie 和 Session？ 9、讲讲你对 Spring 中的 IOC 和 AOP 的理解？ 10、问了好几个注解的作用？ 11、statement 和 preparedstatement 区别？ 12、$ 和 # 的区别？以及这两个在哪些地方用？ 13、前面项目介绍了数据是爬虫爬取过来的，那你讲讲你的爬虫是多线程的吧？ 14、讲讲 Python 中的多线程和 Java 中的多线程区别？ 15、自己刚好前几天在看线程池，立马就把面试官带到我熟悉的线程池，和面试官讲了下 JDK 自带的四种线程池、ThreadPoolExecutor 类中的最重要的构造器里面的七个参数，然后再讲了下线程任务进入线程池和核心线程数、缓冲队列、最大线程数量比较。 16、线程同步，你了解哪几种方式？ 17、讲下 Synchronized？ 18、讲下 RecentLock 可重入锁？ 什么是可重入锁？为什么要设计可重入锁？ 19、讲下 Volatile 吧？他是怎样做到同步的？ 20、Volatile 为什么不支持原子性？举个例子 21、Atomic 怎么设计的？（没看过源码，当时回答错了，后来才发现里面全部用 final 修饰的属性和方法） 22、问几个前端的标签吧？（问了一个不会，直接说明我偏后端，前端只是了解，后面就不问了） 23、SpringBoot 的了解？ 24、Linux 常用命令？ 25、JVM 里的几个问题？ 26、事务的特性？ 27、隔离级别？ 28、网络状态码？以 2、3、4、5 开头的代表什么意思。 29、并发和并行的区别？ 30、你有什么问题想问我的？ 一面面完后面试官和说这份试卷是用来考 1~3 年开发工作经验的，让我准备一下，接下来的二面。 第二轮面试（半个小时）1、一上来就问怎么简历名字都没有，我指了简历第一行的我的名字，还特意大写了，然后就问学校是不是在上海，我回答在南昌（感觉被鄙视了一波，后面我在回答问题的时候面试官就一直在玩手机，估计后面对我的印象就不是很好了） 2、自我介绍 3、说一说数据库建表吧（从范式讲） 4、讲讲多态？（这个我答出来了，可是面试官竟然说不是这样吧，可能面试官没听请，后面还说我是不是平时写多态比较少，感觉这个也让面试官对我印象减分） 5、将两个数转换（不借助第三个参数） 6、手写个插入排序吧（写完了和面试官讲了下执行流程） 7、讲讲你对 Spring 中的 IOC 和 AOP 的理解？ 8、问了几个常用的 Linux 命令？ 9、也问到多线程？和一面一样把自己最近看的线程池也讲了一遍 10、学 Java 多久了？ 11、你有什么想问的？ 总结：面试题目大概就是这么多了，有些问题自己也忘记了，面试题目顺序不一定是按照上面所写的。再次感谢爱奇艺的第一面面试官了，要不是他帮忙内推的，我可能还没有机会收到面试机会。自己接到爱奇艺面试邀请电话是星期一晚上快7点中的，之后加了面试官微信约好了星期四面试的（时间准备较短，之前没系统的复习过）。星期四一大早（5点就起床了），然后就收拾了下，去等公交车，转了两次车，然后再做地铁去爱奇艺公司的，总共路上花费时间四个多小时。总的来说，这次面试准备的时间不是很充裕，所以准备的个人觉得不是很好，通过这次的面试，发现面试还是比较注重基础和深度的，我也知道了自己的一些弱处，还需要在哪里加强，面试技巧上也要掌握些。为后面的其他公司继续做好充足的准备。加油！！！","tags":[{"name":"面经","slug":"面经","permalink":"http://yoursite.com/tags/面经/"}]},{"title":"秋招第一站 —— 亚信科技","date":"2017-08-04T03:30:50.681Z","path":"2017/08/04/yaxin/","text":"第 1 站、亚信科技 Java 开发1）自我介绍（说到一个亮点：长期坚持写博客，面试官觉得这个习惯很好，算加分项吧） 2）看到简历项目中用到 Solr，详细的问了下 Solr（自己介绍了下 Solr 的使用场景和建立索引等东西）3）项目里面写了一个 “ 敏感词和 JS 标签过滤防 XSS 攻击”，面试官让我讲了下这个 XSS 攻击，并且是怎样实现的 4）项目里写了支持 Markdown，问是不是自己写的解析代码，（回答不是，自己引用的是 GitHub上的一个开源项目解析的） 5）想问我前端的知识，我回复到：自己偏后端开发，前端只是了解，然后面试官就不问了 6）问我考不考研？ 7）觉得杭州怎么样？是打算就呆在杭州还是把杭州作为一个跳板？ 8）有啥小目标？以后是打算继续技术方向，还是先技术后管理（还开玩笑的说：是不是赚他几个亿，当时我笑了笑） 9）有啥兴趣爱好？ 大概就记得这么多了，目前已经拿到 Offer 了。 总结：面试问的问题不算多，主要是通过简历上项目所涉及的东西提问的，如果自己不太会的切记不要写上去。面试主要考察你回答问题来判断你的逻辑是否很清楚。","tags":[{"name":"面经","slug":"面经","permalink":"http://yoursite.com/tags/面经/"}]},{"title":"Java 线程池艺术探索","date":"2017-07-29T14:27:44.446Z","path":"2017/07/29/ThreadPool/","text":"线程池Wiki 上是这样解释的：Thread Pool 作用：利用线程池可以大大减少在创建和销毁线程上所花的时间以及系统资源的开销！ 下面主要讲下线程池中最重要的一个类 ThreadPoolExecutor 。 ThreadPoolExecutor ThreadPoolExecutor 构造器： 有四个构造器的，挑了参数最长的一个进行讲解。 七个参数： corePoolSize：核心池的大小，在创建了线程池后，默认情况下，线程池中并没有任何线程，而是等待有任务到来才创建线程去执行任务，当有任务来之后，就会创建一个线程去执行任务，当线程池中的线程数目达到corePoolSize后，就会把到达的任务放到缓存队列当中； maximumPoolSize：线程池最大线程数； keepAliveTime：表示线程没有任务执行时最多保持多久时间会终止； unit：参数keepAliveTime的时间单位（DAYS、HOURS、MINUTES、SECONDS 等）； workQueue：阻塞队列，用来存储等待执行的任务； ArrayBlockingQueue （有界队列） LinkedBlockingQueue （无界队列） SynchronousQueue threadFactory：线程工厂，主要用来创建线程 handler：拒绝处理任务的策略 AbortPolicy：丢弃任务并抛出 RejectedExecutionException 异常。（默认这种） DiscardPolicy：也是丢弃任务，但是不抛出异常 DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程） CallerRunsPolicy：由调用线程处理该任务 重要方法： execute()：通过这个方法可以向线程池提交一个任务，交由线程池去执行； shutdown()：关闭线程池； execute() 方法： 注：JDK 1.7 和 1.8 这个方法有点区别，下面代码是 1.8 中的。 1234567891011121314151617181920212223public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); int c = ctl.get(); //1、如果当前的线程数小于核心线程池的大小，根据现有的线程作为第一个 Worker 运行的线程，新建一个 Worker，addWorker 自动的检查当前线程池的状态和 Worker 的数量，防止线程池在不能添加线程的状态下添加线程 if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get(); &#125; //2、如果线程入队成功，然后还是要进行 double-check 的，因为线程在入队之后状态是可能会发生变化的 if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); // recheck 防止线程池状态的突变，如果突变，那么将 reject 线程，防止 workQueue 中增加新线程 if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0)//上下两个操作都有 addWorker 的操作，但是如果在workQueue.offer 的时候 Worker 变为 0，那么将没有 Worker 执行新的 task，所以增加一个 Worker. addWorker(null, false); &#125; //3、如果 task 不能入队(队列满了)，这时候尝试增加一个新线程，如果增加失败那么当前的线程池状态变化了或者线程池已经满了然后拒绝task else if (!addWorker(command, false)) reject(command); &#125; 其中调用了 addWorker() 方法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768private boolean addWorker(Runnable firstTask, boolean core) &#123;// firstTask: 新增一个线程并执行这个任务，可空，增加的线程从队列获取任务；core：是否使用 corePoolSize 作为上限，否则使用 maxmunPoolSize retry: for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. /** * rs!=Shutdown || fistTask！=null || workQueue.isEmpty * 如果当前的线程池的状态 &gt; SHUTDOWN 那么拒绝 Worker 的 add 如果 =SHUTDOWN * 那么此时不能新加入不为 null 的 Task，如果在 workQueue 为 empty 的时候不能加入任何类型的 Worker， * 如果不为 empty 可以加入 task 为 null 的 Worker, 增加消费的 Worker */ if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp;! workQueue.isEmpty())) return false; for (;;) &#123; int wc = workerCountOf(c); //如果当前的数量超过了 CAPACITY，或者超过了 corePoolSize 和 maximumPoolSize（试 core 而定） if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; //CAS 尝试增加线程数，如果失败，证明有竞争，那么重新到 retry。 if (compareAndIncrementWorkerCount(c))// AtomicInteger 的 CAS 操作; break retry; c = ctl.get(); // Re-read ctl //判断当前线程池的运行状态,状态发生改变，重试 retry; if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop &#125; &#125; boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try &#123; w = new Worker(firstTask);// Worker 为内部类，封装了线程和任务，通过 ThreadFactory 创建线程，可能失败抛异常或者返回 null final Thread t = w.thread; if (t != null) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int rs = runStateOf(ctl.get()); if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; if (t.isAlive()) // precheck that t is startable // SHUTDOWN 以后的状态和 SHUTDOWN 状态下 firstTask 为 null，不可新增线程 throw new IllegalThreadStateException(); workers.add(w); int s = workers.size(); if (s &gt; largestPoolSize) largestPoolSize = s;//记录最大线程数 workerAdded = true; &#125; &#125; finally &#123; mainLock.unlock(); &#125; if (workerAdded) &#123; t.start(); workerStarted = true; &#125; &#125; &#125; finally &#123; if (! workerStarted) addWorkerFailed(w);//失败回退,从 wokers 移除 w, 线程数减一，尝试结束线程池(调用tryTerminate 方法) &#125; return workerStarted; &#125; 示意图： 执行流程： 1、当有任务进入时，线程池创建线程去执行任务，直到核心线程数满为止 2、核心线程数量满了之后，任务就会进入一个缓冲的任务队列中 当任务队列为无界队列时，任务就会一直放入缓冲的任务队列中，不会和最大线程数量进行比较 当任务队列为有界队列时，任务先放入缓冲的任务队列中，当任务队列满了之后，才会将任务放入线程池，此时会与线程池中最大的线程数量进行比较，如果超出了，则默认会抛出异常。然后线程池才会执行任务，当任务执行完，又会将缓冲队列中的任务放入线程池中，然后重复此操作。 shutdown() 方法： 1234567891011121314151617public void shutdown() &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; //判断是否可以操作目标线程 checkShutdownAccess(); //设置线程池状态为 SHUTDOWN, 此处之后，线程池中不会增加新 Task advanceRunState(SHUTDOWN); //中断所有的空闲线程 interruptIdleWorkers(); onShutdown(); // hook for ScheduledThreadPoolExecutor &#125; finally &#123; mainLock.unlock(); &#125; //转到 Terminate tryTerminate(); &#125; 参考资料：深入理解java线程池—ThreadPoolExecutor JDK 自带四种线程池分析与比较 1、newFixedThreadPool创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。 2、newSingleThreadExecutor创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。 3、newCachedThreadPool创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。 4、newScheduledThreadPool创建一个定长线程池，支持定时及周期性任务执行。 四种线程池其实内部方法都是调用的 ThreadPoolExecutor 类，只不过利用了其不同的构造器方法而已（传入自己需要传入的参数），那么利用这个特性，我们自己也是可以实现自己定义的线程池的。 自定义线程池1、创建任务类 12345678910111213141516171819202122232425262728293031323334353637package com.zhisheng.thread.threadpool.demo;/** * Created by 10412 on 2017/7/24. * 任务 */public class MyTask implements Runnable&#123; private int taskId; //任务 id private String taskName; //任务名字 public int getTaskId() &#123; return taskId; &#125; public void setTaskId(int taskId) &#123; this.taskId = taskId; &#125; public String getTaskName() &#123; return taskName; &#125; public void setTaskName(String taskName) &#123; this.taskName = taskName; &#125; public MyTask(int taskId, String taskName) &#123; this.taskId = taskId; this.taskName = taskName; &#125; @Override public void run() &#123; System.out.println(\"当前正在执行 ****** 线程Id--&gt;\" + taskId + \",任务名称--&gt;\" + taskName); try &#123; Thread.currentThread().sleep(5 * 1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(\"线程Id--&gt;\" + taskId + \",任务名称--&gt;\" + taskName + \" ----------- 执行完毕！\"); &#125;&#125; 2、自定义拒绝策略，实现 RejectedExecutionHandler 接口，重写 rejectedExecution 方法 12345678910111213141516package com.zhisheng.thread.threadpool.demo;import java.util.concurrent.RejectedExecutionHandler;import java.util.concurrent.ThreadPoolExecutor;/** * Created by 10412 on 2017/7/24. * 自定义拒绝策略，实现 RejectedExecutionHandler 接口 */public class RejectedThreadPoolHandler implements RejectedExecutionHandler&#123; public RejectedThreadPoolHandler() &#123; &#125; @Override public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) &#123; System.out.println(\"WARNING 自定义拒绝策略: Task \" + r.toString() + \" rejected from \" + executor.toString()); &#125;&#125; 3、创建线程池 1234567891011121314151617181920212223242526272829303132package com.zhisheng.thread.threadpool.demo;import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;/** * Created by 10412 on 2017/7/24. */public class ThreadPool&#123; public static void main(String[] args) &#123; //核心线程数量为 2，最大线程数量 4，空闲线程存活的时间 60s，有界队列长度为 3, //ThreadPoolExecutor pool = new ThreadPoolExecutor(2, 4, 60, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(3)); //核心线程数量为 2，最大线程数量 4，空闲线程存活的时间 60s， 无界队列, //ThreadPoolExecutor pool = new ThreadPoolExecutor(2, 4, 60L, TimeUnit.SECONDS, new LinkedBlockingDeque&lt;&gt;()); //核心线程数量为 2，最大线程数量 4，空闲线程存活的时间 60s，有界队列长度为 3, 使用自定义拒绝策略 ThreadPoolExecutor pool = new ThreadPoolExecutor(2, 4, 60, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(3), new RejectedThreadPoolHandler()); for (int i = 1; i &lt;= 10; i++) &#123; //创建 10 个任务 MyTask task = new MyTask(i, \"任务\" + i); //运行 pool.execute(task); System.out.println(\"活跃的线程数：\"+pool.getActiveCount() + \",核心线程数：\" + pool.getCorePoolSize() + \",线程池大小：\" + pool.getPoolSize() + \",队列的大小\" + pool.getQueue().size()); &#125; //关闭线程池 pool.shutdown(); &#125;&#125; 这里运行结果就不截图了，我在本地测试了代码是没问题的，感兴趣的建议还是自己跑一下，然后分析下结果是不是和前面分析的一样，如有问题，请在我博客下面评论！ 总结本文一开始讲了线程池的介绍和好处，然后分析了线程池中最核心的 ThreadPoolExecutor 类中构造器的七个参数的作用、类中两个重要的方法，然后在对比研究了下 JDK 中自带的四种线程池的用法和内部代码细节，最后写了一个自定义的线程池。","tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"多线程","slug":"多线程","permalink":"http://yoursite.com/tags/多线程/"},{"name":"线程池","slug":"线程池","permalink":"http://yoursite.com/tags/线程池/"}]},{"title":"看透 Spring MVC 源代码分析与实践 ——  Spring MVC 组件分析","date":"2017-07-21T02:34:05.009Z","path":"2017/07/21/Spring-MVC03/","text":"由于星期一接到面试通知，和面试官约好了星期四面试，所以这几天没更新完这系列的文章，面完试后立马就把这个解决掉。通过这次面试，也让我懂得了很多，知道了自己的一些不足之处，后面还要继续下功夫好好的深入复习下去。这几篇文章写的我觉得还是不够仔细，感兴趣的还是建议自己去看看源码。 第 11 章 —— 组件概览HandlerMapping 根据 request 找到对应的处理器 Handler 和 Interceptors。内部只有一个方法1HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception; HandlerAdapter Handler 适配器，内部方法如下： 123boolean supports(Object handler);//判断是否可以使用某个 HandlerModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception; //具体使用long getLastModified(HttpServletRequest request, Object handler);//获取资源上一次修改的时间 HandlerExceptionResolver 根据异常设置 ModelAndView ，再交给 render 方法进行渲染。 12ModelAndView resolveException( HttpServletRequest request, HttpServletResponse response, @Nullable Object handler, Exception ex) ViewResolver 用来将 String 类型的视图名和 Locale 解析为 View 类型的视图。 1View resolveViewName(String viewName, Locale locale) throws Exception; 它的一个实现类 BeanNameViewResolver，它重写 resolveViewName 方法如下: 1234567891011121314151617181920212223public View resolveViewName(String viewName, Locale locale) throws BeansException &#123; ApplicationContext context = getApplicationContext(); //如果应用上下文没有找到视图，返回 null if (!context.containsBean(viewName)) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(\"No matching bean found for view name '\" + viewName + \"'\"); &#125; // Allow for ViewResolver chaining... return null; &#125; //如果找到的视图类型不匹配，也返回 null if (!context.isTypeMatch(viewName, View.class)) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(\"Found matching bean for view name '\" + viewName + \"' - to be ignored since it does not implement View\"); &#125; // Since we're looking into the general ApplicationContext here, // let's accept this as a non-match and allow for chaining as well... return null; &#125; //根据视图名称从 Spring 容器中查找 Bean，返回找到的 bean return context.getBean(viewName, View.class); &#125; RequestToViewNameTranslator 获取 request 中的视图名。接口里面也是只有一个方法： 1String getViewName(HttpServletRequest request) throws Exception; //根据 request 查找视图名 LocaleResolver 用于从 request 解析出 Locale。 123456public interface LocaleResolver &#123; //从 request 解析出 Locale Locale resolveLocale(HttpServletRequest request); //根据 request 设置 locale void setLocale(HttpServletRequest request, HttpServletResponse response, @Nullable Locale locale);&#125; ThemeResolver 解析主题 123456public interface ThemeResolver &#123; //通过给定的 request 查找主题名 String resolveThemeName(HttpServletRequest request); //根据给定的 request 设置主题名 void setThemeName(HttpServletRequest request, HttpServletResponse response, String themeName);&#125; 在 RequestContext.java 文件中可以获取主题： 1234567891011121314151617public String getThemeMessage(String code, String defaultMessage) &#123; //获取主题的信息 return getTheme().getMessageSource().getMessage(code, null, defaultMessage, this.locale); &#125;public Theme getTheme() &#123; //判断主题是否为空 if (this.theme == null) &#123; // 通过 RequestContextUtils 获取 request 中的主题名 this.theme = RequestContextUtils.getTheme(this.request); if (this.theme == null) &#123; //如果还是为空的话 //那就是没有有效的主题解析器和主题 this.theme = getFallbackTheme(); &#125; &#125; return this.theme; &#125; RequestContextUtils.getTheme() 方法： 1234567891011public static Theme getTheme(HttpServletRequest request) &#123; ThemeResolver themeResolver = getThemeResolver(request); ThemeSource themeSource = getThemeSource(request); if (themeResolver != null &amp;&amp; themeSource != null) &#123; String themeName = themeResolver.resolveThemeName(request); return themeSource.getTheme(themeName); &#125; else &#123; return null; &#125; &#125; MultipartResolver 用于处理上传请求，处理方法：将普通的 request 包装成 MultipartHttpServletRequest 12345678public interface MultipartResolver &#123; //根据 request 判断是否是上传请求 boolean isMultipart(HttpServletRequest request); //将 request 包装成 MultipartHttpServletRequest MultipartHttpServletRequest resolveMultipart(HttpServletRequest request) throws MultipartException; //清理上传过程中产生的临时资源 void cleanupMultipart(MultipartHttpServletRequest request);&#125; FlashMapManager FlashMap 主要在 redirect 中传递参数，FlashMapManager 用来管理 FlashMap 的。 1234567public interface FlashMapManager &#123; //恢复参数，并将恢复过的和超时的参数从保存介质中删除 @Nullable FlashMap retrieveAndUpdate(HttpServletRequest request, HttpServletResponse response); //将参数保存起来 void saveOutputFlashMap(FlashMap flashMap, HttpServletRequest request, HttpServletResponse response);&#125; 小结介绍 Spring MVC 中九大组件的接口、作用、内部方法实现及作用进行了简单的介绍，详细的还需大家自己去看源码。 总结Spring MVC 原理总结本质是一个 Servlet，这个 Servlet 继承自 HttpServlet。Spring MVC 中提供了三个层次的 Servlet：HttpServletBean、FrameworkServlet 和 DispatcherServlet。他们相互继承， HttpServletBean 直接继承自 Java 的 HttpServlet。HttpServletBean 用于将 Servlet 中的 Servlet 中配置的参数设置到相应的属性中，FrameworkServlet 初始化了 Spring MVC 中所使用的 WebApplicationContext，具体处理请求的 9 大组件是在 DispatcherServlet 中初始化的，整个继承图如下： 最后文章可转发，但请注明原创地址，谢谢支持。","tags":[{"name":"Spring MVC","slug":"Spring-MVC","permalink":"http://yoursite.com/tags/Spring-MVC/"}]},{"title":"看透 Spring MVC 源代码分析与实践 ——  俯视 Spring MVC","date":"2017-07-14T11:15:25.357Z","path":"2017/07/14/Spring-MVC02/","text":"Spring MVC Spring MVC 之初体验环境搭建在 IDEA 中新建一个 web 项目，用 Maven 管理项目的话，在 pom.xml 中加入 Spring MVC 和 Servlet 依赖即可。 12345678910111213&lt;!-- https://mvnrepository.com/artifact/org.springframework/spring-webmvc --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;4.3.9.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/javax.servlet/javax.servlet-api --&gt;&lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; Spring MVC 简单配置 在 web.xml 中配置 Servlet 创建 Spring MVC 的 xml 配置文件 创建 Controller 和 View 1、web.xml 12345678910111213141516171819202122232425262728293031323334&lt;!-- Spring MVC配置 --&gt;&lt;!-- ====================================== --&gt;&lt;servlet&gt; &lt;servlet-name&gt;spring&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;!-- 可以自定义servlet.xml配置文件的位置和名称，默认为WEB-INF目录下，名称为[&lt;servlet-name&gt;]-servlet.xml，如spring-servlet.xml &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;/WEB-INF/spring-servlet.xml&lt;/param-value&gt;&amp;nbsp; 默认 &lt;/init-param&gt; --&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;spring&lt;/servlet-name&gt; &lt;url-pattern&gt;*.do&lt;/url-pattern&gt;&lt;/servlet-mapping&gt;&lt;!-- Spring配置 --&gt;&lt;!-- ====================================== --&gt;&lt;listener&gt; &lt;listenerclass&gt; org.springframework.web.context.ContextLoaderListener &lt;/listener-class&gt;&lt;/listener&gt;&lt;!-- 指定Spring Bean的配置文件所在目录。默认配置在WEB-INF目录下 --&gt;&lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:config/applicationContext.xml&lt;/param-value&gt;&lt;/context-param&gt; 2、spring-servlet.xml 123456789101112131415161718192021&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:p=\"http://www.springframework.org/schema/p\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-3.0.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-3.0.xsd http://www.springframework.org/schema/context &lt;a href=\"http://www.springframework.org/schema/context/spring-context-3.0.xsd\"&gt;http://www.springframework.org/schema/context/spring-context-3.0.xsd&lt;/a&gt;\"&gt; &lt;!-- 启用spring mvc 注解 --&gt; &lt;context:annotation-config /&gt; &lt;!-- 设置使用注解的类所在的jar包 --&gt; &lt;context:component-scan base-package=\"controller\"&gt;&lt;/context:component-scan&gt; &lt;!-- 完成请求和注解POJO的映射 --&gt; &lt;bean class=\"org.springframework.web.servlet.mvc.annotation.AnnotationMethodHandlerAdapter\" /&gt; &lt;!-- 对转向页面的路径解析。prefix：前缀， suffix：后缀 --&gt; &lt;bean class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\" p:prefix=\"/jsp/\" p:suffix=\".jsp\" /&gt;&lt;/beans&gt; 3、Controller 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061package controller;import javax.servlet.http.HttpServletRequest;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestParam;import entity.User;@Controller //类似Struts的Actionpublic class TestController &#123; @RequestMapping(\"/test/login.do\") // 请求url地址映射，类似Struts的action-mapping public String testLogin(@RequestParam(value=\"username\")String username, String password, HttpServletRequest request) &#123; // @RequestParam是指请求url地址映射中必须含有的参数(除非属性 required=false, 默认为 true) // @RequestParam可简写为：@RequestParam(\"username\") if (!\"admin\".equals(username) || !\"admin\".equals(password)) &#123; return \"loginError\"; // 跳转页面路径（默认为转发），该路径不需要包含spring-servlet配置文件中配置的前缀和后缀 &#125; return \"loginSuccess\"; &#125; @RequestMapping(\"/test/login2.do\") public ModelAndView testLogin2(String username, String password, int age)&#123; // request和response不必非要出现在方法中，如果用不上的话可以去掉 // 参数的名称是与页面控件的name相匹配，参数类型会自动被转换 if (!\"admin\".equals(username) || !\"admin\".equals(password) || age &lt; 5) &#123; return new ModelAndView(\"loginError\"); // 手动实例化ModelAndView完成跳转页面（转发），效果等同于上面的方法返回字符串 &#125; return new ModelAndView(new RedirectView(\"../index.jsp\")); // 采用重定向方式跳转页面 // 重定向还有一种简单写法 // return new ModelAndView(\"redirect:../index.jsp\"); &#125; @RequestMapping(\"/test/login3.do\") public ModelAndView testLogin3(User user) &#123; // 同样支持参数为表单对象，类似于Struts的ActionForm，User不需要任何配置，直接写即可 String username = user.getUsername(); String password = user.getPassword(); int age = user.getAge(); if (!\"admin\".equals(username) || !\"admin\".equals(password) || age &lt; 5) &#123; return new ModelAndView(\"loginError\"); &#125; return new ModelAndView(\"loginSuccess\"); &#125; @Resource(name = \"loginService\") // 获取applicationContext.xml中bean的id为loginService的，并注入 private LoginService loginService; //等价于spring传统注入方式写get和set方法，这样的好处是简洁工整，省去了不必要得代码 @RequestMapping(\"/test/login4.do\") public String testLogin4(User user) &#123; if (loginService.login(user) == false) &#123; return \"loginError\"; &#125; return \"loginSuccess\"; &#125;&#125; @RequestMapping 可以写在方法上，也可以写在类上，上面代码方法上的 RequestMapping 都含有 /test ， 那么我们就可以将其抽出直接写在类上，那么方法里面就不需要写 /test 了。 如下即可： 12345678910111213141516@Controller@RequestMapping(\"/test\")public class TestController &#123; @RequestMapping(\"/login.do\") // 请求url地址映射，类似Struts的action-mapping public String testLogin(@RequestParam(value=\"username\")String username, String password, HttpServletRequest request) &#123; // @RequestParam是指请求url地址映射中必须含有的参数(除非属性 required=false, 默认为 true) // @RequestParam可简写为：@RequestParam(\"username\") if (!\"admin\".equals(username) || !\"admin\".equals(password)) &#123; return \"loginError\"; // 跳转页面路径（默认为转发），该路径不需要包含spring-servlet配置文件中配置的前缀和后缀 &#125; return \"loginSuccess\"; &#125; //省略其他的&#125; 上面的代码方法的参数中可以看到有一个 @RequestParam 注解，其实还有 @PathVariable 。这两个的区别是啥呢？ @PathVariable 标记在方法的参数上，利用它标记的参数可以利用请求路径传值。 @RequestParam是指请求url地址映射中必须含有的参数(除非属性 required=false, 默认为 true) 看如下例子： 123456789101112@RequestMapping(\"/user/&#123;userId&#125;\") // 请求url地址映射public String userinfo(Model model, @PathVariable(\"userId\") int userId, HttpSession session) &#123; System.out.println(\"进入 userinfo 页面\"); //判断是否有用户登录 User user1 = (User) session.getAttribute(\"user\"); if (user1 == null) &#123; return \"login\"; &#125; User user = userService.selectUserById(userId); model.addAttribute(\"user\", user); return \"userinfo\"; &#125; 上面例子中如果浏览器请求的是 /user/1 的时候，就表示此时的用户 id 为 1，此时就会先从 session 中查找是否有 “user” 属性，如果有的话，就代表用户此时处于登录的状态，如果没有的话，就会让用户返回到登录页面，这种机制在各种网站经常会使用的，然后根据这个 id = 1 ，去查找用户的信息，然后把查找的 “user” 放在 model 中，然后返回用户详情页面，最后在页面中用 $!{user.name} 获取用户的名字，同样的方式可以获取用户的其他信息，把所有的用户详情信息展示出来。 创建 Spring MVC 之器Spring MVC 核心 Servlet 架构图如下： Java 中常用的 Servlet 我在另外一篇文章写的很清楚了，有兴趣的请看：通过源码详解 Servlet ，这里我就不再解释了。 这里主要讲 Spring 中的 HttpServletBean、FrameworkServlet、DispatcherServlet 这三个类的创建过程。 通过上面的图，可以看到这三个类直接实现三个接口：EnvironmentCapable、EnvironmentAware、ApplicationContextAware。下面我们直接看下这三个接口的内部是怎样写的。 EnvironmentCapable.java 12345public interface EnvironmentCapable &#123; //返回组件的环境，可能返回 null 或者默认环境 @Nullable Environment getEnvironment();&#125; EnvironmentAware.java 1234public interface EnvironmentAware extends Aware &#123; //设置组件的运行环境 void setEnvironment(Environment environment);&#125; ApplicationContextAware.java 12345public interface ApplicationContextAware extends Aware &#123; //设置运行对象的应用上下文 //当类实现这个接口后，这个类可以获取ApplicationContext中所有的bean，也就是说这个类可以直接获取Spring配置文件中所有有引用到的bean对象 void setApplicationContext(ApplicationContext applicationContext) throws BeansException;&#125; 怎么使用这个这个接口呢？ 参考文章：org.springframework.context.ApplicationContextAware使用理解 HttpServletBean 这里就直接看其中最重要的 init() 方法的代码了： 12345678910111213141516171819202122232425262728293031323334/** * 将配置参数映射到此servlet的bean属性，并调用子类初始化。 * 如果 bean 配置不合法（或者需要的参数丢失）或者子类初始化发生错误，那么就会抛出 ServletException 异常 */@Overridepublic final void init() throws ServletException &#123; //日志代码删除了 // 从init参数设置bean属性。 //获得web.xml中的contextConfigLocation配置属性，就是spring MVC的配置文件 PropertyValues pvs = new ServletConfigPropertyValues(getServletConfig(), this.requiredProperties); if (!pvs.isEmpty()) &#123; try &#123; BeanWrapper bw = PropertyAccessorFactory.forBeanPropertyAccess(this); //获取服务器的各种信息 ResourceLoader resourceLoader = new ServletContextResourceLoader(getServletContext()); bw.registerCustomEditor(Resource.class, new ResourceEditor(resourceLoader, getEnvironment())); //模板方法，可以在子类中调用，做一些初始化工作，bw代表DispatcherServelt initBeanWrapper(bw); //将配置的初始化值设置到DispatcherServlet中 bw.setPropertyValues(pvs, true); &#125; catch (BeansException ex) &#123; //日志代码 throw ex; &#125; &#125; // Let subclasses do whatever initialization they like. //模板方法，子类初始化的入口方法 initServletBean(); //日志代码删除了&#125; FrameworkServlet 其中重要方法如下：里面也就两句关键代码，日志代码我直接删掉了 12345678910111213141516171819202122protected final void initServletBean() throws ServletException &#123; //日志代码删除了 long startTime = System.currentTimeMillis(); //就是 try 语句里面有两句关键代码 try &#123; //初始化 webApplicationContext this.webApplicationContext = initWebApplicationContext(); //模板方法， initFrameworkServlet(); &#125; catch (ServletException ex) &#123; this.logger.error(\"Context initialization failed\", ex); throw ex; &#125; catch (RuntimeException ex) &#123; this.logger.error(\"Context initialization failed\", ex); throw ex; &#125; //日志代码删除了 &#125; 再来看看上面代码中调用的 initWebApplicationContext() 方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344protected WebApplicationContext initWebApplicationContext() &#123; //获取 rootContext WebApplicationContext rootContext = WebApplicationContextUtils.getWebApplicationContext(getServletContext()); WebApplicationContext wac = null; if (this.webApplicationContext != null) &#123; // 上下文实例在构造时注入 - &gt;使用它 wac = this.webApplicationContext; if (wac instanceof ConfigurableWebApplicationContext) &#123; ConfigurableWebApplicationContext cwac = (ConfigurableWebApplicationContext) wac; if (!cwac.isActive()) &#123; // 如果上下文尚未刷新 -&gt; 提供诸如设置父上下文，设置应用程序上下文ID等服务 if (cwac.getParent() == null) &#123; // 上下文实例被注入没有显式的父类 -&gt; 将根应用程序上下文（如果有的话可能为null）设置为父级 cwac.setParent(rootContext); &#125; configureAndRefreshWebApplicationContext(cwac); &#125; &#125; &#125; if (wac == null) &#123; // 当 WebApplicationContext 已经存在 ServletContext 中时，通过配置在 servlet 中的 ContextAttribute 参数获取 wac = findWebApplicationContext(); &#125; if (wac == null) &#123; // 如果 WebApplicationContext 还没有创建，则创建一个 wac = createWebApplicationContext(rootContext); &#125; if (!this.refreshEventReceived) &#123; // 当 ContextRefreshedEvent 事件没有触发时调用此方法，模板方法，可以在子类重写 onRefresh(wac); &#125; if (this.publishContext) &#123; // 将 ApplicationContext 保存到 ServletContext 中去 String attrName = getServletContextAttributeName(); getServletContext().setAttribute(attrName, wac); if (this.logger.isDebugEnabled()) &#123; this.logger.debug(\"Published WebApplicationContext of servlet '\" + getServletName() + \"' as ServletContext attribute with name [\" + attrName + \"]\"); &#125; &#125; return wac; &#125; initWebApplicationContext 方法做了三件事： 获取 Spring 的根容器 rootContext 设置 webApplicationContext 并根据情况调用 onRefresh 方法 将 webApplicationContext 设置到 ServletContext 中 这里在讲讲上面代码中的 wac == null 的几种情况： 1）、当 WebApplicationContext 已经存在 ServletContext 中时，通过配置在 servlet 中的 ContextAttribute 参数获取，调用的是 findWebApplicationContext() 方法 123456789101112protected WebApplicationContext findWebApplicationContext() &#123; String attrName = getContextAttribute(); if (attrName == null) &#123; return null; &#125; WebApplicationContext wac = WebApplicationContextUtils.getWebApplicationContext(getServletContext(), attrName); if (wac == null) &#123; throw new IllegalStateException(\"No WebApplicationContext found: initializer not registered?\"); &#125; return wac; &#125; 2)、如果 WebApplicationContext 还没有创建，调用的是 createWebApplicationContext 方法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758protected WebApplicationContext createWebApplicationContext(@Nullable ApplicationContext parent) &#123; //获取创建类型 Class&lt;?&gt; contextClass = getContextClass(); //删除了打印日志代码 //检查创建类型 if (!ConfigurableWebApplicationContext.class.isAssignableFrom(contextClass)) &#123; throw new ApplicationContextException( \"Fatal initialization error in servlet with name '\" + getServletName() + \"': custom WebApplicationContext class [\" + contextClass.getName() + \"] is not of type ConfigurableWebApplicationContext\"); &#125; //具体创建 ConfigurableWebApplicationContext wac = (ConfigurableWebApplicationContext) BeanUtils.instantiateClass(contextClass); wac.setEnvironment(getEnvironment()); wac.setParent(parent); //并设置的 contextConfigLocation 参数传给 wac，默认是 WEB-INFO/[ServletName]-Servlet.xml wac.setConfigLocation(getContextConfigLocation()); //调用的是下面的方法 configureAndRefreshWebApplicationContext(wac); return wac; &#125;protected void configureAndRefreshWebApplicationContext(ConfigurableWebApplicationContext wac) &#123; if (ObjectUtils.identityToString(wac).equals(wac.getId())) &#123; // The application context id is still set to its original default value // -&gt; assign a more useful id based on available information if (this.contextId != null) &#123; wac.setId(this.contextId); &#125; else &#123; // Generate default id... wac.setId(ConfigurableWebApplicationContext.APPLICATION_CONTEXT_ID_PREFIX + ObjectUtils.getDisplayString(getServletContext().getContextPath()) + '/' + getServletName()); &#125; &#125; wac.setServletContext(getServletContext()); wac.setServletConfig(getServletConfig()); wac.setNamespace(getNamespace()); wac.addApplicationListener(new SourceFilteringListener(wac, new ContextRefreshListener())); // The wac environment's #initPropertySources will be called in any case when the context // is refreshed; do it eagerly here to ensure servlet property sources are in place for // use in any post-processing or initialization that occurs below prior to #refresh ConfigurableEnvironment env = wac.getEnvironment(); if (env instanceof ConfigurableWebEnvironment) &#123; ((ConfigurableWebEnvironment) env).initPropertySources(getServletContext(), getServletConfig()); &#125; postProcessWebApplicationContext(wac); applyInitializers(wac); wac.refresh(); &#125; 里面还有 doXXX() 方法，大家感兴趣的可以去看看。 DispatcherServlet DispatcherServlet 继承自 FrameworkServlet，onRefresh 方法是 DispatcherServlet 的入口方法，在 initStrategies 方法中调用了 9 个初始化的方法。 这里分析其中一个初始化方法：initLocaleResolver() 方法 123456789101112private void initLocaleResolver(ApplicationContext context) &#123; try &#123; //在 context 中获取 this.localeResolver = context.getBean(LOCALE_RESOLVER_BEAN_NAME, LocaleResolver.class); //删除了打印日志的代码 &#125; catch (NoSuchBeanDefinitionException ex) &#123; //使用默认的策略 this.localeResolver = getDefaultStrategy(context, LocaleResolver.class); //删除了打印日志的代码 &#125; &#125; 查看默认策略代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647protected &lt;T&gt; T getDefaultStrategy(ApplicationContext context, Class&lt;T&gt; strategyInterface) &#123; //调用 getDefaultStrategies 方法 List&lt;T&gt; strategies = getDefaultStrategies(context, strategyInterface); if (strategies.size() != 1) &#123; throw new BeanInitializationException( \"DispatcherServlet needs exactly 1 strategy for interface [\" + strategyInterface.getName() + \"]\"); &#125; return strategies.get(0); &#125; /** * Create a List of default strategy objects for the given strategy interface. * &lt;p&gt;The default implementation uses the \"DispatcherServlet.properties\" file (in the same * package as the DispatcherServlet class) to determine the class names. It instantiates * the strategy objects through the context's BeanFactory. */ @SuppressWarnings(\"unchecked\") protected &lt;T&gt; List&lt;T&gt; getDefaultStrategies(ApplicationContext context, Class&lt;T&gt; strategyInterface) &#123; String key = strategyInterface.getName(); //根据策略接口的名字从 defaultStrategies 获取所需策略的类型 String value = defaultStrategies.getProperty(key); if (value != null) &#123; //如果有多个默认值的话，就以逗号分隔为数组 String[] classNames = StringUtils.commaDelimitedListToStringArray(value); List&lt;T&gt; strategies = new ArrayList&lt;&gt;(classNames.length); //按获取到的类型初始化策略 for (String className : classNames) &#123; try &#123; Class&lt;?&gt; clazz = ClassUtils.forName(className, DispatcherServlet.class.getClassLoader()); Object strategy = createDefaultStrategy(context, clazz); strategies.add((T) strategy); &#125; catch (ClassNotFoundException ex) &#123; throw new BeanInitializationException( \"Could not find DispatcherServlet's default strategy class [\" + className + \"] for interface [\" + key + \"]\", ex); &#125; catch (LinkageError err) &#123; throw new BeanInitializationException( \"Error loading DispatcherServlet's default strategy class [\" + className + \"] for interface [\" + key + \"]: problem with class file or dependent class\", err); &#125; &#125; return strategies; &#125; else &#123; return new LinkedList&lt;&gt;(); &#125; &#125; 其他几个方法大概也类似，我就不再写了。 小结主要讲了 Spring MVC 自身创建过程，分析了 Spring MVC 中 Servlet 的三个层次：HttpServletBean、FrameworkServlet 和 DispatcherServlet。HttpServletBean 继承自 Java 的 HttpServlet，其作用是将配置的参数设置到相应的属性上；FrameworkServlet 初始化了 WebApplicationContext；DispatcherServlet 初始化了自身的 9 个组件。 Spring MVC 之用分析 Spring MVC 是怎么处理请求的。首先分析 HttpServletBean、FrameworkServlet 和 DispatcherServlet 这三个 Servlet 的处理过程，最后分析 doDispatcher 的结构。 HttpServletBean 参与了创建工作，并没有涉及请求的处理。 FrameworkServlet 在类中的 service() 、doGet()、doPost()、doPut()、doDelete()、doOptions()、doTrace() 这些方法中可以看到都调用了一个共同的方法 processRequest() ，它是类在处理请求中最核心的方法。 123456789101112131415161718192021222324252627282930313233343536373839404142protected final void processRequest(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; long startTime = System.currentTimeMillis(); Throwable failureCause = null; //获取 LocaleContextHolder 中原来保存的 LocaleContext LocaleContext previousLocaleContext = LocaleContextHolder.getLocaleContext(); //获取当前请求的 LocaleContext LocaleContext localeContext = buildLocaleContext(request); //获取 RequestContextHolder 中原来保存的 RequestAttributes RequestAttributes previousAttributes = RequestContextHolder.getRequestAttributes(); //获取当前请求的 ServletRequestAttributes ServletRequestAttributes requestAttributes = buildRequestAttributes(request, response, previousAttributes); WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); asyncManager.registerCallableInterceptor(FrameworkServlet.class.getName(), new RequestBindingInterceptor());//将当前请求的 LocaleContext 和 ServletRequestAttributes 设置到 LocaleContextHolder 和 RequestContextHolder initContextHolders(request, localeContext, requestAttributes); try &#123; //实际处理请求的入口，这是一个模板方法，在 Dispatcher 类中才有具体实现 doService(request, response); &#125;catch (ServletException ex) &#123; failureCause = ex; throw ex; &#125;catch (IOException ex) &#123; failureCause = ex; throw ex; &#125;catch (Throwable ex) &#123; failureCause = ex; throw new NestedServletException(\"Request processing failed\", ex); &#125;finally &#123; //将 previousLocaleContext，previousAttributes 恢复到 LocaleContextHolder 和 RequestContextHolder 中 resetContextHolders(request, previousLocaleContext, previousAttributes); if (requestAttributes != null) &#123; requestAttributes.requestCompleted(); &#125; //删除了日志打印代码 //发布了一个 ServletRequestHandledEvent 类型的消息 publishRequestHandledEvent(request, response, startTime, failureCause); &#125; &#125; DispatcherServlet 上一章中其实还没把该类讲清楚，在这个类中，里面的智行处理的入口方法应该是 doService 方法，方法里面调用了 doDispatch 进行具体的处理，在调用 doDispatch 方法之前 doService 做了一些事情：首先判断是不是 include 请求，如果是则对 request 的 Attribute 做个快照备份，等 doDispatcher 处理完之后（如果不是异步调用且未完成）进行还原 ，在做完快照后又对 request 设置了一些属性。 123456789101112131415161718192021222324252627282930313233343536373839protected void doService(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; // Keep a snapshot of the request attributes in case of an include, // to be able to restore the original attributes after the include. Map&lt;String, Object&gt; attributesSnapshot = null; if (WebUtils.isIncludeRequest(request)) &#123; attributesSnapshot = new HashMap&lt;&gt;(); Enumeration&lt;?&gt; attrNames = request.getAttributeNames(); while (attrNames.hasMoreElements()) &#123; String attrName = (String) attrNames.nextElement(); if (this.cleanupAfterInclude || attrName.startsWith(DEFAULT_STRATEGIES_PREFIX))&#123; attributesSnapshot.put(attrName, request.getAttribute(attrName)); &#125; &#125; &#125; // Make framework objects available to handlers and view objects. request.setAttribute(WEB_APPLICATION_CONTEXT_ATTRIBUTE, getWebApplicationContext()); request.setAttribute(LOCALE_RESOLVER_ATTRIBUTE, this.localeResolver); request.setAttribute(THEME_RESOLVER_ATTRIBUTE, this.themeResolver); request.setAttribute(THEME_SOURCE_ATTRIBUTE, getThemeSource()); FlashMap inputFlashMap = this.flashMapManager.retrieveAndUpdate(request, response); if (inputFlashMap != null) &#123; request.setAttribute(INPUT_FLASH_MAP_ATTRIBUTE, Collections.unmodifiableMap(inputFlashMap)); &#125; request.setAttribute(OUTPUT_FLASH_MAP_ATTRIBUTE, new FlashMap()); request.setAttribute(FLASH_MAP_MANAGER_ATTRIBUTE, this.flashMapManager); try &#123; //调用 doDispatch 方法 doDispatch(request, response); &#125;finally &#123; if (!WebAsyncUtils.getAsyncManager(request).isConcurrentHandlingStarted()) &#123; // Restore the original attribute snapshot, in case of an include. if (attributesSnapshot != null) &#123; restoreAttributesAfterInclude(request, attributesSnapshot); &#125; &#125; &#125; &#125; doDispatch() 方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; HttpServletRequest processedRequest = request; HandlerExecutionChain mappedHandler = null; boolean multipartRequestParsed = false; WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); try &#123; ModelAndView mv = null; Exception dispatchException = null; try &#123; //检查是不是上传请求 processedRequest = checkMultipart(request); multipartRequestParsed = (processedRequest != request); // Determine handler for the current request. 根据 request 找到 Handler mappedHandler = getHandler(processedRequest); if (mappedHandler == null || mappedHandler.getHandler() == null) &#123; noHandlerFound(processedRequest, response); return; &#125; // Determine handler adapter for the current request.根据 Handler 找到对应的 HandlerAdapter HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler()); // Process last-modified header, if supported by the handler. //处理 GET 、 HEAD 请求的 LastModified String method = request.getMethod(); boolean isGet = \"GET\".equals(method); if (isGet || \"HEAD\".equals(method)) &#123; long lastModified = ha.getLastModified(request, mappedHandler.getHandler()); if (logger.isDebugEnabled()) &#123; logger.debug(\"Last-Modified value for [\" + getRequestUri(request) + \"] is: \" + lastModified); &#125; if (new ServletWebRequest(request, response).checkNotModified(lastModified) &amp;&amp; isGet) &#123; return; &#125; &#125; //执行相应的 Interceptor 的 preHandle if (!mappedHandler.applyPreHandle(processedRequest, response)) &#123; return; &#125; // Actually invoke the handler. HandlerAdapter 使用 Handler 处理请求 mv = ha.handle(processedRequest, response, mappedHandler.getHandler()); //如果需要异步处理，直接返回 if (asyncManager.isConcurrentHandlingStarted()) &#123; return; &#125; //当 view 为空时，根据 request 设置默认 view applyDefaultViewName(processedRequest, mv); //执行相应 Interceptor 的 postHandler mappedHandler.applyPostHandle(processedRequest, response, mv); &#125;catch (Exception ex) &#123; dispatchException = ex; &#125;catch (Throwable err) &#123; // As of 4.3, we're processing Errors thrown from handler methods as well, // making them available for @ExceptionHandler methods and other scenarios. dispatchException = new NestedServletException(\"Handler dispatch failed\", err); &#125; //调用 processDispatchResult 方法处理上面处理之后的结果（包括处理异常，渲染页面，发出完成通知触发 Interceptor 的 afterCompletion） processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException); &#125;catch (Exception ex) &#123; triggerAfterCompletion(processedRequest, response, mappedHandler, ex); &#125;catch (Throwable err) &#123; triggerAfterCompletion(processedRequest, response, mappedHandler, new NestedServletException(\"Handler processing failed\", err)); &#125;finally &#123; //判断是否执行异步请求 if (asyncManager.isConcurrentHandlingStarted()) &#123; // Instead of postHandle and afterCompletion if (mappedHandler != null) &#123; mappedHandler.applyAfterConcurrentHandlingStarted(processedRequest, response); &#125; &#125;else &#123; // Clean up any resources used by a multipart request. 删除上传请求的资源 if (multipartRequestParsed) &#123; cleanupMultipart(processedRequest); &#125; &#125; &#125; &#125; Handler，HandlerMapping，HandlerAdapter 三个区别： Handler：处理器，对应 MVC 的 C层，也就是 Controller 层，具体表现形式有很多种，可以是类，方法，它的类型是 Object，只要可以处理实际请求就可以是 Handler。 HandlerMapping：用来查找 Handler 的。 HandlerAdapter ：Handler 适配器， 另外 View 和 ViewResolver 的原理与 Handler 和 HandlerMapping 的原理类似。 小结本章分析了 Spring MVC 的请求处理的过程。","tags":[{"name":"Spring MVC","slug":"Spring-MVC","permalink":"http://yoursite.com/tags/Spring-MVC/"}]},{"title":"看透 Spring MVC 源代码分析与实践 ——  网站基础知识","date":"2017-07-14T11:08:14.505Z","path":"2017/07/14/Spring-MVC01/","text":"网站架构及其演变过程基础结构网络传输分解方式： 标准的 OSI 参考模型 TCP/IP 参考模型 海量数据的解决方案 缓存和页面静态化 缓存 通过程序直接保存在内存中 使用缓存框架 （Encache、Redis、Memcache） 页面静态化 使用模板技术生成（Velocity、FreeMaker等） 数据库优化 表结构优化 SQL 语句优化 分区 分表 索引优化 使用存储过程代替直接操作过程 分离活跃数据 批量读取和延迟修改 读写分离 分布式数据库 NoSQL 和 Hadoop 高并发的解决方案 应用和静态资源的分离：静态文件（图片、视频、JS、CSS等）放在专门的服务器上 页面缓存（Nginx 服务器、Squid 服务器） 集群与分布式 反向代理 CDN 底层优化：网络传输协议 常见协议和标准TCP/IP 协议IP：查找地址，对应着国际互联网 TCP：规范传输规则，对应着传输层 TCP 在传输之前会进行三次沟通，称 “三次握手”，传完数据断开的时候要进行四次沟通，称 “四次挥手”。 TCP 两个序号，三个标志位含义： seq：表示所传数据的序号。TCP 传输时每一个字节都有一个序号，发送数据的时候会将数据的第一个序号发送给对方，接收方会按序号检查是否接收完整了，如果没接收完整就需要重新传送，这样就可以保证数据的完整性。 ack：表示确认号。接收端用它来给发送端反馈已经成功接收到的数据信息，它的值为希望接收的下一个数据包起始序号。 ACK：确认位，只有 ACK = 1 的时候 ack 才起作用。正常通信时 ACK 为 1，第一次发起请求时因为没有需要确认接收的数据所以 ACK 为 0。 SYN：同步位，用于在建立连接时同步序号。刚开始建立连接时并没有历史接收的数据，所以 ack 也就没有办法设置，这是按照正常的机制就无法运行了，SYN 的作用就是解决这个问题的，当接收端接收到 SYN = 1 的报文时就会直接将 ack 设置为接收到的 seq + 1 的值，注意这里的值并不是检验后设置的，而是根据 SYN 直接设置的，这样正常的机制就可以运行了，所以 SYN 叫同步位。SYN 会在前两次握手时都为 1，这是因为通信的双方的 ack 都需要设置一个初始值。 FIN：终止位，用来在数据传输完毕后释放连接。 DNS 的设置DNS 解析参考域名设置，如下是我在腾讯云域名的设置 记录类型： A记录： 将域名指向一个IPv4地址（例如：8.8.8.8）CNAME：将域名指向另一个域名（例如 www.54tianzhisheng.cn）MX： 将域名指向邮件服务器地址TXT： 可任意填写，长度限制255，通常做SPF记录（反垃圾邮件）NS： 域名服务器记录，将子域名指定其他DNS服务器解析AAAA：将域名指向一个iPv6地址（例如：ff06:0:0:0:0:0:0:c3）SRV：记录提供特定服务的服务器（例如_xmpp-server._tcp）显性URL：将域名301重定向到另一个地址隐性URL：类似显性URL，但是会隐藏真实目标地址 主机记录： 要解析 www.54tianzhisheng.cn，请填写 www。主机记录就是域名前缀，常见用法有： www: 解析后的域名为 www.54tianzhisheng.cn。@: 直接解析主域名 54tianzhisheng.cn。*: 泛解析，匹配其他所有域名 .54tianzhisheng.cn。mail: 将域名解析为 mail.54tianzhisheng.cn，通常用于解析邮箱服务器。二级域名: 如：abc.54tianzhisheng.cn，填写abc。*手机网站: 如：m.54tianzhisheng.cn，填写m。 Java 中 Socket 的用法普通 Soket 的用法Socket 分为 ServerSocket 和 Socket 两大类。 ServerSocket 用于服务器端，可以通过 accept 方法监听请求，监听到请求后返回 Socket； Socket 用户具体完成数据传输，客户端直接使用 Socket 发送请求并传输数据。 随便写了个单方面发送消息的 demo： 客户端： 12345678910111213141516171819202122232425import java.io.IOException;import java.io.OutputStream;import java.net.Socket;/** * Created by 10412 on 2017/5/2. * TCP客户端： ①：建立tcp的socket服务，最好明确具体的地址和端口。这个对象在创建时，就已经可以对指定ip和端口进行连接(三次握手)。 ②：如果连接成功，就意味着通道建立了，socket流就已经产生了。只要获取到socket流中的读取流和写入流即可，只要通过getInputStream和getOutputStream就可以获取两个流对象。 ③：关闭资源。 *///单方面的输入！public class TcpClient&#123; public static void main(String[] args) &#123; try &#123; Socket s = new Socket(\"127.0.0.1\", 9999); OutputStream o = s.getOutputStream(); o.write(\"tcp sssss\".getBytes()); s.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 服务器端： 1234567891011121314151617181920212223242526272829303132import java.io.IOException;import java.io.InputStream;import java.net.ServerSocket;import java.net.Socket;/** * Created by 10412 on 2017/5/2. */public class TcpServer&#123; public static void main(String[] args) &#123; try &#123; ServerSocket ss = new ServerSocket(9999);//建立服务端的socket服务 Socket s = ss.accept();//获取客户端对象 String ip = s.getInetAddress().getHostAddress(); int port = s.getPort(); System.out.println(ip + \" : \" + port + \" connected\"); // 可以通过获取到的socket对象中的socket流和具体的客户端进行通讯。 InputStream ins = s.getInputStream();//读取客户端的数据，使用客户端对象的socket读取流 byte[] bytes = new byte[1024]; int len = ins.read(bytes); String text = new String(bytes, 0, len); System.out.println(text); //关闭资源 s.close(); ss.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; NioSocket 的用法见以前的一篇文章：Java NIO 系列教程 书中第五章简单的讲了下实现 HTTP 协议。第六章主要讲 Servlet，写了 Servlet 接口和其实现类。第七章把 Tomcat 分析的很不错，如果有读者感兴趣的话，可以去看看。","tags":[{"name":"Spring MVC","slug":"Spring-MVC","permalink":"http://yoursite.com/tags/Spring-MVC/"}]},{"title":"通过源码详解 Servlet","date":"2017-07-09T05:47:19.553Z","path":"2017/07/09/servlet/","text":"Servlet 结构 1、ServletServlet 该接口定义了5个方法。 init()，初始化 servlet 对象，完成一些初始化工作。它是由 servlet 容器控制的，该方法只能被调用一次 service()，接受客户端请求对象，执行业务操作，利用响应对象响应客户端请求。 destroy()，当容器监测到一个servlet从服务中被移除时，容器调用该方法，释放资源，该方法只能被调用一次。 getServletConfig()，ServletConfig 是容器向 servlet 传递参数的载体。 getServletInfo()，获取 servlet 相关信息。 Servlet 的生命周期： 1，初始化阶段 调用 init() 方法 2，响应客户请求阶段 调用 service() 方法 3，终止阶段 调用 destroy() 方法 在 Servlet 接口中的五个方法中涉及的接口有三个：ServletConfig 、 ServletRequest、 ServletResponse 这里先讲讲 ServletRequest 和 ServletResponse。 1）ServletRequest 由 Servlet 容器来管理，当客户请求到来时，容器创建一个 ServletRequest 对象，封装请求数据，同时创建一个 ServletResponse 对象，封装响应数据。这两个对象将被容器作为 service（）方法的参数传递给 Servlet，Serlvet 利用 ServletRequest 对象获取客户端发来的请求数据，利用 ServletResponse 对象发送响应数据。 下面是 ServletRequest 中所有的方法，根据方法名大概就可以猜到这些方法到底是干啥用的。 2）ServletResponse 发送响应数据 2、ServletConfigServletConfig 是容器向 servlet 传递参数的载体。 ServletConfig的4个常用方法： 1）public String getInitParameter（String name）：返回指定名称的初始化参数值； 2）public Enumeration getInitParameterNames（）：返回一个包含所有初始化参数名的 Enumeration 对象； 3）public String getServletName()：返回在 DD 文件中&lt;servlet-name&gt;元素指定的 Servlet 名称； 4）public ServletContext getServletContext（）：返回该 Servlet 所在的上下文对象； 这里详细讲下 ServletContext ： Servlet 上下文对象（ServletContext）：每个Web应用程序在被启动时都会创建一个唯一的上下文对象，Servlet 可通过其获得 Web 应用程序的初始化参数或 Servlet 容器的版本等信息，也可被 Servlet 用来与其他 Servlet 共享数据。 1、获得 ServletContext 应用： （1）、直接调用 getServletContext（）方法 ServletContext context = getServletContext（）; （2）、使用 ServletConfig 应用，再调用它的 getServletContext（）方法 ServletContext context = getServletConfig.getServletContext(); 2、获得应用程序的初始化参数： （1）、public String getInitParameter（String name）：返回指定参数名的字符串参数值，没有则返回 null； （2）、public Enumeration getInitParameterNames()：返回一个包含多有初始化参数名的 Enumeration 对象； 3、通过 ServletContext 对象获得资源 （1）、public URl getResource（String path）:返回由给定路径的资源的 URL 对象，以 “/” 开头，为相对路径，相对于Web 应用程序的文档根目录； （2）、public InputStream getResourceAsStream（String path）：从资源上获得一个 InputStream 对象，等价于getResource（path）.oprenStream(); （3）、public String getRealPath(String path)：返回给定的虚拟路径的真实路径； 4、登陆日志：使用 log（）方法可以将指定的消息写到服务器的日志文件中 （1）、public void log（String msg）：参数 msg 为写入日志文件消息 （2）、public void log（String msg，Throwable throwable）：将 msg 指定的消息和异常的栈跟踪信息写入日志文件 5、使用 RequestDispatcher 实现请求转发 （1）、RequestDispatcher getRequestDiapatcher(String path)：必须以 “/“ 开头相对于应用程序根目录，而ServletRequest 可以传递一个相对路径 （2）、RequestDipatcher getNamedDiapatcher（String name）：参数 name 为一个命名的 Servlet 对象 6、使用 ServletContext 对象存储数据 （1）、public void serAttribute（String name，Object object）：将给定名称的属性值对象绑定到上下文对象上； （2）、public Object getAttribute（String name）：返回绑定到上下文对象的给定名称的属性值； （3）、public Enumeration getAttributeNames()：返回绑定到上下文对象上的所有属性名的 Enumeration 对象； （4）、public void removeAttribute（String name）：删除绑定到上下文对象指定名称的属性； ServletRequest 共享的对象仅在请求的生存周期中可以被访问； HttpSession 共享的对象仅在会话的生存周期中可以被访问； ServletContext 共享的对象在整个 Web 应用程序启动的生存周期中可以被访问； 7、检索 Servlet 容器的信息 （1）、public String getServletInfo()：返回 Servlet 所运行容器的名称和版本； （2）、public int getMajorVersion（）：返回容器所支持的 Servlet API 的主版本号； （3）、public int getMinorVersion（）：返回容器所支持的 Servlet API 的次版本号； （4）、public String getServletContext（）：返回 ServletContext 对应的 web 应用程序名称 &lt;display-name&gt;元素定义的名称； 3、GenericServlet 抽象类GenericServlet 定义了一个通用的，不依赖具体协议的 Servlet，它实现了 Servlet 接口和 ServletConfig 接口，它的方法在文章的第一张图就给出了。 4、HttpServlet 抽象类4.1、HTTP 请求方式 GET : 获取由请求 URL 标识的资源 POST : 向 Web 服务器发送无限制长度的数据 PUT : 存储一个资源到请求的 URL DELETE : 删除由 URL 标识的资源 HEAD : 返回 URL 标识的头信息 OPTIONS : 返回服务器支持的 HTTP 方法 TRACE : 返回 TRACE 请求附带的头字段 4.2、对应的服务方法： doGet() : 调用服务器的资源, 并将其作为响应返回给客户端. doGet() 调用在 URL 里显示正在传送给 Servlet 的数据,这在系统的安全方面可能带来一些问题, 比如说, 用户登录时, 表单里的用户名和密码需要发送到服务器端, doGet() 调用会在浏览器的 URL 里显示用户名和密码. doPost() : 它用于把客户端的数据传给服务端, 使用它可以以隐藏方式给服务器端发送数据. Post 适合发送大量数据. doPut() : 调用和 doPost() 相似, 并且它允许客户端把真正的文件存放在服务器上, 而不仅仅是传送数据. doDelete() : 它允许客户端删除服务器端的文件或者 Web 页面．它的使用非常少． doHead() : 它用于处理客户端的 Head 调用,并且返回一个 response. 当客户端只需要响应的 Header 时,它就发出一个Header 请求.这种情况下客户端往往关心响应的长度和响应的 MIME 类型. doOptions(): 它用于处理客户端的 Options 调用,通过这个调用, 客户端可以获得此 Servlet 支持的方法.如果 Servlet 覆盖了 doPost() 方法, 那么将返回: Allow: POST, TRACE, OPTIONS, HEAD doTrace：处理 TRACE 请求 4.3、Servlet Service 方法详解12345678910111213141516public void service(ServletRequest req, ServletResponse res) throws ServletException, IOException &#123; HttpServletRequest request; HttpServletResponse response; // 如果传入的 HTTP 请求和 HTTP 响应不是 HTTP 的领域模型，则抛出 Servlet 异常，这个异常会被 Servlet 容器所处理 if (!(req instanceof HttpServletRequest &amp;&amp; res instanceof HttpServletResponse)) &#123; throw new ServletException(\"non-HTTP request or response\"); &#125; // 既然是 HTTP 协议绑定的 Serlvet, 强制转换到 HTTP 的领域模型 request = (HttpServletRequest) req; response = (HttpServletResponse) res; // 如果传入的请求和响应是预期的 HTTP 请求和 HTTP 响应，则调用 HttpServlet 的 service() 方法。 service(request, response); &#125; 4.4、HttpServlet service 方法详解1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; // 从 HTTP 请求中取得这次请求所使用的 HTTT 方法 String method = req.getMethod(); // 如果这次请求使用 GET 方法 if (method.equals(METHOD_GET)) &#123; // 取得这个 Servlet 的最后修改的时间 long lastModified = getLastModified(req); if (lastModified == -1) &#123; // servlet doesn't support if-modified-since, no reason // to go through further expensive logic //-1 代表这个 Servlet 不支持最后修改操作，直接调用 doGet() 进行处理 HTTP GET 请求 doGet(req, resp); &#125; else &#123; // 如果这个 Servlet 支持最后修改操作，取得请求头中包含的请求的最后修改时间 long ifModifiedSince = req.getDateHeader(HEADER_IFMODSINCE); if (ifModifiedSince &lt; lastModified) &#123; // If the servlet mod time is later, call doGet() // Round down to the nearest second for a proper compare // A ifModifiedSince of -1 will always be less // 如果请求头中包含的修改时间早于这个 Servlet 的最后修改时间，说明这个 Servlet 自从客户上一次 HTTP 请求已经被修改了 , 设置最新修改时间到响应头中 maybeSetLastModified(resp, lastModified); // 调用 doGet 进行进行处理 HTTP GET 请求 doGet(req, resp); &#125; else &#123; // 如果请求头中包含修改时间晚于这个 Servlet 的最后修改时间，说明这个 Servlet 自从请求的最后修改时间后没有更改过，这种情况下，仅仅返回一个 HTTP 响应状态 SC_NOT_MODIFIED resp.setStatus(HttpServletResponse.SC_NOT_MODIFIED); &#125; &#125; &#125; else if (method.equals(METHOD_HEAD)) &#123; // 如果这次请求使用 HEAD 方法 // 如果这个 Servlet 支持最后修改操作，则设置这个 Servlet 的最后修改时间到响应头中 long lastModified = getLastModified(req); maybeSetLastModified(resp, lastModified); // 和对 HTTP GET 方法处理不同的是，无论请求头中的修改时间是不是早于这个 Sevlet 的最后修改时间，都会发 HEAD 响应给客户，因为 HTTP HEAD 响应是用来查询 Servlet 头信息的操作 doHead(req, resp); &#125; else if (method.equals(METHOD_POST)) &#123; // 如果这次请求使用 POST 方法 doPost(req, resp); &#125; else if (method.equals(METHOD_PUT)) &#123; // 如果这次请求使用 PUT 方法 doPut(req, resp); &#125; else if (method.equals(METHOD_DELETE)) &#123; // 如果这次请求使用 DELETE 方法 doDelete(req, resp); &#125; else if (method.equals(METHOD_OPTIONS)) &#123; // 如果这次请求使用 OPTIONS 方法 doOptions(req,resp); &#125; else if (method.equals(METHOD_TRACE)) &#123; // 如果这次请求使用 TRACE 方法 doTrace(req,resp); &#125; else &#123; // Note that this means NO servlet supports whatever // method was requested, anywhere on this server. // 如果这次请求是其他未知方法，返回错误代码 SC_NOT_IMPLEMENTED 给 HTTP 响应，并且显示一个错误消息，说明这个操作是没有实现的 String errMsg = lStrings.getString(\"http.method_not_implemented\"); Object[] errArgs = new Object[1]; errArgs[0] = method; errMsg = MessageFormat.format(errMsg, errArgs); resp.sendError(HttpServletResponse.SC_NOT_IMPLEMENTED, errMsg); &#125; &#125; 5、Servlet 的多线程问题1、当涉及到 Servlet 需要共享资源是，需保证 Servlet 是线程安全的 2、注意事项： （1）、用方法的局部变量保持请求中的专有数据； （2）、只用 Servlet 的成员变量来存放那些不会改变的数据； （3）、对可能被请求修改的成员变量同步（用 Synchronized 关键字修饰）； （4）、如果 Servlet 访问外部资源，那么需要同步访问这些资源； 3、实现 SingleThreadModel 接口的 Servlet 在被多个客户请求时一个时刻只能有一个线程运行，不推荐使用。 4、如果必须在 servlet 使用同步代码，应尽量在最小的范围上（代码块）进行同步，同步代码越少，Servlet 执行才能越好，避免对 doGet() 或 doPost() 方法同步。 总结全文首先通过一张 Servlet 中的核心 Servlet 类图关系，了解了几种 Servlet 之间的关系及其内部方法。然后在分别介绍这几种 Servlet，通过分析部分重要方法的源码来了解，还介绍了 Servlet 中多线程的问题的解决方法。 注：文章原创，首发于：zhisheng 的博客，文章可转载但请注明地址为：http://www.54tianzhisheng.cn/2017/07/09/servlet/","tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"Servlet","slug":"Servlet","permalink":"http://yoursite.com/tags/Servlet/"}]},{"title":"Velocity 循环指令一种好的解决方法","date":"2017-06-25T05:01:16.352Z","path":"2017/06/25/Velocity-foreach/","text":"前提前台的数据经常是由需要通过 foreach 循环获取。 好的解决方案：（拿我最近做的一个项目做例子）购物商城左边的导航栏，商品大分类和小分类（Category） 1、在 model 包下创建一个 ViewObject 类 1234567891011public class ViewObject&#123; private Map&lt;String, Object&gt; objs = new HashMap&lt;&gt;(); public void set(String key, Object value) &#123; objs.put(key, value); &#125; public Object get(String key) &#123; return objs.get(key); &#125;&#125; 2、在 controller 包下创建个 BaseController 类 12345678910111213141516171819202122232425262728293031323334/** * 在每个页面显示图书大分类，抽离出来 * @return */ public List&lt;ViewObject&gt; selectAllCategory() &#123; List&lt;Category&gt; categories = categoryService.selectAllCategory(); List&lt;ViewObject&gt; vos = new ArrayList&lt;&gt;(); for (Category category : categories) &#123; ViewObject vo = new ViewObject(); vo.set(\"category\", category); vo.set(\"id\", category.getId()); //System.out.println(\"category 中的 id 是 \"+category.getId()); vos.add(vo); &#125; return vos; &#125; /** * 获取图书的小分类，在这里将小分类中的大分类id查找出来，保存在 cds.id 中， * 然后在模板引擎中通过将 vos.id 和 cds.id 相比较。然后如果相同的话，就取出来放在对应的大分类下 * @return */ public List&lt;ViewObject&gt; selectAllCategoryDetail() &#123; List&lt;CategoryDetail&gt; categoryDetails = categoryDetailService.selectAllCategoryDetail(); List&lt;ViewObject&gt; cds = new ArrayList&lt;&gt;(); for (CategoryDetail categoryDetail : categoryDetails) &#123; ViewObject vo = new ViewObject(); vo.set(\"categoryDetail\", categoryDetail); //System.out.println(\"categoryDetail 中的 categoryDetail id =\" + categoryDetail.getId() + \"category id = \" + categoryDetail.getCategory_id() + \" name = \" + categoryDetail.getName()); vo.set(\"id\", categoryDetail.getCategory_id()); cds.add(vo); &#125; return cds; &#125; 3、在 IndexController 类下，需要继承 BaseController.java 类 12345678910111213/** * 返回首页 * @param model * @return */ @RequestMapping(path = &#123;\"/\", \"/index\"&#125;) public String index(Model model) &#123; //模板引擎设置图书分类左边导航栏 model.addAttribute(\"vos\", selectAllCategory()); model.addAttribute(\"cds\", selectAllCategoryDetail()); //返回主页 return \"index\"; &#125; 4、抽离导航部分的代码 left.html 1234567891011121314151617&lt;!--左边图书分类导航栏--&gt;&lt;div class=\"c3_b1_left\"&gt; &lt;dl&gt; #foreach($vo in $vos) &lt;dd&gt; &lt;h1&gt;$!&#123;vo.category.name&#125;&lt;/h1&gt; &lt;p&gt; #foreach($cd in $cds) #if($vo.id == $cd.id) &lt;a href=\"/list\"&gt;$!&#123;cd.categoryDetail.name&#125;&lt;/a&gt; #end #end &lt;/p&gt; &lt;/dd&gt; #end &lt;/dl&gt;&lt;/div&gt; 5、首页中相应的位置引入 left.html 1#parse(\"left.html\") 这样就可以解决问题了，可是有时候我们需要控制循环的个数，因为我们网页端可能只需要特定的数据量 那么就需要中断 foreach，可以使用 #break 指令终止循环 123456#foreach( $vo in $vos ) #if( $foreach.count &gt; 5 ) #break #end $!&#123;vo.customer.Name&#125;#end 参考Velocity入门指南——第七章 循环指令","tags":[{"name":"Velocity","slug":"Velocity","permalink":"http://yoursite.com/tags/Velocity/"}]},{"title":"AJAX 学习","date":"2017-06-23T14:00:05.420Z","path":"2017/06/23/AJAX/","text":"背景最近的项目中大量地方需要使用 AJAX，无奈，谁叫我既要写前台又要写后台呢，只好学习下这个技术点，主要参考 W3school 文档，下面记录下这些知识点，便于日后自己查阅，下面的一些测试代码建议在 W3school 中测试。 AJAX 基础： AJAX = Asynchronous JavaScript and XML（异步的 JavaScript 和 XML）。 AJAX 是一种在无需重新加载整个网页的情况下，能够更新部分网页的技术。 在很多网站可以见到使用这种技术。 AJAX - XMLHttpRequest 创建 XMLHttpRequest 对象 XMLHttpRequest 是 AJAX 的基础。XMLHttpRequest 用于在后台与服务器交换数据。这意味着可以在不重新加载整个网页的情况下，对网页的某部分进行更新。 创建 XMLHttpRequest 对象的语法： 1variable = new XMLHttpRequest(); 但是对于老版本的 Internet Explorer （IE5 和 IE6）却是使用 ActiveX 对象，所以在开发中为了适应大多数的浏览器，常使用如下： 123456789var xmlhttp;if (window.XMLHttpRequest) &#123;// code for IE7+, Firefox, Chrome, Opera, Safari xmlhttp = new XMLHttpRequest(); &#125;else &#123;// code for IE6, IE5 xmlhttp = new ActiveXObject(\"Microsoft.XMLHTTP\"); &#125; 向服务器发送请求 使用 XMLHttpRequest 对象的 open() 和 send() 方法： 12xmlhttp.open(\"GET\",\"test1.txt\",true);xmlhttp.send(); method description open(method, url, async) 规定请求的类型、URL 以及是否异步处理请求。method：请求的类型；GET 或 POST url：文件在服务器上的位置 async：true（异步）或 false（同步） send(string) 将请求发送到服务器。string：仅用于 POST 请求 GET 还是 POST？ 与 POST 相比，GET 更简单也更快，并且在大部分情况下都能用。 然而，在以下情况中，请使用 POST 请求： 无法使用缓存文件（更新服务器上的文件或数据库） 向服务器发送大量数据（POST 没有数据量限制） 发送包含未知字符的用户输入时，POST 比 GET 更稳定也更可靠 示例：GET 请求 1、简单的 GET 请求 12345678910111213141516171819202122232425262728293031323334&lt;html&gt;&lt;head&gt;&lt;script type=\"text/javascript\"&gt;function loadXMLDoc()&#123;var xmlhttp;if (window.XMLHttpRequest) &#123;// code for IE7+, Firefox, Chrome, Opera, Safari xmlhttp=new XMLHttpRequest(); &#125;else &#123;// code for IE6, IE5 xmlhttp=new ActiveXObject(\"Microsoft.XMLHTTP\"); &#125;xmlhttp.onreadystatechange=function() &#123; if (xmlhttp.readyState==4 &amp;&amp; xmlhttp.status==200) &#123; document.getElementById(\"myDiv\").innerHTML=xmlhttp.responseText; &#125; &#125;xmlhttp.open(\"GET\",\"/ajax/demo_get.asp?t=\" + Math.random(),true);xmlhttp.send();&#125;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;h2&gt;AJAX&lt;/h2&gt;&lt;button type=\"button\" onclick=\"loadXMLDoc()\"&gt;请求数据&lt;/button&gt;&lt;div id=\"myDiv\"&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 2、通过 GET 方法发送信息 12345678910111213141516171819202122232425262728293031323334&lt;html&gt;&lt;head&gt;&lt;script type=\"text/javascript\"&gt;function loadXMLDoc()&#123;var xmlhttp;if (window.XMLHttpRequest) &#123;// code for IE7+, Firefox, Chrome, Opera, Safari xmlhttp=new XMLHttpRequest(); &#125;else &#123;// code for IE6, IE5 xmlhttp=new ActiveXObject(\"Microsoft.XMLHTTP\"); &#125;xmlhttp.onreadystatechange=function() &#123; if (xmlhttp.readyState==4 &amp;&amp; xmlhttp.status==200) &#123; document.getElementById(\"myDiv\").innerHTML=xmlhttp.responseText; &#125; &#125;xmlhttp.open(\"GET\",\"/ajax/demo_get2.asp?fname=Bill&amp;lname=Gates\",true);xmlhttp.send();&#125;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;h2&gt;AJAX&lt;/h2&gt;&lt;button type=\"button\" onclick=\"loadXMLDoc()\"&gt;请求数据&lt;/button&gt;&lt;div id=\"myDiv\"&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 示例：POST 请求 1、简单 POST 请求 12345678910111213141516171819202122232425262728293031323334&lt;html&gt;&lt;head&gt;&lt;script type=\"text/javascript\"&gt;function loadXMLDoc()&#123;var xmlhttp;if (window.XMLHttpRequest) &#123;// code for IE7+, Firefox, Chrome, Opera, Safari xmlhttp=new XMLHttpRequest(); &#125;else &#123;// code for IE6, IE5 xmlhttp=new ActiveXObject(\"Microsoft.XMLHTTP\"); &#125;xmlhttp.onreadystatechange=function() &#123; if (xmlhttp.readyState==4 &amp;&amp; xmlhttp.status==200) &#123; document.getElementById(\"myDiv\").innerHTML=xmlhttp.responseText; &#125; &#125;xmlhttp.open(\"POST\",\"/ajax/demo_post.asp\",true);xmlhttp.send();&#125;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;h2&gt;AJAX&lt;/h2&gt;&lt;button type=\"button\" onclick=\"loadXMLDoc()\"&gt;请求数据&lt;/button&gt;&lt;div id=\"myDiv\"&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 2、像 HTML 表单那样 POST 数据，请使用 setRequestHeader() 来添加 HTTP 头。然后在 send() 方法中规定您希望发送的数据 123456789101112131415161718192021222324252627282930313233343536&lt;html&gt;&lt;head&gt;&lt;script type=\"text/javascript\"&gt;function loadXMLDoc()&#123;var xmlhttp;if (window.XMLHttpRequest) &#123;// code for IE7+, Firefox, Chrome, Opera, Safari xmlhttp=new XMLHttpRequest(); &#125;else &#123;// code for IE6, IE5 xmlhttp=new ActiveXObject(\"Microsoft.XMLHTTP\"); &#125;xmlhttp.onreadystatechange=function() &#123; if (xmlhttp.readyState==4 &amp;&amp; xmlhttp.status==200) &#123; document.getElementById(\"myDiv\").innerHTML=xmlhttp.responseText; &#125; &#125;xmlhttp.open(\"POST\",\"/ajax/demo_post2.asp\",true);xmlhttp.setRequestHeader(\"Content-type\",\"application/x-www-form-urlencoded\");xmlhttp.send(\"fname=Bill&amp;lname=Gates\");&#125;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;h2&gt;AJAX&lt;/h2&gt;&lt;button type=\"button\" onclick=\"loadXMLDoc()\"&gt;请求数据&lt;/button&gt;&lt;div id=\"myDiv\"&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 注意：setRequestHeader(header, value) 向请求添加 HTTP 头，header: 规定头的名称, value: 规定头的值。 url - 服务器上的文件 open() 方法的 url 参数是服务器上文件的地址： 1xmlhttp.open(\"GET\",\"ajax_test.asp\",true); 该文件可以是任何类型的文件，比如 .txt 和 .xml，或者服务器脚本文件，比如 .asp 和 .php （在传回响应之前，能够在服务器上执行任务）。 异步 - True or False ？ XMLHttpRequest 对象如果要用于 AJAX 的话，其 open() 方法的 async 参数必须设置为 true，对于 web 开发人员来说，发送异步请求是一个巨大的进步。很多在服务器执行的任务都相当费时。AJAX 出现之前，这可能会引起应用程序挂起或停止。 通过 AJAX，JavaScript 无需等待服务器的响应，而是： 在等待服务器响应时执行其他脚本 当响应就绪后对响应进行处理 Async = true 当使用 async = true 时，请规定在响应处于 onreadystatechange 事件中的就绪状态时执行的函数 123456789101112131415161718192021222324252627282930313233&lt;html&gt;&lt;head&gt;&lt;script type=\"text/javascript\"&gt;function loadXMLDoc()&#123;var xmlhttp;if (window.XMLHttpRequest) &#123;// code for IE7+, Firefox, Chrome, Opera, Safari xmlhttp=new XMLHttpRequest(); &#125;else &#123;// code for IE6, IE5 xmlhttp=new ActiveXObject(\"Microsoft.XMLHTTP\"); &#125;xmlhttp.onreadystatechange=function() &#123; if (xmlhttp.readyState==4 &amp;&amp; xmlhttp.status==200) &#123; document.getElementById(\"myDiv\").innerHTML=xmlhttp.responseText; &#125; &#125;xmlhttp.open(\"GET\",\"/ajax/test1.txt\",true);xmlhttp.send();&#125;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;div id=\"myDiv\"&gt;&lt;h2&gt;Let AJAX change this text&lt;/h2&gt;&lt;/div&gt;&lt;button type=\"button\" onclick=\"loadXMLDoc()\"&gt;通过 AJAX 改变内容&lt;/button&gt;&lt;/body&gt;&lt;/html&gt; Async = false 如需使用 async = false，请将 open() 方法中的第三个参数改为 false 不推荐使用 async = false，但是对于一些小型的请求，也是可以的。 请记住，JavaScript 会等到服务器响应就绪才继续执行。如果服务器繁忙或缓慢，应用程序会挂起或停止。 注释：当您使用 async=false 时，请不要编写 onreadystatechange 函数 - 把代码放到 send() 语句后面即可： 123456789101112131415161718192021222324252627&lt;html&gt;&lt;head&gt;&lt;script type=\"text/javascript\"&gt;function loadXMLDoc()&#123;var xmlhttp;if (window.XMLHttpRequest) &#123;// code for IE7+, Firefox, Chrome, Opera, Safari xmlhttp=new XMLHttpRequest(); &#125;else &#123;// code for IE6, IE5 xmlhttp=new ActiveXObject(\"Microsoft.XMLHTTP\"); &#125;xmlhttp.open(\"GET\",\"/ajax/test1.txt\",false);xmlhttp.send();document.getElementById(\"myDiv\").innerHTML=xmlhttp.responseText;&#125;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;div id=\"myDiv\"&gt;&lt;h2&gt;Let AJAX change this text&lt;/h2&gt;&lt;/div&gt;&lt;button type=\"button\" onclick=\"loadXMLDoc()\"&gt;通过 AJAX 改变内容&lt;/button&gt;&lt;/body&gt;&lt;/html&gt; 服务器响应 使用 XMLHttpRequest 对象的 responseText 或 responseXML 属性。 responseText 获得字符串形式的响应数据。 responseXML 获得 XML 形式的响应数据。 1、responseText 属性 如果来自服务器的响应并非 XML，请使用 responseText 属性。 responseText 属性返回字符串形式的响应，因此您可以这样使用： 1document.getElementById(\"myDiv\").innerHTML=xmlhttp.responseText; 2、responseXML 属性 如果来自服务器的响应是 XML，而且需要作为 XML 对象进行解析，请使用 responseXML 属性： 请求 books.xml 文件，并解析响应： 12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;html&gt;&lt;head&gt;&lt;script type=\"text/javascript\"&gt;function loadXMLDoc()&#123;var xmlhttp;var txt,x,i;if (window.XMLHttpRequest) &#123;// code for IE7+, Firefox, Chrome, Opera, Safari xmlhttp=new XMLHttpRequest(); &#125;else &#123;// code for IE6, IE5 xmlhttp=new ActiveXObject(\"Microsoft.XMLHTTP\"); &#125;xmlhttp.onreadystatechange=function() &#123; if (xmlhttp.readyState==4 &amp;&amp; xmlhttp.status==200) &#123; xmlDoc=xmlhttp.responseXML; txt=\"\"; x=xmlDoc.getElementsByTagName(\"title\"); for (i=0;i&lt;x.length;i++) &#123; txt=txt + x[i].childNodes[0].nodeValue + \"&lt;br /&gt;\"; &#125; document.getElementById(\"myDiv\").innerHTML=txt; &#125; &#125;xmlhttp.open(\"GET\",\"/example/xmle/books.xml\",true);xmlhttp.send();&#125;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;h2&gt;My Book Collection:&lt;/h2&gt;&lt;div id=\"myDiv\"&gt;&lt;/div&gt;&lt;button type=\"button\" onclick=\"loadXMLDoc()\"&gt;获得我的图书收藏列表&lt;/button&gt;&lt;/body&gt;&lt;/html&gt; onreadystatechange 事件 当请求被发送到服务器时，我们需要执行一些基于响应的任务。每当 readyState 改变时，就会触发 onreadystatechange 事件。readyState 属性存有 XMLHttpRequest 的状态信息。 下面是 XMLHttpRequest 对象的三个重要的属性： onreadystatechange 存储函数（或函数名），每当 readyState 属性改变时，就会调用该函数 readyState 存有 XMLHttpRequest 的状态。从 0 到 4 发生变化。 0: 请求未初始化 1: 服务器连接已建立 2: 请求已接收 3: 请求处理中 4: 请求已完成，且响应已就绪 status 200: “OK” 404: 未找到页面 在 onreadystatechange 事件中，我们规定当服务器响应已做好被处理的准备时所执行的任务。 当 readyState 等于 4 且状态为 200 时，表示响应已就绪： 1234567xmlhttp.onreadystatechange=function() &#123; if (xmlhttp.readyState==4 &amp;&amp; xmlhttp.status==200) &#123; document.getElementById(\"myDiv\").innerHTML=xmlhttp.responseText; &#125; &#125; 使用 Callback 函数 callback 函数是一种以参数形式传递给另一个函数的函数。 如果您的网站上存在多个 AJAX 任务，那么您应该为创建 XMLHttpRequest 对象编写一个标准 的函数，并为每个 AJAX 任务调用该函数。 该函数调用应该包含 URL 以及发生 onreadystatechange 事件时执行的任务（每次调用可能不尽相同）： 12345678910function myFunction()&#123;loadXMLDoc(\"ajax_info.txt\",function() &#123; if (xmlhttp.readyState==4 &amp;&amp; xmlhttp.status==200) &#123; document.getElementById(\"myDiv\").innerHTML=xmlhttp.responseText; &#125; &#125;);&#125; AJAX - 高级ASP/PHP 请求实例 - AJAX 用于创造动态性更强的应用程序。 AJAX 可用来与数据库进行动态通信。 AJAX 可用来与 XML 文件进行交互式通信。 AJAX 实例使用 XMLHttpRequest 对象的实例","tags":[{"name":"AJAX","slug":"AJAX","permalink":"http://yoursite.com/tags/AJAX/"}]},{"title":"java.sql.SQLException Field 'id' doesn't have a default value","date":"2017-06-20T07:10:47.405Z","path":"2017/06/20/Java-error1/","text":"1、错误描述 在做一个电商网站项目时，使用 Mybatis + MySQL 时出现问题 Caused by: java.sql.SQLException: Field &#39;id&#39; doesn&#39;t have a default value ，网上很多人说是 MyBatis 插入数据行 ID 没生成自增。但是我尝试好久，没解决该问题。 2、错误原因 后来才发现是因为创建数据库时的建表语句中的 id 是主键的，但是在插入的过程中，没有给予数值，并且没有让 id 自增。 3、解决办法 修改数据库表中的id，让其自增（在插入的过程中，不插入id数据时）。 （我是直接将整个数据库都导出来，然后在每个表的 id 后面加上一个 auto_increment）, 如下 ：12345678910CREATE TABLE `d_user` ( `id` int(11) NOT NULL auto_increment, `name` varchar(45) DEFAULT NULL, `password` varchar(45) DEFAULT NULL, `zip` varchar(45) DEFAULT NULL, `address` varchar(45) DEFAULT NULL, `phone` varchar(45) DEFAULT NULL, `email` varchar(45) DEFAULT NULL, PRIMARY KEY (`id`))","tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"}]},{"title":"搭建一个博客项目后的碎碎念","date":"2017-06-17T14:01:44.007Z","path":"2017/06/17/blog-talk/","text":"前言 以前大二的时候就想一个人独立做一个由 Java 开发的个人博客, 可耐当时还很弱鸡，一个人难以独挡一片，因为要会的东西太多，后来自己看到很多都是由 WordPress 搭建的博客，很多模板很漂亮，可是自己要稍微对 “拍黄片” 了解一点，并且里面的各种插件特特别的多。去年的时候就开始用上了 GitHub Page 搭建静态的博客，因为自己一直习惯用 Markdown 写作，写完后，软件可以直接生成 PDF 和 HTML 文件，这样就很方便了，直接将自己的 HTML、PDF 和 MD 文件一起 push 到 GitHub 上，然后自己在通过域名加上文章链接就可以直接访问我的博客了，这样就省了很多事了。还提供了 PDF 和 MD 版本，对有不同需求的人都可满足了。可是后来觉得这样的逼格还是不够高，就又开始折腾 Hexo 了，发现用 Hexo 也是很非常简单的（其实是看到 Hexo 的 yilia 主题非常漂亮）。于是就换上了 Hexo 了，自己在这上面写博客也很方便。每次用软件写完后，在 Git Bash 下敲一行命令 hexo d -g 就行了，很方便！前段时间看到了一款开源的博客（由 Java 搭建而成）—— Tale，主题比较简洁，符合程序员的范。也刚好符合自己最初的想法，但是我是没打算放弃现在的博客，就是有一个想法，自己也跟着在那个基础山修改下。（因为 Tale 使用的是轻量级 mvc 框架 Blade 开发，我好像不太了解这个框架呢），想着就 SpringBoot 开发比较快，上手也简单。当时就有这个想法，可怜没时间，不过前些天发现有人就是基于那个 Tale 博客重新修改了，用的就是 SpringBoot ，哇，果然是英雄所见略同。当时就和作者邮件联系了，于是蹭这些天的时间赶紧去看看，结果不只是看看，完全自己就全部敲了一遍，终于在今天搞定了，为了庆祝，才写下这篇文章，好好记录这些美好的时刻（博客可以完全发挥，不限题材）。通过自己深入这个项目，才能够很了解内部的实现方式，这点收获很大，这十天时间花的值，再此感谢两位原作者 ZHENFENG13 、otale 。 博客介绍Tale 使用了轻量级 mvc 框架 Blade 开发，默认主题使用了漂亮的 pinghsu 。 My-Blog 使用的是 Docker + SpringBoot + Mybatis + thymeleaf 打造的一个个人博客模板。 Blog 是自己花了十天的时间把整个项目的代码都敲了一遍，熟悉了整个项目，做了优化，去除了 Docker， 其中修改了原来的一些 bug，并在原作者的项目中提出了 issue ， 原作者已修复。 : 喜欢该项目的话，可以给项目点个 star，如果你想在这基础上修改，那么建议你 fork 该项目，然后再修改哦。 博客首页： 归档： 友链： 关于： 搜索： 后台管理 管理登录： 管理首页： 发布文章： 文章管理： 页面管理： 分类标签： 文件管理： 友链管理： 系统设置： 最后我什么我这么喜欢折腾博客呢，熟悉我的朋友都知道，我再很多平台都写过博客，有些是他们平台的运营人员邀请过去的。可是在这些平台上写博客终究是没有感觉，如今自己在自己的博客网站写文章，比较轻松，而且也符合我的写作风格。在其他的平台都有些大大小小的不适（对程序员来说应该是 bug），虽然目前还是会在这些平台继续发布我新写的文章，但是我保证最新的文章，首发肯定是我自己的博客网站，有些是不会在其他平台发的，有觉得不错的可以 RSS 订阅我的博客，或者是直接收藏网址下来。自从写博客下来遇到很多志同道合的人，这点正是让我觉得有写下去的必要了。自己将会坚持下去，时刻警醒自己：勿忘初心！最后的最后，还是想说一句：如果你想和我一样折腾博客，那么我建议你先在一家平台坚持写下去，等博客数量上来了，在自己折腾自己的博客网站。还有就是你想提高自己的话，还是需要很在意你的基础，然后就是要多练手几个项目，我自己在练手这个项目的时候就收获很多。","tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"}]},{"title":"Hexo + yilia 主题实现文章目录","date":"2017-06-13T10:53:33.974Z","path":"2017/06/13/Hexo-yilia-toc/","text":"前提为了方便查看每篇文章的目录结构，可以定位到想看的地方，特地找了下如何实现这个功能。 添加 CSS 样式打开 themes\\yilia\\source 下的 main.234bc0.css 文件，直接在后面添加如下代码：123456789/* 新添加的 */#container .show-toc-btn,#container .toc-article&#123;display:block&#125;.toc-article&#123;z-index:100;background:#fff;border:1px solid #ccc;max-width:250px;min-width:150px;max-height:500px;overflow-y:auto;-webkit-box-shadow:5px 5px 2px #ccc;box-shadow:5px 5px 2px #ccc;font-size:12px;padding:10px;position:fixed;right:35px;top:129px&#125;.toc-article .toc-close&#123;font-weight:700;font-size:20px;cursor:pointer;float:right;color:#ccc&#125;.toc-article .toc-close:hover&#123;color:#000&#125;.toc-article .toc&#123;font-size:12px;padding:0;line-height:20px&#125;.toc-article .toc .toc-number&#123;color:#333&#125;.toc-article .toc .toc-text:hover&#123;text-decoration:underline;color:#2a6496&#125;.toc-article li&#123;list-style-type:none&#125;.toc-article .toc-level-1&#123;margin:4px 0&#125;.toc-article .toc-child&#123;&#125;@-moz-keyframes cd-bounce-1&#123;0%&#123;opacity:0;-o-transform:scale(1);-webkit-transform:scale(1);-moz-transform:scale(1);-ms-transform:scale(1);transform:scale(1)&#125;60%&#123;opacity:1;-o-transform:scale(1.01);-webkit-transform:scale(1.01);-moz-transform:scale(1.01);-ms-transform:scale(1.01);transform:scale(1.01)&#125;100%&#123;-o-transform:scale(1);-webkit-transform:scale(1);-moz-transform:scale(1);-ms-transform:scale(1);transform:scale(1)&#125;&#125;@-webkit-keyframes cd-bounce-1&#123;0%&#123;opacity:0;-o-transform:scale(1);-webkit-transform:scale(1);-moz-transform:scale(1);-ms-transform:scale(1);transform:scale(1)&#125;60%&#123;opacity:1;-o-transform:scale(1.01);-webkit-transform:scale(1.01);-moz-transform:scale(1.01);-ms-transform:scale(1.01);transform:scale(1.01)&#125;100%&#123;-o-transform:scale(1);-webkit-transform:scale(1);-moz-transform:scale(1);-ms-transform:scale(1);transform:scale(1)&#125;&#125;@-o-keyframes cd-bounce-1&#123;0%&#123;opacity:0;-o-transform:scale(1);-webkit-transform:scale(1);-moz-transform:scale(1);-ms-transform:scale(1);transform:scale(1)&#125;60%&#123;opacity:1;-o-transform:scale(1.01);-webkit-transform:scale(1.01);-moz-transform:scale(1.01);-ms-transform:scale(1.01);transform:scale(1.01)&#125;100%&#123;-o-transform:scale(1);-webkit-transform:scale(1);-moz-transform:scale(1);-ms-transform:scale(1);transform:scale(1)&#125;&#125;@keyframes cd-bounce-1&#123;0%&#123;opacity:0;-o-transform:scale(1);-webkit-transform:scale(1);-moz-transform:scale(1);-ms-transform:scale(1);transform:scale(1)&#125;60%&#123;opacity:1;-o-transform:scale(1.01);-webkit-transform:scale(1.01);-moz-transform:scale(1.01);-ms-transform:scale(1.01);transform:scale(1.01)&#125;100%&#123;-o-transform:scale(1);-webkit-transform:scale(1);-moz-transform:scale(1);-ms-transform:scale(1);transform:scale(1)&#125;&#125;.show-toc-btn&#123;display:none;z-index:10;width:30px;min-height:14px;overflow:hidden;padding:4px 6px 8px 5px;border:1px solid #ddd;border-right:none;position:fixed;right:40px;text-align:center;background-color:#f9f9f9&#125;.show-toc-btn .btn-bg&#123;margin-top:2px;display:block;width:16px;height:14px;background:url(http://7xtawy.com1.z0.glb.clouddn.com/show.png) no-repeat;-webkit-background-size:100%;-moz-background-size:100%;background-size:100%&#125;.show-toc-btn .btn-text&#123;color:#999;font-size:12px&#125;.show-toc-btn:hover&#123;cursor:pointer&#125;.show-toc-btn:hover .btn-bg&#123;background-position:0 -16px&#125;.show-toc-btn:hover .btn-text&#123;font-size:12px;color:#ea8010&#125;.toc-article li ol, .toc-article li ul &#123; margin-left: 30px;&#125;.toc-article ol, .toc-article ul &#123; margin: 10px 0;&#125; 修改 article.ejs 文件打开 themes\\yilia\\layout\\_partial 文件夹下的 article.ejs 文件, 在 &lt;/header&gt; &lt;% } %&gt; 下面加入如下内容（注意位置） 123456789101112131415161718192021222324252627&lt;!-- 目录内容 --&gt;&lt;% if (!index &amp;&amp; post.toc)&#123; %&gt; &lt;p class=&quot;show-toc-btn&quot; id=&quot;show-toc-btn&quot; onclick=&quot;showToc();&quot; style=&quot;display:none&quot;&gt; &lt;span class=&quot;btn-bg&quot;&gt;&lt;/span&gt; &lt;span class=&quot;btn-text&quot;&gt;文章导航&lt;/span&gt; &lt;/p&gt; &lt;div id=&quot;toc-article&quot; class=&quot;toc-article&quot;&gt; &lt;span id=&quot;toc-close&quot; class=&quot;toc-close&quot; title=&quot;隐藏导航&quot; onclick=&quot;showBtn();&quot;&gt;×&lt;/span&gt; &lt;strong class=&quot;toc-title&quot;&gt;文章目录&lt;/strong&gt; &lt;%- toc(post.content) %&gt; &lt;/div&gt; &lt;script type=&quot;text/javascript&quot;&gt; function showToc()&#123; var toc_article = document.getElementById(&quot;toc-article&quot;); var show_toc_btn = document.getElementById(&quot;show-toc-btn&quot;); toc_article.setAttribute(&quot;style&quot;,&quot;display:block&quot;); show_toc_btn.setAttribute(&quot;style&quot;,&quot;display:none&quot;); &#125;; function showBtn()&#123; var toc_article = document.getElementById(&quot;toc-article&quot;); var show_toc_btn = document.getElementById(&quot;show-toc-btn&quot;); toc_article.setAttribute(&quot;style&quot;,&quot;display:none&quot;); show_toc_btn.setAttribute(&quot;style&quot;,&quot;display:block&quot;); &#125;; &lt;/script&gt; &lt;% &#125; %&gt;&lt;!-- 目录内容结束 --&gt; 然后若想要文章显示目录，在每篇文章开头加入：toc: true 即可。 参考文章：Hexo+yilia主题实现文章目录和添加视频","tags":[{"name":"hexo","slug":"hexo","permalink":"http://yoursite.com/tags/hexo/"}]},{"title":"HashMap、Hashtable、HashSet 和 ConcurrentHashMap 的比较","date":"2017-06-10T14:09:09.072Z","path":"2017/06/10/HashMap-Hashtable/","text":"HashMap 和 Hashtable 的比较是 Java 面试中的常见问题，用来考验程序员是否能够正确使用集合类以及是否可以随机应变使用多种思路解决问题。HashMap 的工作原理、ArrayList 与 Vector 的比较以及这个问题是有关 Java 集合框架的最经典的问题。Hashtable 是个过时的集合类，存在于 Java API 中很久了。在 Java 4 中被重写了，实现了 Map 接口，所以自此以后也成了 Java 集合框架中的一部分。Hashtable 和 HashMap 在 Java 面试中相当容易被问到，甚至成为了集合框架面试题中最常被考的问题，所以在参加任何 Java 面试之前，都不要忘了准备这一题。这篇文章中，我们不仅将会看到 HashMap 和 Hashtable 的区别，还将看到它们之间的相似之处。 HashMap 和 Hashtable 的区别HashMap 和 Hashtable 都实现了 Map 接口，但决定用哪一个之前先要弄清楚它们之间的分别。主要的区别有：线程安全性，同步 (synchronization)，以及速度。 HashMap 几乎可以等价于 Hashtable，除了 HashMap 是非 synchronized 的，并可以接受 null(HashMap 可以接受为 null 的键值 (key) 和值 (value)，而 Hashtable 则不行)。 HashMap 是非 synchronized，而 Hashtable 是 synchronized，这意味着 Hashtable 是线程安全的，多个线程可以共享一个 Hashtable；而如果没有正确的同步的话，多个线程是不能共享 HashMap 的。Java 5 提供了 ConcurrentHashMap，它是 HashTable 的替代，比 HashTable 的扩展性更好。 另一个区别是 HashMap 的迭代器 (Iterator) 是 fail-fast 迭代器，而 Hashtable 的 enumerator 迭代器不是 fail-fast 的。所以当有其它线程改变了 HashMap 的结构（增加或者移除元素），将会抛出ConcurrentModificationException，但迭代器本身的 remove() 方法移除元素则不会抛出ConcurrentModificationException 异常。但这并不是一个一定发生的行为，要看 JVM。这条同样也是Enumeration 和 Iterato r的区别。 由于 Hashtable 是线程安全的也是 synchronized，所以在单线程环境下它比 HashMap 要慢。如果你不需要同步，只需要单一线程，那么使用 HashMap 性能要好过 Hashtable。 HashMap 不能保证随着时间的推移 Map 中的元素次序是不变的。 要注意的一些重要术语：1) sychronized 意味着在一次仅有一个线程能够更改 Hashtable。就是说任何线程要更新 Hashtable 时要首先获得同步锁，其它线程要等到同步锁被释放之后才能再次获得同步锁更新 Hashtable。 2) Fail-safe 和 iterator 迭代器相关。如果某个集合对象创建了 Iterator 或者 ListIterator，然后其它的线程试图“结构上”更改集合对象，将会抛出 ConcurrentModificationException 异常。但其它线程可以通过 set() 方法更改集合对象是允许的，因为这并没有从“结构上”更改集合。但是假如已经从结构上进行了更改，再调用 set() 方法，将会抛出 IllegalArgumentException 异常。 3) 结构上的更改指的是删除或者插入一个元素，这样会影响到 map 的结构。 我们能否让 HashMap 同步？HashMap 可以通过下面的语句进行同步：Map m = Collections.synchronizeMap(hashMap); 结论Hashtable 和 HashMap 有几个主要的不同：线程安全以及速度。仅在你需要完全的线程安全的时候使用Hashtable，而如果你使用 Java 5 或以上的话，请使用 ConcurrentHashMap 吧。 转载自：HashMap和Hashtable的区别 关于 HashMap 线程不安全这一点，《Java并发编程的艺术》一书中是这样说的： HashMap 在并发执行 put 操作时会引起死循环，导致 CPU 利用率接近 100%。因为多线程会导致 HashMap 的 Node 链表形成环形数据结构，一旦形成环形数据结构，Node 的 next 节点永远不为空，就会在获取 Node 时产生死循环。 原因： 疫苗：JAVA HASHMAP的死循环 —— 酷壳 HashMap在java并发中如何发生死循环 How does a HashMap work in JAVA 下面的是自己有道云笔记中记录的： HashMap ， HashTable 和 HashSet 区别 关于 HashMap 的一些说法： a) HashMap 实际上是一个“链表散列”的数据结构，即数组和链表的结合体。HashMap 的底层结构是一个数组，数组中的每一项是一条链表。 b) HashMap 的实例有俩个参数影响其性能： “初始容量” 和 装填因子。 c) HashMap 实现不同步，线程不安全。 HashTable 线程安全 d) HashMap 中的 key-value 都是存储在 Entry 中的。 e) HashMap 可以存 null 键和 null 值，不保证元素的顺序恒久不变，它的底层使用的是数组和链表，通过hashCode() 方法和 equals 方法保证键的唯一性 f) 解决冲突主要有三种方法：定址法，拉链法，再散列法。HashMap 是采用拉链法解决哈希冲突的。 注： 链表法是将相同 hash 值的对象组成一个链表放在 hash 值对应的槽位； 用开放定址法解决冲突的做法是：当冲突发生时，使用某种探查(亦称探测)技术在散列表中形成一个探查(测)序列。 沿此序列逐个单元地查找，直到找到给定 的关键字，或者碰到一个开放的地址(即该地址单元为空)为止（若要插入，在探查到开放的地址，则可将待插入的新结点存人该地址单元）。 拉链法解决冲突的做法是： 将所有关键字为同义词的结点链接在同一个单链表中 。若选定的散列表长度为m，则可将散列表定义为一个由m个头指针组成的指针数 组T[0..m-1]。凡是散列地址为i的结点，均插入到以T[i]为头指针的单链表中。T中各分量的初值均应为空指针。在拉链法中，装填因子α可以大于1，但一般均取α≤1。拉链法适合未规定元素的大小。 Hashtable 和 HashMap 的区别： a) 继承不同。 public class Hashtable extends Dictionary implements Map public class HashMap extends AbstractMap implements Map b) Hashtable 中的方法是同步的，而 HashMap 中的方法在缺省情况下是非同步的。在多线程并发的环境下，可以直接使用 Hashtable，但是要使用 HashMap 的话就要自己增加同步处理了。 c) Hashtable 中， key 和 value 都不允许出现 null 值。 在 HashMap 中， null 可以作为键，这样的键只有一个；可以有一个或多个键所对应的值为 null 。当 get() 方法返回 null 值时，即可以表示 HashMap 中没有该键，也可以表示该键所对应的值为 null 。因此，在 HashMap 中不能由 get() 方法来判断 HashMap 中是否存在某个键， 而应该用 containsKey() 方法来判断。 d) 两个遍历方式的内部实现上不同。Hashtable、HashMap 都使用了Iterator。而由于历史原因，Hashtable还使用了 Enumeration 的方式 。 e) 哈希值的使用不同，HashTable 直接使用对象的 hashCode。而 HashMap 重新计算 hash 值。 f) Hashtable 和 HashMap 它们两个内部实现方式的数组的初始大小和扩容的方式。HashTable 中 hash 数组默认大小是11，增加的方式是 old*2+1。HashMap 中 hash 数组的默认大小是 16，而且一定是2的指数。 注： HashSet 子类依靠 hashCode() 和 equal() 方法来区分重复元素。 HashSet 内部使用 Map 保存数据，即将 HashSet 的数据作为 Map 的 key 值保存，这也是 HashSet 中元素不能重复的原因。而 Map 中保存 key 值的,会去判断当前 Map 中是否含有该 Key 对象，内部是先通过 key 的hashCode, 确定有相同的 hashCode 之后，再通过 equals 方法判断是否相同。 《HashMap 的工作原理》 HashMap的工作原理是近年来常见的Java面试题。几乎每个Java程序员都知道HashMap，都知道哪里要用HashMap，知道 Hashtable和HashMap之间的区别，那么为何这道面试题如此特殊呢？是因为这道题考察的深度很深。这题经常出现在高级或中高级面试中。投资银行更喜欢问这个问题，甚至会要求你实现HashMap来考察你的编程能力。ConcurrentHashMap和其它同步集合的引入让这道题变得更加复杂。让我们开始探索的旅程吧！ 先来些简单的问题“你用过HashMap吗？” “什么是HashMap？你为什么用到它？” 几乎每个人都会回答“是的”，然后回答HashMap的一些特性，譬如HashMap可以接受null键值和值，而Hashtable则不能；HashMap是非synchronized;HashMap很快；以及HashMap储存的是键值对等等。这显示出你已经用过HashMap，而且对它相当的熟悉。但是面试官来个急转直下，从此刻开始问出一些刁钻的问题，关于HashMap的更多基础的细节。面试官可能会问出下面的问题： “你知道HashMap的工作原理吗？” “你知道HashMap的get()方法的工作原理吗？” 你也许会回答“我没有详查标准的Java API，你可以看看Java源代码或者Open JDK。”“我可以用Google找到答案。” 但一些面试者可能可以给出答案，“HashMap是基于hashing的原理，我们使用put(key, value)存储对象到HashMap中，使用get(key)从HashMap中获取对象。当我们给put()方法传递键和值时，我们先对键调用hashCode()方法，返回的hashCode用于找到bucket位置来储存Entry对象。”这里关键点在于指出，HashMap是在bucket中储存键对象和值对象，作为Map.Entry。这一点有助于理解获取对象的逻辑。如果你没有意识到这一点，或者错误的认为仅仅只在bucket中存储值的话，你将不会回答如何从HashMap中获取对象的逻辑。这个答案相当的正确，也显示出面试者确实知道hashing以及HashMap的工作原理。但是这仅仅是故事的开始，当面试官加入一些Java程序员每天要碰到的实际场景的时候，错误的答案频现。下个问题可能是关于HashMap中的碰撞探测(collision detection)以及碰撞的解决方法： “当两个对象的hashcode相同会发生什么？” 从这里开始，真正的困惑开始了，一些面试者会回答因为hashcode相同，所以两个对象是相等的，HashMap将会抛出异常，或者不会存储它们。然后面试官可能会提醒他们有equals()和hashCode()两个方法，并告诉他们两个对象就算hashcode相同，但是它们可能并不相等。一些面试者可能就此放弃，而另外一些还能继续挺进，他们回答“因为hashcode相同，所以它们的bucket位置相同，‘碰撞’会发生。因为HashMap使用链表存储对象，这个Entry(包含有键值对的Map.Entry对象)会存储在链表中。”这个答案非常的合理，虽然有很多种处理碰撞的方法，这种方法是最简单的，也正是HashMap的处理方法。但故事还没有完结，面试官会继续问： “如果两个键的hashcode相同，你如何获取值对象？” 面试者会回答：当我们调用get()方法，HashMap会使用键对象的hashcode找到bucket位置，然后获取值对象。面试官提醒他如果有两个值对象储存在同一个bucket，他给出答案:将会遍历链表直到找到值对象。面试官会问因为你并没有值对象去比较，你是如何确定确定找到值对象的？除非面试者直到HashMap在链表中存储的是键值对，否则他们不可能回答出这一题。 其中一些记得这个重要知识点的面试者会说，找到bucket位置之后，会调用keys.equals()方法去找到链表中正确的节点，最终找到要找的值对象。完美的答案！ 许多情况下，面试者会在这个环节中出错，因为他们混淆了hashCode()和equals()方法。因为在此之前hashCode()屡屡出现，而equals()方法仅仅在获取值对象的时候才出现。一些优秀的开发者会指出使用不可变的、声明作final的对象，并且采用合适的equals()和hashCode()方法的话，将会减少碰撞的发生，提高效率。不可变性使得能够缓存不同键的hashcode，这将提高整个获取对象的速度，使用String，Interger这样的wrapper类作为键是非常好的选择。 如果你认为到这里已经完结了，那么听到下面这个问题的时候，你会大吃一惊。 “如果HashMap的大小超过了负载因子(load factor)定义的容量，怎么办？” 除非你真正知道HashMap的工作原理，否则你将回答不出这道题。默认的负载因子大小为0.75，也就是说，当一个map填满了75%的bucket时候，和其它集合类(如ArrayList等)一样，将会创建原来HashMap大小的两倍的bucket数组，来重新调整map的大小，并将原来的对象放入新的bucket数组中。这个过程叫作rehashing，因为它调用hash方法找到新的bucket位置。 如果你能够回答这道问题，下面的问题来了： “你了解重新调整HashMap大小存在什么问题吗？” 你可能回答不上来，这时面试官会提醒你当多线程的情况下，可能产生条件竞争(race condition)。 当重新调整HashMap大小的时候，确实存在条件竞争，因为如果两个线程都发现HashMap需要重新调整大小了，它们会同时试着调整大小。在调整大小的过程中，存储在链表中的元素的次序会反过来，因为移动到新的bucket位置的时候，HashMap并不会将元素放在链表的尾部，而是放在头部，这是为了避免尾部遍历(tail traversing)。如果条件竞争发生了，那么就死循环了。这个时候，你可以质问面试官，为什么这么奇怪，要在多线程的环境下使用HashMap呢？：） 热心的读者贡献了更多的关于HashMap的问题： 为什么String, Interger这样的wrapper类适合作为键？ String, Interger这样的wrapper类作为HashMap的键是再适合不过了，而且String最为常用。因为String是不可变的，也是final的，而且已经重写了equals()和hashCode()方法了。其他的wrapper类也有这个特点。不可变性是必要的，因为为了要计算hashCode()，就要防止键值改变，如果键值在放入时和获取时返回不同的hashcode的话，那么就不能从HashMap中找到你想要的对象。不可变性还有其他的优点如线程安全。如果你可以仅仅通过将某个field声明成final就能保证hashCode是不变的，那么请这么做吧。因为获取对象的时候要用到equals()和hashCode()方法，那么键对象正确的重写这两个方法是非常重要的。如果两个不相等的对象返回不同的hashcode的话，那么碰撞的几率就会小些，这样就能提高HashMap的性能。 我们可以使用自定义的对象作为键吗？ 这是前一个问题的延伸。当然你可能使用任何对象作为键，只要它遵守了equals()和hashCode()方法的定义规则，并且当对象插入到Map中之后将不会再改变了。如果这个自定义对象时不可变的，那么它已经满足了作为键的条件，因为当它创建之后就已经不能改变了。 我们可以使用CocurrentHashMap来代替Hashtable吗？ 这是另外一个很热门的面试题，因为ConcurrentHashMap越来越多人用了。我们知道Hashtable是synchronized的，但是ConcurrentHashMap同步性能更好，因为它仅仅根据同步级别对map的一部分进行上锁。ConcurrentHashMap当然可以代替HashTable，但是HashTable提供更强的线程安全性。看看 这篇博客 查看Hashtable和ConcurrentHashMap的区别。 我个人很喜欢这个问题，因为这个问题的深度和广度，也不直接的涉及到不同的概念。让我们再来看看这些问题设计哪些知识点： hashing的概念 HashMap中解决碰撞的方法 equals()和hashCode()的应用，以及它们在HashMap中的重要性 不可变对象的好处 HashMap多线程的条件竞争 重新调整HashMap的大小 总结HashMap的工作原理HashMap基于hashing原理，我们通过put()和get()方法储存和获取对象。当我们将键值对传递给put()方法时，它调用键对象的hashCode()方法来计算hashcode，让后找到bucket位置来储存值对象。当获取对象时，通过键对象的equals()方法找到正确的键值对，然后返回值对象。HashMap使用链表来解决碰撞问题，当发生碰撞了，对象将会储存在链表的下一个节点中。 HashMap在每个链表节点中储存键值对对象。 当两个不同的键对象的hashcode相同时会发生什么？ 它们会储存在同一个bucket位置的链表中。键对象的equals()方法用来找到键值对。 因为HashMap的好处非常多，我曾经在电子商务的应用中使用HashMap作为缓存。因为金融领域非常多的运用Java，也出于性能的考虑，我们会经常用到HashMap和ConcurrentHashMap。你可以查看更多的关于HashMap的文章: HashMap和Hashtable的区别 HashMap和HashSet的区别 转载自：HashMap的工作原理 其他的 HashMap 学习资料： jdk7中HashMap知识点整理 HashMap源码分析（四）put-jdk8-红黑树的引入 JDK7与JDK8中HashMap的实现 JDK1.8HashMap原理和源码分析(java面试收藏) 谈谈ConcurrentHashMap1.7和1.8的不同实现 jdk1.8的HashMap和ConcurrentHashMap ConcurrentHashMap源码分析（JDK8版本） 最后谢谢阅读，如果可以的话欢迎大家转发和点赞。如需转载注明原地址就行。 群 528776268 欢迎各位大牛进群一起讨论。","tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"}]},{"title":"《Java 多线程编程核心技术》学习笔记及总结","date":"2017-06-04T13:04:18.921Z","path":"2017/06/04/Java-Thread/","text":"第一章 —— Java 多线程技能线程技术点： 线程的启动 如何使线程暂停 如何使线程停止 线程的优先级 线程安全相关问题 进程和线程的概念及多线程的优点进程：比如我们电脑运行的 QQ.exe 程序，是操作系统管理的基本运行单元 线程：在进程中独立运行的子任务，比如 QQ.exe 进程中就有很多线程在运行，下载文件线程、发送消息线程、语音线程、视频线程等。 多线程优点：我们电脑可以同时操作不同的软件，边听着歌，敲着代码，查看 pdf 文档，浏览网页等，CPU 在这些任务之间不停的切换，切换非常快，所以我们就觉得他们是在同时运行的。 使用多线程继承 Thread 类JDK 源码注释（Thread.java）如下： 12345678910111213141516171819One is to declare a class to be a subclass(子类) of &lt;code&gt;Thread&lt;/code&gt;. This subclass should override the &lt;code&gt;run&lt;/code&gt; method of class &lt;code&gt;Thread&lt;/code&gt;. An instance of the subclass can then be allocated and started. For example, a thread that computes primeslarger than a stated value could be written as follows://继承 Thread 类class PrimeThread extends Thread &#123; long minPrime; PrimeThread(long minPrime) &#123; this.minPrime = minPrime; &#125; public void run() &#123; // compute primes larger than minPrime 重写 Thread 类的 run 方法 &#125; &#125;The following code would then create a thread and start it running://开启线程 PrimeThread p = new PrimeThread(143); p.start(); 实现 Runnable 接口JDK 源码注释（Thread.java）如下： 12345678910111213141516171819The other way to create a thread is to declare a class that implements the &lt;code&gt;Runnable&lt;/code&gt; interface. That class then implements the &lt;code&gt;run&lt;/code&gt; method. An instance of the class can then be allocated, passed as an argument when creating&lt;code&gt;Thread&lt;/code&gt;, and started. The same example in this other style looks like the following://实现 Runnable 接口 class PrimeRun implements Runnable &#123; long minPrime; PrimeRun(long minPrime) &#123; this.minPrime = minPrime; &#125; public void run() &#123; // compute primes larger than minPrime //重写 run 方法 &#125; &#125;The following code would then create a thread and start it running://开启线程 PrimeRun p = new PrimeRun(143); new Thread(p).start(); currentThread() 方法该方法返回代码段正在被哪个线程调用的信息。 isAlive() 方法判断当前线程是否处于活动状态（已经启动但未终止） sleep() 方法在指定的毫秒数内让当前“正在执行的线程（this.currentThread() 返回的线程）”休眠（暂停执行）。 getId() 方法获取线程的唯一标识 停止线程可以使用 Thread.stop() 方法，但最好不要用，因为这个方法是不安全的，已经弃用作废了。 大多数停止一个线程是使用 Thread.interrupt() 方法 判断线程是否是停止状态 interrupted() 12345//测试当前线程是否已经中断了，这个线程的中断状态会被这个方法清除。//换句话说，如果连续两次调用了这个方法，第二次调用的时候将会返回 false ，public static boolean interrupted() &#123; return currentThread().isInterrupted(true);&#125; isInterrupted() 1234567891011 //测试线程是否已经中断了，线程的状态不会受这个方法的影响 //线程中断被忽略，因为线程处于中断下不处于活动状态的线程由此返回false的方法反映出来 public boolean isInterrupted() &#123; return isInterrupted(false); &#125; /*** Tests if some Thread has been interrupted. The interrupted state* is reset or not based on the value of ClearInterrupted that is* passed.*/private native boolean isInterrupted(boolean ClearInterrupted); 在沉睡中停止1234567891011121314151617181920212223242526public class MyThread2 extends Thread&#123; @Override public void run() &#123; try &#123; System.out.println(\"run start\"); Thread.sleep(20000); System.out.println(\"run end\"); &#125; catch (InterruptedException e) &#123; System.out.println(\"run catch \"+this.isInterrupted()); e.printStackTrace(); &#125; &#125; public static void main(String[] args) &#123; try &#123; MyThread2 t2 = new MyThread2(); t2.start(); Thread.sleep(200); t2.interrupt(); &#125; catch (InterruptedException e) &#123; System.out.println(\"main catch\"); e.printStackTrace(); &#125; System.out.println(\"main end\"); &#125;&#125; 运行结果： 123456run startmain endrun catch falsejava.lang.InterruptedException: sleep interrupted at java.lang.Thread.sleep(Native Method) at com.zhisheng.thread.thread1.MyThread2.run(MyThread2.java:12) 从运行结果来看，如果在 sleep 状态下停止某一线程，会进入 catch 语句，并清除停止状态值，使之变成 false。 在停止中沉睡12345678910111213141516171819public class MyThread3 extends Thread&#123; @Override public void run() &#123; try &#123; System.out.println(\"run start\"); Thread.sleep(20000); System.out.println(\"run end\"); &#125; catch (InterruptedException e) &#123; System.out.println(\"run catch \"+this.isInterrupted()); e.printStackTrace(); &#125; &#125; public static void main(String[] args) &#123; MyThread3 t3 = new MyThread3(); t3.start(); t3.interrupt(); &#125;&#125; 运行结果： 12345run startrun catch falsejava.lang.InterruptedException: sleep interrupted at java.lang.Thread.sleep(Native Method) at com.zhisheng.thread.thread1.MyThread3.run(MyThread3.java:12) 能停止的线程 —— 暴力停止使用 stop() 方法停止线程 暂停线程可使用 suspend 方法暂停线程，使用 resume() 方法恢复线程的执行。 suspend 和 resume 方法的使用1234567891011121314151617181920212223242526272829public class MyThread4 extends Thread&#123; private int i; public int getI() &#123; return i; &#125; public void setI(int i) &#123; this.i = i; &#125; @Override public void run() &#123; while (true) &#123; i++; &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; MyThread4 t4 = new MyThread4(); t4.start(); System.out.println(\"A----- \" + System.currentTimeMillis() + \" ---- \" + t4.getI()); Thread.sleep(2000); System.out.println(\"A----- \" + System.currentTimeMillis() + \" ---- \" + t4.getI()); t4.suspend(); Thread.sleep(2000); t4.resume(); System.out.println(\"B----- \" + System.currentTimeMillis() + \" ---- \" + t4.getI()); Thread.sleep(2000); System.out.println(\"B----- \" + System.currentTimeMillis() + \" ---- \" + t4.getI()); &#125;&#125; 从运行结果来看，线程的确能够暂停和恢复。 但是 suspend 和 resume 方法的缺点就是：不同步，因为线程的暂停导致数据的不同步。 yield 方法123456789101112131415161718/** * A hint to the scheduler that the current thread is willing to yield * its current use of a processor. The scheduler is free to ignore this * hint. * * &lt;p&gt; Yield is a heuristic attempt to improve relative progression * between threads that would otherwise over-utilise a CPU. Its use * should be combined with detailed profiling and benchmarking to * ensure that it actually has the desired effect. * * &lt;p&gt; It is rarely appropriate to use this method. It may be useful * for debugging or testing purposes, where it may help to reproduce * bugs due to race conditions. It may also be useful when designing * concurrency control constructs such as the ones in the * &#123;@link java.util.concurrent.locks&#125; package. */ //暂停当前正在执行的线程对象，并执行其他线程。暂停的时间不确定。 public static native void yield(); 1234567891011121314151617public class MyThread5 extends Thread&#123; @Override public void run() &#123; double start = System.currentTimeMillis(); for (int i = 0; i &lt; 200000; i++) &#123; //yield();//暂停的时间不确定 i++; &#125; double end = System.currentTimeMillis(); System.out.println(\"time is \"+(end - start)); &#125; public static void main(String[] args) &#123; MyThread5 t5 = new MyThread5(); t5.start(); &#125;&#125; 线程的优先级设置优先级的方法：setPriority() 方法 12345678910111213public final void setPriority(int newPriority) &#123; ThreadGroup g; checkAccess(); if (newPriority &gt; MAX_PRIORITY || newPriority &lt; MIN_PRIORITY) &#123; throw new IllegalArgumentException(); &#125; if((g = getThreadGroup()) != null) &#123; if (newPriority &gt; g.getMaxPriority()) &#123; newPriority = g.getMaxPriority(); &#125; setPriority0(priority = newPriority); &#125; &#125; 不一定优先级高的线程就先执行。 守护线程当进程中不存在非守护线程了，则守护线程自动销毁。垃圾回收线程就是典型的守护线程，当进程中没有非守护线程了，则垃圾回收线程也就没有存在的必要了，自动销毁。 12345678910111213141516171819202122/** * Marks this thread as either a &#123;@linkplain #isDaemon daemon&#125; thread * or a user thread. The Java Virtual Machine exits when the only * threads running are all daemon threads. * * &lt;p&gt; This method must be invoked before the thread is started. * * @param on * if &#123;@code true&#125;, marks this thread as a daemon thread * @throws IllegalThreadStateException * if this thread is &#123;@linkplain #isAlive alive&#125; * @throws SecurityException * if &#123;@link #checkAccess&#125; determines that the current * thread cannot modify this thread */ public final void setDaemon(boolean on) &#123; checkAccess(); if (isAlive()) &#123; throw new IllegalThreadStateException(); &#125; daemon = on; &#125; 第二章 —— 对象及变量的并发访问技术点： synchronized 对象监视器为 Object 时的使用 synchronized 对象监视器为 Class 时的使用 非线程安全是如何出现的 关键字 volatile 的主要作用 关键字 volatile 与 synchronized 的区别及使用情况 synchronized 同步方法方法内的变量为线程安全“非线程安全”问题存在于“实例变量”中，如果是方法内部的私有变量，则不存在“非线程安全”问题，所得结果也就是“线程安全”了。 实例变量非线程安全如果多线程共同访问一个对象中的实例变量，则有可能出现“非线程安全”问题。 在两个线程访问同一个对象中的同步方法时一定是线程安全的。 脏读发生脏读的情况是在读取实例变量时，此值已经被其他线程更改过了。 如下例子就可以说明，如果不加 synchronized 关键字在 setValue 和 getValue 方法上，就会出现数据脏读。 123456789101112131415161718192021222324252627282930313233343536373839404142class VarName&#123; private String userName = \"A\"; private String password = \"AA\"; synchronized public void setValue(String userName, String password) &#123; try &#123; this.userName = userName; Thread.sleep(500); this.password = password; System.out.println(\"setValue method Thread name is : \" + Thread.currentThread().getName() + \" userName = \" + userName + \" password = \" + password); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; //synchronized public void getValue() &#123; System.out.println(\"getValue method Thread name is : \" + Thread.currentThread().getName() + \" userName = \" + userName + \" password = \" + password); &#125;&#125;class Thread1 extends Thread&#123; private VarName varName; public Thread1(VarName varName) &#123; this.varName = varName; &#125; @Override public void run() &#123; varName.setValue(\"B\", \"BB\"); &#125;&#125;public class Test&#123; public static void main(String[] args) throws InterruptedException &#123; VarName v = new VarName(); Thread1 thread1 = new Thread1(v); thread1.start(); Thread.sleep(200);//打印结果受睡眠时间的影响 v.getValue(); &#125;&#125; synchronized 锁重入关键字 synchronized 拥有锁重入的功能，也就是在使用 synchronized 时，当一个线程得到一个对象锁后，再次请求此对象锁是可以再次得到该对象的锁的。这也证明了在一个 synchronized 方法/块的内部调用本类的其他 synchronized 方法/块时，是永远可以得到锁的。 12345678910111213141516171819202122232425262728293031class Service&#123; synchronized public void service1() &#123; System.out.println(\"service 1\"); service2(); &#125; synchronized public void service2() &#123; System.out.println(\"service 2\"); service3(); &#125; synchronized public void service3() &#123; System.out.println(\"service 3\"); &#125;&#125;class Thread2 extends Thread&#123; @Override public void run() &#123; Service s = new Service(); s.service1(); &#125;&#125;public class Test2&#123; public static void main(String[] args) &#123; Thread2 t2 = new Thread2(); t2.start(); &#125;&#125; 运行结果： 123service 1service 2service 3 同步不具有继承性同步不可以继承。 synchronized 同步语句块synchronized 代码块间的同步性当一个线程访问 object 的一个 synchronized(this) 同步代码块时，其他线程对同一个 object 中所有其他 synchronized(this) 同步代码块的访问将被阻塞，这说明 synchronized 使用的 “对象监视器” 是一个。 将任意对象作为对象监视器多个线程调用同一个对象中的不同名称的 synchronized 同步方法或者 synchronized(this) 同步代码块时，调用的效果就是按顺序执行，也就是同步的，阻塞的。 静态同步 synchronized 方法与 synchronized(class) 代码块关键字 synchronized 还可以应用在 static 静态方法上，如果这样写就是对当前的 *.java 文件对应的 Class 类进行加锁。而 synchronized 关键字加到非 static 静态方法上就是给对象加锁。 多线程的死锁volatile 关键字作用：使变量在多个线程间可见。 通过使用 volatile 关键字，强制的从公共内存中读取变量的值。使用 volatile 关键字增加了实例变量在多个线程之间的可见性，但 volatile 关键字最致命的缺点就是不支持原子性。 关键字 synchronized 和 volatile 比较： 关键字 volatile 是线程同步的轻量实现，所以 volatile 性能肯定要比 synchronized 要好，并且 volatile 只能修饰于变量，而 synchronized 可以修饰方法，以及代码块。 多线程访问 volatile 不会发生阻塞，而 synchronized 会出现阻塞。 volatile 能保证数据的可见性，但不能保证原子性；而 synchronized 可以保证原子性，也可以间接保证可见性，因为它会将私有内存和公有内存中的数据做同步。 关键字 volatile 解决的是变量在多个线程之间的可见性；而 synchronized 关键字解决的是多个线程之间访问资源的同步性。 ​ 第三章 —— 线程间通信技术点： 使用 wait/notify 实现线程间的通信 生产者/消费者模式的实现 方法 join 的使用 ThreadLocal 类的使用 等待/通知机制wait 使线程停止运行，notify 使停止的线程继续运行。 关键字 synchronized 可以将任何一个 Object 对象作为同步对象看待，而 Java 为每个 Object 都实现了 wait() 和 notify() 方法，他们必须用在被 synchronized 同步的 Object 的临界区内。通过调用 wait 方法可以使处于临界区内的线程进入等待状态，同时释放被同步对象的锁。而 notify 操作可以唤醒一个因调用了 wait 方法而处于阻塞状态的线程，使其进入就绪状态。被重新唤醒的线程会试图重新获得临界区的控制权，继续执行临界区内 wait 之后的代码。 wait 方法可以使调用该方法的线程释放共享资源的锁，从运行状态退出，进入等待状态，直到再次被唤醒。 notify() 方法可以随机唤醒等待对列中等待同一共享资源的一个线程，并使该线程退出等待状态，进入可运行状态。 notifyAll() 方法可以随机唤醒等待对列中等待同一共享资源的所有线程，并使这些线程退出等待状态，进入可运行状态。 线程状态示意图： 新创建一个线程对象后，在调用它的 start() 方法，系统会为此线程分配 CPU 资源，使其处于 Runnable（可运行）状态，如果线程抢占到 CPU 资源，此线程就会处于 Running （运行）状态 Runnable 和 Running 状态之间可以相互切换，因为线程有可能运行一段时间后，有其他优先级高的线程抢占了 CPU 资源，此时线程就从 Running 状态变成了 Runnable 状态。 线程进入 Runnable 状态有如下几种情况： 调用 sleep() 方法后经过的时间超过了指定的休眠时间 线程调用的阻塞 IO 已经返回，阻塞方法执行完毕 线程成功的获得了试图同步的监视器 线程正在等待某个通知，其他线程发出了通知 处于挂状态的线程调用了 resume 恢复方法 Blocked 是阻塞的意思，例如线程遇到一个 IO 操作，此时 CPU 处于空闲状态，可能会转而把 CPU 时间片分配给其他线程，这时也可以称为 “暂停”状态。Blocked 状态结束之后，进入 Runnable 状态，等待系统重新分配资源。 出现阻塞状态的有如下几种情况： 线程调用 sleep 方法，主动放弃占用的处理器资源 线程调用了阻塞式 IO 方法，在该方法返回之前，该线程被阻塞 线程试图获得一个同步监视器，但该同步监视器正在被其他线程所持有 线程等待某个通知 程序调用了 suspend 方法将该线程挂起 run 方法运行结束后进入销毁阶段，整个线程执行完毕。 生产者/消费者模式实现一个生产者，一个消费者 存储值对象： 12345678910package com.zhisheng.thread.thread5;/** * Created by 10412 on 2017/6/3. * 存储值对象 */public class ValueObject&#123; public static String value = \"\";&#125; 生产者： 123456789101112131415161718192021222324252627282930package com.zhisheng.thread.thread5;/** * Created by 10412 on 2017/6/3. * 生产者 */public class Product&#123; private String lock; public Product(String lock) &#123; this.lock = lock; &#125; public void setValue() &#123; synchronized (lock) &#123; if (!ValueObject.value.equals(\"\")) &#123; try &#123; lock.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; String value = System.currentTimeMillis() + \"_\" + System.nanoTime(); System.out.println(\"生产者 set 的值是：\" + value); ValueObject.value = value; lock.notify(); &#125; &#125;&#125; 消费者： 1234567891011121314151617181920212223242526272829package com.zhisheng.thread.thread5;/** * Created by 10412 on 2017/6/3. * 消费者 */public class Resume&#123; private String lock; public Resume(String lock) &#123; this.lock = lock; &#125; public void getValue() &#123; synchronized (lock) &#123; if (ValueObject.value.equals(\"\")) &#123; try &#123; lock.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; System.out.println(\"消费者 get 的值：\" + ValueObject.value); ValueObject.value = \"\"; lock.notify(); &#125; &#125;&#125; 生产者线程： 123456789101112131415161718192021package com.zhisheng.thread.thread5;/** * Created by 10412 on 2017/6/3. * 生产者线程 */public class ProductThread extends Thread&#123; private Product p; public ProductThread(Product p) &#123; this.p = p; &#125; @Override public void run() &#123; while (true) &#123; p.setValue(); &#125; &#125;&#125; 消费者线程： 123456789101112131415161718192021package com.zhisheng.thread.thread5;/** * Created by 10412 on 2017/6/3. * 消费者线程 */public class ResumeThread extends Thread&#123; private Resume r; public ResumeThread(Resume r) &#123; this.r = r; &#125; @Override public void run() &#123; while (true) &#123; r.getValue(); &#125; &#125;&#125; 主函数： 123456789101112131415161718package com.zhisheng.thread.thread5;/** * Created by 10412 on 2017/6/3. * 一个生产者一个消费者测试 */public class Test&#123; public static void main(String[] args) &#123; String str = new String(\"\"); Product p = new Product(str); Resume r = new Resume(str);; ProductThread pt = new ProductThread(p); ResumeThread rt = new ResumeThread(r); pt.start(); rt.start(); &#125;&#125; 题目：创建20个线程，其中10个线程是将数据备份到数据库A，另外10个线程将数据备份到数据库B中去，并且备份数据库A和备份数据库B是交叉进行的。 工具类： 123456789101112131415161718192021222324252627282930313233343536373839404142package com.zhisheng.thread.thread6;/** * Created by 10412 on 2017/6/3. * 创建20个线程，其中10个线程是将数据备份到数据库A，另外10个线程将数据备份到数据库B中去，并且 * 备份数据库A和备份数据库B是交叉进行的 */public class DBTools&#123; volatile private boolean prevIsA = false; //确保A备份先进行 synchronized public void backA() &#123; while (prevIsA == true) &#123; try &#123; wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; for (int i = 0; i &lt; 5; i++) &#123; System.out.println(\"AAAAA\"); &#125; prevIsA = true; notifyAll(); &#125; synchronized public void backB() &#123; while (prevIsA == false) &#123; try &#123; wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; for (int i = 0; i &lt; 5; i++) &#123; System.out.println(\"BBBBB\"); &#125; prevIsA = false; notifyAll(); &#125;&#125; 备份A先线程： 123456789101112131415161718package com.zhisheng.thread.thread6;/** * Created by 10412 on 2017/6/3. */public class ThreadA extends Thread&#123; private DBTools dbTools; public ThreadA(DBTools dbTools) &#123; this.dbTools = dbTools; &#125; @Override public void run() &#123; dbTools.backA(); &#125;&#125; 备份B线程： 123456789101112131415161718package com.zhisheng.thread.thread6;/** * Created by 10412 on 2017/6/3. */public class ThreadB extends Thread&#123; private DBTools dbTools; public ThreadB(DBTools dbTools) &#123; this.dbTools = dbTools; &#125; @Override public void run() &#123; dbTools.backB(); &#125;&#125; 测试： 1234567891011121314151617package com.zhisheng.thread.thread6;/** * Created by 10412 on 2017/6/3. */public class Test&#123; public static void main(String[] args) &#123; DBTools dbTools = new DBTools(); for (int i = 0; i &lt; 20; i++) &#123; ThreadB tb = new ThreadB(dbTools); tb.start(); ThreadA ta = new ThreadA(dbTools); ta.start(); &#125; &#125;&#125; Join 方法的使用作用：等待线程对象销毁 join 方法具有使线程排队运行的作用，有些类似同步的运行效果。join 与 synchronized 的区别是：join 在内部使用 wait() 方法进行等待，而 synchronized 关键字使用的是 “对象监视器” 原理做为同步。 在 join 过程中，如果当前线程对象被中断，则当前线程出现异常。 方法 join(long) 中的参数是设定等待的时间。 12345678910111213141516171819202122232425262728293031323334353637383940414243/** * 等待该线程终止的时间最长为 millis 毫秒。超时为 0 意味着要一直等下去。 * Waits at most &#123;@code millis&#125; milliseconds for this thread to * die. A timeout of &#123;@code 0&#125; means to wait forever. * * &lt;p&gt; This implementation uses a loop of &#123;@code this.wait&#125; calls * conditioned on &#123;@code this.isAlive&#125;. As a thread terminates the * &#123;@code this.notifyAll&#125; method is invoked. It is recommended that * applications not use &#123;@code wait&#125;, &#123;@code notify&#125;, or * &#123;@code notifyAll&#125; on &#123;@code Thread&#125; instances. * * @param millis * the time to wait in milliseconds * * @throws IllegalArgumentException * if the value of &#123;@code millis&#125; is negative * * @throws InterruptedException * if any thread has interrupted the current thread. The * &lt;i&gt;interrupted status&lt;/i&gt; of the current thread is * cleared when this exception is thrown. */ public final synchronized void join(long millis) throws InterruptedException &#123; long base = System.currentTimeMillis(); long now = 0; if (millis &lt; 0) &#123; throw new IllegalArgumentException(\"timeout value is negative\"); if (millis == 0) &#123; while (isAlive()) &#123; wait(0); &#125; &#125; else &#123; while (isAlive()) &#123; long delay = millis - now; if (delay &lt;= 0) &#123; break; &#125; wait(delay); now = System.currentTimeMillis() - base; &#125; &#125; &#125; 类 ThreadLocal 的使用该类提供了线程局部 (thread-local) 变量。这些变量不同于它们的普通对应物，因为访问某个变量（通过其 get 或set 方法）的每个线程都有自己的局部变量，它独立于变量的初始化副本。ThreadLocal 实例通常是类中的private static 字段，它们希望将状态与某一个线程（例如，用户 ID 或事务 ID）相关联。 get() 方法12345678910111213public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings(\"unchecked\") T result = (T)e.value; return result; &#125; &#125; return setInitialValue(); &#125; 返回此线程局部变量的当前线程副本中的值。如果变量没有用于当前线程的值，则先将其初始化为调用 initialValue() 方法返回的值。 InheritableThreadLocal 类的使用该类扩展了 ThreadLocal，为子线程提供从父线程那里继承的值：在创建子线程时，子线程会接收所有可继承的线程局部变量的初始值，以获得父线程所具有的值。通常，子线程的值与父线程的值是一致的；但是，通过重写这个类中的 childValue 方法，子线程的值可以作为父线程值的一个任意函数。 当必须将变量（如用户 ID 和 事务 ID）中维护的每线程属性（per-thread-attribute）自动传送给创建的所有子线程时，应尽可能地采用可继承的线程局部变量，而不是采用普通的线程局部变量。 第四章 —— Lock 的使用使用 ReentrantLock 类一个可重入的互斥锁 Lock，它具有与使用 synchronized 方法和语句所访问的隐式监视器锁相同的一些基本行为和语义，但功能更强大。 ReentrantLock 将由最近成功获得锁，并且还没有释放该锁的线程所拥有。当锁没有被另一个线程所拥有时，调用 lock 的线程将成功获取该锁并返回。如果当前线程已经拥有该锁，此方法将立即返回。可以使用 isHeldByCurrentThread()和 getHoldCount()方法来检查此情况是否发生。 此类的构造方法接受一个可选的公平 参数。当设置为 true 时，在多个线程的争用下，这些锁倾向于将访问权授予等待时间最长的线程。否则此锁将无法保证任何特定访问顺序。与采用默认设置（使用不公平锁）相比，使用公平锁的程序在许多线程访问时表现为很低的总体吞吐量（即速度很慢，常常极其慢），但是在获得锁和保证锁分配的均衡性时差异较小。不过要注意的是，公平锁不能保证线程调度的公平性。因此，使用公平锁的众多线程中的一员可能获得多倍的成功机会，这种情况发生在其他活动线程没有被处理并且目前并未持有锁时。还要注意的是，未定时的 tryLock方法并没有使用公平设置。因为即使其他线程正在等待，只要该锁是可用的，此方法就可以获得成功。 建议总是 立即实践，使用 lock 块来调用 try，在之前/之后的构造中，最典型的代码如下： 12345678910111213class X &#123; private final ReentrantLock lock = new ReentrantLock(); // ... public void m() &#123; lock.lock(); // block until condition holds try &#123; // ... method body &#125; finally &#123; lock.unlock() &#125; &#125; &#125; ConditionCondition 将 Object 监视器方法（wait、notify 和 notifyAll）分解成截然不同的对象，以便通过将这些对象与任意 Lock 实现组合使用，为每个对象提供多个等待 set（wait-set）。其中，Lock 替代了 synchronized 方法和语句的使用，Condition 替代了 Object 监视器方法的使用。 假定有一个绑定的缓冲区，它支持 put 和 take 方法。如果试图在空的缓冲区上执行 take 操作，则在某一个项变得可用之前，线程将一直阻塞；如果试图在满的缓冲区上执行 put 操作，则在有空间变得可用之前，线程将一直阻塞。我们喜欢在单独的等待 set 中保存 put 线程和 take 线程，这样就可以在缓冲区中的项或空间变得可用时利用最佳规划，一次只通知一个线程。可以使用两个 Condition 实例来做到这一点。 12345678910111213141516171819202122232425262728293031323334353637class BoundedBuffer &#123; final Lock lock = new ReentrantLock(); final Condition notFull = lock.newCondition(); final Condition notEmpty = lock.newCondition(); final Object[] items = new Object[100]; int putptr, takeptr, count; public void put(Object x) throws InterruptedException &#123; lock.lock(); try &#123; while (count == items.length) notFull.await(); items[putptr] = x; if (++putptr == items.length) putptr = 0; ++count; notEmpty.signal(); &#125; finally &#123; lock.unlock(); &#125; &#125; public Object take() throws InterruptedException &#123; lock.lock(); try &#123; while (count == 0) notEmpty.await(); Object x = items[takeptr]; if (++takeptr == items.length) takeptr = 0; --count; notFull.signal(); return x; &#125; finally &#123; lock.unlock(); &#125; &#125; &#125; 正确使用 Condition 实现等待/通知MyService.java 123456789101112131415161718192021222324252627282930313233343536package com.zhisheng.thread.Thread9;import java.util.concurrent.locks.Condition;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantLock;/** * Created by 10412 on 2017/6/4. */public class MyService&#123; private Lock lock = new ReentrantLock(); private Condition condition = lock.newCondition(); public void await() &#123; lock.lock(); try &#123; System.out.println(\"await A\"); condition.await();//使当前执行的线程处于等待状态 waiting System.out.println(\"await B\"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;finally &#123; lock.unlock(); System.out.println(\"释放锁\"); &#125; &#125; public void signal() &#123; lock.lock(); System.out.println(\"signal A\"); condition.signal(); System.out.println(\"signal B\"); lock.unlock(); &#125;&#125; ThreadA.java 123456789101112131415161718package com.zhisheng.thread.Thread9;/** * Created by 10412 on 2017/6/4. */public class ThreadA extends Thread&#123; private MyService service; public ThreadA(MyService service) &#123; this.service = service; &#125; @Override public void run() &#123; service.await(); &#125;&#125; Test.java 123456789101112131415package com.zhisheng.thread.Thread9;/** * Created by 10412 on 2017/6/4. */public class Test&#123; public static void main(String[] args) throws InterruptedException &#123; MyService service = new MyService(); ThreadA ta = new ThreadA(service); ta.start(); Thread.sleep(5000); service.signal(); &#125;&#125; 运行结果： 12345await Asignal Asignal Bawait B释放锁 Object 类中的 wait() 方法相当于 Condition 类中 await() 方法 Object 类中的 wait(long time) 方法相当于 Condition 类中 await(long time, TimeUnit unit) 方法 Object 类中的 notify() 方法相当于 Condition 类中 signal() 方法 Object 类中的 notifyAll() 方法相当于 Condition 类中 signalAll() 方法 题目：实现生产者与消费者 一对一交替打印 MyService.java 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package com.zhisheng.thread.thread10;import java.util.concurrent.locks.Condition;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantLock;/** * Created by 10412 on 2017/6/4. * 实现生产者与消费者 一对一·交替打印 */public class MyService&#123; private Lock lock = new ReentrantLock(); private Condition condition = lock.newCondition(); private boolean flag = false; public void setValue() &#123; lock.lock(); while (flag == true) &#123; try &#123; condition.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; System.out.println(\"SetValue AAAAAA\"); flag = true; condition.signal(); lock.unlock(); &#125; public void getValue() &#123; lock.lock(); while (flag == false) &#123; try &#123; condition.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; System.out.println(\"GetValue BBBB\"); flag = false; condition.signal(); lock.unlock(); &#125;&#125; ThreadA.java 1234567891011121314151617181920package com.zhisheng.thread.thread10;/** * Created by 10412 on 2017/6/4. */public class ThreadA extends Thread&#123; private MyService service; public ThreadA(MyService service) &#123; this.service = service; &#125; @Override public void run() &#123; for (int i = 0; i &lt; Integer.MAX_VALUE; i++) &#123; service.setValue(); &#125; &#125;&#125; ThreadB.java 1234567891011121314151617181920package com.zhisheng.thread.thread10;/** * Created by 10412 on 2017/6/4. */public class ThreadB extends Thread&#123; private MyService service; public ThreadB(MyService service) &#123; this.service = service; &#125; @Override public void run() &#123; for (int i = 0; i &lt; Integer.MAX_VALUE; i++) &#123; service.getValue(); &#125; &#125;&#125; Test.java 123456789101112131415package com.zhisheng.thread.thread10;/** * Created by 10412 on 2017/6/4. */public class Test&#123; public static void main(String[] args) &#123; MyService service = new MyService(); ThreadA ta = new ThreadA(service); ThreadB tb = new ThreadB(service); ta.start(); tb.start(); &#125;&#125; getHoldCount() 查询当前线程保持此锁定的个数，也就是调用 lock() 的方法 getQueueLength() 返回正等待获取此锁定的线程估计数 getWaitQueueLength() 返回等待与此锁定相关的给定条件 Condition 的线程估计数 hasQueuedThread() 查询指定的线程是否正在等待获取此锁定 hasQueuedThreads() 查询是否有线程正在等待获取此锁定 hasWaiters() 查询是否有线程正在等待与此锁定有关的 condition 条件 isFair() 判断是否是公平锁（默认下 ReentrantLock类使用的是非公平锁） isHeldByCurrentThread() 查询当前线程是否保持此锁定 isLocked() 查询此锁定是否由任意线程保持 lockInterruptibly() 如果当前线程未被中断，则获取锁定，如果已经被中断则出现异常 tryLock() 仅在调用时锁定未被另一个线程保持的情况下，才获取该锁定 tryLock(long time, TimeUtil util) 如果锁定在给定的等待时间内没有被另一个线程保持，且当前线程未被中断，则获取该锁定。 使用 ReentrantReadWriteLock 类读写互斥： MyService.java 123456789101112131415161718192021222324252627282930313233package com.zhisheng.thread.Thread11;import java.util.concurrent.locks.ReentrantReadWriteLock;/** * Created by 10412 on 2017/6/4. */public class MyService&#123; private ReentrantReadWriteLock lock = new ReentrantReadWriteLock(); public void read() &#123; lock.readLock().lock(); System.out.println(Thread.currentThread().getName() + \" Read AAA \" + System.currentTimeMillis()); try &#123; Thread.sleep(10000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; lock.readLock().unlock(); &#125; public void write() &#123; lock.writeLock().lock(); System.out.println(Thread.currentThread().getName() + \" write BBB \" + System.currentTimeMillis()); try &#123; Thread.sleep(10000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; lock.writeLock().unlock(); &#125;&#125; ThreadA.java 123456789101112131415161718package com.zhisheng.thread.Thread11;/** * Created by 10412 on 2017/6/4. */public class ThreadA extends Thread&#123; private MyService service; public ThreadA(MyService service) &#123; this.service = service; &#125; @Override public void run() &#123; service.read(); &#125;&#125; ThreadB.java 123456789101112131415161718package com.zhisheng.thread.Thread11;/** * Created by 10412 on 2017/6/4. */public class ThreadB extends Thread&#123; private MyService service; public ThreadB(MyService service) &#123; this.service = service; &#125; @Override public void run() &#123; service.write(); &#125;&#125; Test.java 123456789101112131415161718package com.zhisheng.thread.Thread11;/** * Created by 10412 on 2017/6/4. */public class Test&#123; public static void main(String[] args) throws InterruptedException &#123; MyService service = new MyService(); ThreadA ta = new ThreadA(service); ta.setName(\"A\"); ta.start(); Thread.sleep(1000); ThreadB tb = new ThreadB(service); tb.setName(\"B\"); tb.start(); &#125;&#125; 运行结果： 12A Read AAA 1496556770402B write BBB 1496556780402 第六章 —— 单例模式与多线程推荐文章 《深入浅出单实例Singleton设计模式》 立即加载模式 / “饿汉模式”立即加载：使用类的时候已经将对象创建完毕，new 实例化 123456789public class MyObject&#123; private static MyObject object = new MyObject(); private MyObject() &#123; &#125; public static MyObject getInstance() &#123; return object; &#125;&#125; 延迟加载 / “ 懒汉模式 ”就是在调用 get 的时候实例才被创建。在 get() 方法中进行 new 实例化。 12345678910111213public class MyObject&#123; private static MyObject object; private MyObject() &#123; &#125; public static MyObject getInstance() &#123; if (object != null) &#123; &#125; else &#123; object = new MyObject(); &#125; return object; &#125;&#125; 使用 DCL 双重检查锁，解决“懒汉模式”遇到的多线程问题 123456789101112131415161718public class MyObject&#123; private volatile static MyObject object; private MyObject() &#123; &#125; //synchronized public static MyObject getInstance() &#123; if (object != null) &#123; &#125; else &#123; synchronized (MyObject.class) &#123; if (object == null) &#123; object = new MyObject(); &#125; &#125; &#125; return object; &#125;&#125; 使用静态内部类实现单例模式123456789101112public class MyObject&#123; private static class MyObjectHandler &#123; private static MyObject object = new MyObject(); &#125; private MyObject() &#123; &#125; public static MyObject getInstance() &#123; return MyObjectHandler.object; &#125;&#125; 序列化与反序列化的单例模式实现MyObject.java 12345678910111213141516171819202122232425package com.zhisheng.thread.thread15;import java.io.ObjectStreamException;import java.io.Serializable;/** * Created by 10412 on 2017/6/4. */public class MyObject implements Serializable&#123; private static final long serialVersionUID = 888L; private static class MyObjectHandler &#123; private static final MyObject object = new MyObject(); &#125; private MyObject() &#123; &#125; public static MyObject getInstance() &#123; return MyObjectHandler.object; &#125; protected Object readResolve() throws ObjectStreamException &#123; System.out.println(\"调用了readResolve方法！\"); return MyObjectHandler.object; &#125;&#125; SaveAndRead.java 12345678910111213141516171819202122232425262728293031323334353637383940package com.zhisheng.thread.thread15;import java.io.*;/** * Created by 10412 on 2017/6/4. */public class SaveAndRead&#123; public static void main(String[] args) &#123; try &#123; MyObject object = MyObject.getInstance(); FileOutputStream fos = new FileOutputStream(new File(\"fos.txt\")); ObjectOutputStream oos = new ObjectOutputStream(fos); oos.writeObject(object); oos.close(); fos.close(); System.out.println(object.hashCode()); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; try &#123; FileInputStream fis = new FileInputStream(new File(\"fos.txt\")); ObjectInputStream ois = new ObjectInputStream(fis); MyObject o = (MyObject) ois.readObject(); ois.close(); fis.close(); System.out.println(o.hashCode()); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 这里主要要指出 MyObject.java 中 readResolve 方法 1234protected Object readResolve() throws ObjectStreamException &#123; System.out.println(\"调用了readResolve方法！\"); return MyObjectHandler.object; &#125; 方法 readResolve 允许 class 在反序列化返回对象前替换、解析在流中读出来的对象。实现 readResolve 方法，一个 class 可以直接控制反序化返回的类型和对象引用。 方法 readResolve 会在 ObjectInputStream 已经读取一个对象并在准备返回前调用。ObjectInputStream 会检查对象的 class 是否定义了 readResolve 方法。如果定义了，将由 readResolve 方法指定返回的对象。返回对象的类型一定要是兼容的，否则会抛出 ClassCastException 。 使用 static 代码块实现单例模式1234567891011121314151617package com.zhisheng.thread.thread16;/** * Created by 10412 on 2017/6/4. */public class MyObject&#123; private static MyObject instance = null; private MyObject() &#123; &#125; static &#123; instance = new MyObject(); &#125; public static MyObject getInstance() &#123; return instance; &#125;&#125; ThreadA.java 1234567891011121314package com.zhisheng.thread.thread16;/** * Created by 10412 on 2017/6/4. */public class ThreadA extends Thread&#123; @Override public void run() &#123; for (int i = 0; i &lt; 5; i++) &#123; System.out.println(MyObject.getInstance().hashCode()); &#125; &#125;&#125; Test.java 12345678910111213141516package com.zhisheng.thread.thread16;/** * Created by 10412 on 2017/6/4. */public class Test&#123; public static void main(String[] args) &#123; ThreadA ta1 = new ThreadA(); ThreadA ta2 = new ThreadA(); ThreadA ta3 = new ThreadA(); ta1.start(); ta2.start(); ta3.start(); &#125;&#125; 使用枚举数据类型实现单例模式在使用枚举类时，构造方法会被自动调用，也可以应用这个特性实现单例模式。 123456789101112131415public class MyObject &#123; private enum MyEnumSingleton&#123; INSTANCE; private Resource resource; private MyEnumSingleton()&#123; resource = new Resource(); &#125; public Resource getResource()&#123; return resource; &#125; &#125; public static Resource getResource()&#123; return MyEnumSingleton.INSTANCE.getResource(); &#125;&#125; 测试： 123456789101112131415161718192021import test.MyObject;public class Run &#123; class MyThread extends Thread &#123; @Override public void run() &#123; for (int i = 0; i &lt; 5; i++) &#123; System.out.println(MyObject.getResource().hashCode()); &#125; &#125; &#125; public static void main(String[] args) &#123; Run.MyThread t1 = new Run().new MyThread(); Run.MyThread t2 = new Run().new MyThread(); Run.MyThread t3 = new Run().new MyThread(); t1.start(); t2.start(); t3.start(); &#125;&#125; 这里再推荐一篇 stackoverflow 上的一个问题回答： What is an efficient way to implement a singleton pattern in Java? 总结本篇文章是我读 《Java多线程编程核心技术》 的笔记及自己的一些总结，觉得不错，欢迎点赞和转发。","tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"多线程","slug":"多线程","permalink":"http://yoursite.com/tags/多线程/"}]},{"title":" 六月 —— 愿你做最美好的自己！","date":"2017-06-02T09:49:19.563Z","path":"2017/06/02/poetry2/","text":"美妙的六月已经到来，送你八封信，愿时光轻缓，愿微风正好，愿你做最美好的自己。 第一封 —— 关于压力 鸡蛋，从外打破是食物，从内打破是生命。人生亦是，从外打破是压力，从内打破是成长。如果你等待别人打破你，那么你注定成为别人的食物；如果能让自己从内打破，那么你会发现自己的成长相当于一种重生。 第二封 —— 关于读书 读书是一种充实人生的艺术，没有书的人生就像空心的竹子一样，空洞无物。犹太人让孩子们亲吻涂有蜂蜜的书本，是为了让他们记住：书本是甜的，要让甜蜜充满人生就要读书。读书是一本人生最难得的存折，一点一滴地积累，最后你会发现：自己是世界上最富有的人。第三封 —— 关于人际关系 你可以要求自己守信，但不能要求别人守信；你可以要求自己对人好，但不能期待别人对你好。你怎样对人，并不代表人家就会怎么对你。如果看不透这一点，你只会徒添不必要的烦恼。 第四封 —— 关于孤独 每个人都要经历一段孤独的日子，每段路都有一段独孤的时光。父母不可能一直帮着你，朋友也不可能一直围着你转。孤独不是孤僻，更不是寂寞。经历过孤独的人，内心更坚强，不管处于什么样的环境都能让自己安静，更好地调整状态，面对环境。 第五封 —— 关于修养 看别人不顺眼，是自己修养不够。人愤怒的那一瞬间，智商是零，过一分钟后恢复正常。人的优雅关键在于控制自己的惰绪，用嘴伤害人，是最愚蠢的一种行为。 第六封 —— 关于现实 现实有太多的不如意，就算生活给你的是垃圾，你同样能把垃圾踩在脚底下登上世界之巅。你要把自己逼出最大的潜能，没有人会为你的未来买单，你要么努力向上爬，要么烂在社会最底层的泥里，这就是生活。 第七封 —— 关于自己 一个人经过不同程度的鍛炼，就获得不同程度的修养。好比香料，捣得愈碎，磨得愈细，香得愈浓烈。我们曾如此渴望命运的波澜，到最后才发现：人生最曼妙的风景，竟是内心的淡定与从容。我们曾如此期盼外界的认可，到最后才知道：世界是自己的，与他人毫无关系。 第八封 —— 关于幸福 常有人说，我现在不幸福，等我结了婚或买了房……就幸福了。事实是，幸福的人在哪儿都幸福，不幸福的人在哪儿都不幸福。所以要先培养自己的幸福力，不论发生什么，别人都动不了你的自在开心。这才是真正强大的气场和自信。 幸福的人生，需要三种姿态：对过去，要淡；对现在，要惜；对未来，要信。愿你拥有幸福的能力，做最美好的自己。","tags":[{"name":"随笔","slug":"随笔","permalink":"http://yoursite.com/tags/随笔/"}]},{"title":"《疯狂 Java 突破程序员基本功的 16 课》读书笔记","date":"2017-05-31T13:11:32.805Z","path":"2017/05/31/Java-16-lession/","text":"第 1 课 —— 数组与内存控制数组初始化数组初始化之后，该数组的长度是不可变的（可通过数组的 length 属性访问数组的长度）。Java 中的数组必须经过初始化（为数组对象的元素分配内存空间，并为每个数组元素指定初始值）才可使用。 数组初始化的形式： 静态初始化：初始化时由程序员显示的指定每个数组的初始值，系统决定数组长度。 动态初始化：初始化时程序员只指定数组的长度，系统为数组元素分配初始值。 使用数组数组元素就是变量：例如 int[] 数组元素相当于 int 类型的变量 当通过索引来使用数组元素时（访问数组元素的值、为数组元素赋值），将该数组元素当成普通变量使用即可。 第 2 课 —— 对象与内存的控制Java 内存管理分为：内存分配和内存回收。 内存分配：创建 Java 对象时 JVM 为该对象在堆内存中所分配的内存空间。 内存回收：当 Java 对象失去引用，变成垃圾，JVM 的垃圾回收机制自动清理该对象，并回收内存 实例变量 和 类变量局部变量特点：作用时间短，存储在方法的栈内存中 种类： 形参：方法签名中定义的局部变量，由方法调用者负责为其赋值，随方法结束而消亡 方法内的局部变量：方法内定义的局部变量，必须在方法内对其进行显示初始化，从初始化后开始生效，随方法结束而消亡 代码块内的局部变量：在代码块中定义的局部变量，必须在代码块中进行显示初始化，从初始化后开始生效，随代码块结束而消亡 成员变量类体内定义的变量，如果该成员变量没有使用 static 修饰，那该成员变量又被称为非静态变量或实例变量，如果使用 static 修饰，则该成员变量又可被称为静态变量或类变量。 实例变量和类变量的属性使用 static 修饰的成员变量是类变量，属于该类本身，没有使用 static 修饰的成员变量是实例变量，属于该类的实例，在同一个类中，每一个类只对应一个 Class 对象，但每个类可以创建多个对象。 由于同一个 JVM 内的每个类只对应一个 CLass 对象，因此同一个 JVM 内的一个类的类变量只需要一块内存空间；但对于实例变量而言，该类每创建一次实例，就需要为该实例变量分配一块内存空间。也就是说，程序中创建了几个实例，实例变量就需要几块内存空间。 这里我想到一道面试题目： 123456789101112public class A&#123; &#123; System.out.println(\"我是代码块\"); &#125; static&#123; System.out.println(\"我是静态代码块\"); &#125; public static void main(String[] args) &#123; A a = new A(); A a1 = new A(); &#125;&#125; 结果： 123我是静态代码块我是代码块我是代码块 静态代码块只执行一次，而代码块每创建一个实例，就会打印一次。 实例变量的初始化时机程序可在3个地方对实例变量执行初始化： 定义实例变量时指定初始值 非静态初始化块中对实例变量指定初始值 构造器中对实例变量指定初始值 上面第一种和第二种方式比第三种方式更早执行，但第一、二种方式的执行顺序与他们在源程序中的排列顺序相同。 同样在上面那个代码上加上一个变量 weight 的成员变量，我们来验证下上面的初始化顺序： 1、定义实例变量指定初始值 在 非静态初始化块对实例变量指定初始值 之后: 123456789101112131415public class A&#123; &#123; weight = 2.1; System.out.println(\"我是代码块\"); &#125; double weight = 2.0; static&#123; System.out.println(\"我是静态代码块\"); &#125; public static void main(String[] args) &#123; A a = new A(); A a1 = new A(); System.out.println(a.weight); &#125;&#125; 结果是： 1234我是静态代码块我是代码块我是代码块2.0 2、定义实例变量指定初始值 在 非静态初始化块对实例变量指定初始值 之前: 123456789101112131415public class A&#123; double weight = 2.0; &#123; weight = 2.1; System.out.println(\"我是代码块\"); &#125; static&#123; System.out.println(\"我是静态代码块\"); &#125; public static void main(String[] args) &#123; A a = new A(); A a1 = new A(); System.out.println(a.weight); &#125;&#125; 结果为： 1234我是静态代码块我是代码块我是代码块2.1 大家有没有觉得很奇怪？ 我来好好说清楚下： 定义实例变量时指定的初始值、初始代码块中为实例变量指定初始值的语句的地位是平等的，当经过编译器处理后，他们都将会被提取到构造器中。也就是说，这条语句 double weight = 2.0; 实际上会被分成如下 2 次执行： double weight; : 创建 Java 对象时系统根据该语句为该对象分配内存。 weight = 2.1; : 这条语句将会被提取到 Java 类的构造器中执行。 只说原理，大家肯定不怎么信，那么还有拿出源码来，这样才有信服能力的吗？是不？ 这里我直接使用软件将代码的字节码文件反编译过来，看看里面是怎样的组成？ 第一个代码的反编译源码如下： 1234567891011121314151617181920public class A&#123; double weight; public A() &#123; this.weight = 2.1D; System.out.println(\"我是代码块\"); this.weight = 2.0D; &#125; static &#123; System.out.println(\"我是静态代码块\"); &#125; public static void main(String[] args) &#123; A a = new A(); A a1 = new A(); System.out.println(a.weight); &#125;&#125; 第二个代码反编译源码如下： 1234567891011121314151617181920public class A&#123; double weight; public A() &#123; this.weight = 2.0D; this.weight = 2.1D; System.out.println(\"我是代码块\"); &#125; static &#123; System.out.println(\"我是静态代码块\"); &#125; public static void main(String[] args) &#123; A a = new A(); A a1 = new A(); System.out.println(a.weight); &#125;&#125; 这下子满意了吧！ 通过反编译的源码可以看到该类定义的 weight 实例变量时不再有初始值，为 weight 指定初始值的代码也被提到了构造器中去了，但是我们也可以发现之前规则也是满足的。 他们的赋值语句都被合并到构造器中，在合并过程中，定义的变量语句转换得到的赋值语句，初始代码块中的语句都转换得到的赋值语句，总是位于构造器的所有语句之前，合并后，两种赋值语句的顺序也保持了它们在 Java 源代码中的顺序。 大致过程应该了解了吧？如果还不怎么清楚的，建议还是自己将怎个过程在自己的电脑上操作一遍，毕竟光看不练假把式。 类变量的初始化时机JVM 对每一个 Java 类只初始化一次，因此 Java 程序每运行一次，系统只为类变量分配一次内存空间，执行一次初始化。程序可在两个地方对类变量执行初始化： 定义类变量时指定初始值 静态初始化代码块中对类变量指定初始值 这两种方式的执行顺序与它们在源代码中的排列顺序相同。 还是用上面那个示例，我们在其基础上加个被 static 修饰的变量 height： 1、定义类变量时指定初始值 在 静态初始化代码块中对类变量指定初始值 之后： 123456789101112131415161718public class A&#123; double weight = 2.0; &#123; weight = 2.1; System.out.println(\"我是代码块\"); &#125; static&#123; height = 10.1; System.out.println(\"我是静态代码块\"); &#125; static double height = 10.0; public static void main(String[] args) &#123; A a = new A(); A a1 = new A(); System.out.println(a.weight); System.out.println(height); &#125;&#125; 运行结果： 12345我是静态代码块我是代码块我是代码块2.110.0 2、定义类变量时指定初始值 在 静态初始化代码块中对类变量指定初始值 之前： 123456789101112131415161718public class A&#123; static double height = 10.0; double weight = 2.0; &#123; weight = 2.1; System.out.println(\"我是代码块\"); &#125; static&#123; height = 10.1; System.out.println(\"我是静态代码块\"); &#125; public static void main(String[] args) &#123; A a = new A(); A a1 = new A(); System.out.println(a.weight); System.out.println(height); &#125;&#125; 运行结果： 12345我是静态代码块我是代码块我是代码块2.110.1 其运行结果正如我们预料，但是我们还是看看反编译后的代码吧！ 第一种情况下反编译的代码： 1234567891011121314151617181920212223public class A&#123; double weight; public A() &#123; this.weight = 2.0D; this.weight = 2.1D; System.out.println(\"我是代码块\"); &#125; static &#123; System.out.println(\"我是静态代码块\"); &#125; static double height = 10.0D; public static void main(String[] args) &#123; A a = new A(); A a1 = new A(); System.out.println(a.weight); System.out.println(height); &#125;&#125; 第二种情况下反编译的代码： 123456789101112131415161718192021222324public class A&#123; static double height = 10.0D; double weight; public A() &#123; this.weight = 2.0D; this.weight = 2.1D; System.out.println(\"我是代码块\"); &#125; static &#123; height = 10.1D; System.out.println(\"我是静态代码块\"); &#125; public static void main(String[] args) &#123; A a = new A(); A a1 = new A(); System.out.println(a.weight); System.out.println(height); &#125;&#125; 通过反编译源码，可以看到第一种情况下(定义类变量时指定初始值 在 静态初始化代码块中对类变量指定初始值 之后): 我们在 静态初始化代码块中对类变量指定初始值 已经不存在了，只有一个类变量指定的初始值 static double height = 10.0D; , 而在第二种情况下（定义类变量时指定初始值 在 静态初始化代码块中对类变量指定初始值 之前）和之前的源代码顺序是一样的，没啥区别。 上面的代码中充分的展示了类变量的两种初始化方式 ：每次运行该程序时，系统会为 A 类执行初始化，先为所有类变量分配内存空间，再按照源代码中的排列顺序执行静态初始代码块中所指定的初始值和定义类变量时所指定的初始值。 父类构造器当创建任何 Java 对象时，程序总会先依次调用每个父类非静态初始化代码块、父类构造器（总是从 Object 开始）执行初始化，最后才调用本类的非静态初始化代码块、构造器执行初始化。 隐式调用和显示调用当调用某个类的构造器来创建 Java 对象时，系统总会先调用父类的非静态初始化代码块进行初始化。这个调用是隐式执行的，而且父类的静态初始化代码块总是会被执行。接着会调用父类的一个或多个构造器执行初始化，这个调用既可以是通过 super 进行显示调用，也可以是隐式调用。 当所有父类的非静态初始代码块、构造器依次调用完成后，系统调用本类的非静态代码块、构造器执行初始化，最后返回本类的实例。至于调用父类的哪个构造器执行初始化，分以下几种情况： 子类构造器执行体的第一行代码使用 super 显式调用父类构造器，系统将根据 super 调用里传入的实参列表来确定调用父类的哪个构造器； 子类构造器执行体的第一行代码使用 this 显式调用本类中的重载构造器，系统将根据 this 调用里传入的实参列表来确定奔雷的另一个构造器（执行本类中另一个构造器时即进入第一种情况）； 子类构造器中既没有 super 调用，也没有 this 调用，系统将会在执行子类构造器之前，隐式调用父类无参构造器。 注：super 和 this 必须在构造器的第一行，且不能同时存在。 推荐一篇博客：Java初始化顺序 文章从无继承和继承两种情况下分析了 Java 初始化的顺序。 Java初始化顺序如图： 访问子类对象的实例变量调用被子类重写的方法父子实例的内存控制继承成员变量和继承方法的区别方法的行为总是表现出它们实际类型的行为；实例变量的值总是表现出声明这些变量所用类型的行为。 内存中的子类实例父、子类的类变量final 修饰符final 可以修饰变量、方法、类。 修饰变量，变量被赋初始值之后，不能够对他在进行修改 修饰方法，不能够被重写 修饰类，不能够被继承 final 修饰的实例变量只能在如下位置指定初始值： 定义 final 实例变量时指定初始值 在非静态代码块中为 final 实例变量指定初始值 在构造器中为 final 实例变量指定初始值 final 修饰的类变量只能在如下位置指定初始值： 定义 final 类变量时指定初始值 在静态代码块中为 final 类变量指定初始值 第 3 课 —— 常见 Java 集合的实现细节Java 集合框架类图： Set 和 MapSet 代表一种集合元素无序、集合元素不可重复的集合，Map 则代表一种由多个 key-value 对组合的集合，Map 集合类似于传统的关联数组。 Set 和 Map 的关系1、Map 集合中的 key 不能重复且没有顺序。将这些 key 组合起来就是一个 Set 集合。所以有一个 Set&lt;k&gt; keySet() 方法来返回所有 key 组成的 Set 集合。 2、Set 也可以转换成 Map。（在 Set 中将 每一对 key 和 value 存放在一起） HashMap 和 HashSetHashSet：系统采用 Hash 算法决定集合元素的存储位置。（基于 HashMap 实现的） HashMap：系统将 value 当成 key 的附属，系统根据 Hash 算法决定 key 的存储位置。 HashSet 的绝大部分方法都是通过调用 HashMap 的方法实现的，因此 HashSet 和 HashMap 两个集合在实现本质上是相同的。 TreeMap 和 TreeSetTreeSet 底层使用 TreeMap 来包含 Set 集合中的所有元素。 TreeMap 采用的是一种“红黑树”的排序二叉树来保存 Map 中每个 Entry —— 每个 Entry 都被当成 “红黑树” 的一个节点对待。 Map 和 ListMap 的 values() 方法不管是 HashMap 还是 TreeMap ，它们的 values() 方法都可以返回其所有 value 组成的 Collection 集合，其实是一个不存储元素的 Collection 集合，当程序遍历 Collection 集合时，实际上就是遍历 Map 对象的 value。 HashMap 和 TreeMap 的 values() 方法并未把 Map 中的 values 重新组合成一个包含元素的集合对象，这样就可以降低系统内存开销。 Map 和 List 的关系底层实现很相似；用法上很相似。 Map 接口提供 get(K key) 方法允许 Map 对象根据 key 来取得 value； List 接口提供了 get(int index) 方法允许 List 对象根据元素索引来取得 value； ArrayList 和 LinkedListList 集合的实现类，主要有 ArrayList 、Vector 和 LinkedList。 ArrayList 是一个可改变大小的数组.当更多的元素加入到 ArrayList 中时, 其大小将会动态地增长. 内部的元素可以直接通过 get 与 set 方法进行访问, 因为 ArrayList 本质上就是一个数组. LinkedList 是一个双链表, 在添加和删除元素时具有比 ArrayList 更好的性能. 但在 get 与 set 方面弱于ArrayList. 当然, 这些对比都是指数据量很大或者操作很频繁的情况下的对比, 如果数据和运算量很小,那么对比将失去意义. Vector 和 ArrayList 类似, 但属于强同步类。如果你的程序本身是线程安全的(thread-safe,没有在多个线程之间共享同一个集合/对象),那么使用 ArrayList 是更好的选择。 Vector 和 ArrayList 在更多元素添加进来时会请求更大的空间。Vector 每次请求其大小的双倍空间，而 ArrayList每次对 size 增长 50%. 而 LinkedList 还实现了 Queue 接口, 该接口比 List 提供了更多的方法,包括 offer(), peek(), poll()等. 注意: 默认情况下 ArrayList 的初始容量非常小, 所以如果可以预估数据量的话, 分配一个较大的初始值属于最佳实践, 这样可以减少调整大小的开销。 ArrayList与LinkedList性能对比 时间复杂度对比如下: LinkedList 更适用于: 没有大规模的随机读取 大量的增加/删除操作 Iterator 迭代器是一个迭代器接口，专门用于迭代各种 Collection 集合，包括 Set 集合和 List 集合。 第 4 课 —— Java 的内存回收Java 引用的种类对象在内存中的状态JVM 垃圾回收机制，是否回收一个对象的标准在于：是否还有引用变量引用该对象？只要有引用变量引用该对象，垃圾回收机制就不会回收它。 Java 语言对对象的引用有： 强引用 软引用 弱引用 虚引用 强引用程序创建一个对象，并把这个对象赋给一个引用变量，这个引用变量就是强引用。当一个对象被一个或者一个以上的强引用变量所引用时，它处于可达状态，它是不会被系统的垃圾回收机制回收。 软引用软引用需要通过 SoftReference 类来实现，当一个对象只具有软引用时，它有可能会被垃圾回收机制回收。对于只有软引用的对象而言，当系统内存空间足够时，它不会被系统回收，程序也可使用该对象；当系统内存空间不足时，系统将会回收它。 弱引用弱引用和软引用有点相似，区别在于弱引用所引用对象的生存期更短。 虚引用虚引用主要用于跟踪对象被垃圾回收的状态，虚引用不能单独使用，虚引用必须和引用队列联合使用。 Java 的内存泄漏ArrayList.java 中的 remove 方法 1234567891011public E remove(int index) &#123; rangeCheck(index); modCount++; E oldValue = elementData(index); int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work return oldValue; &#125; 其中 elementData[--size] = null; // clear to let GC do its work 语句是清除数组元素的引用，避免内存的泄漏，如果没有这句的话，那么就是只有两个作用： 修饰 Stack 的属性，也就是将值减 1； 返回索引为 size -1 的值。 垃圾回收机制 跟踪并监控每个 Java 对象，当某个对象处于不可达状态时，回收该对象所占用的内存。 清理内存分配，回收过程中产生的内存碎片。 垃圾回收的基本算法对于一个垃圾回收器的设计算法来说，大概有如下几个设计： 串行回收 和 并行回收 串行回收：不管系统有多少个 CPU，始终使用一个 CPU 来执行垃圾回收操作 并行回收：把整个回收工作拆分成多部分，每个部分由一个 CPU 负责，从而让多个 CPU 并行回收 并发执行 和 应用程序停止 压缩 和 不压缩 和 复制 复制：将堆内分成两个相同的空间，从根开始访问每一个关联的可达对象，将空间A的可达对象全部复制到空间B，然后一次性回收整个空间A。 标记清除：也就是 不压缩 的回收方式。垃圾回收器先从根开始访问所有可达对象，将它们标记为可达状态，然后再遍历一次整个内存区域，把所有没有标记为可达的对象进行回收处理。 标记压缩：这是压缩方式，这种方式充分利用上述两种算法的优点，垃圾回收器先从根开始访问所有可达对象，将他们标记为可达状态，接下来垃圾回收器会将这些活动对象搬迁在一起，这个过程叫做内存压缩，然后垃圾回收机制再次回收那些不可达对象所占用的内存空间，这样就避免了回收产生的内存碎片。 堆内存的分代回收1、Young 代 2、Old 代 3、Permanent 代 内存管理小技巧 尽量使用直接量 使用 StringBuilder 和 StringBuffer 进行字符串拼接 尽早释放无用对象的引用 尽量少用静态变量 避免在经常调用的方法、循环中创建 Java 对象 缓存经常使用的对象 尽量不要使用 finalize 方法 考虑使用 SoftReference 第 5 课 —— 表达式中的陷阱关于字符串的陷阱JVM 对字符串的处理String java = new String(&quot;Java&quot;) 这句创建了两个字符串对象，一个是 “Java” 这个直接量对应的字符串对象，另外一个是 new String() 构造器返回的字符串对象。 Java 程序中创建对象的方法： 通过 new 调用构造器创建 Java 对象 通过 Class 对象的 newInstance() 方法调用构造器创建 Java 对象 通过 Java 的反序列化机制从 IO 流中恢复 Java 对象 通过 Java 对象提供的 clone() 方法复制一个新的 Java 对象 对于字符串以及 Byte、Short、Int、Long、Character、Float、Double 和 Boolean 这些基本类型的包装类 直接量的方式来创建 Java 对象 Integer in = 5； 通过简单的算法表达式，连接运算来创建 Java 对象 String str = “a” + “b”; （如果这个字符串表达式的值在编译时确定下来，那么 JVM 会在编译时计算该字符串变量的值，并让它指向字符串池中对应的字符串。如果这些算法表达式都是字符串直接量、整数直接量，没有变量和方法参与，那么就可以在编译期就可以确定字符串的值；如果使用了变量、调用了方法，那么只有等到运行时才能确定字符串表达式的值；如果字符串连接运算所有的变量都可执行 “宏替换”（使用 final 修饰的变量），那在编译时期也能确定字符串连接表达式的值） 对于 Java 程序的字符直接量，JVM 会使用一个字符串池来保护它们；当第一次使用某个字符串直接量时，JVM 会将它放入字符串池进行缓存。在一般的情况下，字符串池中的字符串对象不会被垃圾回收器回收，当程序再次需要使用该字符串时，无需重新创建一个新的字符串，而是直接让引用变量指向字符串池中已有的字符串。 不可变的字符串String 类是一个不可变类，当一个 String 对象创建完成后，该 String 类里包含的字符序列就被固定下来，以后永远不能修改。 如果程序需要一个字符序列会发生改变的字符串，那么建议使用 StringBuilder （效率比 StringBuffer 高） 字符串比较如果要比较两个字符串是否相同，用 == 进行判断就行，但如果要判断两个字符串所包含的字符序列是否相同，则应该用 String 重写过的 equals() 方法进行比较。 123456789101112131415161718192021222324252627public boolean equals(Object anObject) &#123; //如果两个字符串相同 if (this == anObject) &#123; return true; &#125; //如果anObject是String类型 if (anObject instanceof String) &#123; String anotherString = (String)anObject; //n代表字符串的长度 int n = value.length; //如果两个字符串长度相等 if (n == anotherString.value.length) &#123; //获取当前字符串、anotherString底层封装的字符数组 char v1[] = value; char v2[] = anotherString.value; int i = 0; //逐一比较v1 和 v2数组中的每个字符 while (n-- != 0) &#123; if (v1[i] != v2[i]) return false; i++; &#125; return true; &#125; &#125; return false; &#125; 还可以使用 String 提供的 compareTo() 方法返回两个字符串的大小 123456789101112131415161718public int compareTo(String anotherString) &#123; int len1 = value.length; int len2 = anotherString.value.length; int lim = Math.min(len1, len2); char v1[] = value; char v2[] = anotherString.value; int k = 0; while (k &lt; lim) &#123; char c1 = v1[k]; char c2 = v2[k]; if (c1 != c2) &#123; return c1 - c2; &#125; k++; &#125; return len1 - len2; &#125; 表达式类型的陷阱表达式类型的自动提升 所有 byte、short、char类型将被提升到 int 类型参与运算 整个算术表达式的数据类型自动提升到与表达式中最高等级操作数同样的类型，操作数的等级排列如下：char -&gt; int -&gt; long -&gt;float -&gt; double byte -&gt; short -&gt; int -&gt; long -&gt;float -&gt; double 复合赋值运算符的陷阱Java 语言允许所有的双目运算符和 = 一起结合组成复合赋值运算符，如 +=、-=、*=、/=、%= 、&amp;= 等，复合赋值运算符包含了一个隐式的类型转换。 123//下面这两条语句不等价a = a + 5; //a += 5; //实际上等价于 a = (a的类型) (a + 5); 复合赋值运算符会自动的将它计算的结果值强制转换为其左侧变量的类型。 输入法导致的陷阱注释的字符必须合法转义字符的陷阱 慎用字符的 Unicode 转义形式 中止行注释的转义字符 泛型可能引起的错误原始类型变量的赋值 当程序把一个原始类型的变量赋给一个带有泛型信息的变量时，总是可以通过编译（只是会提示警告信息） 当程序试图访问带泛型声明的集合的集合元素时，编译器总是把集合元素当成泛型类型处理（它并不关心集合里集合元素的实际类型） 当程序试图访问带泛型声明的集合的集合元素时，JVM会遍历每个集合元素自动执行强制转型，如果集合元素的实际类型与集合所带的泛型信息不匹配，运行时将引发 ClassCastException 原始类型带来的擦除当把一个具有泛型信息的对象赋给另一个没有泛型信息的变量时，所有在尖括号之间的类型信息都会丢弃。 创建泛型数组的陷阱Java 中不允许创建泛型数组 正则表达式的陷阱有些符号本身就是正则表达式，我们需要对符号做转义运算。 多线程的陷阱不要调用 run 方法开启线程是用 start() 方法，而不是 run() 方法。 静态的同步方法对于同步代码块而言，程序必须显式为它指定同步监视器；对于同步非静态方法而言，该方法的同步监视器是 this —— 即调用该方法的 Java 对象；对于静态的同步方法而言，该方法的同步监视器不是 this，而是该类本身。 第 6 课 —— 流程控制的陷阱switch 语句陷阱break 语句不要忘记写 switch 的表达式类型： byte short int char enum String （Jdk 1.7 以后有 String） 标签引起的陷阱Java 中的标签通常是和循环中的 break 和 continue 结合使用，让 break 直接终止标签所标识的循环，让 continue 语句忽略标签所标识的循环的剩下语句。 。。 第 7 课 —— 面向对象的陷阱instanceof 运算符的陷阱instanceof 它用于判断前面的对象是否是后面的类或其子类、实现类的实例。如果是返回 true，否则返回 false。 instanceof 运算符前面操作数的编译时类型必须是： 要么与后面的类相同 要么是后面类的父类 要么是后面类型的子类 构造器陷阱构造器是 Java 中每个类都会提供的一个“特殊方法”。构造器负责对 Java 对象执行初始化操作，不管是定义实例变量时指定的初始值，还是在非静态初始化代码块中所做的操作，实际上都会被提取到构造器中执行。 构造器不能声明返回值类型，也不能使用void声明构造器没有返回值。 构造器创建对象吗构造器并不会创建 Java 对象，构造器只是负责执行初始化，在构造器执行之前，Java 对象所需要的内存空间，是由 new 关键字申请出来的。绝大部分时候，程序使用 new 关键字为一个 Java 对象申请空间之后，都需要使用构造器为这个对象执行初始化，但在某些时候，程序创建 Java 对象无需调用构造器，如下： 使用反序列化的方式恢复 Java 对象 使用 clone 方法复制 Java 对象 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778package com.zhisheng.test;import java.io.*;/** * Created by 10412 on 2017/5/31. */class Wolf implements Serializable&#123; private String name; public Wolf(String name) &#123; System.out.println(\"调用了有参构造方法\"); this.name = name; &#125; @Override public boolean equals(Object o) &#123; if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; Wolf wolf = (Wolf) o; return name != null ? name.equals(wolf.name) : wolf.name == null; &#125; @Override public int hashCode() &#123; return name != null ? name.hashCode() : 0; &#125;&#125;public class SerializableTest&#123; public static void main(String[] args) &#123; Wolf w = new Wolf(\"灰太狼\"); System.out.println(\"对象创建完成\"); Wolf w2 = null; ObjectInputStream ois = null; ObjectOutputStream oos = null; try &#123; //创建输出对象流 oos = new ObjectOutputStream(new FileOutputStream(\"a.bin\")); //创建输入对象流 ois = new ObjectInputStream(new FileInputStream(\"a.bin\")); //序列输出java 对象 oos.writeObject(w); oos.flush(); //反序列化恢复java对象 w2 = (Wolf) ois.readObject(); System.out.println(w); System.out.println(w2); //两个对象的实例变量值完全相等，输出true System.out.println(w.equals(w2)); //两个对象不同，输出false System.out.println(w == w2); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125;finally &#123; if (ois!=null) try &#123; ois.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; if (oos!=null) try &#123; oos.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 程序运行结果： 123456调用了有参构造方法对象创建完成com.zhisheng.test.Wolf@1b15382com.zhisheng.test.Wolf@1b15382truefalse 正如结果所示：创建 Wolf 对象时，程序调用了相应的构造器来对该对象执行初始化；当程序通过反序列化机制恢复 Java 对象时，系统无需在调用构造器来进行初始化。通过反序列化恢复出来的 Wolf 对象和原来的 Wolf 对象具有完全相同的实例变量值，但系统会产生两个对象。 无限递归构造器12345678910111213public class ConstrutionTest&#123; ConstrutionTest ct; &#123; ct = new ConstrutionTest(); &#125; public ConstrutionTest() &#123; System.out.println(\"无参构造器\"); &#125; public static void main(String[] args) &#123; ConstrutionTest ct = new ConstrutionTest(); &#125;&#125; 运行结果抛出异常 java.lang.StackOverflowError 因为不管定义实例变量时指定的初始值，还是在非静态初始化代码块中执行的初始化操作，最终都将提取到构造器中执行，因为代码中递归调用了类的构造器，最终导致出现 java.lang.StackOverflowError 异常。 到底调用哪个重载方法1、第一阶段 JVM 将会选取所有可获得并匹配调用的方法或者构造器 2、第二个阶段决定到底要调用哪个方法，此时 JVM 会在第一阶段所选取的方法或者构造器中再次选取最精确匹配的那一个。 1234567891011121314151617public class OverrideTest&#123; public void info(Object obj, int a) &#123; System.out.println(\"obj 参数\" + obj); System.out.println(\"整型参数 \" + a); &#125; public void info(Object[] obj, double a) &#123; System.out.println(\"obj 参数\" + obj); System.out.println(\"整型参数 \" + a); &#125; public static void main(String[] args) &#123; OverrideTest o = new OverrideTest(); o.info(null, 5); &#125;&#125; 报错如下： 12Error:(20, 10) java: 对info的引用不明确 com.zhisheng.test.OverrideTest 中的方法 info(java.lang.Object,int) 和 com.zhisheng.test.OverrideTest 中的方法 info(java.lang.Object[],double) 都匹配 在这种复杂的条件下，JVM 无法判断哪个方法更匹配实际调用，将会导致程序编译错误。 方法重写的陷阱无法重写父类 private 方法。如果子类有一个与父类 private 方法具有相同方法名、相同形参列表、相同返回值类型的方法，依然不是重写，只是子类定义了一个与父类相同的方法。 static 关键字static 可以修饰类中定义的成员：field、方法、内部类、初始化代码块、内部枚举类 静态方法属于类被 static 修饰的成员（field、方法、内部类、初始化块、内部枚举类）属于类本身，而不是单个的 Java 对象。静态方法也是属于类。 第 8 课 —— 异常捕捉的陷阱正确关闭资源的方式 使用 finally 块来保证回收，保证关闭操作总是会被执行 关闭每个资源之前首先保证引用该资源的引用变量不为 null 为每个物理资源单独使用 try .. catch 块关闭资源，保证关闭资源时引发的异常不会影响其他资源的关闭。 finally 块陷阱finally 执行顺序，看我以前写的一篇文章《深度探究Java 中 finally 语句块》。 catch 块用法在 try 块后使用 catch 块来捕获多个异常时，程序应该小心多个 catch 块之间的顺序：捕获父类异常的 catch 块都应该排在捕获子类异常的 catch 块之后（先处理小异常，再处理大异常），否则出现编译错误。 继承得到的异常子类重写父类方法时，不能声明抛出比父类方法类型更多、范围更大的异常。 二叉树性质： 二叉树第 i 层上的节点数目至多为 2 ^(i - 1) (i &gt;= 1) 深度为 k 的二叉树至多有 2 ^ k - 1 个节点 在任何一颗二叉树中，如果其叶子结点的数量为 n0，度为 2 的子节点数量为 n2，则 n0 = n2 + 1 具有 n 个节点的完全二叉树的深度为 log n + 1 (log 的底为 2) 对于一棵有 n 个节点的完全二叉树的节点按层自左向右编号，则对任一编号为 i 的节点有如下性质： 当 i == 1 时，节点 i 是二叉树的根；若 i &gt; 1 时，则节点的父节点是 i/2 当 2i &lt;= n，则节点 i 有左孩子，左孩子的编号是 2i，否则，节点无左孩子，并且是叶子结点 若 2i + 1 &lt;= n ，则节点 i 有右孩子，右孩子的编号是 2i + 1；否则，节点无右孩子。 对于一颗 n 个节点的完全二叉树的节点按层自左向右编号，1 ~ n/2 范围的节点都是有孩子节点的非叶子结点，其余的节点全部都是叶子结点。编号为 n/2 的节点有可能只有左节点，也可能既有左节点，又有右节点。 选择排序直接选择排序需要经过 n - 1 趟比较 第一趟比较：程序将记录定位在第一个数据上，拿第一个数据依次和它后面的每个数据进行比较，如果第一个数据大于后面某个数据，交换它们。。依此类推，经过第一趟比较，这组数据中最小的数据被选出来，它被排在第一位。 第二趟比较：程序将记录定位在第二个数据上，拿第二个数据依次和它后面每个数据进行比较，如果第二个数据大于后面某个数据，交换它们。。依次类推，经过第二趟比较，这组数据中第二小的数据被选出，它排在第二位 。。 按此规则一共进行 n-1 趟比较，这组数据中第 n - 1小（第二大）的数据被选出，被排在第 n -1 位（倒数第一位）；剩下的就是最大的数据，它排在最后。 直接选择排序的优点就是算法简单，容易实现，缺点就是每趟只能确定一个元素，n个数组需要进行 n-1 趟比较。 堆排序 建堆 拿堆的根节点和最后一个节点交换 交换排序冒泡排序第一趟：依次比较0和1，1和2，2和3 … n-2 和 n - 1 索引的元素，如果发现第一个数据大于后一个数据，交换它们，经过第一趟，最大的元素排到了最后。 第二趟：依次比较0和1，1和2，2和3 … n-3 和 n - 2 索引的元素，如果发现第一个数据大于后一个数据，交换它们，经过第二趟，第二大的元素排到了倒数第二位 。。 第 n -1 趟：依次比较0和1元素，如果发现第一个数据大于后一个数据，交换它们，经过第 n - 1 趟，第二小的元素排到了第二位。 快速排序从待排的数据序列中任取一个数据作为分界值，所有比它小的数据元素一律放在左边，所有比他大的元素一律放在右边，这样一趟下来，该序列就分成了两个子序列，接下来对两个子序列进行递归，直到每个子序列只剩一个，排序完成。 插入排序直接插入排序依次将待排序的数据元素按其关键字值的大小插入前面的有序序列。 折半插入排序当第 i - 1 趟需要将第 i 个元素插入前面的 0 ~ i -1 个元素序列中时： 计算 0 ~ i - 1 索引的中间点，也就是用 i 索引处的元素和 （0 + i - 1）/2 索引处的元素进行比较，如果 i 索引处的元素大，就直接在 （（0 + i - 1）/2 ） ~ （i - 1）后半个范围内进行搜索，反之在前半个范围搜索。 重复上面步骤 确定第 i 个元素的插入位置，就将该位置的后面所有元素整体后移一位，然后将第 i 个元素放入该位置。","tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"}]},{"title":"源码大招：不服来战！撸这些完整项目，你不牛逼都难！","date":"2017-05-13T10:04:51.795Z","path":"2017/05/13/android-projects/","text":"经常有人问我有没有什么项目代码，我回复说去 Github 找，但是还是好多人不知道如何找到那些比较好的项目。 今天花了点时间找了些安卓的项目，觉得还是不错的，几乎就是自己生活常用的一些 app ，如果你是一个 Android 开发者，我觉得撸完这些项目，你想不牛逼都难。 菜鸟新闻菜鸟新闻 客户端是一个仿照36Kr官方,实 时抓取36Kr官网数据的资讯类新闻客户端。 包括首页新闻,详情,发现,活动,实时数据抓取,侧滑效果,第三方登录以及分享,消息推送等相关功能客户端。 课程地址： http://www.cniao5.com/clazz/view/10076.html视频下载链接： http://pan.baidu.com/s/1eQLyQxc 密码：3ts1 项目源码下载地址：https://github.com/yxs666/cniao5-news 运行截图: .gif) KuaiChuan仿茄子快传的一款文件传输应用， 涉及到Socket通信，包括TCP，UDP通信 项目源码：https://github.com/mayubao/KuaiChuan 运行截图： CoolShopping一个仿拉手团购的购物App，采用Bmob后台实现短信验证码注册、登录、收藏、订单管理、自动更新等功能，数据抓取自拉手团购 项目地址：https://github.com/myxh/CoolShopping 运行截图： RNPolymerPoRNPolymerPo 是一个基于 React Native 的生活类聚合实战项目，目前由于没有 MAC 设备，所以没有适配 iOS，感兴趣的可以自行适配 app 目录下相关 JS 代码即可。 项目地址：https://github.com/yanbober/RNPolymerPo 运行截图： bilibili仿 bilibili 的客户端 项目地址：https://github.com/HotBitmapGG/bilibili-android-client 运行截图： StockChart采用主流rxjava+retrofit+dagger2框架，StockChart看股票的分时图，k线图。 项目地址：https://github.com/AndroidJiang/StockChart Android精准计步器项目地址：https://github.com/linglongxin24/DylanStepCount 运行截图： 菜鸟微博菜鸟微博《通过对新浪微博开发案例的详细解析，讲解了一个完整的 Android 实际项目的开发过程。 有新浪微博的主要功能，有Toolbar,RecyclerView等最新控件的用法；各种快速开发框架的使用，比如 Glide,PhotoView ，EventBus ，OKHttp，pullToRefresh等。 学习视频+源码 视频中还会讲到MVP设计模式以及一些架构师的入门知识。 课程地址： http://www.cniao5.com/clazz/view/10075.html视频下载链接： http://pan.baidu.com/s/1gexq3VP 密码：f0t9 项目地址：https://github.com/yxs666/cniao5-weibo 运行截图： 在线云打印平台一个在线云打印平台（android部分）含订单管理、百度地图、二维码等等 项目地址：https://github.com/LehmanHe/A4print 运行截图： 铜板街项目地址：https://github.com/robotlife/TongBanJie 运行截图： 礼物说项目地址：https://github.com/Orangelittle/Liwusuo IotXmpp本项目是基于XMPP的物联网客户端软件的实现，其实现的主要功能是一款能和物联网节点交互的即时通讯软件。目前支持九类传感器节点交互，主要有：温湿度、风扇、直流电机、LED灯、步进电机、门磁、光电接近、烟雾和光照。本软件不仅能和这些传感器节点交互，还实现了类似微信的订阅和取消订阅功能。当订阅一个节点后节点就会按照设定好的周期向客户端汇报数据，客户端也能设置周期、设置报警上下限等。这些功能的实现极大的方便了我们和物联网节点的交互。 项目地址：https://github.com/tiandawu/IotXmpp 项目截图： Lives生活娱乐结合的APP, 现有主要功能： 图书 翻译 音乐 视频 项目地址：https://github.com/Allyns/Lives 项目截图： CoCoin一款多视图记账APP 项目地址：https://github.com/Nightonke/CoCoin 运行截图： AppLockAppLock应用锁，保护你的隐私 项目地址：https://github.com/lizixian18/AppLock 运行截图： jianshi 简诗一款优雅的中国风Android App，包括Android端和Server端，支持登录注册，数据云端同步，离线数据存储和截屏分享等功能。 项目地址： 运行截图： storage-chooser一款文件管理器app 项目地址：https://github.com/codekidX/storage-chooser 运行截图： LQRWeChat仿最新版微信6.5.7（除图片选择器外）。本项目基于融云SDK，使用目前较火的 Rxjava+Retrofit+MVP+Glide 技术开发。相比上个版本，加入发送位置消息，红包消息等功能。 项目地址：https://github.com/GitLqr/LQRWeChat 运行截图： PonyExpress 小马快递小马快递，您的好帮手。查询并跟踪快递，快递信息及时掌握。支持全国100多家快递公司，支持扫码查询，智能识别快递公司。附带生成二维码小工具，方便实用。体积小巧，无广告，无多余权限。 项目地址：https://github.com/wangchenyan/PonyExpress 运行截图： CloudReader 云阅一款基于网易云音乐UI，使用Gank.Io及豆瓣api开发的符合Google Material Design的Android客户端。项目采取的是MVVM-DataBinding架构开发，现主要包括：干货区、电影区和书籍区三个子模块。DIY网易云音乐原来是如此Cool 项目地址：https://github.com/youlookwhat/CloudReader 运行截图： 硅谷商城是一款按照企业级标准研发的项目。本套代码是目前国内市场第一套详细讲解商城类项目的免费代码。该代码中的内容包括但不仅限于，框架的搭建 、主页模块、分类模块、发现模块、购物车模块和个人中心模块。项目中讲解的主流技术包括且不限于RadioGroup + Fragment、OKHttp、FastJson、RecyclerView、 ScrollViewContainer、Banner、倒计时秒杀、自定义购物车、支付宝等技术。该项目中讲解的技术可应用在电商、新闻、旅游、医疗、在线教育等领域。 项目地址：https://github.com/atguigu01/Shopping 运行截图： 觉得棒的，欢迎点赞和转发分享，谢谢大家！转载的话注明来源地址为 www.54tianzhisheng.cn/2017/05/13/android-projects/ 即可。","tags":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/tags/Android/"}]},{"title":"最近很火的鸡汤，分享给大家","date":"2017-05-11T12:33:20.123Z","path":"2017/05/11/poetry/","text":"&lt;最近很火的一首小诗，分享给大家&gt; 纽约时间比加州时间早三个小时， New York is 3 hours ahead of California, 但加州时间并没有变慢。 but it does not make California slow. 有人22岁就毕业了， Someone graduated at the age of 22, 但等了五年才找到好的工作！ but waited 5 years before securing a good job! 有人25岁就当上CEO， Someone became a CEO at 25, 却在50岁去世。 and died at 50. 也有人迟到50岁才当上CEO， While another became a CEO at 50, 然后活到90岁。 and lived to 90 years. 有人依然单身， Someone is still single, 同时也有人已婚。 while someone else got married. 奥巴马55岁就退休， Obama retires at 55, 川普70岁才开始当总统。 but Trump starts at 70. 世上每个人本来就有自己的发展时区。 Absolutely everyone in this world works based on their Time Zone. 身边有些人看似走在你前面， People around you might seem to go ahead of you, 也有人看似走在你后面。 some might seem to be behind you. 但其实每个人在自己的时区有自己的步程。 But everyone is running their own RACE, in their own TIME. 不用嫉妒或嘲笑他们。 Don’t envy them or mock them. 他们都在自己的时区里，你也是！ They are in their TIME ZONE, and you are in yours! 生命就是等待正确的行动时机。 Life is about waiting for the right moment to act. 所以，放轻松。 So, RELAX. 你没有落后。 You’re not LATE. 你没有领先。 You’re not EARLY. 在命运为你安排的属于自己的时区里，一切都准时。 You are very much ON TIME, and in your TIME ZONE Destiny set up for you.","tags":[{"name":"随笔","slug":"随笔","permalink":"http://yoursite.com/tags/随笔/"}]},{"title":"从对象深入分析 Java 中实例变量和类变量的区别","date":"2017-05-06T06:24:51.333Z","path":"2017/05/06/java-var/","text":"实例变量 和 类变量局部变量特点：作用时间短，存储在方法的栈内存中 种类： 形参：方法签名中定义的局部变量，由方法调用者负责为其赋值，随方法结束而消亡 方法内的局部变量：方法内定义的局部变量，必须在方法内对其进行显示初始化，从初始化后开始生效，随方法结束而消亡 代码块内的局部变量：在代码块中定义的局部变量，必须在代码块中进行显示初始化，从初始化后开始生效，随代码块结束而消亡 成员变量类体内定义的变量，如果该成员变量没有使用 static 修饰，那该成员变量又被称为非静态变量或实例变量，如果使用 static 修饰，则该成员变量又可被称为静态变量或类变量。 实例变量和类变量的属性使用 static 修饰的成员变量是类变量，属于该类本身，没有使用 static 修饰的成员变量是实例变量，属于该类的实例，在同一个类中，每一个类只对应一个 Class 对象，但每个类可以创建多个对象。 由于同一个 JVM 内的每个类只对应一个 CLass 对象，因此同一个 JVM 内的一个类的类变量只需要一块内存空间；但对于实例变量而言，该类每创建一次实例，就需要为该实例变量分配一块内存空间。也就是说，程序中创建了几个实例，实例变量就需要几块内存空间。 这里我想到一道面试题目： 123456789101112public class A&#123; &#123; System.out.println(\"我是代码块\"); &#125; static&#123; System.out.println(\"我是静态代码块\"); &#125; public static void main(String[] args) &#123; A a = new A(); A a1 = new A(); &#125;&#125; 结果： 123我是静态代码块我是代码块我是代码块 静态代码块只执行一次，而代码块每创建一个实例，就会打印一次。 实例变量的初始化时机程序可在3个地方对实例变量执行初始化： 定义实例变量时指定初始值 非静态初始化块中对实例变量指定初始值 构造器中对实例变量指定初始值 上面第一种和第二种方式比第三种方式更早执行，但第一、二种方式的执行顺序与他们在源程序中的排列顺序相同。 同样在上面那个代码上加上一个变量 weight 的成员变量，我们来验证下上面的初始化顺序： 1、定义实例变量指定初始值 在 非静态初始化块对实例变量指定初始值 之后: 123456789101112131415public class A&#123; &#123; weight = 2.1; System.out.println(\"我是代码块\"); &#125; double weight = 2.0; static&#123; System.out.println(\"我是静态代码块\"); &#125; public static void main(String[] args) &#123; A a = new A(); A a1 = new A(); System.out.println(a.weight); &#125;&#125; 结果是： 1234我是静态代码块我是代码块我是代码块2.0 2、定义实例变量指定初始值 在 非静态初始化块对实例变量指定初始值 之前: 123456789101112131415public class A&#123; double weight = 2.0; &#123; weight = 2.1; System.out.println(\"我是代码块\"); &#125; static&#123; System.out.println(\"我是静态代码块\"); &#125; public static void main(String[] args) &#123; A a = new A(); A a1 = new A(); System.out.println(a.weight); &#125;&#125; 结果为： 1234我是静态代码块我是代码块我是代码块2.1 大家有没有觉得很奇怪？ 我来好好说清楚下： 定义实例变量时指定的初始值、初始代码块中为实例变量指定初始值的语句的地位是平等的，当经过编译器处理后，他们都将会被提取到构造器中。也就是说，这条语句 double weight = 2.0; 实际上会被分成如下 2 次执行： double weight; : 创建 Java 对象时系统根据该语句为该对象分配内存。 weight = 2.1; : 这条语句将会被提取到 Java 类的构造器中执行。 只说原理，大家肯定不怎么信，那么还有拿出源码来，这样才有信服能力的吗？是不？ 这里我直接使用软件将代码的字节码文件反编译过来，看看里面是怎样的组成？ 第一个代码的反编译源码如下： 1234567891011121314151617181920public class A&#123; double weight; public A() &#123; this.weight = 2.1D; System.out.println(\"我是代码块\"); this.weight = 2.0D; &#125; static &#123; System.out.println(\"我是静态代码块\"); &#125; public static void main(String[] args) &#123; A a = new A(); A a1 = new A(); System.out.println(a.weight); &#125;&#125; 第二个代码反编译源码如下： 1234567891011121314151617181920public class A&#123; double weight; public A() &#123; this.weight = 2.0D; this.weight = 2.1D; System.out.println(\"我是代码块\"); &#125; static &#123; System.out.println(\"我是静态代码块\"); &#125; public static void main(String[] args) &#123; A a = new A(); A a1 = new A(); System.out.println(a.weight); &#125;&#125; 这下子满意了吧！ 通过反编译的源码可以看到该类定义的 weight 实例变量时不再有初始值，为 weight 指定初始值的代码也被提到了构造器中去了，但是我们也可以发现之前规则也是满足的。 他们的赋值语句都被合并到构造器中，在合并过程中，定义的变量语句转换得到的赋值语句，初始代码块中的语句都转换得到的赋值语句，总是位于构造器的所有语句之前，合并后，两种赋值语句的顺序也保持了它们在 Java 源代码中的顺序。 大致过程应该了解了吧？如果还不怎么清楚的，建议还是自己将怎个过程在自己的电脑上操作一遍，毕竟光看不练假把式。 类变量的初始化时机JVM 对每一个 Java 类只初始化一次，因此 Java 程序每运行一次，系统只为类变量分配一次内存空间，执行一次初始化。程序可在两个地方对类变量执行初始化： 定义类变量时指定初始值 静态初始化代码块中对类变量指定初始值 这两种方式的执行顺序与它们在源代码中的排列顺序相同。 还是用上面那个示例，我们在其基础上加个被 static 修饰的变量 height： 1、定义类变量时指定初始值 在 静态初始化代码块中对类变量指定初始值 之后： 123456789101112131415161718public class A&#123; double weight = 2.0; &#123; weight = 2.1; System.out.println(\"我是代码块\"); &#125; static&#123; height = 10.1; System.out.println(\"我是静态代码块\"); &#125; static double height = 10.0; public static void main(String[] args) &#123; A a = new A(); A a1 = new A(); System.out.println(a.weight); System.out.println(height); &#125;&#125; 运行结果： 12345我是静态代码块我是代码块我是代码块2.110.0 2、定义类变量时指定初始值 在 静态初始化代码块中对类变量指定初始值 之前： 123456789101112131415161718public class A&#123; static double height = 10.0; double weight = 2.0; &#123; weight = 2.1; System.out.println(\"我是代码块\"); &#125; static&#123; height = 10.1; System.out.println(\"我是静态代码块\"); &#125; public static void main(String[] args) &#123; A a = new A(); A a1 = new A(); System.out.println(a.weight); System.out.println(height); &#125;&#125; 运行结果： 12345我是静态代码块我是代码块我是代码块2.110.1 其运行结果正如我们预料，但是我们还是看看反编译后的代码吧！ 第一种情况下反编译的代码： 1234567891011121314151617181920212223public class A&#123; double weight; public A() &#123; this.weight = 2.0D; this.weight = 2.1D; System.out.println(\"我是代码块\"); &#125; static &#123; System.out.println(\"我是静态代码块\"); &#125; static double height = 10.0D; public static void main(String[] args) &#123; A a = new A(); A a1 = new A(); System.out.println(a.weight); System.out.println(height); &#125;&#125; 第二种情况下反编译的代码： 123456789101112131415161718192021222324public class A&#123; static double height = 10.0D; double weight; public A() &#123; this.weight = 2.0D; this.weight = 2.1D; System.out.println(\"我是代码块\"); &#125; static &#123; height = 10.1D; System.out.println(\"我是静态代码块\"); &#125; public static void main(String[] args) &#123; A a = new A(); A a1 = new A(); System.out.println(a.weight); System.out.println(height); &#125;&#125; 通过反编译源码，可以看到第一种情况下(定义类变量时指定初始值 在 静态初始化代码块中对类变量指定初始值 之后): 我们在 静态初始化代码块中对类变量指定初始值 已经不存在了，只有一个类变量指定的初始值 static double height = 10.0D; , 而在第二种情况下（定义类变量时指定初始值 在 静态初始化代码块中对类变量指定初始值 之前）和之前的源代码顺序是一样的，没啥区别。 上面的代码中充分的展示了类变量的两种初始化方式 ：每次运行该程序时，系统会为 A 类执行初始化，先为所有类变量分配内存空间，再按照源代码中的排列顺序执行静态初始代码块中所指定的初始值和定义类变量时所指定的初始值。","tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"}]},{"title":"Java 性能调优需要格外注意的细节","date":"2017-04-30T05:20:06.291Z","path":"2017/04/30/Java-performance-tuning/","text":"昨天写了篇文章 《MySQL 处理海量数据时的一些优化查询速度方法》 ，其实开发中不止数据库要优化，还有我们本身的开发代码也需要优化，这样我们开发的产品才能够得到极致的体验。也许有些人认为这些细小的地方没有啥好修改的，改与不改对运行效率没啥大的影响？首先在我们本地一个人测试下效率是不怎么明显，但是如果到发布上线后，你的用户有几百万，甚至上千万，这些用户同时访问你的网站，那么你的网站是否经得住考验呢，效率那高不高呢，如果效率不高，那么需要多出很多买服务器的经费呢，所以想想还是很有必要注意这些小的细节。今天就讲讲一些 Java 性能调优需要格外注意的一些细节。 代码优化的目标： 减少代码的体积 提高代码的运行效率 代码优化细节1、尽量指定类、方法的final修饰符 带有final修饰符的类是不可派生的。在Java核心API中，有许多应用final的例子，例如java.lang.String，整个类都是final的。为类指定final修饰符可以让类不可以被继承，为方法指定final修饰符可以让方法不可以被重写。如果指定了一个类为final。Java编译器会寻找机会内联所有的final方法，内联对于提升Java运行效率作用重大，具体参见Java运行期优化。 此举能够使性能平均提高50% 。 2、尽量重用对象 特别是String对象的使用，出现字符串连接时应该使用StringBuilder/StringBuffer代替。由于Java虚拟机不仅要花时间生成对象，以后可能还需要花时间对这些对象进行垃圾回收和处理，因此，生成过多的对象将会给程序的性能带来很大的影响。 3、尽可能使用局部变量 调用方法时传递的参数以及在调用中创建的临时变量都保存在栈中速度较快，其他变量，如静态变量、实例变量等，都在堆中创建，速度较慢。另外，栈中创建的变量，随着方法的运行结束，这些内容就没了，不需要额外的垃圾回收。 4、及时关闭流 Java编程过程中，进行数据库连接、I/O流操作时务必小心，在使用完毕后，及时关闭以释放资源。因为对这些大对象的操作会造成系统大的开销，稍有不慎，将会导致严重的后果。 5、尽量减少对变量的重复计算 明确一个概念，对方法的调用，即使方法中只有一句语句，也是有消耗的，包括创建栈帧、调用方法时保护现场、调用方法完毕时恢复现场等。所以例如下面的操作： 12for (int i = 0; i &lt; list.size(); i++)&#123;...&#125; 建议替换为： 12for (int i = 0, int length = list.size(); i &lt; length; i++)&#123;...&#125; 这样，在list.size()很大的时候，就减少了很多的消耗 6、尽量采用懒加载的策略，即在需要的时候才创建 例如： 1234String str = \"aaa\";if (i == 1)&#123; list.add(str);&#125; 建议替换为： 12345if (i == 1)&#123; String str = \"aaa\"; list.add(str);&#125; 7、慎用异常 异常对性能不利。抛出异常首先要创建一个新的对象，Throwable接口的构造函数调用名为 fillInStackTrace() 的本地同步方法，fillInStackTrace() 方法检查堆栈，收集调用跟踪信息。只要有异常被抛出，Java虚拟机就必须调整调用堆栈，因为在处理过程中创建了一个新的对象。异常只能用于错误处理，不应该用来控制程序流程。 8、不要在循环中使用 try…catch…，应该把其放在最外层 除非不得已。如果毫无理由地这么写了，只要你的领导资深一点、有强迫症一点，八成就要骂你为什么写出这种垃圾代码来了。 9、如果能估计到待添加的内容长度，为底层以数组方式实现的集合、工具类指定初始长度 比如 ArrayList、LinkedLlist、StringBuilder、StringBuffer、HashMap、HashSet 等等，以 StringBuilder 为例： （1）StringBuilder() // 默认分配16个字符的空间 （2）StringBuilder(int size) // 默认分配size个字符的空间 （3）StringBuilder(String str) // 默认分配16个字符+str.length()个字符空间 可以通过类（这里指的不仅仅是上面的 StringBuilder ）的来设定它的初始化容量，这样可以明显地提升性能。比如 StringBuilder 吧，length 表示当前的 StringBuilder 能保持的字符数量。因为当 StringBuilder 达到最大容量的时候，它会将自身容量增加到当前的2倍再加2，无论何时只要 StringBuilder 达到它的最大容量，它就不得不创建一个新的字符数组然后将旧的字符数组内容拷贝到新字符数组中—-这是十分耗费性能的一个操作。试想，如果能预估到字符数组中大概要存放5000个字符而不指定长度，最接近5000的2次幂是4096，每次扩容加的2不管，那么： （1）在4096 的基础上，再申请8194个大小的字符数组，加起来相当于一次申请了12290个大小的字符数组，如果一开始能指定5000个大小的字符数组，就节省了一倍以上的空间； （2）把原来的4096个字符拷贝到新的的字符数组中去。 这样，既浪费内存空间又降低代码运行效率。所以，给底层以数组实现的集合、工具类设置一个合理的初始化容量是错不了的，这会带来立竿见影的效果。但是，注意，像HashMap这种是以数组+链表实现的集合，别把初始大小和你估计的大小设置得一样，因为一个table上只连接一个对象的可能性几乎为0。初始大小建议设置为2的N次幂，如果能估计到有2000个元素，设置成 new HashMap(128)、new HashMap(256) 都可以。 10、当复制大量数据时，使用 System.arraycopy() 命令 11、乘法和除法使用移位操作 例如： 12345for (val = 0; val &lt; 100000; val += 5)&#123; a = val * 8; b = val / 2;&#125; 用移位操作可以极大地提高性能，因为在计算机底层，对位的操作是最方便、最快的，因此建议修改为： 12345for (val = 0; val &lt; 100000; val += 5)&#123; a = val &lt;&lt; 3; b = val &gt;&gt; 1;&#125; 移位操作虽然快，但是可能会使代码不太好理解，因此最好加上相应的注释。 12、循环内不要不断创建对象引用 例如： 1234for (int i = 1; i &lt;= count; i++)&#123; Object obj = new Object();&#125; 这种做法会导致内存中有count份Object对象引用存在，count很大的话，就耗费内存了，建议为改为： 12345Object obj = null;for (int i = 0; i &lt;= count; i++) &#123; obj = new Object(); &#125; 这样的话，内存中只有一份 Object 对象引用，每次 new Object() 的时候，Object 对象引用指向不同的Object罢了，但是内存中只有一份，这样就大大节省了内存空间了。 13、基于效率和类型检查的考虑，应该尽可能使用array，无法确定数组大小时才使用 ArrayList 14、尽量使用 HashMap、ArrayList、StringBuilder，除非线程安全需要，否则不推荐使用 Hashtable、Vector、StringBuffer，后三者由于使用同步机制而导致了性能开销 15、不要将数组声明为 public static final 因为这毫无意义，这样只是定义了引用为 static final，数组的内容还是可以随意改变的，将数组声明为 public 更是一个安全漏洞，这意味着这个数组可以被外部类所改变。 16、尽量在合适的场合使用单例 使用单例可以减轻加载的负担、缩短加载的时间、提高加载的效率，但并不是所有地方都适用于单例，简单来说，单例主要适用于以下三个方面： （1）控制资源的使用，通过线程同步来控制资源的并发访问 （2）控制实例的产生，以达到节约资源的目的 （3）控制数据的共享，在不建立直接关联的条件下，让多个不相关的进程或线程之间实现通信 17、尽量避免随意使用静态变量 要知道，当某个对象被定义为static的变量所引用，那么gc通常是不会回收这个对象所占有的堆内存的，如： 1234public class A&#123; private static B b = new B();&#125; 此时静态变量b的生命周期与A类相同，如果A类不被卸载，那么引用B指向的B对象会常驻内存，直到程序终止 18、及时清除不再需要的会话 为了清除不再活动的会话，许多应用服务器都有默认的会话超时时间，一般为30分钟。当应用服务器需要保存更多的会话时，如果内存不足，那么操作系统会把部分数据转移到磁盘，应用服务器也可能根据MRU（最近最频繁使用）算法把部分不活跃的会话转储到磁盘，甚至可能抛出内存不足的异常。如果会话要被转储到磁盘，那么必须要先被序列化，在大规模集群中，对对象进行序列化的代价是很昂贵的。因此，当会话不再需要时，应当及时调用 HttpSession 的 invalidate() 方法清除会话。 19、实现 RandomAccess 接口的集合比如 ArrayList，应当使用最普通的 for 循环而不是 foreach 循环来遍历 这是JDK推荐给用户的。JDK API对于 RandomAccess 接口的解释是：实现 RandomAccess 接口用来表明其支持快速随机访问，此接口的主要目的是允许一般的算法更改其行为，从而将其应用到随机或连续访问列表时能提供良好的性能。实际经验表明，实现 RandomAccess 接口的类实例，假如是随机访问的，使用普通 for 循环效率将高于使用 foreach 循环；反过来，如果是顺序访问的，则使用 Iterator 会效率更高。可以使用类似如下的代码作判断： 12345678910if (list instanceof RandomAccess)&#123; for (int i = 0; i &lt; list.size(); i++)&#123;&#125;&#125;else&#123; Iterator&lt;?&gt; iterator = list.iterable(); while (iterator.hasNext()) &#123; iterator.next(); &#125;&#125; foreach 循环的底层实现原理就是迭代器 Iterator，参见Java语法糖1：可变长度参数以及 foreach 循环原理。所以后半句”反过来，如果是顺序访问的，则使用 Iterator 会效率更高”的意思就是顺序访问的那些类实例，使用 foreach 循环去遍历。 20、使用同步代码块替代同步方法 这点在多线程模块中的 synchronized 锁方法块一文中已经讲得很清楚了，除非能确定一整个方法都是需要进行同步的，否则尽量使用同步代码块，避免对那些不需要进行同步的代码也进行了同步，影响了代码执行效率。 21、将常量声明为 static final，并以大写命名 这样在编译期间就可以把这些内容放入常量池中，避免运行期间计算生成常量的值。另外，将常量的名字以大写命名也可以方便区分出常量与变量 22、不要创建一些不使用的对象，不要导入一些不使用的类 这毫无意义，如果代码中出现”The value of the local variable i is not used”、”The import java.util is never used”，那么请删除这些无用的内容 23、程序运行过程中避免使用反射 关于，请参见反射。反射是Java提供给用户一个很强大的功能，功能强大往往意味着效率不高。不建议在程序运行过程中使用尤其是频繁使用反射机制，特别是Method的invoke方法，如果确实有必要，一种建议性的做法是将那些需要通过反射加载的类在项目启动的时候通过反射实例化出一个对象并放入内存—-用户只关心和对端交互的时候获取最快的响应速度，并不关心对端的项目启动花多久时间。 24、使用数据库连接池和线程池 这两个池都是用于重用对象的，前者可以避免频繁地打开和关闭连接，后者可以避免频繁地创建和销毁线程 25、使用带缓冲的输入输出流进行IO操作 带缓冲的输入输出流，即BufferedReader、BufferedWriter、BufferedInputStream、BufferedOutputStream，这可以极大地提升IO效率 26、顺序插入和随机访问比较多的场景使用ArrayList，元素删除和中间插入比较多的场景使用LinkedList这个，理解ArrayList和LinkedList的原理就知道了 27、不要让public方法中有太多的形参 public方法即对外提供的方法，如果给这些方法太多形参的话主要有两点坏处： 1、违反了面向对象的编程思想，Java讲求一切都是对象，太多的形参，和面向对象的编程思想并不契合 2、参数太多势必导致方法调用的出错概率增加 至于这个”太多”指的是多少个，3、4个吧。比如我们用JDBC写一个insertStudentInfo方法，有10个学生信息字段要插如Student表中，可以把这10个参数封装在一个实体类中，作为insert方法的形参。 28、字符串变量和字符串常量equals的时候将字符串常量写在前面 这是一个比较常见的小技巧了，如果有以下代码： 12String str = \"123\";if (str.equals(\"123\")) &#123;...&#125; 建议修改为： 12345String str = \"123\";if (\"123\".equals(str))&#123;...&#125; 这么做主要是可以避免空指针异常 29、请知道，在java中if (i == 1)和if (1 == i)是没有区别的，但从阅读习惯上讲，建议使用前者 平时有人问，”if (i == 1)”和”if (1== i)”有没有区别，这就要从C/C++讲起。 在C/C++中，”if (i == 1)”判断条件成立，是以0与非0为基准的，0表示false，非0表示true，如果有这么一段代码： 123456int i = 2;if (i == 1)&#123;...&#125;else&#123;...&#125; C/C++判断”i==1″不成立，所以以0表示，即false。但是如果： 1234567int i = 2;if (i = 1)&#123; ... &#125;else&#123;... &#125; 万一程序员一个不小心，把”if (i == 1)”写成”if (i = 1)”，这样就有问题了。在if之内将i赋值为1，if判断里面的内容非0，返回的就是true了，但是明明i为2，比较的值是1，应该返回的false。这种情况在C/C++的开发中是很可能发生的并且会导致一些难以理解的错误产生，所以，为了避免开发者在if语句中不正确的赋值操作，建议将if语句写为： 123456int i = 2;if (1 == i) &#123;... &#125;else&#123;... &#125; 这样，即使开发者不小心写成了”1 = i”，C/C++编译器也可以第一时间检查出来，因为我们可以对一个变量赋值i为1，但是不能对一个常量赋值1为i。 但是，在Java中，C/C++这种”if (i = 1)”的语法是不可能出现的，因为一旦写了这种语法，Java就会编译报错”Type mismatch: cannot convert from int to boolean”。但是，尽管Java的”if (i == 1)”和”if (1 == i)”在语义上没有任何区别，但是从阅读习惯上讲，建议使用前者会更好些。 30、不要对数组使用toString()方法 看一下对数组使用toString()打印出来的是什么： 12345public static void main(String[] args)&#123; int[] is = new int[]&#123;1, 2, 3&#125;; System.out.println(is.toString());&#125; 结果是： 1[I@18a992f 本意是想打印出数组内容，却有可能因为数组引用is为空而导致空指针异常。不过虽然对数组toString()没有意义，但是对集合toString()是可以打印出集合里面的内容的，因为集合的父类AbstractCollections重写了Object的toString()方法。 31、不要对超出范围的基本数据类型做向下强制转型 这绝不会得到想要的结果： 12345public static void main(String[] args)&#123; long l = 12345678901234L;int i = (int)l; System.out.println(i);&#125; 我们可能期望得到其中的某几位，但是结果却是： 1942892530 解释一下。Java中long是8个字节64位的，所以12345678901234在计算机中的表示应该是： 0000 0000 0000 0000 0000 1011 0011 1010 0111 0011 1100 1110 0010 1111 1111 0010 一个int型数据是4个字节32位的，从低位取出上面这串二进制数据的前32位是： 0111 0011 1100 1110 0010 1111 1111 0010 这串二进制表示为十进制1942892530，所以就是我们上面的控制台上输出的内容。从这个例子上还能顺便得到两个结论： 1、整型默认的数据类型是int，long l = 12345678901234L，这个数字已经超出了int的范围了，所以最后有一个L，表示这是一个long型数。顺便，浮点型的默认类型是double，所以定义float的时候要写成””float f = 3.5f” 2、接下来再写一句”int ii = l + i;”会报错，因为long + int是一个long，不能赋值给int 32、公用的集合类中不使用的数据一定要及时remove掉 如果一个集合类是公用的（也就是说不是方法里面的属性），那么这个集合里面的元素是不会自动释放的，因为始终有引用指向它们。所以，如果公用集合里面的某些数据不使用而不去remove掉它们，那么将会造成这个公用集合不断增大，使得系统有内存泄露的隐患。 33、把一个基本数据类型转为字符串，基本数据类型.toString()是最快的方式、String.valueOf(数据)次之、数据+””最慢 把一个基本数据类型转为一般有三种方式，我有一个Integer型数据i，可以使用i.toString()、String.valueOf(i)、i+””三种方式，三种方式的效率如何，看一个测试： 1234567891011121314151617181920212223public static void main(String[] args)&#123; int loopTime = 50000; Integer i = 0; long startTime = System.currentTimeMillis(); for (int j = 0; j &lt; loopTime; j++) &#123; String str = String.valueOf(i); &#125;System.out.println(\"String.valueOf()：\" + (System.currentTimeMillis() - startTime) + \"ms\"); startTime = System.currentTimeMillis(); for (int j = 0; j &lt; loopTime; j++) &#123; String str = i.toString(); &#125;System.out.println(\"Integer.toString()：\" + (System.currentTimeMillis() - startTime) + \"ms\");startTime = System.currentTimeMillis(); for (int j = 0; j &lt; loopTime; j++)&#123; String str = i + \"\";&#125;System.out.println(\"i + \\\"\\\"：\" + (System.currentTimeMillis() - startTime) + \"ms\");&#125; 运行结果为： 1String.valueOf()：11ms Integer.toString()：5ms i + &quot;&quot;：25ms 所以以后遇到把一个基本数据类型转为String的时候，优先考虑使用toString()方法。至于为什么，很简单： 1、String.valueOf()方法底层调用了Integer.toString()方法，但是会在调用前做空判断 2、Integer.toString()方法就不说了，直接调用了 3、i + “”底层使用了StringBuilder实现，先用append方法拼接，再用toString()方法获取字符串 三者对比下来，明显是2最快、1次之、3最慢 34、使用最有效率的方式去遍历Map 遍历Map的方式有很多，通常场景下我们需要的是遍历Map中的Key和Value，那么推荐使用的、效率最高的方式是： 123456789101112public static void main(String[] args)&#123;HashMap&lt;String, String&gt; hm = new HashMap&lt;String, String&gt;();hm.put(\"111\", \"222\");Set&lt;Map.Entry&lt;String, String&gt;&gt; entrySet = hm.entrySet();Iterator&lt;Map.Entry&lt;String, String&gt;&gt; iter = entrySet.iterator(); while (iter.hasNext())&#123;Map.Entry&lt;String, String&gt; entry = iter.next();System.out.println(entry.getKey() + \"\\t\" + entry.getValue());&#125;&#125; 如果你只是想遍历一下这个Map的key值，那用”Set keySet = hm.keySet();”会比较合适一些 35、对资源的close()建议分开操作 意思是，比如我有这么一段代码： 12345try&#123;XXX.close();YYY.close();&#125;catch (Exception e)&#123;...&#125; 建议修改为： 123456789try&#123; XXX.close(); &#125;catch (Exception e) &#123; ... &#125;try&#123; YYY.close(); &#125;catch (Exception e) &#123; ... &#125; 虽然有些麻烦，却能避免资源泄露。我想，如果没有修改过的代码，万一XXX.close()抛异常了，那么就进入了cath块中了，YYY.close()不会执行，YYY这块资源就不会回收了，一直占用着，这样的代码一多，是可能引起资源句柄泄露的。而改为上面的写法之后，就保证了无论如何XXX和YYY都会被close掉。 以上就是 Java 开发编程注意细节的全部内容了，感谢大家的阅读！","tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"}]},{"title":"MySQL 处理海量数据时的一些优化查询速度方法","date":"2017-04-29T10:05:54.287Z","path":"2017/04/29/MySQL-select-good/","text":"在参与实际项目中，当 MySQL 表的数据量达到百万级时，普通的 SQL 查询效率呈直线下降，而且如果 where 中的查询条件较多时，其查询速度无法容忍。想想可知，假如我们查询淘宝的一个订单详情，如果查询时间高达几十秒，这么高的查询延时，任何用户都会抓狂。因此如何提高 SQL 语句查询效率，显得十分重要。 查询速度慢的原因1、没有索引或者没有用到索引（这是查询慢最常见的问题，是程序设计的缺陷） 2、I/O 吞吐量小，形成了瓶颈效应。 3、没有创建计算列导致查询不优化。 4、内存不足 5、网络速度慢 6、查询出的数据量过大（可采用多次查询，其他的方法降低数据量） 7、锁或者死锁（这是查询慢最常见的问题，是程序设计的缺陷） 8、sp_lock,sp_who,活动的用户查看,原因是读写竞争资源。 9、返回了不必要的行和列 10、查询语句不好，没有优化 30 种 SQL 查询语句的优化方法：1、应尽量避免在 where 子句中使用 != 或者 &lt;&gt; 操作符，否则将引擎放弃使用索引而进行全表扫描。 2、应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描，如： 1select id from t where num is null; 可以在 num 上设置默认值 0 ，确保表中 num 列没有 null 值，然后这样查询： 1select id from t where num = 0; 3、对查询进行优化，应尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引。 4、尽量避免在 where 子句中使用 or 来连接条件，否则将导致引擎放弃使用索引而进行全表扫描，如： 1select id from t where num = 10 or num = 20; 可以这样查询： 123select id from t where num = 10union allselect id from t where num = 20; 5、下面的查询也将导致全表扫描：（不能前置百分号） 1select id from t where name like '%abc%'; 若要提高效率，可以考虑全文检索。 6、in 和 not in 也要慎用，否则会导致全表扫描，如： 1select id from t where num in(1, 2, 3); 对于连续的数值，能用 between 就不要用 in 了： 1select id from t where num between 1 and 3; 12345select xx,phone FROM send a JOIN ( select '13891030091' phone union select '13992085916' ………… UNION SELECT '13619100234' ) b on a.Phone=b.phone--替代下面 很多数据隔开的时候in('13891030091','13992085916','13619100234'…………) 7、如果在 where 子句中使用参数，也会导致全表扫描。因为 SQL 只有在运行时才会解析局部变量，但优化程序不能将访问计划的选择到运行时；它必须在编译时进行选择。然而，如果在编译时简历访问计划，变量的值还是未知的，因而无法作为索引选择的输入项。如下面语句将进行全表扫描： 1select id from t where num = @num; 可以改为强制查询使用索引： 1select id from t with(index(索引名)) where num = @num; 8、应尽量避免在 where 子句中对字段进行表达式操作，这将导致引擎放弃使用索引而进行全表扫描。如： 1select id from t where num/2 = 100; 应改为： 1select id from t where num = 100 * 2; 9、应尽量避免在 where 子句中对字段进行函数操作，这将导致引擎放弃使用索引而进行全表扫描。如： 12select id from t where substring(name, 1, 3) = ’abc’–name; //以abc开头的idselect id from t where datediff(day,createdate,’2005-11-30′) = 0–’2005-11-30′; //生成的id 应改为: 12select id from t where name like ‘abc%’select id from t where createdate &gt;= ’2005-11-30′ and createdate &lt; ’2005-12-1′; 10、不要在 where 子句中的 “=” 左边进行函数，算术运算或者其他表达式运算，否则系统将可能无法正确使用索引。 11、在使用索引字段作为条件时，如果该索引是复合索引，那么必须使用到该索引的第一个字段作为条件时才能保证系统使用该索引，否则该索引将不会被使用，并且应尽可能的让字段顺序与索引顺序相一致。 12、不要些一些没有意义的查询，如需要生成一个空表结构： 1select col1,col2 into #t from t where 1=0; 这类代码不会返回任何结果集，但是会消耗系统资源的，应改成这样： 1create table #t(…) 13、很多时候用 exists 代替 in 是一个好的选择： 1select num from a where num in(select num from b); 用下面的语句替换： 1select num from a where exists(select 1 from b where num=a.num); 14、并不是所有索引对查询都有效，SQL是根据表中数据来进行查询优化的，当索引列有大量数据重复时，SQL查询可能不会去利用索引，如一表中有字段 sex，male、female几乎各一半，那么即使在sex上建了索引也对查询效率起不了作用。 15、索引并不是越多越好，索引固然可以提高相应的 select 的效率，但同时也降低了 insert 及 update 的效率，因为 insert 或 update 时有可能会重建索引，所以怎样建索引需要慎重考虑，视具体情况而定。一个表的索引数最好不要超过6个，若太多则应考虑一些不常使用到的列上建的索引是否有必要。 16、应尽可能的避免更新 clustered 索引数据列，因为 clustered 索引数据列的顺序就是表记录的物理存储顺序，一旦该列值改变将导致整个表记录的顺序的调整，会耗费相当大的资源。若应用系统需要频繁更新 clustered 索引数据列，那么需要考虑是否应将该索引建为 clustered 索引。 17、尽量使用数字型字段，若只含数值信息的字段尽量不要设计为字符型，这会降低查询和连接的性能，并会增加存储开销。这是因为引擎在处理查询和连接时会 逐个比较字符串中每一个字符，而对于数字型而言只需要比较一次就够了。 18、尽可能的使用 varchar/nvarchar 代替 char/nchar ，因为首先变长字段存储空间小，可以节省存储空间，其次对于查询来说，在一个相对较小的字段内搜索效率显然要高些。 19、任何地方都不要使用 select * from t ，用具体的字段列表代替 *，不要返回用不到的任何字段。 20、尽量使用表变量来代替临时表。如果表变量包含大量数据，请注意索引非常有限（只有主键索引）。 21、避免频繁创建和删除临时表，以减少系统表资源的消耗。 22、临时表并不是不可使用，适当地使用它们可以使某些例程更有效，例如，当需要重复引用大型表或常用表中的某个数据集时。但是，对于一次性事件，最好使用导出表。 23、在新建临时表时，如果一次性插入数据量很大，那么可以使用 select into 代替 create table，避免造成大量 log ，以提高速度；如果数据量不大，为了缓和系统表的资源，应先 create table，然后 insert。 24、如果使用到了临时表，在存储过程的最后务必将所有的临时表显式删除，先 truncate table ，然后 drop table ，这样可以避免系统表的较长时间锁定。 25、尽量避免使用游标，因为游标的效率较差，如果游标操作的数据超过1万行，那么就应该考虑改写。 26、使用基于游标的方法或临时表方法之前，应先寻找基于集的解决方案来解决问题，基于集的方法通常更有效。 27、与临时表一样，游标并不是不可使用。对小型数据集使用 FAST_FORWARD 游标通常要优于其他逐行处理方法，尤其是在必须引用几个表才能获得所需的数据时。在结果集中包括“合计”的例程通常要比使用游标执行的速度快。如果开发时 间允许，基于游标的方法和基于集的方法都可以尝试一下，看哪一种方法的效果更好。 28、在所有的存储过程和触发器的开始处设置 SET NOCOUNT ON ，在结束时设置 SET NOCOUNT OFF 。无需在执行存储过程和触发器的每个语句后向客户端发送 DONE_IN_PROC 消息。 29、尽量避免向客户端返回大数据量，若数据量过大，应该考虑相应需求是否合理。 30、尽量避免大事务操作，提高系统并发能力。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://yoursite.com/tags/MySQL/"}]},{"title":"记录下自己第一次坐飞机的感受","date":"2017-04-23T02:20:42.665Z","path":"2017/04/23/feiji/","text":"前提因为学校的原因，需要在大三的时候出去实训几个月，然后选择的是在昆山，公司规定要在 2017 年 4 月 19 号之前赶到，所以我提前订的机票是 17 号，之所以会订机票，其实很大一部分原因是由于自己之前没有坐过飞机，所以想体验一下坐飞机的感脚（嘿嘿），再加上这是机票的淡季，所以坐飞机的价钱比做高铁还便宜。整个行程：学校 ——&gt; 南昌机场 ——&gt; 上海虹桥机场 ——&gt; 公司 学校出发10 点左右去食堂吃了个早餐，然后打包好自己的行李，由于第一次坐飞机，所以打算提前时间去机场，然后在机场熟悉熟悉环境，不然的话错过飞机，那就 gg 了。大概 11：30 了，就拖着行李出门，在学校门口叫了辆 滴滴车 去机场（因为公交车要坐好久并且去机场的路好烂），叫的滴滴车他走的是高速，很快。 南昌机场不到半小时就到了机场，首先干的事就是取票。 然后将行李箱免费托运（小于20公斤可免费托运，超过的话那就准备好 Money 吧），一个同行的同学就超重了。干完了这些事就没啥事了，然后就坐在凳子上看起了最近很火的电视剧《人民的名义》，的确很好看的，没看过的话，可以去看看。 大概 13：40 时，准备进站了，这里要说的就比较有趣了。我就具体的说下： 一开始排队（人不多），轮到我，把机票和身份证给她，然后对着摄像头拍了个照就进去检查随身携带的物品了。 这里之前我就听说了：说是飞机上不能携带液体，不知道我书包带的洗发液能不能过关？同学和我之前还在一起开玩笑说：1、如果不能带，我就当场一口闷了它。（这也行，下图随意找了个表情包） 2、我免费请大家洗个头 电脑和雨伞而外检查 书包和随身携带物品都拿出来过安检 人扫描（检查的挺细致的，比火车严多了） 结果检查人员告知我：把 洗发液 和 两个螺丝刀 拿出来。（我当场就震惊了，我那么小的螺丝刀都被检查到了，这几乎把我的书包给透视了一个遍） 然后呢，自己只好将违禁物品都拿出来，再次检查就可以通过了。 走进去的时候拍的一张照片, （电梯好长，不过后来在上海机场下车才发现那个也还好了） 进去后，又有一个小的进站室，又在那里等待了会。 又开始检票，检完票后坐公交车去飞机下面（因为飞机场太大，我坐的那架飞机不是靠近站台的） 上飞机后从窗口拍的一张照片 飞机上看见飞机的空姐和空少了。。（空姐很漂亮，嘻嘻，没拍照片） 飞机起飞的时候，机舱里有语音播放叫我们系上安全带，并且关闭手机，所以后面就没照片了。 起飞感觉走了好远，然后突然一加速，飞机就慢慢的向上飞起，整个人重心都是往后倒的。 不一会，飞机就飞的好高了，从窗口望下去，下面的感觉好美，一路上的风景感觉都挺漂亮的，有时还可以看到白云。 大概一个小时后，空姐推着个车，提供给我们点零食（面包、饼干、榨菜）和饮料（橙汁、苹果醋、矿泉水、咖啡，可自选一样，可再加一杯），服务还是挺贴心的，我在这里给中国东方航空点个赞。 飞机中途有时会颠簸，机舱里语音说是遇到空气气流的影响。（大部分时间还是很好的） 说说飞机下降的时候吧，同样，感觉声音很大，耳朵有点受不了。不知道空姐、空少们怎么长期受得了这这声音，长期下去，那估计耳朵都要出毛病的吧？ 上海虹桥机场机场给人的感觉很大，走了那个电梯都走了很远。 就只有一张照片。 然后再去取我的行李箱，有个专门来自南昌的取行李处，行李箱一个的放在传送带上，自己拿自己的行李出去。这里有个疑问，如果行李被别人提走的话，那该咋办，我看出口都没设置检查行李是否和本人的匹配？ 公司公司提前有大巴来接我们，坐上大巴，然后在车上躺了下，就睡着了，直到到达公司。 住宿地址和公司有点远，所以买了辆 死飞自行车，方便出行，自己周末也可以出去玩玩。 总结第一次坐飞机，感觉还是挺好的。流程也不复杂，所以不麻烦。 不过自己要注意一些东西： 不要携带飞机上违禁物品（液体、超过多大的充电宝、刀枪等） 一定要提前动身，以防发生突发事件 注意保管好自己的身份证 最后这是我在我博客上写的第一篇随笔文章，不知道咋写，就随便写。 因为星期六（昨天）出去玩了，所以今天早上起来写下来这篇，有些事还是得赶紧做掉去，不然一直拖，拖着拖着就没有想做的欲望了。 公司周围环境挺好的，水乡之地，有个阳澄湖，盛产大闸蟹，周围的大闸蟹庄，那叫一个字：多。有空的时候我尽量多去逛逛，拍点照片回来。 今后也会多写点随笔，记录生活中一些有趣且值得纪念的点滴。 感谢阅读！！！","tags":[{"name":"随笔","slug":"随笔","permalink":"http://yoursite.com/tags/随笔/"}]},{"title":"Github pages + Hexo 博客 yilia 主题使用畅言评论系统","date":"2017-04-13T14:38:53.710Z","path":"2017/04/13/Hexo-yilia-changyan/","text":"前言Hexo的Yilia主题由于原来使用的是多说的留言板，近期多说公告要停止提供服务了，所以我就把多说换成搜狐的畅言了，下面写一个简单的小教程。 注册畅言进入畅言官网 , 点击右上角 “免费注册”，并填写注册信息。（注意域名需要备案信息） 登录并进入畅言后台注册完后，登录进入畅言官网，获取你的畅言 app id 和 app key。 使用畅言系统下面说下修改评论为畅言的方法，其实方法和多说是差不多的。 1、修改 themes\\yilia\\layout\\_partial\\article.ejs 模板，把如下代码 1234567&lt;% if (!index &amp;&amp; post.comments &amp;&amp; config.disqus_shortname)&#123; %&gt; &lt;section id=\"comments\"&gt; &lt;div id=\"disqus_thread\"&gt; 这里还有很多代码 &lt;/div&gt; &lt;/section&gt; &lt;% &#125; %&gt; 修改为： 1234567891011121314151617181920 &lt;% if (!index &amp;&amp; post.comments)&#123; %&gt; &lt;section id=&quot;comments&quot;&gt;&lt;!--高速版，加载速度快，使用前需测试页面的兼容性--&gt;&lt;div id=&quot;SOHUCS&quot; sid=&quot;&lt;%= page.title %&gt;&quot;&gt;&lt;/div&gt;&lt;script&gt; (function()&#123; var appid = &apos;你的APP ID&apos;, conf = &apos;你的APP KEY&apos;; var doc = document, s = doc.createElement(&apos;script&apos;), h = doc.getElementsByTagName(&apos;head&apos;)[0] || doc.head || doc.documentElement; s.type = &apos;text/javascript&apos;; s.charset = &apos;utf-8&apos;; s.src = &apos;http://assets.changyan.sohu.com/upload/changyan.js?conf=&apos;+ conf +&apos;&amp;appid=&apos; + appid; h.insertBefore(s,h.firstChild); window.SCS_NO_IFRAME = true; &#125;)()&lt;/script&gt; &lt;/section&gt; &lt;% &#125; %&gt; 上面的APP ID和APP KEY是在畅言设置中得到。 这里需要注意一点的是：sid=&quot;&lt;%= page.title %&gt;&quot;&gt; 这样的话畅言就可以直接根据对应的文章来识别，使得文章有对应的评论，不会都乱在一起。 2、在每篇文章开头的 front-matter 中添加一句comments: true，然后回到博客根目录执行命令 hexo d -g ，重新生成博客并部署博客，然后刷新，任选一篇文章进入下拉，会发现评论功能可以使用了。 修改 BUG但是，这是你会发现一个 Bug，表情按钮点击不了，原因是被左侧的 div 层覆盖了，回到我们刚才改过的代码，找到 &lt;div id=&quot;SOHUCS&quot; 开头的一串代码。并做如下更改 1&lt;div id=\"SOHUCS\" sid=\"&lt;%=title %&gt;\" style=\"padding: 0px 30px 0px 46px;\"&gt;&lt;/div&gt; 加上上面这一段样式代码，即可修复。 参考文章： 1、Hexo博客yilia主题更换畅言评论系统 2、在Hexo中使用畅言评论系统","tags":[{"name":"hexo","slug":"hexo","permalink":"http://yoursite.com/tags/hexo/"},{"name":"yilia","slug":"yilia","permalink":"http://yoursite.com/tags/yilia/"}]},{"title":"MyBatis的foreach语句详解","date":"2017-04-09T12:11:33.627Z","path":"2017/04/09/MyBatis-foreach/","text":"foreach 的主要用在构建in条件中，它可以在SQL语句中进行迭代一个集合。 foreach 元素的属性主要有 item，index，collection，open，separator，close。 item 表示集合中每一个元素进行迭代时的别名， index 指 定一个名字，用于表示在迭代过程中，每次迭代到的位置， open 表示该语句以什么开始， separator 表示在每次进行迭代之间以什么符号作为分隔 符， close 表示以什么结束。 在使用 foreach 的时候最关键的也是最容易出错的就是 collection 属性，该属性是必须指定的，但是在不同情况 下，该属性的值是不一样的，主要有一下3种情况： 如果传入的是单参数且参数类型是一个List的时候，collection 属性值为 list 如果传入的是单参数且参数类型是一个 array 数组的时候，collection 的属性值为 array 如果传入的参数是多个的时候，我们就需要把它们封装成一个 Map 了，当然单参数也可以封装成map，实际上如果你在传入参数的时候，在 breast 里面也是会把它封装成一个 Map 的，map 的 key 就是参数名，所以这个时候 collection 属性值就是传入的 List 或 array 对象在自己封装的 map 里面的 key 。 下面分别来看看上述三种情况的示例代码： 1.单参数 List 的类型： 123456&lt;select id=\"dynamicForeachTest\" resultType=\"Blog\"&gt; select * from t_blog where id in &lt;foreach collection=\"list\" index=\"index\" item=\"item\" open=\"(\" separator=\",\" close=\")\"&gt; #&#123;item&#125; &lt;/foreach&gt;&lt;/select&gt; 上述 collection 的值为list，对应的 Mapper 是这样的 1public List&lt;Blog&gt; dynamicForeachTest(List&lt;Integer&gt; ids); 测试代码： 12345678910111213@Test public void dynamicForeachTest() &#123; SqlSession session = Util.getSqlSessionFactory().openSession(); BlogMapper blogMapper = session.getMapper(BlogMapper.class); List&lt;Integer&gt; ids = new ArrayList&lt;Integer&gt;(); ids.add(1); ids.add(3); ids.add(6); List&lt;Blog&gt; blogs = blogMapper.dynamicForeachTest(ids); for (Blog blog : blogs) System.out.println(blog); session.close(); &#125; 2.单参数array数组的类型： 123456&lt;select id=\"dynamicForeach2Test\" resultType=\"Blog\"&gt; select * from t_blog where id in &lt;foreach collection=\"array\" index=\"index\" item=\"item\" open=\"(\" separator=\",\" close=\")\"&gt; #&#123;item&#125; &lt;/foreach&gt;&lt;/select&gt; 上述collection为array，对应的Mapper代码： 1public List&lt;Blog&gt; dynamicForeach2Test(int[] ids); 对应的测试代码： 12345678910@Test public void dynamicForeach2Test() &#123; SqlSession session = Util.getSqlSessionFactory().openSession(); BlogMapper blogMapper = session.getMapper(BlogMapper.class); int[] ids = new int[] &#123;1,3,6,9&#125;; List&lt;Blog&gt; blogs = blogMapper.dynamicForeach2Test(ids); for (Blog blog : blogs) System.out.println(blog); session.close(); &#125; 3.自己把参数封装成Map的类型 123456&lt;select id=\"dynamicForeach3Test\" resultType=\"Blog\"&gt; select * from t_blog where title like \"%\"#&#123;title&#125;\"%\" and id in &lt;foreach collection=\"ids\" index=\"index\" item=\"item\" open=\"(\" separator=\",\" close=\")\"&gt; #&#123;item&#125; &lt;/foreach&gt;&lt;/select&gt; 上述collection的值为ids，是传入的参数Map的key，对应的Mapper代码： 1public List&lt;Blog&gt; dynamicForeach3Test(Map&lt;String, Object&gt; params); 对应测试代码： 12345678910111213141516171819@Test public void dynamicForeach3Test() &#123; SqlSession session = Util.getSqlSessionFactory().openSession(); BlogMapper blogMapper = session.getMapper(BlogMapper.class); final List&lt;Integer&gt; ids = new ArrayList&lt;Integer&gt;(); ids.add(1); ids.add(2); ids.add(3); ids.add(6); ids.add(7); ids.add(9); Map&lt;String, Object&gt; params = new HashMap&lt;String, Object&gt;(); params.put(\"ids\", ids); params.put(\"title\", \"中国\"); List&lt;Blog&gt; blogs = blogMapper.dynamicForeach3Test(params); for (Blog blog : blogs) System.out.println(blog); session.close(); &#125;","tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://yoursite.com/tags/Mybatis/"},{"name":"foreach","slug":"foreach","permalink":"http://yoursite.com/tags/foreach/"}]},{"title":"关于String s = new String(\"xyz\"); 创建几个对象的问题","date":"2017-04-05T14:42:32.955Z","path":"2017/04/05/String-new/","text":"你知道在 java 中除了 8 种基本类型外，其他的都是类对象以及其引用。所以 &quot;xyz &quot;在 java 中它是一个String 对象.对于 string 类对象来说他的对象值是不能修改的，也就是具有不变性。 看：1234String s= &quot;hello &quot;; s= &quot;Java &quot;; String s1= &quot;hello &quot;; String s2=new String( &quot;hello &quot;); 结果如下图： 啊，s 所引用的 string 对象不是被修改了吗？之前所说的不变性，去那里了啊？你别着急，让我告诉你说发生了什么事情：在 jvm 的工作过程中，会创建一片的内存空间专门存入 string 对象。我们把这片内存空间叫做 string 池。 String s = “hello “; 当 jvm 看到 “hello”，在 string 池创建 string 对象存储它，并将他的引用返回给s。s = “java “，当 jvm 看到 “java “，在 string 池创建新的 string 对象存储它，再把新建的 string 对象的引用返回给s。而原先的 “hello”仍然在 string 池内。没有消失，他是不能被修改的。 所以我们仅仅是改变了s的引用，而没有改变他所引用的对象，因为 string 对象的值是不能被修改的。 String s1 = “hello” ; jvm 首先在 string 池内里面看找不找得到字符串 “hello”, 如果找得到,返回他的引用给 s1，否则的话就会创建新的 string 对象，放到 string 池里。这里由于 s = “hello”了,对象已经被引用，所以依据规则 s 和 s1 都是引用同一个对象。所以 s == s1 将返回 true。( == 对于非基本类型，是比较两引用是否引用内存中的同一个对象，这里先不区分 == 和 equals 的区别 ) String s2 = new String( “hello”); jvm 首先在 string 池内里面看找不找得到字符串 “hello”, 如果找得到, 不做任何事情，否则的话就会创建新的 string 对象，放到 string 池里面。由于遇到了 new，还会在内存上（不是 string 池里面）创建 string 对象存储 “hello”，并将内存上的（不是 string 池内的）string 对象返回给 s2。所以 s == s2 将返回 false，不是引用同一个对象。 好现在我们看题目：String s = new String( “xyz “);首先在 string 池内找，找到？不创建 string 对象，否则创建一个对象，遇到 new 运算符号了，在内存上创建 string 对象，并将其返回给 s，又一个对象 所以总共是 1个 或者 2个对象 。 而为什么在网上都说 String s=new String(“hello”); 创建了2个对象？那可能因为它就写这么一句代码，误让人默认的认为执行代码之前并不实例任何一个 String 对象过（也许 很多人不会这么想，），跟着别人或者不经思考的就说2个，斟是说存放在栈内存中专门存放 String 对象引用的 s 变量是一个对象！","tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"String","slug":"String","permalink":"http://yoursite.com/tags/String/"}]},{"title":"解决jdk1.8中发送邮件失败（handshake_failure）问题","date":"2017-03-28T11:00:47.293Z","path":"2017/03/28/解决jdk1.8中发送邮件失败（handshake_failure）问题/","text":"暑假在家做一个类似知乎的问答型网站（代码可见：Github/wenda 喜欢的可以给个star或者自己fork然后修改，目前功能还未很完善），其中有一个站内邮件通知系统（这里简单的讲一个例子：如果用户登录的时候出现异常，那么就会通过邮件发送通知用户）。然而却碰到一个问题。问题错误信息如下： 发送邮件失败Mail server connection failed; nested exception is javax.mail.MessagingException: Could not connect to SMTP host: smtp.qq.com, port: 465;nested exception is: javax.net.ssl.SSLHandshakeException: Received fatal alert: handshake_failure. Failed messages: javax.mail. MessagingException: Could not connect to SMTP host: smtp.qq.com, port: 465;nested exception is: javax.net.ssl.SSLHandshakeException: Received fatal alert: handshake_failure 自己在将错误信息代码google了一下，找了很久发现很多解决方案，包括stackoverflow上的一些解决方案，但还是没用。然后呢用百度试了下，结果在第一条是开源中国的一篇博客:javax.net.ssl.SSLHandshakeException: Received fatal alert: handshake_failure。 点进去是这样的：（如下图） 结果就是：这个问题是jdk导致的，jdk1.8里面有一个jce的包，安全性机制导致的访问https会报错，官网上有替代的jar包，如果替换掉就可以了。问题的解决方法还可以就是在整个项目中把你的jdk换成是1.7去，同样也可以解决这个我问题。 这两个jar包的下载地址：http://www.oracle.com/technetwork/java/javase/downloads/jce-7-download-432124.html 然后下载之后，把这个压缩文件解压，得到两个jar包去覆盖jdk安装目录下的jre\\lib\\security\\下相同的jar包就能解决java8的邮件发送问题。 接着用QQ邮箱我亲测有用，但是要注意一点就是：开启SMTP服务后要记得将你的16位授权码作为你的qq邮箱登录密码。 MailSender.java中mailSender.setPassword(“16位授权码”); mailSender.setHost(“smtp.qq.com”);mailSender.setPort(465); 下面把完整代码发布出来： 1. LoginExceptionHandler.java 12345678910111213141516171819202122232425262728293031323334package com.nowcoder.async.handler;import com.nowcoder.async.EventHandler;import com.nowcoder.async.EventModel;import com.nowcoder.async.EventType;import com.nowcoder.util.MailSender;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Component;import java.util.Arrays;import java.util.HashMap;import java.util.List;import java.util.Map;/** * Created by 10412 on 2016/8/10. */@Componentpublic class LoginExceptionHandler implements EventHandler&#123; @Autowired MailSender mailSender; @Override public void doHandle(EventModel model) &#123; // xxxx判断发现这个用户登陆异常 Map&lt;String, Object&gt; map = new HashMap&lt;String, Object&gt;(); map.put(\"username\", model.getExt(\"username\")); mailSender.sendWithHTMLTemplate(model.getExt(\"email\"), \"登陆IP异常\", \"mails/login_exception.html\", map); &#125; @Override public List&lt;EventType&gt; getSupportEventTypes() &#123; return Arrays.asList(EventType.LOGIN); &#125;&#125; 2. LoginController.java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114package com.nowcoder.controller;import com.nowcoder.async.EventModel;import com.nowcoder.async.EventProducer;import com.nowcoder.async.EventType;import com.nowcoder.service.UserService;import org.apache.commons.lang.StringUtils;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.CookieValue;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestMethod;import org.springframework.web.bind.annotation.RequestParam;import javax.servlet.http.Cookie;import javax.servlet.http.HttpServletResponse;import java.util.Map;/** * Created by 10412 on 2016/7/2. */@Controllerpublic class LoginController &#123; private static final Logger logger = LoggerFactory.getLogger(LoginController.class); @Autowired UserService userService; @Autowired EventProducer eventProducer; @RequestMapping(path = &#123;&quot;/reg/&quot;&#125;, method = &#123;RequestMethod.POST&#125;) public String reg(Model model, @RequestParam(&quot;username&quot;) String username, @RequestParam(&quot;password&quot;) String password, @RequestParam(&quot;next&quot;) String next, @RequestParam(value=&quot;rememberme&quot;, defaultValue = &quot;false&quot;) boolean rememberme, HttpServletResponse response) &#123; try &#123; Map&lt;String, Object&gt; map = userService.register(username, password); if (map.containsKey(&quot;ticket&quot;)) &#123; Cookie cookie = new Cookie(&quot;ticket&quot;, map.get(&quot;ticket&quot;).toString()); cookie.setPath(&quot;/&quot;); if (rememberme) &#123; cookie.setMaxAge(3600*24*5); &#125; response.addCookie(cookie); if (StringUtils.isNotBlank(next)) &#123; return &quot;redirect:&quot; + next; &#125; return &quot;redirect:/&quot;; &#125; else &#123; model.addAttribute(&quot;msg&quot;, map.get(&quot;msg&quot;)); return &quot;login&quot;; &#125; &#125; catch (Exception e) &#123; logger.error(&quot;注册异常&quot; + e.getMessage()); model.addAttribute(&quot;msg&quot;, &quot;服务器错误&quot;); return &quot;login&quot;; &#125; &#125; @RequestMapping(path = &#123;&quot;/reglogin&quot;&#125;, method = &#123;RequestMethod.GET&#125;) public String regloginPage(Model model, @RequestParam(value = &quot;next&quot;, required = false) String next) &#123; model.addAttribute(&quot;next&quot;, next); return &quot;login&quot;; &#125; @RequestMapping(path = &#123;&quot;/login/&quot;&#125;, method = &#123;RequestMethod.POST&#125;) public String login(Model model, @RequestParam(&quot;username&quot;) String username, @RequestParam(&quot;password&quot;) String password, @RequestParam(value=&quot;next&quot;, required = false) String next, @RequestParam(value=&quot;rememberme&quot;, defaultValue = &quot;false&quot;) boolean rememberme, HttpServletResponse response) &#123; try &#123; Map&lt;String, Object&gt; map = userService.login(username, password); if (map.containsKey(&quot;ticket&quot;)) &#123; Cookie cookie = new Cookie(&quot;ticket&quot;, map.get(&quot;ticket&quot;).toString()); cookie.setPath(&quot;/&quot;); if (rememberme) &#123; cookie.setMaxAge(3600*24*5); &#125; response.addCookie(cookie); eventProducer.fireEvent(new EventModel(EventType.LOGIN) .setExt(&quot;username&quot;, username).setExt(&quot;email&quot;, &quot;****@qq.com&quot;) .setActorId((int)map.get(&quot;userId&quot;))); if (StringUtils.isNotBlank(next)) &#123; return &quot;redirect:&quot; + next; &#125; return &quot;redirect:/&quot;; &#125; else &#123; model.addAttribute(&quot;msg&quot;, map.get(&quot;msg&quot;)); return &quot;login&quot;; &#125; &#125; catch (Exception e) &#123; logger.error(&quot;登陆异常&quot; + e.getMessage()); return &quot;login&quot;; &#125; &#125; @RequestMapping(path = &#123;&quot;/logout&quot;&#125;, method = &#123;RequestMethod.GET, RequestMethod.POST&#125;) public String logout(@CookieValue(&quot;ticket&quot;) String ticket) &#123; userService.logout(ticket); return &quot;redirect:/&quot;; &#125;&#125; 3. EventHandler.java1234567891011121314package com.nowcoder.async;import java.util.List;/** * Created by 10412 on 2016/8/10. */public interface EventHandler&#123; void doHandle(EventModel model); List&lt;EventType&gt; getSupportEventTypes();&#125; 4. MailSender.java 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970package com.nowcoder.util;import org.apache.velocity.app.VelocityEngine;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.beans.factory.InitializingBean;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.mail.javamail.JavaMailSenderImpl;import org.springframework.mail.javamail.MimeMessageHelper;import org.springframework.stereotype.Service;import org.springframework.ui.velocity.VelocityEngineUtils;import javax.mail.internet.InternetAddress;import javax.mail.internet.MimeMessage;import javax.mail.internet.MimeUtility;import java.util.Map;import java.util.Properties;/** * Created by 10412 on 2016/8/10. // ***@qq.com wnppafhsbrcgbfbh（16位授权码） */@Servicepublic class MailSender implements InitializingBean &#123; private static final Logger logger = LoggerFactory.getLogger(MailSender.class); private JavaMailSenderImpl mailSender; @Autowired private VelocityEngine velocityEngine; public boolean sendWithHTMLTemplate(String to, String subject, String template, Map&lt;String, Object&gt; model) &#123; try &#123; String nick = MimeUtility.encodeText(\"***\"); InternetAddress from = new InternetAddress(nick + \"&lt;****@qq.com&gt;\"); MimeMessage mimeMessage = mailSender.createMimeMessage(); MimeMessageHelper mimeMessageHelper = new MimeMessageHelper(mimeMessage); String result = VelocityEngineUtils .mergeTemplateIntoString(velocityEngine, template, \"UTF-8\", model); mimeMessageHelper.setTo(to); mimeMessageHelper.setFrom(from); mimeMessageHelper.setSubject(subject); mimeMessageHelper.setText(result, true); mailSender.send(mimeMessage); return true; &#125; catch (Exception e) &#123; logger.error(\"发送邮件失败\" + e.getMessage()); return false; &#125; &#125; @Override public void afterPropertiesSet() throws Exception &#123; mailSender = new JavaMailSenderImpl(); mailSender.setUsername(\"***@qq.com\"); mailSender.setPassword(\"wnppafhsbrcgbfbh\"); //qq邮箱开启smtp服务后使用16位授权码在第三方登录// mailSender.setHost(\"smtp.exmail.qq.com\"); mailSender.setHost(\"smtp.qq.com\"); mailSender.setPort(465);// mailSender.setHost(\"smtp.163.com\"); //163邮箱// mailSender.setPort(25); mailSender.setProtocol(\"smtps\"); mailSender.setDefaultEncoding(\"utf8\"); Properties javaMailProperties = new Properties(); javaMailProperties.put(\"mail.smtp.ssl.enable\", true); //javaMailProperties.put(\"mail.smtp.auth\", true); //javaMailProperties.put(\"mail.smtp.starttls.enable\", true); mailSender.setJavaMailProperties(javaMailProperties); &#125;&#125; 5. login_exception.html 发送消息模板（可自定义） 1你好$username，你的登陆有问题! 一切都好了，运行。 登录。 发送邮件过来了。 总结来说：这个错误就是jdk1.8中的一个jce的包，安全性机制导致访问https会报错。","tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"邮件发送","slug":"邮件发送","permalink":"http://yoursite.com/tags/邮件发送/"}]},{"title":"循环队列的相关条件和公式","date":"2017-03-28T11:00:11.318Z","path":"2017/03/28/循环队列的相关条件和公式/","text":"循环队列的相关条件和公式：队尾指针是rear,队头是front，其中QueueSize为循环队列的最大长度 队空条件：rear==front 队满条件：(rear+1) %QueueSIze==front 计算队列长度：（rear-front+QueueSize）%QueueSize 入队：（rear+1）%QueueSize 出队：（front+1）%QueueSize 队列中元素的个数： (rear-front+QueueSize)%QueueSize","tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://yoursite.com/tags/数据结构/"},{"name":"算法","slug":"算法","permalink":"http://yoursite.com/tags/算法/"},{"name":"循环队列","slug":"循环队列","permalink":"http://yoursite.com/tags/循环队列/"}]},{"title":"Python爬虫实战之爬取糗事百科段子","date":"2017-03-28T10:59:16.278Z","path":"2017/03/28/Python爬虫实战之爬取糗事百科段子/","text":"完整代码地址：Python爬虫实战之爬取糗事百科段子程序代码详解： Spider1-qiushibaike.py：爬取糗事百科的8小时最新页的段子。包含的信息有作者名称，觉得好笑人数，评论人数，发布的内容。如果发布的内容中含有图片的话，则过滤图片，内容依然显示出来。 Spider2-qiushibaike.py：在Spider1-qiushibaike.py基础上，引入类和方法，进行优化和封装，爬取糗事百科的24小时热门页的段子。进一步优化，每按一次回车更新一条内容，当前页的内容抓取完毕后，自动抓取下一页的内容，按‘q’退出。 Spider3-qiushibaike.py：在Spiders-qiushibaike.py基础上，爬取了百科段子的评论。按C查看当前这个糗事的评论，当切换到查看评论时，换回车显示下一个评论,按Q退出回到查看糗事。糗事段子页数是一页一页加载的，如果你已经看完所有的糗事，就会自动退出！ 本爬虫目标： 抓取糗事百科热门段子 过滤带有图片的段子 实现每按一次回车显示一个段子的发布时间，发布人，段子内容，点赞数，评论人数。 糗事百科是不需要登录的，所以也没必要用到Cookie，另外糗事百科有的段子是附图的，我们把图抓下来图片不便于显示，那么我们就尝试过滤掉有图的段子吧。 好，现在我们尝试抓取一下糗事百科的热门段子吧，每按下一次回车我们显示一个段子。 1.确定URL并抓取页面代码首先我们确定好页面的URL是 http://www.qiushibaike.com/hot/page/1，其中最后一个数字1代表页数，我们可以传入不同的值来获得某一页的段子内容。 2.提取某一页的所有段子好，获取了HTML代码之后，我们开始分析怎样获取某一页的所有段子。 首先我们审查元素看一下，按浏览器的F12，截图如下: 我们可以看到，每一个段子都是 &lt;div class=”article block untagged mb15″ id=”…”&gt;…&lt;/div&gt; 包裹的内容。 现在我们想获取发布人，发布日期，段子内容，点赞人数和评论人数。不过另外注意的是，段子有些是带图片的，如果我们想在控制台显示图片是不现实的，所以我们直接把带有图片的段子给它剔除掉，只保存仅含文本的段子。 所以我们加入如下正则表达式来匹配一下，用到的方法是 re.findall 是找寻所有匹配的内容。方法的用法详情可以看前面说的正则表达式的介绍。 好，我们的正则表达式匹配语句书写如下，在原来的基础上追加如下代码： 123456789#正则表达式匹配 pattern = re.compile(&apos;&lt;div.*?author.*?&gt;.*?&lt;img.*?&gt;.*?&lt;h2&gt;(.*?)&lt;/h2&gt;.*?&lt;div.*?&apos;+ &apos;content&quot;&gt;(.*?)&lt;/div&gt;(.*?)&lt;div.*?class=&quot;number&quot;&gt;(.*?)&lt;/i&gt;.*?class=&quot;number&quot;&gt;(.*?)&lt;/i&gt;&apos;,re.S) items = re.findall(pattern,content) for item in items: haveImg = re.search(&quot;img&quot;,item[2]) if not haveImg: print item[0],item[3],item[4],item[1] #item[0]是作者名称 item[3]好笑人数 item[4]评论人数 item[1]内容 item[2]是内容后面的东西，如果含有图片，过滤掉 现在正则表达式在这里稍作说明 1） .*? 是一个固定的搭配， . 和 * 代表可以匹配任意无限多个字符，加上 ？ 表示使用非贪婪模式进行匹配，也就是我们会尽可能短地做匹配，以后我们还会大量用到 .*? 的搭配。 2）(.*?) 代表一个分组，在这个正则表达式中我们匹配了五个分组，在后面的遍历 item 中，item[0] 就代表第一个 (.*?) 所指代的内容，item[1] 就代表第二个 (.*?) 所指代的内容，以此类推。 3）re.S 标志代表在匹配时为点任意匹配模式，点 . 也可以代表换行符。 这样我们就获取了发布人，发布时间，发布内容，附加图片以及点赞数。 在这里注意一下，我们要获取的内容如果是带有图片，直接输出出来比较繁琐，所以这里我们只获取不带图片的段子就好了。 所以，在这里我们就需要对带图片的段子进行过滤。 我们可以发现，带有图片的段子会带有类似下面的代码，而不带图片的则没有，所以，我们的正则表达式的 item[2] 就是获取了下面的内容，如果不带图片，item[2]获取的内容便是空，所以我们只需要判断 item[2]中是否含有 img 标签就可以了。 整体代码如下： 12345678910111213141516171819202122232425262728293031323334#-*-coding:utf8-*-#created by 10412 2016/8/23#爬取糗事百科的8小时最新页的段子。包含的信息有作者名称，觉得好笑人数，评论人数，发布的内容。#如果发布的内容中含有图片的话，则过滤图片，内容依然显示出来。import urllibimport urllib2import re#自定义输入爬取的页数page = raw_input(&quot;please enter the page number:&quot;)url = &apos;http://www.qiushibaike.com/8hr/page/&apos;+ page +&apos;/?s=4880477&apos;user_agent = &apos;Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)&apos;headers = &#123; &apos;User-Agent&apos; : user_agent &#125;try: request = urllib2.Request(url,headers = headers) response = urllib2.urlopen(request) content = response.read().decode(&apos;utf-8&apos;) #正则表达式匹配 pattern = re.compile(&apos;&lt;div.*?author.*?&gt;.*?&lt;img.*?&gt;.*?&lt;h2&gt;(.*?)&lt;/h2&gt;.*?&lt;div.*?&apos;+ &apos;content&quot;&gt;(.*?)&lt;/div&gt;(.*?)&lt;div.*?class=&quot;number&quot;&gt;(.*?)&lt;/i&gt;.*?class=&quot;number&quot;&gt;(.*?)&lt;/i&gt;&apos;,re.S) items = re.findall(pattern,content) for item in items: haveImg = re.search(&quot;img&quot;,item[2]) if not haveImg: print item[0],item[3],item[4],item[1] #item[0]是作者名称 item[3]好笑人数 item[4]评论人数 item[1]内容 item[2]是内容后面的东西，如果含有图片，过滤掉except urllib2.URLError, e: if hasattr(e,&quot;code&quot;): print e.code if hasattr(e,&quot;reason&quot;): print e.reason 运行一下看下效果: 恩，带有图片的段子已经被剔除啦。 3.完善交互，设计面向对象模式好啦，现在最核心的部分我们已经完成啦，剩下的就是修一下边边角角的东西，我们想达到的目的是： 按下回车，读取一个段子，显示出段子的发布人，内容，点赞个数及评论数量。 另外我们需要设计面向对象模式，引入类和方法，将代码做一下优化和封装，最后，我们的代码如下所示 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788#-*-coding:utf8-*-#created by 10412# 在Spider1-qiushibaike.py基础上，引入类和方法，进行优化和封装，爬取糗事百科的24小时热门页的段子。# 进一步优化，每按一次回车更新一条内容，当前页的内容抓取完毕后，自动抓取下一页的内容，按‘q’退出。import urllib2import reclass QSBK: def __init__(self): self.pageIndex = 1 self.user_agent = &apos;Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)&apos; self.headers = &#123;&apos;User-Agent&apos; : self.user_agent&#125; self.stories = [] # 存放程序是否继续运行的变量 self.enable = False # 传入某一页的索引获得页面代码 def getPage(self, pageIndex): try: url = &apos;http://www.qiushibaike.com/hot/page/&apos; + str(pageIndex) request = urllib2.Request(url, headers=self.headers) response = urllib2.urlopen(request) pageCode = response.read().decode(&apos;utf-8&apos;) return pageCode except urllib2.URLError, e: if hasattr(e, &quot;reason&quot;): print u&quot;连接糗事百科失败,错误原因&quot;, e.reason return None # 传入某一页代码，返回本页不带图片的段子列表 def getPageItems(self, pageIndex): pageCode = self.getPage(pageIndex) if not pageCode: print u&quot;出错了&quot; return None pattern = re.compile(&apos;&lt;div class=&quot;author.*?href.*?&lt;img src.*?title=.*?&lt;h2&gt;(.*?)&lt;/h2&gt;.*?&lt;div class=&quot;content&quot;&gt;(.*?)&lt;/div&gt;.*?&lt;i class=&quot;number&quot;&gt;(.*?)&lt;/i&gt;.*?class=&quot;number&quot;&gt;(.*?)&lt;/i&gt;&apos;,re.S) items = re.findall(pattern, pageCode) pageStories = [] for item in items: replaceBR = re.compile(&apos;&lt;br/&gt;&apos;) text = re.sub(replaceBR, &quot;\\n&quot;, item [1] ) pageStories.append([item[0].strip(), text.strip(), item[2].strip(), item[3].strip()]) return pageStories # 加载并提取页面内容，加入到列表中 def loadPage(self): if self.enable == True: if len(self.stories) &lt; 2: # 获取新一页 pageStories = self.getPageItems(self.pageIndex) if pageStories: self.stories.append(pageStories) self.pageIndex += 1 # 调用该方法，回车打印一个段子 def getOneStory(self, pageStories, page): for story in pageStories: input = raw_input() self.loadPage() if input == &quot;Q&quot;: self.enable = False return print u&quot;第%d页\\t发布人:%s\\t赞:%s\\t评论:%s\\n%s&quot; %(page, story[0], story[2], story[2], story [1]) # 开始方法 def start(self): print u&quot;正在读取糗事百科,按回车查看新段子，Q退出&quot; # 使变量为True，程序可以正常运行 self.enable = True # 先加载一页内容 self.loadPage() # 局部变量，控制当前读到了第几页 nowPage = 0 while self.enable: if len(self.stories) &gt; 0: # 从全局list中获取一页的段子 pageStories = self.stories[0] # 当前读到的页数加一 nowPage += 1 # 将全局list中第一个元素删除，因为已经取出 del self.stories[0] # 输出该页的段子 self.getOneStory(pageStories, nowPage)spider = QSBK()spider.start() 好啦，大家来测试一下吧，点一下回车会输出一个段子，包括第几页，发布人，段子内容，点赞数以及评论数量，是不是感觉爽爆了！ 完善更新版爬虫代码在上面爬虫的基础上，还增加爬取了百科段子的评论。按C查看当前这个糗事的评论，当切换到查看评论时，换回车显示下一个评论,按Q退出回到查看糗事。糗事段子页数是一页一页加载的，如果你已经看完所有的糗事，就会自动退出！ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198#-*-coding:utf8-*-#created by 10412#在Spiders-qiushibaike.py基础上，爬取了百科段子的评论。按C查看当前这个糗事的评论，当切换到查看评论时，# 换回车显示下一个评论,按Q退出回到查看糗事。糗事段子页数是一页一页加载的，如果你已经看完所有的糗事，就会自动退出！import urllibimport urllib2import reimport os.pathhtmlCharacterMap = &#123; &apos;&lt;br/&gt;&apos; : &apos;\\n&apos;, &apos;&amp;quot;&apos; : &apos;&quot;&apos;, &apos;&amp;nbsp;&apos; : &apos; &apos;, &apos;&amp;gt;&apos; : &apos;&gt;&apos;, &apos;&amp;lt;&apos; : &apos;&lt;&apos;, &apos;&amp;amp;&apos;: &apos;&amp;&apos;, &apos;&amp;#39&apos;:&quot;&apos;&quot;,&#125;class QSBK(object): &quot;&quot;&quot;糗事百科的爬虫&quot;&quot;&quot; def __init__(self): self.pageIndex = 1 self.pagetotal = 9999 self.user_agent = &apos;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36&apos; self.headers = &#123;&apos;User-Agent&apos; : self.user_agent&#125; self.stories = [] self.comments = [] self.currentStoryId = &apos;&apos; #是否要退出了 self.enable = False #记录当前是否在查看评论 self.viewComment = False def getPageContent(self, pageIndex): try: url = &apos;http://www.qiushibaike.com/8hr/page/%d/&apos; % pageIndex request = urllib2.Request(url, headers=self.headers) print u&apos;开始加载%02d页&apos; % pageIndex response = urllib2.urlopen(request, timeout=5) print u&apos;成功加载%02d页&apos; % pageIndex pageContent = response.read().decode(&apos;utf-8&apos;) return pageContent except urllib2.URLError, e: if hasattr(e, &apos;reason&apos;): print u&quot;连接糗事百科失败，错误原因：&quot;, e.reason return None def getCommentsContent(self, storyId): # 得到段子的评论 try: url = &apos;http://www.qiushibaike.com/article/%s&apos; % storyId request = urllib2.Request(url, headers=self.headers) response = urllib2.urlopen(request, timeout=5) pageContent = response.read().decode(&apos;utf-8&apos;) return pageContent except urllib2.URLError, e: if hasattr(e, &apos;reason&apos;): print u&quot;连接糗事百科失败，错误原因：&quot;, e.reason return None def getPageTotal(self, content): # 得到总页数 if self.pagetotal != 9999: # print u&apos;加载第%d页&apos; % self.pageIndex return pattrenStr = &apos;&lt;span class=&quot;page-numbers&quot;&gt;(?P&lt;pagetotal&gt;.*?)&lt;/span&gt;&apos; pattern = re.compile(pattrenStr, re.S) items = re.findall(pattern, content) if len(items)&gt;0: self.pagetotal = int(items[-1].strip()) print u&apos;总共有%d页&apos; % self.pagetotal def getPageItems(self, pageIndex): pageContent = self.getPageContent(pageIndex) with open(&apos;temp%02d.html&apos; % pageIndex, &apos;w&apos;) as f: f.write(pageContent.encode(&apos;utf-8&apos;)) if not pageContent: print &quot;页面加载失败...&quot; return None self.getPageTotal(pageContent) pattrenStr = r&apos;&lt;h2&gt;(?P&lt;authorname&gt;.*?)&lt;/h2&gt;.*?&apos;\\ r&apos;&lt;div class=&quot;content&quot;&gt;(?P&lt;content&gt;.*?)&lt;/div&gt;&apos;\\ r&apos;(?P&lt;maybehaveimage&gt;.*?)&apos;\\ r&apos;&lt;i class=&quot;number&quot;&gt;(?P&lt;numbervote&gt;.*?)&lt;/i&gt;.*?&apos;\\ r&apos;&lt;span class=&quot;stats-comments&quot;&gt;(?P&lt;comments&gt;.*?)&lt;/div&gt;&apos; pattern = re.compile(pattrenStr, re.S) items = re.findall(pattern, pageContent) return items def getCurrentStoryComments(self, storyId): #切换到查看评论模式 self.viewComment = True content = self.getCommentsContent(storyId) if not content: print &quot;页面加载失败...&quot; return None reStr = r&apos;&lt;div id=&quot;comment-.*?&apos;\\ r&apos;&lt;a href=&quot;/users/.*?/&quot; class=&quot;userlogin&quot; target=&quot;_blank&quot; title=&quot;(?P&lt;username&gt;.*?)&quot;&gt;(?P=username)&lt;/a&gt;.*?&apos;\\ r&apos;&lt;span class=&quot;body&quot;&gt;(?P&lt;comment&gt;.*?)&lt;/span&gt;.*?&apos;\\ r&apos;&lt;div class=&quot;report&quot;&gt;(?P&lt;index&gt;.*?)&lt;/div&gt;&apos; pattern = re.compile(reStr, re.S) items = re.findall(pattern, content) del self.comments[:] for item in items: comentstr = item[0]+&apos;(&apos;+ item[2] + u&apos;楼)&apos; + &apos;\\n&apos; + item[1] + &apos;\\n&apos; for (k,v) in htmlCharacterMap.items(): re.sub(re.compile(k), v, comentstr) self.comments.append(comentstr) if len(self.comments)&gt;0: print &apos;已切换到查看评论，换回车显示下一个评论,按Q退出回到查看糗事&apos; else: print &apos;当前糗事没有评论&apos; self.viewComment = False def getNextPage(self): if self.pageIndex &gt; self.pagetotal: self.enable = False print &quot;你已经看完所有的糗事，现在自动退出！&quot; return items = self.getPageItems(self.pageIndex) self.pageIndex += 1 for item in items: #如果有图片直接跳过，因为图片在终端显示不了 if re.search(&apos;img&apos;, item[2]): continue content = item[1].strip() #转换html的特殊字符 for (k,v) in htmlCharacterMap.items(): content = re.sub(re.compile(k), v, content) authorname = item[0].strip() for (k,v) in htmlCharacterMap.items(): authorname = re.sub(re.compile(k), v, authorname) #找出评论个数，没有为0 pattern = re.compile(r&apos;.*?&lt;a href=&quot;/article/(?P&lt;id&gt;.*?)&quot;.*?&lt;i class=&quot;number&quot;&gt;(?P&lt;number&gt;.*?)&lt;/i&gt;.*?&apos;, re.S) result = re.match(pattern, item[4]) commentnumbers = 0 articleId = &apos;&apos; if result: commentnumbers = result.groupdict().get(&apos;number&apos;, &apos;0&apos;) articleId = result.groupdict().get(&apos;id&apos;, &apos;&apos;) self.stories.append(authorname + &apos;(&apos; + item[3].strip() + u&apos;好笑·&apos; + str(commentnumbers) + u&apos;评论)&apos; + &apos;\\n&apos; + content + &apos;\\n&apos;) self.stories.append(articleId) def getNextComment(self): print self.comments[0] self.comments.pop(0) if len(self.comments)==0: print &apos;你已查看完这个糗事的所有评论,现在自动退出到查看糗事&apos; self.viewComment = False def getOneStory(self): #防止有的页面全是带图片的 while (len(self.stories)==0 and self.enable): self.getNextPage() story = self.stories[0] self.currentStoryId = self.stories[1] print story self.stories.pop(0) self.stories.pop(0) if len(self.stories)==0: self.getNextPage() def start(self): #先删除临时保存的网页 tempfiles = [x for x in os.listdir(&apos;.&apos;) if os.path.isfile(x) and os.path.splitext(x)[1]==&apos;.html&apos; and x.startswith(&apos;temp&apos;)] for file in tempfiles: os.remove(file) print u&quot;正在读取糗事百科，按回车查看下一个糗事，按C查看当前这个糗事的评论，按Q退出或返回&quot; self.enable = True self.getNextPage() while self.enable: input = raw_input() if input.upper() == &quot;Q&quot;: if not self.viewComment: self.enable = False else: self.viewComment = False print &apos;现在退出到查看糗事了&apos; elif input.upper() == &quot;C&quot;: #查看当前看到的糗事的评论 if len(self.currentStoryId)&gt;0: self.getCurrentStoryComments(self.currentStoryId) else: print &apos;这条糗事没有评论&apos; else: if not self.viewComment: self.getOneStory() else: self.getNextComment()if __name__ == &apos;__main__&apos;: spider = QSBK() spider.start()","tags":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/tags/Python/"},{"name":"爬虫","slug":"爬虫","permalink":"http://yoursite.com/tags/爬虫/"}]},{"title":"Python爬虫实战之爬取百度贴吧帖子","date":"2017-03-28T10:58:38.918Z","path":"2017/03/28/Python爬虫实战之爬取百度贴吧帖子/","text":"大家好，上次我们实验了爬取了糗事百科的段子，那么这次我们来尝试一下爬取百度贴吧的帖子。与上一篇不同的是，这次我们需要用到文件的相关操作。 本篇目标 对百度贴吧的任意帖子进行抓取 指定是否只抓取楼主发帖内容 将抓取到的内容分析并保存到文件 1. URL格式的确定首先，我们先观察一下百度贴吧的任意一个帖子。 比如：http://tieba.baidu.com/p/3138733512?see_lz=1&amp;pn=1，这是一个关于NBA50大的盘点，分析一下这个地址。 http:// 代表资源传输使用http协议 tieba.baidu.com 是百度的二级域名，指向百度贴吧的服务器。 /p/3138733512 是服务器某个资源，即这个帖子的地址定位符 see_lz 和 pn 是该 URL 的两个参数，分别代表了只看楼主和帖子页码，等于1表示该条件为真 所以我们可以把URL分为两部分，一部分为基础部分，一部分为参数部分。 例如，上面的URL我们划分基础部分是 http://tieba.baidu.com/p/3138733512，参数部分是 ?see_lz=1&amp;pn=1 2. 页面的抓取熟悉了URL的格式，那就让我们用urllib2库来试着抓取页面内容吧。上一篇糗事百科我们最后改成了面向对象的编码方式，这次我们直接尝试一下，定义一个类名叫BDTB(百度贴吧)，一个初始化方法，一个获取页面的方法。 其中，有些帖子我们想指定给程序是否要只看楼主，所以我们把只看楼主的参数初始化放在类的初始化上，即init方法。另外，获取页面的方法我们需要知道一个参数就是帖子页码，所以这个参数的指定我们放在该方法中。 综上，我们初步构建出基础代码如下： 1234567891011121314151617181920212223242526#-*-coding:utf8-*-#created by 10412import urllibimport urllib2import re#百度贴吧爬虫类class BDTB: #初始化，传入基地址，是否只看楼主的参数 def __init__(self, baseUrl, seeLZ): self.baseURL = baseUrl self.seeLZ = &apos;?see_lz=&apos; + str(seeLZ) #传入页码，获取该页帖子的代码 def getPage(self, pageNum): try: url = self.baseURL + self.seeLZ + &apos;&amp;pn=&apos; + str(pageNum) request = urllib2.Request(url) response = urllib2.urlopen(request) print response.read() return response except urllib2.URLError, e: if hasattr(e, &quot;reason&quot;): print u&quot;连接百度贴吧失败,错误原因&quot;,e.reason return NonebaseURL = &apos;http://tieba.baidu.com/p/3138733512&apos;bdtb = BDTB(baseURL, 1)bdtb.getPage(1) 运行代码，我们可以看到屏幕上打印出了这个帖子第一页楼主发言的所有内容，形式为HTML代码。 3. 提取相关信息1)提取帖子标题在浏览器中审查元素，或者按F12，查看页面源代码，我们找到标题所在的代码段如下: 1&lt;h3 class=\"core_title_txt pull-left text-overflow \" title=\"纯原创我心中的NBA2014-2015赛季现役50大\" style=\"width: 416px\"&gt;纯原创我心中的NBA2014-2015赛季现役50大&lt;/h3&gt; 所以我们要提取 &lt;h3&gt; 中的内容，因为一开始可以查看整个界面的原代码，查看里面含有 &lt;h3&gt;标签的不止一个。所以需要写正则表达式来匹配，如下： 1&lt;h3 class=&quot;core_title_txt.*?&gt;(.*?)&lt;/h3&gt; 然后，我们可以写个获取标题的方法 12345678910# 获取帖子标题 def getTitle(self): page = self.getPage(1) pattern = re.compile(&apos;&lt;h3 class=&quot;core_title_txt.*?&gt;(.*?)&lt;/h3&gt;&apos;, re.S) result = re.search(pattern, page) if result: # print result.group(1) #测试输出 return result.group(1).strip() else: return None 2）提取帖子页数同样地，帖子总页数我们也可以通过分析页面中的共?页来获取。 1&lt;li class=\"l_reply_num\" style=\"margin-left:8px\"&gt;&lt;span class=\"red\" style=\"margin-right:3px\"&gt;4784&lt;/span&gt;回复贴，共&lt;span class=\"red\"&gt;36&lt;/span&gt;页&lt;/li&gt; 所以我们的获取总页数的方法如下 12345678910#获取帖子一共有多少页def getPageNum(self): page = self.getPage(1) pattern = re.compile('&lt;li class=\"l_reply_num.*?&lt;/span&gt;.*?&lt;span.*?&gt;(.*?)&lt;/span&gt;',re.S) result = re.search(pattern,page) if result: #print result.group(1) #测试输出 return result.group(1).strip() else: return None 3）提取正文内容审查元素，可以看到百度贴吧每一层楼的主要内容都在标签里面，所以我们可以写如下的正则表达式 1&lt;div id=\"post_content_.*?&gt;(.*?)&lt;/div&gt; 所以提取正文内容的方法： 123456#获取每一层楼的内容,传入页面内容def getContent(self,page): pattern = re.compile('&lt;div id=\"post_content_.*?&gt;(.*?)&lt;/div&gt;',re.S) items = re.findall(pattern,page) for item in items: print item 运行截图如下： 可以看到有很多的换行符和图片符，既然出现这样的情况，那肯定不是我们想要的结果。那我们就必须要将文本进行处理，将各种复杂的标签给剔除，还原帖子的原来面貌。可以使用一个方法或者类将这个处理文本的实现，不过为了更好的代码重用和架构，还是建议使用一个类。 我们将这个类命名为Too（工具类），里面定义一个replace方法，替换各种标签。然后在类中定义几个正则表达式，利用re.sub方法对文本进行匹配后然后替换。 123456789101112131415161718192021222324252627import re#处理页面标签类class Tool: #去除img标签,7位长空格 removeImg = re.compile('&lt;img.*?&gt;| &#123;7&#125;|') #删除超链接标签 removeAddr = re.compile('&lt;a.*?&gt;|&lt;/a&gt;') #把换行的标签换为\\n replaceLine = re.compile('&lt;tr&gt;|&lt;div&gt;|&lt;/div&gt;|&lt;/p&gt;') #将表格制表&lt;td&gt;替换为\\t replaceTD= re.compile('&lt;td&gt;') #把段落开头换为\\n加空两格 replacePara = re.compile('&lt;p.*?&gt;') #将换行符或双换行符替换为\\n replaceBR = re.compile('&lt;br&gt;&lt;br&gt;|&lt;br&gt;') #将其余标签剔除 removeExtraTag = re.compile('&lt;.*?&gt;') def replace(self,x): x = re.sub(self.removeImg,\"\",x) x = re.sub(self.removeAddr,\"\",x) x = re.sub(self.replaceLine,\"\\n\",x) x = re.sub(self.replaceTD,\"\\t\",x) x = re.sub(self.replacePara,\"\\n \",x) x = re.sub(self.replaceBR,\"\\n\",x) x = re.sub(self.removeExtraTag,\"\",x) #strip()将前后多余内容删除 return x.strip() 在使用时，我们只需要初始化一下这个类，然后调用replace方法即可。 现在整体代码是如下这样子的，现在我的代码是写到这样子的: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879#-*-coding:utf8-*-#created by 10412import urllibimport urllib2import re# 处理页面标签类class Tool: # 去除img标签,7位长空格 removeImg = re.compile('&lt;img.*?&gt;| &#123;7&#125;|') # 删除超链接标签 removeAddr = re.compile('&lt;a.*?&gt;|&lt;/a&gt;') # 把换行的标签换为\\n replaceLine = re.compile('&lt;tr&gt;|&lt;div&gt;|&lt;/div&gt;|&lt;/p&gt;') # 将表格制表&lt;td&gt;替换为\\t replaceTD = re.compile('&lt;td&gt;') # 把段落开头换为\\n加空两格 replacePara = re.compile('&lt;p.*?&gt;') # 将换行符或双换行符替换为\\n replaceBR = re.compile('&lt;br&gt;&lt;br&gt;|&lt;br&gt;') # 将其余标签剔除 removeExtraTag = re.compile('&lt;.*?&gt;') def replace(self, x): x = re.sub(self.removeImg, \"\", x) x = re.sub(self.removeAddr, \"\", x) x = re.sub(self.replaceLine, \"\\n\", x) x = re.sub(self.replaceTD, \"\\t\", x) x = re.sub(self.replacePara, \"\\n \", x) x = re.sub(self.replaceBR, \"\\n\", x) x = re.sub(self.removeExtraTag, \"\", x) # strip()将前后多余内容删除 return x.strip()# 百度贴吧爬虫类class BDTB: # 初始化，传入基地址，是否只看楼主的参数 def __init__(self, baseUrl, seeLZ): self.baseURL = baseUrl self.seeLZ = '?see_lz=' + str(seeLZ) self.tool = Tool() # 传入页码，获取该页帖子的代码 def getPage(self, pageNum): try: url = self.baseURL + self.seeLZ + '&amp;pn=' + str(pageNum) request = urllib2.Request(url) response = urllib2.urlopen(request) return response.read().decode('utf-8') except urllib2.URLError, e: if hasattr(e, \"reason\"): print u\"连接百度贴吧失败,错误原因\", e.reason return None # 获取帖子标题 def getTitle(self): page = self.getPage(1) pattern = re.compile('&lt;h1 class=\"core_title_txt.*?&gt;(.*?)&lt;/h1&gt;', re.S) result = re.search(pattern, page) if result: # print result.group(1) #测试输出 return result.group(1).strip() else: return None # 获取帖子一共有多少页 def getPageNum(self): page = self.getPage(1) pattern = re.compile('&lt;li class=\"l_reply_num.*?&lt;/span&gt;.*?&lt;span.*?&gt;(.*?)&lt;/span&gt;', re.S) result = re.search(pattern, page) if result: # print result.group(1) #测试输出 return result.group(1).strip() else: return None # 获取每一层楼的内容,传入页面内容 def getContent(self, page): pattern = re.compile('&lt;div id=\"post_content_.*?&gt;(.*?)&lt;/div&gt;', re.S) items = re.findall(pattern, page) # for item in items: # print item print self.tool.replace(items[1])baseURL = 'http://tieba.baidu.com/p/3138733512'bdtb = BDTB(baseURL, 1)bdtb.getContent(bdtb.getPage(1)) 运行截图如下： 4）替换楼层至于这个问题，我感觉直接提取楼层没什么必要呀，因为只看楼主的话，有些楼层的编号是间隔的，所以我们得到的楼层序号是不连续的，这样我们保存下来也没什么用。 所以可以尝试下面的方法： 1.每打印输出一段楼层，写入一行横线来间隔，或者换行符也好。 2.试着重新编一个楼层，按照顺序，设置一个变量，每打印出一个结果变量加一，打印出这个变量当做楼层。 将getContent方法修改如下： 123456789#获取每一层楼的内容,传入页面内容def getContent(self,page): pattern = re.compile('&lt;div id=\"post_content_.*?&gt;(.*?)&lt;/div&gt;',re.S) items = re.findall(pattern,page) floor = 1 for item in items: print floor,u\"楼------------------------------------------------------------------------------------------------------------------------------------\\n\" print self.tool.replace(item) floor += 1 运行结果截图如下： 4. 写入文件代码： 12file = open(“tb.txt”,”w”)file.writelines(obj) 5. 完善代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134#-*-coding:utf8-*-#created by 10412import urllibimport urllib2import re#处理页面标签类class Tool: #去除img标签,7位长空格 removeImg = re.compile('&lt;img.*?&gt;| &#123;7&#125;|') #删除超链接标签 removeAddr = re.compile('&lt;a.*?&gt;|&lt;/a&gt;') #把换行的标签换为\\n replaceLine = re.compile('&lt;tr&gt;|&lt;div&gt;|&lt;/div&gt;|&lt;/p&gt;') #将表格制表&lt;td&gt;替换为\\t replaceTD= re.compile('&lt;td&gt;') #把段落开头换为\\n加空两格 replacePara = re.compile('&lt;p.*?&gt;') #将换行符或双换行符替换为\\n replaceBR = re.compile('&lt;br&gt;&lt;br&gt;|&lt;br&gt;') #将其余标签剔除 removeExtraTag = re.compile('&lt;.*?&gt;') def replace(self,x): x = re.sub(self.removeImg,\"\",x) x = re.sub(self.removeAddr,\"\",x) x = re.sub(self.replaceLine,\"\\n\",x) x = re.sub(self.replaceTD,\"\\t\",x) x = re.sub(self.replacePara,\"\\n \",x) x = re.sub(self.replaceBR,\"\\n\",x) x = re.sub(self.removeExtraTag,\"\",x) #strip()将前后多余内容删除 return x.strip()#百度贴吧爬虫类class BDTB: #初始化，传入基地址，是否只看楼主的参数 def __init__(self,baseUrl,seeLZ,floorTag): #base链接地址 self.baseURL = baseUrl #是否只看楼主 self.seeLZ = '?see_lz='+str(seeLZ) #HTML标签剔除工具类对象 self.tool = Tool() #全局file变量，文件写入操作对象 self.file = None #楼层标号，初始为1 self.floor = 1 #默认的标题，如果没有成功获取到标题的话则会用这个标题 self.defaultTitle = u\"百度贴吧\" #是否写入楼分隔符的标记 self.floorTag = floorTag #传入页码，获取该页帖子的代码 def getPage(self,pageNum): try: #构建URL url = self.baseURL+ self.seeLZ + '&amp;pn=' + str(pageNum) request = urllib2.Request(url) response = urllib2.urlopen(request) #返回UTF-8格式编码内容 return response.read().decode('utf-8') #无法连接，报错 except urllib2.URLError, e: if hasattr(e,\"reason\"): print u\"连接百度贴吧失败,错误原因\",e.reason return None #获取帖子标题 def getTitle(self,page): #得到标题的正则表达式 pattern = re.compile('&lt;h1 class=\"core_title_txt.*?&gt;(.*?)&lt;/h1&gt;',re.S) result = re.search(pattern,page) if result: #如果存在，则返回标题 return result.group(1).strip() else: return None #获取帖子一共有多少页 def getPageNum(self,page): #获取帖子页数的正则表达式 pattern = re.compile('&lt;li class=\"l_reply_num.*?&lt;/span&gt;.*?&lt;span.*?&gt;(.*?)&lt;/span&gt;',re.S) result = re.search(pattern,page) if result: return result.group(1).strip() else: return None #获取每一层楼的内容,传入页面内容 def getContent(self,page): #匹配所有楼层的内容 pattern = re.compile('&lt;div id=\"post_content_.*?&gt;(.*?)&lt;/div&gt;',re.S) items = re.findall(pattern,page) contents = [] for item in items: #将文本进行去除标签处理，同时在前后加入换行符 content = \"\\n\"+self.tool.replace(item)+\"\\n\" contents.append(content.encode('utf-8')) return contents def setFileTitle(self,title): #如果标题不是为None，即成功获取到标题 if title is not None: self.file = open(title + \".txt\",\"w+\") else: self.file = open(self.defaultTitle + \".txt\",\"w+\") def writeData(self,contents): #向文件写入每一楼的信息 for item in contents: if self.floorTag == '1': #楼之间的分隔符 floorLine = \"\\n\" + str(self.floor) + u\"-----------------------------------------------------------------------------------------\\n\" self.file.write(floorLine) self.file.write(item) self.floor += 1 def start(self): indexPage = self.getPage(1) pageNum = self.getPageNum(indexPage) title = self.getTitle(indexPage) self.setFileTitle(title) if pageNum == None: print \"URL已失效，请重试\" return try: print \"该帖子共有\" + str(pageNum) + \"页\" for i in range(1,int(pageNum)+1): print \"正在写入第\" + str(i) + \"页数据\" page = self.getPage(i) contents = self.getContent(page) self.writeData(contents) #出现写入异常 except IOError,e: print \"写入异常，原因\" + e.message finally: print \"写入任务完成\"print u\"请输入帖子代号\"baseURL = 'http://tieba.baidu.com/p/' + str(raw_input(u'http://tieba.baidu.com/p/'))seeLZ = raw_input(\"是否只获取楼主发言，是输入1，否输入0\\n\")floorTag = raw_input(\"是否写入楼层信息，是输入1，否输入0\\n\")bdtb = BDTB(baseURL,seeLZ,floorTag)bdtb.start() 运行后截图如下： 备注： 运行后注意输入帖子的代号先在网址后空格，再输入帖子代号，输入完再把刚才的空格 删除，只有这样才不会报错。 Traceback (most recent call last):File “E:/python/code/PycharmProject/Python-Projects/baidutieba/BDTB3.py”, line 149,in &lt; module &gt; bdtb.start()File “E:/python/code/PycharmProject/Python-Projects/baidutieba/BDTB3.py”, line 123, in startpageNum = self.getPageNum(indexPage)File “E:/python/code/PycharmProject/Python-Projects/baidutieba/BDTB3.py”, line 86, in getPageNumresult = re.search(pattern,page)File “C:\\Python27\\lib\\re.py”, line 146, in searchreturn _compile(pattern, flags).search(string)TypeError: expected string or buffer","tags":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/tags/Python/"},{"name":"爬虫","slug":"爬虫","permalink":"http://yoursite.com/tags/爬虫/"}]},{"title":"中缀表达式转换成前缀和后缀表达式这类题目的超实用解题技巧","date":"2017-03-28T10:58:16.670Z","path":"2017/03/28/中缀表达式转换成前缀和后缀表达式这类题目的超实用解题技巧/","text":"看到了标题如果还不了解的这几个概念的请先看看博客：详解前缀、中缀、后缀表达式 先给几个中缀表达式转换成后缀表达式题目做做吧，最后我们在总结超实用的技巧！！ 1. 表达式“X=A+B*（C–D）/E”的后缀表示形式可以为 A. XAB+CDE/-*= B. XA+BC-DE/*= C. XABCD-*E/+= D. XABCDE+*/= 先把答案说出来吧，不过你可以自己先好好的想想可以怎么做才能更快的把答案选出来呢？ 答案：C 先看看下面图片中的这种方法如何？ 2. 已知-算术表达式的中缀表达式为a-(b+c/d)*e,其后缀形式为() A. -a+b*c/d B. -a+b*cd/e C. -+*abc/de D. abcd/+e*- 答案：D 3. 算术表达式a+b*(c+d/e)转为后缀表达式后为() A. ab+cde/* B. abcde/+*+ C. abcde/*++ D. abcde*/++ 答案：B 4. 表达式a*(b+c)-d的后缀表达式是() A. abcd*+- B. abc+*d- C. abc*+d- D. -+*abcd 答案：B 好，题目我们也看了这么多了，那我们该如何解决这一类的题目呢？如果你看了文章首部的那篇 博客的话，那你肯定会觉得那个解法很复杂，如果真的是在笔试中出现这样的题目，那得耗费不 少的时间啊。有人要问了，说了那么一堆，那究竟有没有什么快速的方法呢或者说有没有什么简 单的方法可以直接口算的把答案写出来呢，答案是：有的！而且还真的是特别的简单！！！ 解题重点： 这里我给出一个中缀表达式~ a+b*c-(d+e) 第一步：按照运算符的优先级对所有的运算单位加括号 则式子变成拉：((a+(b*c))-(d+e)) 第二步：转换前缀与后缀表达式 1. 前缀表达式：把运算符号移动到对应的括号前面 则变成拉：-( +(a *(bc)) +(de)) 把括号去掉：-+a*bc+de 前缀表达式出现 2. 后缀表达式：把运算符号移动到对应的括号后面 则变成拉：((a(bc)* )+ (de)+ )- 把括号去掉：abc*+de+- 后缀表达式出现 发现没有，前缀表达式，后缀表达式是不需要用括号来进行优先级的确定的。 如果你习惯拉他的运算方法。计算的时候也就是从两个操作数的前面 或者后面找运算符。而不是中间找，那么也就直接可以口算啦！ 你说这种方法是不是很简单啊！！！ 现在你再去看看刚才的那四道题目，是不是很简单的答案就口算出来了啊！！！ 6不6？","tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://yoursite.com/tags/数据结构/"},{"name":"表达式","slug":"表达式","permalink":"http://yoursite.com/tags/表达式/"}]},{"title":"深度探究Java 中 finally 语句块","date":"2017-03-28T10:57:39.759Z","path":"2017/03/28/深度探究Java 中 finally 语句块/","text":"乍看这个题目，是不是有人会问，这个谁不知道啊，大凡熟悉 Java 编程的人都知道 finally 语句块的作用和用法。有什么可深度辨析的呢？事实并非如此，我发现即使写了很多年 Java 程序的人，也不一定能够透彻的理解 finally 语句块。本篇将以生动形象的案例来带您由浅入深的来分析一下这个小小的 finally，希望这篇文章能够让您真正的理解 finally 语句块的本质，至少阅读完本篇文章后，没有觉得浪费了时间。 可不能小看这个简单的 finally，看似简单的问题背后，却隐藏了无数的玄机。接下来我就带您一步一步的揭开这个 finally 的神秘面纱。 问题分析首先来问大家一个问题：finally 语句块一定会执行吗？很多人都认为 finally 语句块是肯定要执行的，其中也包括一些很有经验的 Java 程序员。可惜并不像大多人所认为的那样，对于这个问题，答案当然是否定的，我们先来看下面这个例子。 清单 1.12345678910111213141516171819public class Test &#123;public static void main(String[] args) &#123;System.out.println(\"return value of test(): \" + test()); &#125;public static int test() &#123;int i = 1;// if(i == 1)// return 0;System.out.println(\"the previous statement of try block\");i = i / 0;try &#123; System.out.println(\"try block\"); return i; &#125;finally &#123; System.out.println(\"finally block\"); &#125; &#125;&#125; 清单 1 的执行结果如下： 1234the previous statement of try block Exception in thread &quot;main&quot; java.lang.ArithmeticException: / by zero at com.bj.charlie.Test.test(Test.java:15) at com.bj.charlie.Test.main(Test.java:6) 另外，如果去掉上例中被注释的两条语句前的注释符，执行结果则是： 1return value of test(): 0 在以上两种情况下，finally 语句块都没有执行，说明什么问题呢？只有与 finally 相对应的 try 语句块得到执行的情况下，finally 语句块才会执行。以上两种情况，都是在 try 语句块之前返回（return）或者抛出异常，所以 try 对应的 finally 语句块没有执行。 那好，即使与 finally 相对应的 try 语句块得到执行的情况下，finally 语句块一定会执行吗？不好意思，这次可能又让大家失望了，答案仍然是否定的。请看下面这个例子（清单 2）。 清单 2.12345678910111213141516public class Test &#123;public static void main(String[] args) &#123;System.out.println(\"return value of test(): \" + test()); &#125;public static int test() &#123;int i = 1;try &#123;System.out.println(\"try block\");System.exit(0);return i;&#125;finally &#123;System.out.println(\"finally block\"); &#125; &#125;&#125; 清单 2 的执行结果如下： 1try block finally 语句块还是没有执行，为什么呢？因为我们在 try 语句块中执行了 System.exit (0) 语句，终止了 Java 虚拟机的运行。那有人说了，在一般的 Java 应用中基本上是不会调用这个 System.exit(0) 方法的。OK ！没有问题，我们不调用 System.exit(0) 这个方法，那么 finally 语句块就一定会执行吗？ 再一次让大家失望了，答案还是否定的。当一个线程在执行 try 语句块或者 catch 语句块时被打断（interrupted）或者被终止（killed），与其相对应的 finally 语句块可能不会执行。还有更极端的情况，就是在线程运行 try 语句块或者 catch 语句块时，突然死机或者断电，finally 语句块肯定不会执行了。可能有人认为死机、断电这些理由有些强词夺理，没有关系，我们只是为了说明这个问题。 finally 语句剖析说了这么多，还是让我们拿出些有说服力的证据吧！还有什么证据比官方的文档更具说服力呢？让我们来看看官方网站上的《The Java Tutorials》中是怎样来描述 finally 语句块的吧！以下内容原封不动的摘自于《 The Java Tutorials 》文档。 The finally BlockThe finally block always executes when the try block exits. This ensures that the finally block is executed even if an unexpected exception occurs. But finally is useful for more than just exception handling — it allows the programmer to avoid having cleanup code accidentally bypassed by a return,continue, or break. Putting cleanup code in a finally block is always a good practice, even when no exceptions are anticipated.Note: If the JVM exits while the try or catch code is being executed, then the finally block may not execute. Likewise, if the thread executing the try or catch code is interrupted or killed, the finally block may not execute even though the application as a whole continues. 请仔细阅读并认真体会一下以上两段英文，当你真正的理解了这两段英文的确切含义，你就可以非常自信的来回答“finally 语句块是否一定会执行？”这样的问题。看来，大多时候，并不是 Java 语言本身有多么高深，而是我们忽略了对基础知识的深入理解。 接下来，我们看一下 finally 语句块是怎样执行的。在排除了以上 finally 语句块不执行的情况后，finally 语句块就得保证要执行，既然 finally 语句块一定要执行，那么它和 try 语句块与 catch 语句块的执行顺序又是怎样的呢？还有，如果 try 语句块中有 return 语句，那么 finally 语句块是在 return 之前执行，还是在 return 之后执行呢？带着这样一些问题，我们还是以具体的案例来讲解。 关于 try、catch、finally 的执行顺序问题，我们还是来看看权威的论述吧！以下内容摘自 Java 语言规范第四版（《The Java™ Programming Language, Fourth Edition》）中对于 try，catch，和 finally 的描述。 12.4. Try, catch, and finallyYou catch exceptions by enclosing code in Try blocks. The basic syntax for a Try block is:try {statements} catch (exception_type1 identifier1) {statements} catch (exception_type2 identifier2) {statements…} finally {statements} where either at least one catch clause, or the finally clause, must be present. The body of the try statement is executed until either an exception is thrown or the body finishes successfully. If an exception is thrown, each catch clause is examined in turn, from first to last, to see whether the type of the exception object is assignable to the type declared in the catch. When an assignable catch clause is found, its block is executed with its identifier set to reference the exception object. No other catch clause will be executed. Any number of catch clauses, including zero, can be associated with a particular TRy as long as each clause catches a different type of exception. If no appropriate catch is found, the exception percolates out of the try statement into any outer try that might have a catch clause to handle it. If a finally clause is present with a try, its code is executed after all other processing in the try is complete. This happens no matter how completion was achieved, whether normally, through an exception, or through a control flow statement such as return or break. 上面这段文字的大体意思是说，不管 try 语句块正常结束还是异常结束，finally 语句块是保证要执行的。如果 try 语句块正常结束，那么在 try 语句块中的语句都执行完之后，再执行 finally 语句块。如果 try 中有控制转移语句（return、break、continue）呢？那 finally 语句块是在控制转移语句之前执行，还是之后执行呢？似乎从上面的描述中我们还看不出任何端倪，不要着急，后面的讲解中我们会分析这个问题。如果 try 语句块异常结束，应该先去相应的 catch 块做异常处理，然后执行 finally 语句块。同样的问题，如果 catch 语句块中包含控制转移语句呢？ finally 语句块是在这些控制转移语句之前，还是之后执行呢？我们也会在后续讨论中提到。 其实，关于 try，catch，finally 的执行流程远非这么简单，有兴趣的读者可以参考 Java 语言规范第三版（《The Java™ Language Specification, Third Edition》）中对于 Execution of try-catch-finally 的描述，非常复杂的一个流程。限于篇幅的原因，本文不做摘录，请感兴趣的读者自行阅读。 finally 语句示例说明下面，我们先来看一个简单的例子（清单 3）。 清单 3.12345678910public class Test &#123;public static void main(String[] args) &#123;try &#123;System.out.println(\"try block\");return ;&#125; finally &#123;System.out.println(\"finally block\"); &#125; &#125;&#125; 清单 3 的执行结果为：12try blockfinally block 清单 3 说明 finally 语句块在 try 语句块中的 return 语句之前执行。我们再来看另一个例子（清单 4）。 清单 4.123456789101112131415161718public class Test &#123;public static void main(String[] args) &#123;System.out.println(\"reture value of test() : \" + test()); &#125;public static int test()&#123;int i = 1;try &#123; System.out.println(\"try block\"); i = 1 / 0; return 1;&#125;catch (Exception e)&#123;System.out.println(\"exception block\");return 2;&#125;finally &#123;System.out.println(\"finally block\"); &#125; &#125;&#125; 清单 4 的执行结果为：1234try blockexception blockfinally blockreture value of test() : 2 清单 4 说明了 finally 语句块在 catch 语句块中的 return 语句之前执行。 从上面的清单 3 和清单 4，我们可以看出，其实 finally 语句块是在 try 或者 catch 中的 return 语句之前执行的。更加一般的说法是，finally 语句块应该是在控制转移语句之前执行，控制转移语句除了 return 外，还有 break 和 continue。另外，throw 语句也属于控制转移语句。虽然 return、throw、break 和 continue 都是控制转移语句，但是它们之间是有区别的。其中 return 和 throw 把程序控制权转交给它们的调用者（invoker），而 break 和 continue 的控制权是在当前方法内转移。请大家先记住它们的区别，在后续的分析中我们还会谈到。 还是得来点有说服力的证据，下面这段摘自 Java 语言规范第四版（《The Java™ Programming Language, Fourth Edition》），请读者自己体会一下其含义。 Afinallyclause can also be used to clean up forbreak,continue, andreturn, which is one reason you will sometimes see atryclause with nocatchclauses. When any control transfer statement is executed, all relevantfinallyclauses are executed. There is no way to leave atryblock without executing itsfinallyclause. 好了，看到这里，是不是有人认为自己已经掌握了 finally 的用法了？先别忙着下结论，我们再来看两个例子 – 清单 5 和清单 6。 清单 5.123456789101112public class Test &#123; public static void main(String[] args) &#123; System.out.println(\"return value of getValue(): \" + getValue()); &#125; public static int getValue() &#123; try &#123; return 0; &#125; finally &#123; return 1; &#125; &#125; &#125; 清单 5 的执行结果：1return value of getValue(): 1 清单 6.12345678910111213public class Test &#123;public static void main(String[] args) &#123; System.out.println(\"return value of getValue(): \" + getValue()); &#125;public static int getValue() &#123; int i = 1; try &#123; return i; &#125; finally &#123; i++; &#125; &#125;&#125; 清单 6 的执行结果：1return value of getValue(): 1 利用我们上面分析得出的结论：finally 语句块是在 try 或者 catch 中的 return 语句之前执行的。 由此，可以轻松的理解清单 5 的执行结果是 1。因为 finally 中的 return 1；语句要在 try 中的 return 0；语句之前执行，那么 finally 中的 return 1；语句执行后，把程序的控制权转交给了它的调用者 main（）函数，并且返回值为 1。那为什么清单 6 的返回值不是 2，而是 1 呢？按照清单 5 的分析逻辑，finally 中的 i++；语句应该在 try 中的 return i；之前执行啊？ i 的初始值为 1，那么执行 i++；之后为 2，再执行 return i；那不就应该是 2 吗？怎么变成 1 了呢？ 关于 Java 虚拟机是如何编译 finally 语句块的问题，有兴趣的读者可以参考《 The JavaTM Virtual Machine Specification, Second Edition 》中 7.13 节 Compiling finally。那里详细介绍了 Java 虚拟机是如何编译 finally 语句块。实际上，Java 虚拟机会把 finally 语句块作为 subroutine（对于这个 subroutine 不知该如何翻译为好，干脆就不翻译了，免得产生歧义和误解。）直接插入到 try 语句块或者 catch 语句块的控制转移语句之前。但是，还有另外一个不可忽视的因素，那就是在执行 subroutine（也就是 finally 语句块）之前，try 或者 catch 语句块会保留其返回值到本地变量表（Local Variable Table）中。待 subroutine 执行完毕之后，再恢复保留的返回值到操作数栈中，然后通过 return 或者 throw 语句将其返回给该方法的调用者（invoker）。请注意，前文中我们曾经提到过 return、throw 和 break、continue 的区别，对于这条规则（保留返回值），只适用于 return 和 throw 语句，不适用于 break 和 continue 语句，因为它们根本就没有返回值。 是不是不太好理解，那我们就用具体的例子来做形象的说明吧！ 为了能够解释清单 6 的执行结果，我们来分析一下清单 6 的字节码（byte-code）： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647Compiled from &quot;Test.java&quot; public class Test extends java.lang.Object&#123; public Test(); Code: 0: aload_0 1:invokespecial#1; //Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: return LineNumberTable: line 1: 0 public static void main(java.lang.String[]); Code: 0: getstatic #2; //Field java/lang/System.out:Ljava/io/PrintStream; 3: new #3; //class java/lang/StringBuilder 6: dup 7: invokespecial #4; //Method java/lang/StringBuilder.&quot;&lt;init&gt;&quot;:()V 10: ldc #5; //String return value of getValue(): 12: invokevirtual #6; //Method java/lang/StringBuilder.append:( Ljava/lang/String;)Ljava/lang/StringBuilder; 15: invokestatic #7; //Method getValue:()I 18: invokevirtual #8; //Method java/lang/StringBuilder.append:(I)Ljava/lang/StringBuilder; 21: invokevirtual #9; //Method java/lang/StringBuilder.toString:()Ljava/lang/String; 24: invokevirtual #10; //Method java/io/PrintStream.println:(Ljava/lang/String;)V 27: return public static int getValue(); Code: 0: iconst_1 1: istore_0 2: iload_0 3: istore_1 4: iinc 0, 1 7: iload_1 8: ireturn 9: astore_2 10: iinc 0, 1 13: aload_2 14: athrow Exception table: from to target type 2 4 9 any 9 10 9 any &#125; 对于 Test（）构造方法与 main（）方法，在这里，我们不做过多解释。让我们来分析一下 getValue（）方法的执行。在这之前，先让我把 getValue（）中用到的虚拟机指令解释一下，以便读者能够正确的理解该函数的执行。 123456789101112131415161718192021222324252627282930313233343536373839404142434445461. iconst_Description: Push the int constant (-1, 0, 1, 2, 3, 4 or 5) onto the operand stack.Forms: iconst_m1 = 2 (0x2) iconst_0 = 3 (0x3) iconst_1 = 4 (0x4)iconst_2 = 5 (0x5) iconst_3 = 6 (0x6) iconst_4 = 7 (0x7) iconst_5 = 8 (0x8)2. istore_Description: Store int into local variable. The must be an index into thelocal variable array of the current frame.Forms: istore_0 = 59 (0x3b) istore_1 = 60 (0x3c) istore_2 = 61 (0x3d)istore_3 = 62 (0x3e)3. iload_Description: Load int from local variable. The must be an index into thelocal variable array of the current frame.Forms: iload_0 = 26 (0x1a) iload_1 = 27 (0x1b) iload_2 = 28 (0x1c) iload_3 = 29 (0x1d)4. iinc index, constDescription: Increment local variable by constant. The index is an unsigned byte thatmust be an index into the local variable array of the current frame. The const is animmediate signed byte. The local variable at index must contain an int. The valueconst is first sign-extended to an int, and then the local variable at index isincremented by that amount.Forms: iinc = 132 (0x84)Format:iincindexconst5. ireturnDescription: Return int from method.Forms: ireturn = 172 (0xac)6. astore_Description: Store reference into local variable. The must be an index into thelocal variable array of the current frame.Forms: astore_0 = 75 (0x4b) astore_1 = 76 (0x4c) astore_2 =77 (0x4d) astore_3 =78 (0x4e)7. aload_Description: Load reference from local variable. The must be an index into thelocal variable array of the current frame.Forms: aload_0 = 42 (0x2a) aload_1 = 43 (0x2b) aload_2 = 44 (0x2c) aload_3 = 45 (0x2d)8. athrowDescription: Throw exception or error.Forms: athrow = 191 (0xbf) 有了以上的 Java 虚拟机指令，我们来分析一下其执行顺序：分为正常执行（没有 exception）和异常执行（有 exception）两种情况。我们先来看一下正常执行的情况，如图 1 所示： ###图 1. getValue（）函数正常执行的情况 由上图，我们可以清晰的看出，在 finally 语句块（iinc 0, 1）执行之前，getValue（）方法保存了其返回值（1）到本地表量表中 1 的位置，完成这个任务的指令是 istore_1；然后执行 finally 语句块（iinc 0, 1），finally 语句块把位于 0 这个位置的本地变量表中的值加 1，变成 2；待 finally 语句块执行完毕之后，把本地表量表中 1 的位置上值恢复到操作数栈（iload _1），最后执行 ireturn 指令把当前操作数栈中的值（1）返回给其调用者（main）。这就是为什么清单 6 的执行结果是 1，而不是 2 的原因。 再让我们来看看异常执行的情况。是不是有人会问，你的清单 6 中都没有 catch 语句，哪来的异常处理呢？我觉得这是一个好问题，其实，即使没有 catch 语句，Java 编译器编译出的字节码中还是有默认的异常处理的，别忘了，除了需要捕获的异常，还可能有不需捕获的异常（如：RunTimeException 和 Error）。 从 getValue（）方法的字节码中，我们可以看到它的异常处理表（exception table）， 如下：123Exception table:from to target type2 4 9 any 它的意思是说：如果从 2 到 4 这段指令出现异常，则由从 9 开始的指令来处理。 图 2. getValue（）函数异常执行的情况 先说明一点，上图中的 exception 其实应该是 exception 对象的引用，为了方便说明，我直接把它写成 exception 了。 由上图（图 2）可知，当从 2 到 4 这段指令出现异常时，将会产生一个 exception 对象，并且把它压入当前操作数栈的栈顶。接下来是 astore_2 这条指令，它负责把 exception 对象保存到本地变量表中 2 的位置，然后执行 finally 语句块，待 finally 语句块执行完毕后，再由 aload _2 这条指令把预先存储的 exception 对象恢复到操作数栈中，最后由 athrow 指令将其返回给该方法的调用者（main）。 通过以上的分析，大家应该已经清楚 try-catch-finally 语句块的执行流程了吧！为了更具说服力，我们还是来引经据典吧！下面这段仍然摘自 Java 语言规范第四版 《The Java™ Programming Language, Fourth Edition》，请读者自己体会吧！ a finally clause is always entered with a reason. That reason may be that the try code finished normally, that it executed a control flow statement such as return, or that an exception was thrown in code executed in the Try block. The reason is remembered when the finally clause exits by falling out the bottom. However, if the finally block creates its own reason to leave by executing a control flow statement (such as break or return) or by throwing an exception, that reason supersedes the original one, and the original reason is forgotten. For example, consider the following code:try {// … do something …return 1;} finally {return 2;}When the Try block executes its return, the finally block is entered with the “reason” of returning the value 1. However, inside the finally block the value 2 is returned, so the initial intention is forgotten. In fact, if any of the other code in the try block had thrown an exception, the result would still be to return 2. If the finally block did not return a value but simply fell out the bottom, the “return the value 1 ″ reason would be remembered and carried out. 好了，有了以上的知识，让我们再来看以下 3 个例子。 清单 7.123456789101112131415public class Test &#123; public static void main(String[] args) &#123; System.out.println(\"return value of getValue(): \" + getValue()); &#125; @SuppressWarnings(\"finally\") public static int getValue() &#123; int i = 1; try &#123; i = 4; &#125; finally &#123; i++; return i; &#125; &#125; &#125; 清单 7 的执行结果：1return value of getValue(): 5 清单 8.1234567891011121314public class Test &#123;public static void main(String[] args) &#123; System.out.println(\"return value of getValue(): \" + getValue()); &#125;public static int getValue() &#123; int i = 1; try &#123; i = 4; &#125; finally &#123; i++; &#125; return i; &#125;&#125; 清单 8 的执行结果：1return value of getValue(): 5 清单 7 和清单 8 应该还比较简单吧！利用我们上面讲解的知识，很容易分析出其结果。让我们再来看一个稍微复杂一点的例子 – 清单 9。我建议大家最好先不要看执行结果，运用学过的知识来分析一下，看是否能推断出正确的结果。 清单 9.1234567891011121314151617public class Test &#123;public static void main(String[] args) &#123;System.out.println(test()); &#125;public static String test() &#123;try &#123;System.out.println(\"try block\");return test1();&#125; finally &#123;System.out.println(\"finally block\"); &#125; &#125;public static String test1() &#123;System.out.println(\"return statement\");return \"after return\"; &#125;&#125; 清单 9 的结果：1234try blockreturn statementfinally blockafter return 你分析对了吗？其实这个案例也不算很难，return test1();这条语句等同于 : 12String tmp = test1();return tmp; 这样，就应该清楚为什么是上面所示的执行结果了吧！ 如果还是不怎么清楚可以在 IDE 下试用下 Debug，然后查看具体的运行步骤。 好了，就写到这吧！希望大家看完这篇文章能够有所收获！ 总结没想到吧！一个小小的、看似简单的 finally 语句块背后居然隐藏了这么多玄机。看来，我们平时还是应该认真的阅读 Java 相关的基础文档，比如：Java 语言规范、Java 虚拟机规范等，很多棘手的问题都可以从中得到答案。只有真正的吃透了基础知识，才能达到运用自如的境界！ 参考资料参考 The Java Tutorials，查看对 finally 语句块的描述。 参考 《The Java Programming Language, Fourth Edition》，查看 Java 语言规范第四版中对 finally 语句块的解释。 参考 《The Java Language Specification, Third Edition》，查看 Java 语言规范第三版中对 finally 语句块执行流程的具体描述。 参考 《The Java Virtual Machine Specification, Second Edition》，查看 Java 虚拟机是如何来编译 finally 语句块的知识。 查看文章 《Java 的异常处理机制(try … catch … finally)》，了解更多关于 Java 中 finally 语句块的分析。 查看文章 《Java 中 finally 的辨析》，了解更多关于 Java 中 finally 语句块的分析。 查看文章《关于 Java 中 finally 语句块的深度辨析》","tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"finally","slug":"finally","permalink":"http://yoursite.com/tags/finally/"}]},{"title":"利用Github Page 搭建个人博客网站","date":"2017-03-28T10:57:04.193Z","path":"2017/03/28/利用Github Page 搭建个人博客网站/","text":"前言最近这几天，没事干，想找点事折腾下，于是自己便想到了自己一直想干的一件事：搭建一个属于自己的博客网站。目前搭建个人 blog 网站最好的是用 wordpress ，但是那个折腾起来好像还挺麻烦的，再加上还需要自己修改些前端代码和用 PHP 做（虽然我学了几天拍黄片，但是早已忘了），然后就是用 Github Page 吧，自己也一直在这个最大的交友网站装 X 。想想就用这个吧（后来好像觉得这个还挺省事的） 再说说拥有个人博客网站的好处吧： 装 X（如果网站够炫） 很好的用来总结自己所学的知识 面试加分（在简历上放上自己的个人网站链接，面试官就可以更好的了解你，知道你所学知识的深度和广度） 不再受其他博客平台的规则所束缚 如果你现在还没有自己个人博客网站的话，那么我觉得你看完本篇博客后，强烈的建议你去折腾折腾下，搞个自己的，让自己也能够体验装 X 的感觉。 要想用搭建一个个人博客网站，首先你得有一个域名，这样别人才可以通过域名访问，其次你还要一个空间来存放你的页面。 域名 域名的话，你可以在万网、阿里云、腾讯云等注册，我的域名 www.54tianzhisheng.cn 就是在腾讯云注册的，记得是腾讯云一元钱（一个域名+主机）搞的，这是腾讯云对学生才有这优惠。 .cn 的域名需要备案，备案的审核速度我觉得还是挺快的，还需要上传证件。当然你也可以买其他的那些不需要备案的域名，省得麻烦事。 空间 空间有免费的空间，也有收费的空间。免费的当然就不够稳定了，收费的就很贵了，终究是很不爽，有没有什么地方是既免费又稳定的空间呢？有，Github 。它允许上传个人网站项目并自定义你的域名，而且又有稳定的服务，实在是不能够在好了。 下面就一起跟着我来一步一步的利用 Github 搭建个人博客网站吧！ 1. 拥有一个域名这个步骤我就不详述了。 举例： 打开腾讯云官网 搜索你想要的域名，下单买一个 2. 拥有一个 Github账号互联网崇尚自由与分享。Github 是一个全世界程序员聚集的地方，大家相互分享自己写的代码，提升别人，也提升自己。大家都在为着开源社区努力着。因为我从开源项目中学到很多知识，所以我也非常愿意分享我的所见所学所得，我的 Github 主页：https://github.com/zhisheng17 （欢迎 follow 和对我的项目给个 star 或者 fork 我的项目一起来和我完善项目） 如果还没有 Github 账号的话你就先去注册一个吧，有的话，直接登录就行，后面的操作都要用到 Github 的。 3. Github 上新建个人网站项目登录 GitHub 之后，在页面右上角点击 + 加号按钮，点击 New repository。 由于我们是新建一个个人网站项目，所有仓库的名称需要安装 GitHub 个人网站项目的规定来写。 规则就是： YOUR-GITHUB-USERNAME.github.io 比如我的 GitHub 用户名是 zhisheng17，那我就要填写 zhisheng17.github.io。然后选择公开模式，接着点击创建仓库按钮。 创建成功之后，进入了项目主页面。点击设置按钮。 进入之后，滚动页面到下方。点击页面自动生成器按钮。 点击右下方继续去布局按钮。 选择一个模板，点击发布页面按钮。 这个时候，你就可以通过YOUR-GITHUB-USERNAME.github.io来访问此页面了。 4. 上传个人网页到 Github自动生成页面，肯定不符合我们的要求，我们希望能够自己设计自己的个人网站。我们可以自己编写一个网页文件，命名为 index.html。然后上传到 GitHub个人网站项目上。这里为了节约时间，可以先下载我的个人网站项目代码，然后修改为你的网页上传到 GitHub。 下面介绍详细步骤。 进入此项目https://github.com/zhisheng17/zhisheng17.github.io，然后下载源码。解压之后，拿到里面的index.html文件。 然后进入自己的个人网站项目主页 YOUR-GITHUB-USERNAME/YOUR-GITHUB-USERNAME.github.io。点击上传文件按钮，进入上传文件页面，将 index.html 文件拖入蓝色大圈圈区域，点击提交按钮即可提交成功。此时打开网址 YOUR-GITHUB-USERNAME.github.io 就可以看到主页已经改变为我们自己的网页了。 通过 zhisheng17.github.io 查看效果： 5. 域名CNAME到个人网站项目网页上传成功了，我们不想一直通过YOUR-GITHUB-USERNAME.github.io来访问我们的个人网站，而是希望通过自己的域名来访问。 下面讲述详细步骤。 点击我们的个人网站项目设置选项卡，滚动到下面，就会发现一个自定义域名卡片。输入我们买的域名，然后点击保存。 接着我们还要将我们的域名解析到这个个人网站项目上。因为我的域名是在腾讯云上面买的，所以我打开腾讯云域名管理页面，进行相关的设置。 接着，点击添加一条域名解析记录，主机填写www，代表你是一级域名来访问，指向填写YOUR-GITHUB-USERNAME.github.io，然后点击保存按钮。应该要等会，域名的解析时间可能不一样，我的腾讯云就是很慢的 6. 访问你的域名所有这些步骤做完之后，在浏览器里输入自己的域名，回车键一按，就会返回我们刚刚上传到 GitHub 的index.html 页面了。 这里只是入门了 GitHub 搭建个人网站的功能，GitHub 官方推荐 Jekyll 博客系统来发布自己的页面。以后有数据更新，都可以通过 Jekyll 来重新编译整个网站。（期待后续我的使用 Jekyll 博客系统发布自己博客的文章吧） 7. 注意事项尽管GitHub个人网站项目是免费的，但是却有一些限制。总体来说，完全够用，甚至太多了。 单个仓库大小不超过1GB，上传单个文件大小不能超过100MB，如果通过浏览器上传不能超过25MB 个人网站项目也不例外，最大空间1GB 个人网站项目每个月访问请求数不能超过10万次，总流量不能超过100GB 个人网站项目一小时创建数量不能超过10个 当然了，这些政策可能随时改变，可以通过此网页查看最新政策。 https://help.github.com/articles/what-is-github-pages/#recommended-limits","tags":[{"name":"Github Page","slug":"Github-Page","permalink":"http://yoursite.com/tags/Github-Page/"},{"name":"博客网站","slug":"博客网站","permalink":"http://yoursite.com/tags/博客网站/"}]},{"title":"通过项目逐步深入了解Mybatis（一）","date":"2017-03-28T10:56:34.415Z","path":"2017/03/28/通过项目逐步深入了解Mybatis(一)/","text":"Mybatis 和 SpringMVC 通过订单商品案例驱动 官方中文地址：http://www.mybatis.org/mybatis-3/zh/ 官方托管地址：https://github.com/mybatis/mybatis-3 本项目全部代码地址：https://github.com/zhisheng17/mybatis 如果觉得不错的话，欢迎给个 star ， 如果你想完善这个项目的话，你也可以 fork 后修改然后推送给我。 基础知识：对原生态 jdbc 程序（单独使用 jdbc 开发）问题总结1、环境​ java 环境 ：jdk1.8.0_77 ​ 开发工具 ： IDEA 2016.1 ​ 数据库 ： MySQL 5.7 2、创建数据库​ mybatis_test.sql ​ Tables ：items、orderdetail、orders、user 3、JDBC 程序​ 使用 JDBC 查询 MySQL 数据库中用户表的记录 ​ 代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980package cn.zhisheng.mybatis.jdbc;/** * Created by 10412 on 2016/11/27. */import java.sql.*;/** *通过单独的jdbc程序来总结问题 */public class JdbcTest&#123; public static void main(String[] args) &#123; //数据库连接 Connection connection = null; //预编译的Statement，使用预编译的Statement可以提高数据库性能 PreparedStatement preparedStatement = null; //结果集 ResultSet resultSet = null; try &#123; //加载数据库驱动 Class.forName(\"com.mysql.jdbc.Driver\"); //通过驱动管理类获取数据库链接 connection = DriverManager.getConnection(\"jdbc:mysql://localhost:3306/mybatis_test?characterEncoding=utf-8\", \"root\", \"root\"); //定义sql语句 ?表示占位符（在这里表示username） String sql = \"select * from user where username = ?\"; //获取预处理statement preparedStatement = connection.prepareStatement(sql); //设置参数，第一个参数为sql语句中参数的序号（从1开始），第二个参数为设置的参数值 preparedStatement.setString(1, \"王五\"); //向数据库发出sql执行查询，查询出结果集 resultSet = preparedStatement.executeQuery(); //遍历查询结果集 while(resultSet.next()) &#123; System.out.println(resultSet.getString(\"id\")+\" \"+resultSet.getString(\"username\")); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;finally&#123; //释放资源 if(resultSet!=null) &#123; try &#123; resultSet.close(); &#125; catch (SQLException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; if(preparedStatement!=null) &#123; try &#123; preparedStatement.close(); &#125; catch (SQLException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; if(connection!=null) &#123; try &#123; connection.close(); &#125; catch (SQLException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; &#125; &#125;&#125; 4、问题总结 数据库连接，使用时就创建，不使用立即释放，对数据库频繁连接开启和关闭，造成数据库资源的浪费，影响数据库性能。 解决方法：使用数据库连接池管理数据库连接。 将 sql 语句硬编码到 java 代码中，如果 sql 语句需要修改，那么就需要重新编译 java 代码，不利于系统的维护。 设想：将 sql 语句配置在 xml 配置文件中，即使 sql 语句发生变化，也不需要重新编译 java 代码。 向 preparedStatement 中设置参数，对占位符号位置和设置参数值，硬编码在 java 代码中，同样也不利于系统的维护。 设想：将 sql 语句、占位符、参数值配置在 xml 配置文件中。 从 resultSet 中遍历结果集数据时，存在硬编码，将获取表的字段进行硬编码，不利于系统维护。 设想：将查询的结果集自动映射成 java 对象。 Mybatis框架原理（掌握）1、Mybatis 是什么？​ Mybatis 是一个持久层的架构，是 appach 下的顶级项目。 ​ Mybatis 原先是托管在 googlecode 下，再后来是托管在 Github 上。 ​ Mybatis 让程序员将主要的精力放在 sql 上，通过 Mybatis 提供的映射方式，自由灵活生成（半自动，大部分需要程序员编写 sql ）满足需要 sql 语句。 ​ Mybatis 可以将向 preparedStatement 中的输入参数自动进行输入映射，将查询结果集灵活的映射成 java 对象。（输出映射） 2、Mybatis 框架 注解： SqlMapConfig.xml （Mybatis的全局配置文件，名称不定）配置了数据源、事务等 Mybatis 运行环境 Mapper.xml 映射文件（配置 sql 语句） SqlSessionFactory （会话工厂）根据配置文件配置工厂、创建 SqlSession SqlSession （会话）面向用户的接口、操作数据库（发出 sql 增删改查） Executor （执行器）是一个接口（基本执行器、缓存执行器）、SqlSession 内部通过执行器操作数据库 Mapped Statement （底层封装对象）对操作数据库存储封装，包括 sql 语句、输入参数、输出结果类型 ​ Mybatis入门程序1、需求实现以下功能： 根据用户id查询一个用户信息 根据用户名称模糊查询用户信息列表 添加用户 更新用户 删除用户 2、环境java 环境 ：jdk1.8.0_77 开发工具 ： IDEA 2016.1 数据库 ： MySQL 5.7 Mybatis 运行环境（ jar 包） MySQL 驱动包 其他依赖包 3、 log4j.properties在classpath下创建log4j.properties如下： 1234567# Global logging configuration#在开发环境日志级别要设置为DEBUG、生产环境要设置为INFO或者ERRORlog4j.rootLogger=DEBUG, stdout# Console output...log4j.appender.stdout=org.apache.log4j.ConsoleAppenderlog4j.appender.stdout.layout=org.apache.log4j.PatternLayoutlog4j.appender.stdout.layout.ConversionPattern=%5p [%t] - %m%n Mybatis默认使用log4j作为输出日志信息。 4、工程结构 5、SqlMapConfig.xml配置 Mybatis 的运行环境、数据源、事务等 1234567891011121314151617181920&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt;&lt;configuration&gt; &lt;!-- 和spring整合后 environments配置将废除--&gt; &lt;environments default=\"development\"&gt; &lt;environment id=\"development\"&gt; &lt;!-- 使用jdbc事务管理,事务由 Mybatis 控制--&gt; &lt;transactionManager type=\"JDBC\" /&gt; &lt;!-- 数据库连接池,由Mybatis管理，数据库名是mybatis_test，Mysql用户名root，密码root --&gt; &lt;dataSource type=\"POOLED\"&gt; &lt;property name=\"driver\" value=\"com.mysql.jdbc.Driver\" /&gt; &lt;property name=\"url\" value=\"jdbc:mysql://localhost:3306/mybatis_test?characterEncoding=utf-8\" /&gt; &lt;property name=\"username\" value=\"root\" /&gt; &lt;property name=\"password\" value=\"root\" /&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt;&lt;/configuration&gt; 6、创建 po 类Po 类作为 mybatis 进行 sql 映射使用，po 类通常与数据库表对应，User.java 如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package cn.zhisheng.mybatis.po;import java.util.Date;/** * Created by 10412 on 2016/11/28. */public class User&#123; private int id; private String username; // 用户姓名 private String sex; // 性别 private Date birthday; // 生日 private String address; // 地址 //getter and setter public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public String getUsername() &#123; return username; &#125; public void setUsername(String username) &#123; this.username = username; &#125; public Date getBirthday() &#123; return birthday; &#125; public void setBirthday(Date birthday) &#123; this.birthday = birthday; &#125; public String getSex() &#123; return sex; &#125; public void setSex(String sex) &#123; this.sex = sex; &#125; public String getAddress() &#123; return address; &#125; public void setAddress(String address) &#123; this.address = address; &#125;&#125; 7、根据用户 id（主键）查询用户信息 映射文件 User.xml（原在 Ibatis 中命名）在 Mybatis 中命名规则为 xxxmapper.xml 在映射文件中配置 sql 语句 User.xml 123456&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE mapperPUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\"\"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt;&lt;mapper namespace=\"test\"&gt;&lt;/mapper&gt; namespace ：命名空间，对 sql 进行分类化管理，用于隔离 sql 语句，后面会讲另一层非常重要的作用。 ​ 在 User.xml 中加入 123456789101112&lt;!--通过select执行数据库查询 id:标识映射文件中的sql 将sql语句封装到mappedStatement对象中，所以id称为Statement的id #&#123;&#125;：表示占位符 #&#123;id&#125;：其中的id表示接收输入的参数，参数名称就是id，如果输入参数是简单类型，那么#&#123;&#125;中的参数名可以任意，可以是value或者其他名称 parameterType：表示指定输入参数的类型 resultType：表示指定sql输出结果的所映射的java对象类型 --&gt;&lt;!-- 根据id获取用户信息 --&gt; &lt;select id=\"findUserById\" parameterType=\"int\" resultType=\"cn.zhisheng.mybatis.po.User\"&gt; select * from user where id = #&#123;id&#125; &lt;/select&gt; User.xml 映射文件已经完全写好了，那接下来就需要在 SqlMapConfig.xml中加载映射文件 User.xml 1234&lt;!--加载映射文件--&gt; &lt;mappers&gt; &lt;mapper resource=\"sqlmap/User.xml\"/&gt; &lt;/mappers&gt; ​ 编写程序 `MybatisFirst.java` ​ 123456789101112131415161718192021222324252627282930313233343536373839404142434445package cn.zhisheng.mybatis.first;import cn.zhisheng.mybatis.po.User;import org.apache.ibatis.io.Resources;import org.apache.ibatis.session.SqlSession;import org.apache.ibatis.session.SqlSessionFactory;import org.apache.ibatis.session.SqlSessionFactoryBuilder;import org.junit.Test;import java.io.IOException;import java.io.InputStream; /*** Created by 10412 on 2016/11/28.*/public class MybatisFirst&#123; //根据id查询用户信息，得到用户的一条记录 @Test public void findUserByIdTest() throws IOException &#123; //Mybatis 配置文件 String resource = \"SqlMapConfig.xml\"; //得到配置文件流 InputStream inputStream = Resources.getResourceAsStream(resource); //创建会话工厂,传入Mybatis的配置文件信息 SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); //通过工厂得到SqlSession SqlSession sqlSession = sqlSessionFactory.openSession(); //通过SqlSession操作数据库 //第一个参数：映射文件中Statement的id，等于 = namespace + \".\" + Statement的id //第二个参数：指定和映射文件中所匹配的parameterType类型的参数 //sqlSession.selectOne 结果与映射文件中所匹配的resultType类型的对象 User user = sqlSession.selectOne(\"test.findUserById\", 1); System.out.println(user); //释放资源 sqlSession.close(); &#125;&#125; 然后运行一下这个测试，发现结果如下就代表可以了： 8、根据用户名称模糊查询用户信息列表 映射文件 依旧使用 User.xml 文件，只不过要在原来的文件中加入 123456789&lt;!-- 自定义条件查询用户列表 resultType：指定就是单条记录所映射的java对象类型 $&#123;&#125;:表示拼接sql串，将接收到的参数内容不加修饰的拼接在sql中 使用$&#123;&#125;拼接sql，会引起sql注入 $&#123;value&#125;：接收输入参数的内容，如果传入类型是简单类型，$&#123;&#125;中只能够使用value--&gt; &lt;select id=\"findUserByUsername\" parameterType=\"java.lang.String\" resultType=\"cn.zhisheng.mybatis.po.User\"&gt; select * from user where username like '%$&#123;value&#125;%' &lt;/select&gt; 编写程序 依旧直接在刚才那个 MybatisFirst.java 中加入测试代码： 12345678910111213141516171819202122232425262728//根据用户名称模糊查询用户信息列表 @Test public void findUserByUsernameTest() throws IOException &#123; //Mybatis 配置文件 String resource = \"SqlMapConfig.xml\"; //得到配置文件流 InputStream inputStream = Resources.getResourceAsStream(resource); //创建会话工厂,传入Mybatis的配置文件信息 SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); //通过工厂得到SqlSession SqlSession sqlSession = sqlSessionFactory.openSession(); //通过SqlSession操作数据库 //第一个参数：映射文件中Statement的id，等于 = namespace + \".\" + Statement的id //第二个参数：指定和映射文件中所匹配的parameterType类型的参数 //selectList 查询结果可能多条 //list中的user和映射文件中resultType所指定的类型一致 List&lt;User&gt; list = sqlSession.selectList(\"test.findUserByUsername\", \"小明\"); System.out.println(list); //释放资源 sqlSession.close(); &#125; 同样测试一下findUserByUsernameTest ，如果运行结果如下就代表没问题： 提示：通过这个代码可以发现，其中有一部分代码是冗余的，我们可以将其封装成一个函数。 1234567public void createSqlSessionFactory() throws IOException &#123; // 配置文件 String resource = \"SqlMapConfig.xml\"; InputStream inputStream = Resources.getResourceAsStream(resource); // 使用SqlSessionFactoryBuilder从xml配置文件中创建SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); &#125; 注意：1、#{ } 和 ${ } 的区别 #{ }表示一个占位符号，通过#{ }可以实现 preparedStatement 向占位符中设置值，自动进行java 类型和 jdbc 类型转换，#{ } 可以有效防止sql注入。#{ } 可以接收简单类型值或 pojo 属性值（通过 OGNL 读取对象中的值，属性.属性.属性..方式获取对象属性值）。 如果 parameterType 传输单个简单类型值，#{ }括号中可以是 value 或其它名称。 ${ } 表示拼接 sql 串，通过${ }可以将 parameterType 传入的内容拼接在 sql 中且不进行 jdbc 类型转换， ${ }可以接收简单类型值或 pojo 属性值（（通过 OGNL 读取对象中的值，属性.属性.属性..方式获取对象属性值）），如果 parameterType 传输单个简单类型值，${}括号中只能是 value。 2、parameterType 和 resultType 区别 parameterType：指定输入参数类型，mybatis 通过 ognl 从输入对象中获取参数值拼接在 sql 中。 resultType：指定输出结果类型，mybatis 将 sql 查询结果的一行记录数据映射为 resultType 指定类型的对象。 3、selectOne 和 selectList 区别 selectOne 查询一条记录来进行映射，如果使用selectOne查询多条记录则抛出异常： org.apache.ibatis.exceptions.TooManyResultsException: Expected one result (or null) to bereturned by selectOne(), but found: 3 at selectList 可以查询一条或多条记录来进行映射。 9、添加用户 映射文件 在 User.xml 中加入： 12345678&lt;!-- 添加用户 --&gt; &lt;insert id=\"insetrUser\" parameterType=\"cn.zhisheng.mybatis.po.User\" &gt; &lt;selectKey keyProperty=\"id\" order=\"AFTER\" resultType=\"java.lang.Integer\"&gt; select LAST_INSERT_ID() &lt;/selectKey&gt; insert into user(username, birthday, sex, address) values(#&#123;username&#125;, #&#123;birthday&#125;, #&#123;sex&#125;, #&#123;address&#125;) &lt;/insert&gt; 注意: selectKey将主键返回，需要再返回 添加selectKey实现将主键返回 keyProperty:返回的主键存储在pojo中的哪个属性 order：selectKey的执行顺序，是相对与insert语句来说，由于mysql的自增原理执行完insert语句之后才将主键生成，所以这里selectKey的执行顺序为after resultType:返回的主键是什么类型 LAST_INSERT_ID():是mysql的函数，返回auto_increment自增列新记录id值。 然后在 MybatisFirst.java 中写一个测试函数，代码如下 123456789101112131415161718192021@Test public void insetrUser() throws IOException, ParseException &#123; //Mybatis 配置文件 String resource = \"SqlMapConfig.xml\"; //得到配置文件流 InputStream inputStream = Resources.getResourceAsStream(resource); //创建会话工厂,传入Mybatis的配置文件信息 SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); //通过工厂得到SqlSession SqlSession sqlSession = sqlSessionFactory.openSession(); User user = new User(); SimpleDateFormat sdf = new SimpleDateFormat (\"yyyy-MM-dd\"); user.setUsername(\"田志声\"); user.setSex(\"男\"); user.setBirthday(sdf.parse(\"2016-11-29\")); user.setAddress(\"江西南昌\"); sqlSession.insert(\"test.insetrUser\", user); sqlSession.commit(); //释放资源 sqlSession.close(); &#125; 然后 run 一下，如果出现的结果如下，那么就是成功了。 同时数据库也能查询到刚插入的用户信息： 10、自增主键返回 与 非自增主键返回 MySQL 自增主键：执行 insert 提交之前自动生成一个自增主键，通过 MySQL 函数获取到刚插入记录的自增主键： LAST_INSERT_ID() ，是在 insert 函数之后调用。 非自增主键返回：使用 MySQL 的 uuid() 函数生成主键，需要修改表中 id 字段类型为 String ，长度设置为 35 位，执行思路：先通过 uuid() 查询到主键，将主键输入到 sql 语句中；执行 uuid() 语句顺序相对于 insert 语句之前执行。 刚才那个插入用户的地方，其实也可以通过 uuid() 来生成主键，如果是这样的话，那么我们就需要在 User.xml 中加入如下代码： 123456789&lt;!--使用 MySQL 的 uuid()生成主键 执行过程： 首先通过uuid()得到主键，将主键设置到user对象的id属性中 其次执行insert时，从user对象中取出id属性值 --&gt;&lt;selectKey keyProperty=\"id\" order=\"BEFORE\" resultType=\"java.lang.String\"&gt; select uuid()&lt;/selectKey&gt;insert into user(id, username, birthday, sex, address) values(#&#123;id&#125;, #&#123;username&#125;, #&#123;birthday&#125;, #&#123;sex&#125;, #&#123;address&#125;) Oracle 使用序列生成主键 首先自定义一个序列且用于生成主键，selectKey使用如下： 12345678&lt;insert id=\"insertUser\" parameterType=\"cn.itcast.mybatis.po.User\"&gt; &lt;selectKey resultType=\"java.lang.Integer\" order=\"BEFORE\" keyProperty=\"id\"&gt; SELECT 自定义序列.NEXTVAL FROM DUAL &lt;/selectKey&gt;insert into user(id,username,birthday,sex,address) values(#&#123;id&#125;,#&#123;username&#125;,#&#123;birthday&#125;,#&#123;sex&#125;,#&#123;address&#125;)&lt;/insert&gt; ​ 11、删除用户前面说了这么多了，这里就简单来说明下： 在 User.xml 文件中加入如下代码： 1234&lt;!--删除用户--&gt; &lt;delete id=\"deleteUserById\" parameterType=\"int\"&gt; delete from user where user.id = #&#123;id&#125; &lt;/delete&gt; 在 MybatisFirst.java 文件中加入如下代码： 1234567891011121314151617181920212223242526272829//删除用户 @Test public void deleteUserByIdTest() throws IOException &#123; //Mybatis 配置文件 String resource = \"SqlMapConfig.xml\"; //得到配置文件流 InputStream inputStream = Resources.getResourceAsStream(resource); //创建会话工厂,传入Mybatis的配置文件信息 SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); //通过工厂得到SqlSession SqlSession sqlSession = sqlSessionFactory.openSession(); //通过SqlSession操作数据库 //第一个参数：映射文件中Statement的id，等于 = namespace + \".\" + Statement的id //第二个参数：指定和映射文件中所匹配的parameterType类型的参数 sqlSession.delete(\"test.deleteUserById\", 26); //提交事务 sqlSession.commit(); //释放资源 sqlSession.close(); &#125; 测试结果如下： 之前的数据库 user 表查询结果： 执行完测试代码后，结果如下： 12、更新用户信息在 User.xml 中加入如下代码： 123456789&lt;!--根据id更新用户 需要输入用户的id 传入用户要更新的信息 parameterType指定user对象，包括id和更新信息，id必须存在 #&#123;id&#125;：从输入对象中获取id属性值--&gt;&lt;update id=\"updateUserById\" parameterType=\"cn.zhisheng.mybatis.po.User\"&gt; update user set username = #&#123;username&#125;, birthday = #&#123;birthday&#125;, sex = #&#123;sex&#125;, address = #&#123;address&#125; where user.id = #&#123;id&#125; &lt;/update&gt; 然后在 MybatisFirst.java 中加入 12345678910111213141516171819202122232425262728293031323334353637//根据id更新用户信息 @Test public void updateUserByIdTest() throws IOException, ParseException &#123; //Mybatis 配置文件 String resource = \"SqlMapConfig.xml\"; //得到配置文件流 InputStream inputStream = Resources.getResourceAsStream(resource); //创建会话工厂,传入Mybatis的配置文件信息 SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); //通过工厂得到SqlSession SqlSession sqlSession = sqlSessionFactory.openSession(); //为了设置生日的日期输入 SimpleDateFormat sdf = new SimpleDateFormat (\"yyyy-MM-dd\"); User user = new User(); //根据id更新用户信息 user.setId(24); user.setUsername(\"张四风\"); user.setBirthday(sdf.parse(\"2015-01-12\")); user.setSex(\"女\"); user.setAddress(\"上海黄埔\"); //通过SqlSession操作数据库 //第一个参数：映射文件中Statement的id，等于 = namespace + \".\" + Statement的id //第二个参数：指定和映射文件中所匹配的parameterType类型的参数 sqlSession.update(\"test.updateUserById\", user); //提交事务 sqlSession.commit(); //释放资源 sqlSession.close(); &#125; 测试结果如下： 查看数据库，id 为 24 的用户信息是否更新了： 啊，是不是很爽，所有的需求都完成了。 没错，这只是 Mybatis 的一个简单的入门程序，简单的实现了对数据库的增删改查功能，通过这个我们大概可以了解这个编程方式了。 期待接下来的 Mybatis高级知识文章吧！ 更多文章请见 微信公众号：猿blog","tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://yoursite.com/tags/Mybatis/"},{"name":"SpringMVC","slug":"SpringMVC","permalink":"http://yoursite.com/tags/SpringMVC/"}]},{"title":"通过项目逐步深入了解Mybatis（二）","date":"2017-03-28T10:56:21.447Z","path":"2017/03/28/通过项目逐步深入了解Mybatis(二)/","text":"转载请务必注明出处，原创不易！ 相关文章：通过项目逐步深入了解Mybatis&lt;一&gt;本项目全部代码地址：Github-Mybatis Mybatis 解决 jdbc 编程的问题1、 数据库链接创建、释放频繁造成系统资源浪费从而影响系统性能，如果使用数据库链接池可解决此问题。 解决：在SqlMapConfig.xml中配置数据链接池，使用连接池管理数据库链接。 2、 Sql语句写在代码中造成代码不易维护，实际应用sql变化的可能较大，sql变动需要改变java代码。 解决：将Sql语句配置在XXXXmapper.xml文件中与java代码分离。 3、 向sql语句传参数麻烦，因为sql语句的where条件不一定，可能多也可能少，占位符需要和参数一一对应。 解决：Mybatis自动将java对象映射至sql语句，通过statement中的parameterType定义输入参数的类型。 4、 对结果集解析麻烦，sql变化导致解析代码变化，且解析前需要遍历，如果能将数据库记录封装成pojo对象解析比较方便。 解决：Mybatis自动将sql执行结果映射至java对象，通过statement中的resultType定义输出结果的类型。 Mybatis 与 Hibernate 不同Mybatis和hibernate不同，它不完全是一个ORM框架，因为MyBatis需要程序员自己编写Sql语句，不过mybatis可以通过XML或注解方式灵活配置要运行的sql语句，并将java对象和sql语句映射生成最终执行的sql，最后将sql执行的结果再映射生成java对象。 Mybatis学习门槛低，简单易学，程序员直接编写原生态sql，可严格控制sql执行性能，灵活度高，非常适合对关系数据模型要求不高的软件开发，例如互联网软件、企业运营类软件等，因为这类软件需求变化频繁，一但需求变化要求成果输出迅速。但是灵活的前提是mybatis无法做到数据库无关性，如果需要实现支持多种数据库的软件则需要自定义多套sql映射文件，工作量大。 Hibernate对象/关系映射能力强，数据库无关性好，对于关系模型要求高的软件（例如需求固定的定制化软件）如果用hibernate开发可以节省很多代码，提高效率。但是Hibernate的学习门槛高，要精通门槛更高，而且怎么设计O/R映射，在性能和对象模型之间如何权衡，以及怎样用好Hibernate需要具有很强的经验和能力才行。 总之，按照用户的需求在有限的资源环境下只要能做出维护性、扩展性良好的软件架构都是好架构，所以框架只有适合才是最好。 Mybatis 开发 dao两种方法 原始 dao 开发方法（程序需要编写 dao 接口和 dao 实现类）（掌握） Mybatis 的 mapper 接口（相当于 dao 接口）代理开发方法（掌握） 需求将下边的功能实现Dao： 根据用户id查询一个用户信息 根据用户名称模糊查询用户信息列表 添加用户信息 Mybatis 配置文件 SqlMapConfig.xml Sqlsession 的使用范围SqlSession 中封装了对数据库的操作，如：查询、插入、更新、删除等。 通过 SqlSessionFactory 创建 SqlSession，而 SqlSessionFactory 是通过 SqlSessionFactoryBuilder 进行创建。 1、SqlSessionFactoryBuilderSqlSessionFactoryBuilder 用于创建 SqlSessionFacoty，SqlSessionFacoty 一旦创建完成就不需要SqlSessionFactoryBuilder 了，因为 SqlSession 是通过 SqlSessionFactory 生产，所以可以将SqlSessionFactoryBuilder 当成一个工具类使用，最佳使用范围是方法范围即方法体内局部变量。 2、SqlSessionFactorySqlSessionFactory 是一个接口，接口中定义了 openSession 的不同重载方法，SqlSessionFactory 的最佳使用范围是整个应用运行期间，一旦创建后可以重复使用，通常以单例模式管理 SqlSessionFactory。 3、SqlSessionSqlSession 是一个面向用户的接口， sqlSession 中定义了数据库操作，默认使用 DefaultSqlSession 实现类。 执行过程如下： 1）、 加载数据源等配置信息 Environment environment = configuration.getEnvironment(); 2）、 创建数据库链接 3）、 创建事务对象 4）、 创建Executor，SqlSession 所有操作都是通过 Executor 完成，mybatis 源码如下： 12345678910if (ExecutorType.BATCH == executorType) &#123; executor = newBatchExecutor(this, transaction); &#125; elseif (ExecutorType.REUSE == executorType) &#123; executor = new ReuseExecutor(this, transaction); &#125; else &#123; executor = new SimpleExecutor(this, transaction); &#125;if (cacheEnabled) &#123; executor = new CachingExecutor(executor, autoCommit); &#125; 5）、 SqlSession的实现类即 DefaultSqlSession，此对象中对操作数据库实质上用的是 Executor 结论：每个线程都应该有它自己的SqlSession实例。SqlSession的实例不能共享使用，它也是线程不安全的。因此最佳的范围是请求或方法范围(定义局部变量使用)。绝对不能将SqlSession实例的引用放在一个类的静态字段或实例字段中。 打开一个SqlSession；使用完毕就要关闭它。通常把这个关闭操作放到 finally 块中以确保每次都能执行关闭。如下： 123456SqlSession session = sqlSessionFactory.openSession(); try &#123; // do work &#125; finally &#123; session.close();&#125; 原始 Dao 开发方法思路：需要程序员编写 Dao 接口和 Dao 实现类； 需要在 Dao 实现类中注入 SqlsessionFactory ，在方法体内通过 SqlsessionFactory 创建 Sqlsession。 Dao接口1234567891011public interface UserDao //dao接口，用户管理&#123; //根据id查询用户信息 public User findUserById(int id) throws Exception; //添加用户信息 public void addUser(User user) throws Exception; //删除用户信息 public void deleteUser(int id) throws Exception;&#125; Dao 实现类1234567891011121314151617181920212223242526272829303132333435363738394041public class UserDaoImpl implements UserDao //dao接口实现类&#123; //需要在 Dao 实现类中注入 SqlsessionFactory //这里通过构造方法注入 private SqlSessionFactory sqlSessionFactory; public UserDaoImpl(SqlSessionFactory sqlSessionFactory) &#123; this.sqlSessionFactory = sqlSessionFactory; &#125; @Override public User findUserById(int id) throws Exception &#123; //在方法体内通过 SqlsessionFactory 创建 Sqlsession SqlSession sqlSession = sqlSessionFactory.openSession(); User user = sqlSession.selectOne(\"test.findUserById\", id); sqlSession.close(); return user; &#125; @Override public void insertUser(User user) throws Exception &#123; //在方法体内通过 SqlsessionFactory 创建 Sqlsession SqlSession sqlSession = sqlSessionFactory.openSession(); //执行插入的操作 sqlSession.insert(\"test.insetrUser\", user); //提交事务 sqlSession.commit(); //释放资源 sqlSession.close(); &#125; @Override public void deleteUser(int id) throws Exception &#123; //在方法体内通过 SqlsessionFactory 创建 Sqlsession SqlSession sqlSession = sqlSessionFactory.openSession(); sqlSession.delete(\"test.deleteUserById\", id); //提交事务 sqlSession.commit(); sqlSession.close(); &#125;&#125; 测试12345678910111213141516171819202122232425public class UserDaoImplTest&#123; private SqlSessionFactory sqlSessionFactory; //此方法是在 testFindUserById 方法之前执行的 @Before public void setup() throws Exception &#123; //创建sqlSessionFactory //Mybatis 配置文件 String resource = \"SqlMapConfig.xml\"; //得到配置文件流 InputStream inputStream = Resources.getResourceAsStream(resource); //创建会话工厂,传入Mybatis的配置文件信息 sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); &#125; @Test public void testFindUserById() throws Exception &#123; //创建UserDao的对象 UserDao userDao = new UserDaoImpl(sqlSessionFactory); //调用UserDao方法 User user = userDao.findUserById(1); System.out.println(user); &#125;&#125; 通过id查询用户信息测试结果如下：（其他的可以自己在写测试代码，原理类似） 问题原始Dao开发中存在以下问题： Dao方法体存在重复代码：通过 SqlSessionFactory 创建 SqlSession，调用 SqlSession 的数据库操作方法 调用 sqlSession 的数据库操作方法需要指定 statement 的i d，这里存在硬编码，不得于开发维护。 调用 sqlSession 的数据库操作方法时传入的变量，由于 sqlsession 方法使用泛型，即使变量类型传入错误，在编译阶段也不报错，不利于程序员开发。 Mybatis 的 mapper 接口思路程序员需要编写 mapper.xml 映射文件 只需要程序员编写Mapper接口（相当于Dao接口），需遵循一些开发规范，mybatis 可以自动生成 mapper 接口类代理对象。 开发规范： 在 mapper.xml 中 namespace 等于 mapper 接口地址 1&lt;mapper namespace=\"cn.zhisheng.mybatis.mapper.UserMapper\"&gt;&lt;/mapper&gt; 在 xxxmapper.java 接口中的方法名要与 xxxMapper.xml 中 statement 的 id 一致。 在 xxxmapper.java 接口中的输入参数类型要与 xxxMapper.xml 中 statement 的 parameterType 指定的参数类型一致。 在 xxxmapper.java 接口中的返回值类型要与 xxxMapper.xml 中 statement 的 resultType 指定的类型一致。 UserMapper.java 12//根据id查询用户信息 public User findUserById(int id) throws Exception; UserMapper.xml 123&lt;select id=\"findUserById\" parameterType=\"int\" resultType=\"cn.zhisheng.mybatis.po.User\"&gt; select * from user where id = #&#123;1&#125;&lt;/select&gt; 总结：以上的开发规范主要是对下边的代码进行统一的生成： 1234User user = sqlSession.selectOne(\"test.findUserById\", id);sqlSession.insert(\"test.insetrUser\", user);sqlSession.delete(\"test.deleteUserById\", id);List&lt;User&gt; list = sqlSession.selectList(\"test.findUserByName\", username); 测试测试之前记得在 SqlMapConfig.xml 文件中添加加载映射文件 UserMapper.xml： 1&lt;mapper resource=\"mapper/UserMapper.xml\"/&gt; 测试代码： 1234567891011121314151617181920212223242526public class UserMapperTest&#123; private SqlSessionFactory sqlSessionFactory; //此方法是在 testFindUserById 方法之前执行的 @Before public void setup() throws Exception &#123; //创建sqlSessionFactory //Mybatis 配置文件 String resource = \"SqlMapConfig.xml\"; //得到配置文件流 InputStream inputStream = Resources.getResourceAsStream(resource); //创建会话工厂,传入Mybatis的配置文件信息 sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); &#125; @Test public void testFindUserById() throws Exception &#123; SqlSession sqlSession = sqlSessionFactory.openSession(); //创建usermapper对象,mybatis自动生成代理对象 UserMapper userMapper = sqlSession.getMapper(UserMapper.class); //调用UserMapper的方法 User user = userMapper.findUserById(1); System.out.println(user); &#125;&#125; 通过id查询用户信息测试结果如下：（其他的请自己根据上下文写测试代码，或者去看我 Github-Mybatis学习笔记 上看我这个项目的全部代码） 通过姓名查询用户信息： 代理对象内部调用 selectOne 或者 selectList 如果 mapper 方法返回单个 pojo 对象（非集合对象），代理对象内部通过 selectOne 查询数据库 如果 mapper 方法返回集合对象，代理对象内部通过 selectList 查询数据库 mapper接口方法参数只能有一个是否影响系统开发 mapper 接口方法参数只能有一个，系统是否不利于维护？ 系统框架中，dao层的代码是被业务层公用的。 即使 mapper 接口只有一个参数，可以使用包装类型的 pojo 满足不同的业务方法的需求。 注意：持久层方法的参数可以包装类型、map…. ，service方法中不建议使用包装类型。（不利于业务层的可扩展性） SqlMapConfig.xml 文件Mybatis 的全局配置变量，配置内容和顺序如下： properties（属性） settings（全局配置参数） typeAliases（类型别名） typeHandlers（类型处理器） objectFactory（对象工厂） plugins（插件） environments（环境集合属性对象） ​ environment（环境子属性对象） ​ transactionManager（事务管理） ​ dataSource（数据源） mappers（映射器） properties 属性需求：将数据库连接参数单独配置在 db.properties 中，只需要在 SqlMapConfig.xml 中加载该配置文件 db.properties 的属性值。在 SqlMapConfig.xml 中就不需要直接对数据库的连接参数进行硬编码了。方便以后对参数进行统一的管理，其他的xml文件可以引用该 db.properties 。 db.properties 1234jdbc.driver=com.mysql.jdbc.Driverjdbc.url=jdbc:mysql://localhost:3306/mybatis_test?characterEncoding=utf-8jdbc.username=rootjdbc.password=root 那么 SqlMapConfig.xml 中的配置变成如下： 12345678910111213141516&lt;!--加载配置文件--&gt; &lt;properties resource=\"db.properties\"&gt;&lt;/properties&gt; &lt;!-- 和spring整合后 environments配置将废除--&gt; &lt;environments default=\"development\"&gt; &lt;environment id=\"development\"&gt; &lt;!-- 使用jdbc事务管理,事务由 Mybatis 控制--&gt; &lt;transactionManager type=\"JDBC\" /&gt; &lt;!-- 数据库连接池--&gt; &lt;dataSource type=\"POOLED\"&gt; &lt;property name=\"driver\" value=\"$&#123;jdbc.driver&#125;\" /&gt; &lt;property name=\"url\" value=\"$&#123;jdbc.url&#125;\" /&gt; &lt;property name=\"username\" value=\"$&#123;jdbc.username&#125;\" /&gt; &lt;property name=\"password\" value=\"$&#123;jdbc.password&#125;\" /&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; 配置完成后我们测试一下是否能够和刚才一样的能够成功呢？那么我就先在db.properties中把数据库密码故意改错，看是否是正确的？不出意外的话是会报错的。 注意： MyBatis 将按照下面的顺序来加载属性： 在 properties 元素体内定义的属性首先被读取。 然后会读取 properties 元素中 resource 或 url 加载的属性，它会覆盖已读取的同名属性。 最后读取 parameterType 传递的属性，它会覆盖已读取的同名属性。 因此，通过parameterType传递的属性具有最高优先级，resource或 url 加载的属性次之，最低优先级的是 properties 元素体内定义的属性。 建议： 不要在 properties 元素体内添加任何属性值，只将属性值定义在 db.properties 文件之中。 在 db.properties 文件之中定义的属性名要有一定的特殊性。如 xxx.xxx.xxx settings（全局配置参数）Mybatis 框架在运行时可以调整一些运行参数 比如：开启二级缓存、开启延迟加载。。。 typeAliases（类型别名）需求： 在mapper.xml中，定义很多的statement，statement需要parameterType指定输入参数的类型、需要resultType指定输出结果的映射类型。 如果在指定类型时输入类型全路径，不方便进行开发，可以针对parameterType或resultType指定的类型定义一些别名，在mapper.xml中通过别名定义，方便开发。 Mybatis支持的别名： 别名 映射的类型 _byte byte _long long _short short _int int _integer int _double double _float float _boolean boolean string String byte Byte long Long short Short int Integer integer Integer double Double float Float boolean Boolean date Date decimal BigDecimal bigdecimal BigDecimal 自定义别名： 在 SqlMapConfig.xml 中配置：(设置别名) 1234567&lt;typeAliases&gt; &lt;!-- 单个别名定义 --&gt; &lt;typeAlias alias=\"user\" type=\"cn.zhisheng.mybatis.po.User\"/&gt; &lt;!-- 批量别名定义，扫描整个包下的类，别名为类名（首字母大写或小写都可以） --&gt; &lt;package name=\"cn.zhisheng.mybatis.po\"/&gt; &lt;package name=\"其它包\"/&gt;&lt;/typeAliases&gt; 在 UserMapper.xml 中引用别名：( resultType 为 user ) 123&lt;select id=\"findUserById\" parameterType=\"int\" resultType=\"user\"&gt; select * from user where id = #&#123;id&#125;&lt;/select&gt; 测试结果： typeHandlers（类型处理器）mybatis中通过typeHandlers完成jdbc类型和java类型的转换。 通常情况下，mybatis提供的类型处理器满足日常需要，不需要自定义. mybatis支持类型处理器： 类型处理器 Java类型 JDBC类型 BooleanTypeHandler Boolean，boolean 任何兼容的布尔值 ByteTypeHandler Byte，byte 任何兼容的数字或字节类型 ShortTypeHandler Short，short 任何兼容的数字或短整型 IntegerTypeHandler Integer，int 任何兼容的数字和整型 LongTypeHandler Long，long 任何兼容的数字或长整型 FloatTypeHandler Float，float 任何兼容的数字或单精度浮点型 DoubleTypeHandler Double，double 任何兼容的数字或双精度浮点型 BigDecimalTypeHandler BigDecimal 任何兼容的数字或十进制小数类型 StringTypeHandler String CHAR和VARCHAR类型 ClobTypeHandler String CLOB和LONGVARCHAR类型 NStringTypeHandler String NVARCHAR和NCHAR类型 NClobTypeHandler String NCLOB类型 ByteArrayTypeHandler byte[] 任何兼容的字节流类型 BlobTypeHandler byte[] BLOB和LONGVARBINARY类型 DateTypeHandler Date（java.util） TIMESTAMP类型 DateOnlyTypeHandler Date（java.util） DATE类型 TimeOnlyTypeHandler Date（java.util） TIME类型 SqlTimestampTypeHandler Timestamp（java.sql） TIMESTAMP类型 SqlDateTypeHandler Date（java.sql） DATE类型 SqlTimeTypeHandler Time（java.sql） TIME类型 ObjectTypeHandler 任意 其他或未指定类型 EnumTypeHandler Enumeration类型 VARCHAR-任何兼容的字符串类型，作为代码存储（而不是索引）。 mappers（映射器） 使用相对于类路径的资源，如： 使用完全限定路径如： 使用 mapper 接口类路径 如： 注意：此种方法要求 mapper 接口名称和 mapper 映射文件名称相同，且放在同一个目录中。 注册指定包下的所有mapper接口如：注意：此种方法要求 mapper 接口名称和 mapper 映射文件名称相同，且放在同一个目录中。 Mapper.xml 映射文件Mapper.xml映射文件中定义了操作数据库的sql，每个sql是一个statement，映射文件是mybatis的核心。 输入映射通过 parameterType 指定输入参数的类型，类型可以是简单类型、hashmap、pojo的包装类型。 传递 pojo 包装对象 （重点） 开发中通过pojo传递查询条件 ，查询条件是综合的查询条件，不仅包括用户查询条件还包括其它的查询条件（比如将用户购买商品信息也作为查询条件），这时可以使用包装对象传递输入参数。 定义包装对象 定义包装对象将查询条件(pojo)以类组合的方式包装起来。 UserQueryVo.java 123456789101112131415public class UserQueryVo //用户包装类型&#123; //在这里包装所需要的查询条件 //用户查询条件 private UserCustom userCustom; public UserCustom getUserCustom() &#123; return userCustom; &#125; public void setUserCustom(UserCustom userCustom) &#123; this.userCustom = userCustom; &#125; //还可以包装其他的查询条件，比如订单、商品&#125; UserCustomer.java 1234public class UserCustom extends User //用户的扩展类&#123; //可以扩展用户的信息&#125; UserMapper.xml 文件 1234567&lt;!--用户信息综合查询 #&#123;userCustom.sex&#125; :取出pojo包装对象中的性别值 #&#123;userCustom.username&#125; :取出pojo包装对象中的用户名称 --&gt; &lt;select id=\"findUserList\" parameterType=\"cn.zhisheng.mybatis.po.UserQueryVo\" resultType=\"cn.zhisheng.mybatis.po.UserCustom\"&gt; select * from user where user.sex = #&#123;userCustom.sex&#125; and user.username like '%$&#123;userCustom.username&#125;%' &lt;/select&gt; UserMapper.java 12//用户信息综合查询public List&lt;UserCustom&gt; findUserList(UserQueryVo userQueryVo) throws Exception; 测试代码 1234567891011121314151617//测试用户信息综合查询 @Test public void testFindUserList() throws Exception &#123; SqlSession sqlSession = sqlSessionFactory.openSession(); //创建usermapper对象,mybatis自动生成代理对象 UserMapper userMapper = sqlSession.getMapper(UserMapper.class); //创建包装对象，设置查询条件 UserQueryVo userQueryVo = new UserQueryVo(); UserCustom userCustom = new UserCustom(); userCustom.setSex(\"男\"); userCustom.setUsername(\"张小明\"); userQueryVo.setUserCustom(userCustom); //调用UserMapper的方法 List&lt;UserCustom&gt; list = userMapper.findUserList(userQueryVo); System.out.println(list); &#125; 测试结果 输出映射 resultType 使用 resultType 进行输出映射，只有查询出来的列名和 pojo 中的属性名一致，该列才可以映射成功。 如果查询出来的列名和 pojo 中的属性名全部不一致，没有创建 pojo 对象。 只要查询出来的列名和 pojo 中的属性有一个一致，就会创建 pojo 对象。 输出简单类型需求：用户信息综合查询列表总数，通过查询总数和上边用户综合查询列表才可以实现分页 实现： 1234567&lt;!--用户信息综合查询总数 parameterType:指定输入的类型和findUserList一样 resultType:输出结果类型为 int --&gt; &lt;select id=\"findUserCount\" parameterType=\"cn.zhisheng.mybatis.po.UserQueryVo\" resultType=\"int\"&gt; select count(*) from user where user.sex = #&#123;userCustom.sex&#125; and user.username like '%$&#123;userCustom.username&#125;%' &lt;/select&gt; 12//用户信息综合查询总数 public int findUserCount(UserQueryVo userQueryVo) throws Exception; 12345678910111213141516//测试用户信息综合查询总数 @Test public void testFindUserCount() throws Exception &#123; SqlSession sqlSession = sqlSessionFactory.openSession(); //创建usermapper对象,mybatis自动生成代理对象 UserMapper userMapper = sqlSession.getMapper(UserMapper.class); //创建包装对象，设置查询条件 UserQueryVo userQueryVo = new UserQueryVo(); UserCustom userCustom = new UserCustom(); userCustom.setSex(\"男\"); userCustom.setUsername(\"张小明\"); userQueryVo.setUserCustom(userCustom); //调用UserMapper的方法 System.out.println(userMapper.findUserCount(userQueryVo)); &#125; 注意：查询出来的结果集只有一行且一列，可以使用简单类型进行输出映射。 输出pojo对象和pojo列表 不管是输出的pojo单个对象还是一个列表（list中包括pojo），在mapper.xml中resultType指定的类型是一样的。 在mapper.java指定的方法返回值类型不一样： 1、输出单个pojo对象，方法返回值是单个对象类型 12//根据id查询用户信息 public User findUserById(int id) throws Exception; 2、输出pojo对象list，方法返回值是List 12//根据用户名查询用户信息 public List&lt;User&gt; findUserByUsername(String userName) throws Exception; resultType总结： 输出pojo对象和输出pojo列表在sql中定义的resultType是一样的。 返回单个pojo对象要保证sql查询出来的结果集为单条，内部使用session.selectOne方法调用，mapper接口使用pojo对象作为方法返回值。 返回pojo列表表示查询出来的结果集可能为多条，内部使用session.selectList方法，mapper接口使用List对象作为方法返回值。 resultMap resultType 可以指定 pojo 将查询结果映射为 pojo，但需要 pojo 的属性名和 sql 查询的列名一致方可映射成功。 如果sql查询字段名和pojo的属性名不一致，可以通过resultMap将字段名和属性名作一个对应关系 ，resultMap实质上还需要将查询结果映射到pojo对象中。 resultMap可以实现将查询结果映射为复杂类型的pojo，比如在查询结果映射对象中包括pojo和list实现一对一查询和一对多查询。 使用方法： 1、定义 resultMap 2、使用 resultMap 作为 statement 的输出映射类型 将下面的 sql 使用 User 完成映射 1select id id_, username username_ from user where id = #&#123;value&#125; User 类中属性名和上边查询的列名不一致。 所以需要： 1、定义 resultMap 1234567891011121314151617181920&lt;!--定义 resultMap 将select id id_, username username_ from user where id = #&#123;value&#125; 和User类中的属性做一个映射关系 type: resultMap最终映射的java对象类型 id:对resultMap的唯一标识 --&gt; &lt;resultMap id=\"userResultMap\" type=\"user\"&gt; &lt;!--id表示查询结果中的唯一标识 column：查询出来的列名 property：type指定pojo的属性名 最终resultMap对column和property做一个映射关系（对应关系） --&gt; &lt;id column=\"id_\" property=\"id\"/&gt; &lt;!--result: 对普通结果映射定义 column：查询出来的列名 property：type指定pojo的属性名 最终resultMap对column和property做一个映射关系（对应关系） --&gt; &lt;result column=\"username_\" property=\"username\"/&gt; &lt;/resultMap&gt; 2、使用 resultMap 作为 statement 的输出映射类型 12345&lt;!--使用 resultMap 作为输出映射类型 resultMap=\"userResultMap\":其中的userResultMap就是我们刚才定义的 resultMap 的id值,如果这个resultMap在其他的mapper文件中，前边须加上namespace --&gt; &lt;select id=\"findUserByIdResultMap\" parameterType=\"int\" resultMap=\"userResultMap\"&gt; select id id_, username username_ from user where id = #&#123;value&#125; &lt;/select&gt; 3、UserMapper.java 12//根据id查询用户信息，使用 resultMap 输出public User findUserByIdResultMap(int id) throws Exception; 4、测试 1234567891011//测试根据id查询用户信息，使用 resultMap 输出 @Test public void testFindUserByIdResultMap() throws Exception &#123; SqlSession sqlSession = sqlSessionFactory.openSession(); //创建usermapper对象,mybatis自动生成代理对象 UserMapper userMapper = sqlSession.getMapper(UserMapper.class); //调用UserMapper的方法 User user = userMapper.findUserByIdResultMap(1); System.out.println(user); &#125; 5、测试结果 动态 SQL通过mybatis提供的各种标签方法实现动态拼接sql。 需求： 用户信息综合查询列表和用户信息查询列表总数这两个 statement的定义使用动态sql。 对查询条件进行判断，如果输入的参数不为空才进行查询条件拼接。 UserMapper.xml (findUserList的配置如下，那么findUserCount的也是一样的，这里就不全部写出来了) 1234567891011121314&lt;select id=\"findUserList\" parameterType=\"cn.zhisheng.mybatis.po.UserQueryVo\" resultType=\"cn.zhisheng.mybatis.po.UserCustom\"&gt; select * from user &lt;!--where可以自动的去掉条件中的第一个and--&gt; &lt;where&gt; &lt;if test=\"userCustom != null\"&gt; &lt;if test=\"userCustom.sex != null and userCustom.sex != ''\"&gt; and user.sex = #&#123;userCustom.sex&#125; &lt;/if&gt; &lt;if test=\"userCustom.username != null\"&gt; and user.username like '%$&#123;userCustom.username&#125;%' &lt;/if&gt; &lt;/if&gt; &lt;/where&gt; &lt;/select&gt; 测试代码：因为设置了动态的sql，如果不设置某个值，那么条件就不会拼接在sql上 所以我们就注释掉设置username的语句 1//userCustom.setUsername(\"张小明\"); 测试结果： Sql 片段通过上面的其实看到在 where sql语句中有很多重复代码，我们可以将其抽取出来，组成一个sql片段，其他的statement就可以引用这个sql片段，利于系统的开发。 这里我们就拿上边sql 中的where定义一个sq片段如下： 123456789101112131415&lt;!--sql片段 id:唯一标识 经验：是基于单表来定义sql片段，这样的话sql片段的可重用性才高 一般不包含where --&gt; &lt;sql id=\"query_user_where\"&gt; &lt;if test=\"userCustom != null\"&gt; &lt;if test=\"userCustom.sex != null and userCustom.sex != ''\"&gt; and user.sex = #&#123;userCustom.sex&#125; &lt;/if&gt; &lt;if test=\"userCustom.username != null\"&gt; and user.username like '%$&#123;userCustom.username&#125;%' &lt;/if&gt; &lt;/if&gt; &lt;/sql&gt; 那么我们该怎样引用这个sql片段呢？如下： 12345select * from user &lt;where&gt; &lt;!--refid: 指定sql片段的id，如果是写在其他的mapper文件中，则需要在前面加上namespace--&gt; &lt;include refid=\"query_user_where\"/&gt; &lt;/where&gt; 测试的话还是那样了，就不继续说了，前面已经说了很多了。 foreach向sql传递数组或List，mybatis使用foreach解析 需求： 在用户查询列表和查询总数的statement中增加多个id输入查询。 sql语句如下： 123SELECT * FROM USER WHERE id=1 OR id=10 ORid=16或者SELECT * FROM USER WHERE id IN(1,10,16) 在输入参数类型中添加 List ids 传入多个 id 12345public class UserQueryVo //用户包装类型&#123; //传入多个id private List&lt;Integer&gt; ids;&#125; 修改 UserMapper.xml文件 WHERE id=1 OR id=10 OR id=16 在查询条件中，查询条件定义成一个sql片段，需要修改sql片段。 12345678910111213141516171819202122&lt;if test=\"ids!=null\"&gt; &lt;!-- 使用 foreach遍历传入ids collection：指定输入 对象中集合属性 item：每个遍历生成对象中 open：开始遍历时拼接的串 close：结束遍历时拼接的串 separator：遍历的两个对象中需要拼接的串 --&gt; &lt;!-- 使用实现下边的sql拼接： AND (id=1 OR id=10 OR id=16) --&gt; &lt;foreach collection=\"ids\" item=\"user_id\" open=\"AND (\" close=\")\" separator=\"or\"&gt; &lt;!-- 每个遍历需要拼接的串 --&gt; id=#&#123;user_id&#125; &lt;/foreach&gt; &lt;!-- 实现 “ and id IN(1,10,16)”拼接 --&gt; &lt;!-- &lt;foreach collection=\"ids\" item=\"user_id\" open=\"and id IN(\" close=\")\" separator=\",\"&gt; 每个遍历需要拼接的串 #&#123;user_id&#125; &lt;/foreach&gt; --&gt; &lt;/if&gt; 测试代码： 1234567 //传入多个idList&lt;Integer&gt; ids = new ArrayList&lt;&gt;();ids.add(1);ids.add(10);ids.add(16);//将ids传入statement中userQueryVo.setIds(ids); 期待后续的文章吧！","tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://yoursite.com/tags/Mybatis/"},{"name":"SpringMVC","slug":"SpringMVC","permalink":"http://yoursite.com/tags/SpringMVC/"}]},{"title":"通过项目逐步深入了解Mybatis（三）","date":"2017-03-28T10:56:06.191Z","path":"2017/03/28/通过项目逐步深入了解Mybatis(三)/","text":"相关阅读：1、通过项目逐步深入了解Mybatis&lt;一&gt; 2、 通过项目逐步深入了解Mybatis&lt;二&gt; 本项目所有代码及文档都托管在 Github地址：https://github.com/zhisheng17/mybatis Mybatis 高级知识安排：对订单商品数据模型进行分析 订单商品数据模型 数据模型分析思路：1、每张表记录的数据内容（分模块对每张表记录的内容进行熟悉，相当于学习系统需求的过程） 2、每张表重要的的字段设置（非空字段、外键字段） 3、数据库级别表与表之间的关系（外键关系） 4、表与表业务之间的关系（要建立在每个业务意义的基础上去分析） 数据模型分析模型 用户表 user：记录购买商品的用户信息 订单表 order：记录用户所创建的订单(购买商品的订单) 订单明细表 orderdetail：（记录了订单的详细信息即购买商品的信息） 商品表 items：记录了商品信息 表与表业务之间的关系： 在分析表与表之间的业务关系时需要建立在某个业务意义基础上去分析。 先分析数据级别之间有关系的表之间的业务关系： 1、usre和orders： user —&gt; orders：一个用户可以创建多个订单，一对多 orders —&gt; user：一个订单只由一个用户创建，一对一 2、 orders和orderdetail： orders —&gt; orderdetail：一个订单可以包括 多个订单明细，因为一个订单可以购买多个商品，每个商品的购买信息在orderdetail记录，一对多关系 orderdetail —&gt; orders：一个订单明细只能包括在一个订单中，一对一 3、 orderdetail 和 itesm： orderdetail —&gt; itesms：一个订单明细只对应一个商品信息，一对一 items —&gt; orderdetail:一个商品可以包括在多个订单明细 ，一对多 再分析数据库级别没有关系的表之间是否有业务关系： 4、 orders 和 items： orders 和 items 之间可以通过 orderdetail 表建立 关系。 一对一查询需求：查询订单信息，关联查询创建订单的用户信息 使用 resultType sql 语句 确定查询的主表：订单表 确定查询的关联表：用户表 关联查询使用内链接？还是外链接？ 由于orders表中有一个外键（user_id），通过外键关联查询用户表只能查询出一条记录，可以使用内链接。 1SELECT orders.*, USER.username, USER.sex, USER.address FROM orders, USER WHERE orders.user_id = user.id 创建 pojo Orders.java 123456789101112public class Orders &#123; private Integer id; private Integer userId; private String number; private Date createtime; private String note; //用户信息 private User user; //订单明细 private List&lt;Orderdetail&gt; orderdetails; //getter and setter&#125; OrderCustom.java 1234567891011//通过此类映射订单和用户查询的结果，让此类继承包括 字段较多的pojo类public class OrdersCustom extends Orders&#123; //添加用户属性 /*USER.username, USER.sex, USER.address */ private String username; private String sex; private String address; //getter and setter&#125; 映射文件 OrdersMapperCustom.xml 1234&lt;!--查询订单关联查询用户信息--&gt; &lt;select id=\"findOrdersUser\" resultType=\"cn.zhisheng.mybatis.po.OrdersCustom\"&gt; SELECT orders.*, USER.username, USER.sex, USER.address FROM orders, USER WHERE orders.user_id = user.id &lt;/select&gt; Mapper 文件 OrdersMapperCustom.java 1234public interface OrdersMapperCustom&#123; public OrdersCustom findOrdersUser() throws Exception;&#125; 测试代码（记得在 SqlConfig.xml中添加载 OrdersMapperCustom.xml 文件） 1234567891011@Test public void testFindOrdersUser() throws Exception &#123; SqlSession sqlSession = sqlSessionFactory.openSession(); //创建OrdersMapperCustom对象,mybatis自动生成代理对象 OrdersMapperCustom ordersMapperCustom = sqlSession.getMapper(OrdersMapperCustom.class); //调用OrdersMapperCustom的方法 List&lt;OrdersCustom&gt; list = ordersMapperCustom.findOrdersUser(); System.out.println(list); sqlSession.close(); &#125; 测试结果 ​ ​ 使用 resultMap sql 语句（和上面的一致） 使用 resultMap 映射思路 使用 resultMap 将查询结果中的订单信息映射到 Orders 对象中，在 orders 类中添加 User 属性，将关联查询出来的用户信息映射到 orders 对象中的 user 属性中。 12//用户信息private User user; 映射文件 OrdersMapperCustom.xml 先定义 resultMap 1234567891011121314151617181920212223242526272829303132&lt;!--定义查询订单关联查询用户信息的resultMap 将整个查询结果映射到cn.zhisheng.mybatis.po.Orders --&gt; &lt;resultMap id=\"OrdersUserResultMap\" type=\"cn.zhisheng.mybatis.po.Orders\"&gt; &lt;!--配置映射的订单信息--&gt; &lt;!--id表示查询结果中的唯一标识 在这里是订单的唯一标识 如果是由多列组成的唯一标识，那么就需要配置多个id column：id 是订单信息中的唯一标识列 property：id 是订单信息唯一标识列所映射到orders中的id属性 最终resultMap对column和property做一个映射关系（对应关系） --&gt; &lt;id column=\"id\" property=\"id\"/&gt; &lt;result column=\"user_id\" property=\"userId\"/&gt; &lt;result column=\"number\" property=\"number\"/&gt; &lt;result column=\"createtime\" property=\"createtime\"/&gt; &lt;result column=\"note\" property=\"note\"/&gt; &lt;!--配置映射的关联用户信息 association 用于映射关联查询单个对象的信息 property 将要关联查询的用户信息映射到 orders中的属性中去 --&gt; &lt;association property=\"user\" javaType=\"cn.zhisheng.mybatis.po.User\"&gt; &lt;!--id 关联用户信息的唯一标识 column: 指定唯一标识用户的信息 property：映射到user的那个属性 --&gt; &lt;id column=\"user_id\" property=\"id\"/&gt; &lt;result column=\"username\" property=\"username\"/&gt; &lt;result column=\"sex\" property=\"sex\"/&gt; &lt;result column=\"address\" property=\"address\"/&gt; &lt;result column=\"birthday\" property=\"birthday\"/&gt; &lt;/association&gt; &lt;/resultMap&gt; 1234&lt;!--查询订单关联查询用户信息, 使用 resultMap--&gt; &lt;select id=\"findOrdersUserResultMap\" resultMap=\"OrdersUserResultMap\"&gt; SELECT orders.*, USER.username, USER.sex, USER.address FROM orders, USER WHERE orders.user_id = user.id &lt;/select&gt; Mapper 文件 1public List&lt;Orders&gt; findOrdersUserResultMap() throws Exception; 测试代码 1234567891011@Test public void testFindOrdersUserResultMap() throws Exception &#123; SqlSession sqlSession = sqlSessionFactory.openSession(); //创建OrdersMapperCustom对象,mybatis自动生成代理对象 OrdersMapperCustom ordersMapperCustom = sqlSession.getMapper(OrdersMapperCustom.class); //调用OrdersMapperCustom的方法 List&lt;Orders&gt; list = ordersMapperCustom.findOrdersUserResultMap(); System.out.println(list); sqlSession.close(); &#125; 测试结果 使用 resultType 和 resultMap 一对一查询小结 resultType：使用resultType实现较为简单，如果pojo中没有包括查询出来的列名，需要增加列名对应的属性，即可完成映射。如果没有查询结果的特殊要求建议使用resultType。 resultMap：需要单独定义resultMap，实现有点麻烦，如果对查询结果有特殊的要求，使用resultMap可以完成将关联查询映射pojo的属性中。resultMap可以实现延迟加载，resultType无法实现延迟加载。 一对多查询需求：查询订单及订单明细信息 SQL语句： 确定主查询表：订单表 确定关联查询表：订单明细表 在一对一查询基础上添加订单明细表关联即可。 12SELECT orders.*, USER.username, USER.sex, USER.address, orderdetail.id orderdetail_id, orderdetail.items_id, orderdetail.items_num, orderdetail.orders_id FROM orders, USER,orderdetail WHERE orders.user_id = user.id AND orderdetail.orders_id=orders.id 分析： 使用 resultType 将上边的查询结果映射到 pojo 中，订单信息的就是重复。 要求： 对 orders 映射不能出现重复记录。 在 orders.java 类中添加 List orderDetails 属性。 最终会将订单信息映射到 orders 中，订单所对应的订单明细映射到 orders 中的 orderDetails 属性中。 映射成的 orders 记录数为两条（orders信息不重复） 每个 orders 中的 orderDetails 属性存储了该订单所对应的订单明细。 映射文件： 首先定义 resultMap 1234567891011121314151617181920&lt;!--定义查询订单及订单明细信息的resultMap使用extends继承，不用在中配置订单信息和用户信息的映射--&gt; &lt;resultMap id=\"OrdersAndOrderDetailResultMap\" type=\"cn.zhisheng.mybatis.po.Orders\" extends=\"OrdersUserResultMap\"&gt; &lt;!-- 订单信息 --&gt; &lt;!-- 用户信息 --&gt; &lt;!-- 使用extends继承，不用在中配置订单信息和用户信息的映射 --&gt; &lt;!-- 订单明细信息 一个订单关联查询出了多条明细，要使用collection进行映射 collection：对关联查询到多条记录映射到集合对象中 property：将关联查询到多条记录映射到cn.zhisheng.mybatis.po.Orders哪个属性 ofType：指定映射到list集合属性中pojo的类型 --&gt; &lt;collection property=\"orderdetails\" ofType=\"cn.zhisheng.mybatis.po.Orderdetail\"&gt; &lt;!-- id：订单明细唯 一标识 property:要将订单明细的唯 一标识 映射到cn.zhisheng.mybatis.po.Orderdetail的哪个属性--&gt; &lt;id column=\"orderdetail_id\" property=\"id\"/&gt; &lt;result column=\"items_id\" property=\"itemsId\"/&gt; &lt;result column=\"items_num\" property=\"itemsNum\"/&gt; &lt;result column=\"orders_id\" property=\"ordersId\"/&gt; &lt;/collection&gt; &lt;/resultMap&gt; 12345&lt;!--查询订单及订单明细信息, 使用 resultMap--&gt; &lt;select id=\"findOrdersAndOrderDetailResultMap\" resultMap=\"OrdersAndOrderDetailResultMap\"&gt; SELECT orders.*, USER.username, USER.sex, USER.address, orderdetail.id orderdetail_id, orderdetail.items_id, orderdetail.items_num, orderdetail.orders_id FROM orders, USER,orderdetail WHERE orders.user_id = user.id AND orderdetail.orders_id=orders.id &lt;/select&gt; Mapper 文件 1public List&lt;Orders&gt; findOrdersAndOrderDetailResultMap() throws Exception; 测试文件 1234567891011@Test public void testFindOrdersAndOrderDetailResultMap() throws Exception &#123; SqlSession sqlSession = sqlSessionFactory.openSession(); //创建OrdersMapperCustom对象,mybatis自动生成代理对象 OrdersMapperCustom ordersMapperCustom = sqlSession.getMapper(OrdersMapperCustom.class); //调用OrdersMapperCustom的方法 List&lt;Orders&gt; list = ordersMapperCustom.findOrdersAndOrderDetailResultMap(); System.out.println(list); sqlSession.close(); &#125; 测试结果 总结：mybatis使用resultMap的collection对关联查询的多条记录映射到一个list集合属性中。 使用resultType实现：将订单明细映射到orders中的orderdetails中，需要自己处理，使用双重循环遍历，去掉重复记录，将订单明细放在orderdetails中。 多对多查询需求：查询用户及用户购买商品信息。 SQL语句： 查询主表是：用户表 关联表：由于用户和商品没有直接关联，通过订单和订单明细进行关联，所以关联表： orders、orderdetail、items 123SELECT orders.*, USER.username, USER.sex, USER.address, orderdetail.id orderdetail_id,orderdetail.items_id, orderdetail.items_num, orderdetail.orders_id, items.name items_name,items.detail items_detail, items.price items_price FROM orders, USER, orderdetail, items WHERE orders.user_id = user.id AND orderdetail.orders_id=orders.id AND orderdetail.items_id = items.id 映射思路： 将用户信息映射到 user 中。在 user 类中添加订单列表属性List orderslist，将用户创建的订单映射到orderslist在Orders中添加订单明细列表属性Listorderdetials，将订单的明细映射到orderdetials在OrderDetail中添加Items属性，将订单明细所对应的商品映射到Items 定义 resultMap：12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;!--定义查询用户及用户购买商品信息的 resultMap--&gt; &lt;resultMap id=\"UserAndItemsResultMap\" type=\"cn.zhisheng.mybatis.po.User\"&gt; &lt;!--用户信息--&gt; &lt;id column=\"user_id\" property=\"id\"/&gt; &lt;result column=\"username\" property=\"username\"/&gt; &lt;result column=\"sex\" property=\"sex\"/&gt; &lt;result column=\"birthday\" property=\"birthday\"/&gt; &lt;result column=\"address\" property=\"address\"/&gt; &lt;!--订单信息 一个用户对应多个订单，使用collection映射 --&gt; &lt;collection property=\"ordersList\" ofType=\"cn.zhisheng.mybatis.po.Orders\"&gt; &lt;id column=\"id\" property=\"id\"/&gt; &lt;result column=\"user_id\" property=\"userId\"/&gt; &lt;result column=\"number\" property=\"number\"/&gt; &lt;result column=\"createtime\" property=\"createtime\"/&gt; &lt;result column=\"note\" property=\"note\"/&gt; &lt;!-- 订单明细 一个订单包括 多个明细 --&gt; &lt;collection property=\"orderdetails\" ofType=\"cn.zhisheng.mybatis.po.Orderdetail\"&gt; &lt;id column=\"orderdetail_id\" property=\"id\"/&gt; &lt;result column=\"orders_id\" property=\"ordersId\"/&gt; &lt;result column=\"items_id\" property=\"itemsId\"/&gt; &lt;result column=\"items_num\" property=\"itemsNum\"/&gt; &lt;!-- 商品信息 一个订单明细对应一个商品 --&gt; &lt;association property=\"items\" javaType=\"cn.zhisheng.mybatis.po.Items\"&gt; &lt;id column=\"items_id\" property=\"id\"/&gt; &lt;result column=\"items_name\" property=\"name\"/&gt; &lt;result column=\"items_price\" property=\"price\"/&gt; &lt;result column=\"items_pic\" property=\"pic\"/&gt; &lt;result column=\"items_createtime\" property=\"createtime\"/&gt; &lt;result column=\"items_detail\" property=\"detail\"/&gt; &lt;/association&gt; &lt;/collection&gt; &lt;/collection&gt; &lt;/resultMap&gt; 映射文件12345&lt;!--查询用户及用户购买商品信息, 使用 resultMap--&gt; &lt;select id=\"findUserAndItemsResultMap\" resultMap=\"UserAndItemsResultMap\"&gt; SELECT orders.*, USER.username, USER.sex, USER.address, orderdetail.id orderdetail_id, orderdetail.items_id, orderdetail.items_num, orderdetail.orders_id FROM orders, USER,orderdetail WHERE orders.user_id = user.id AND orderdetail.orders_id=orders.id &lt;/select&gt; Mapper 文件1public List&lt;User&gt; findUserAndItemsResultMap() throws Exception; 测试文件1234567891011@Test public void testFindUserAndItemsResultMap() throws Exception &#123; SqlSession sqlSession = sqlSessionFactory.openSession(); //创建OrdersMapperCustom对象,mybatis自动生成代理对象 OrdersMapperCustom ordersMapperCustom = sqlSession.getMapper(OrdersMapperCustom.class); //调用OrdersMapperCustom的方法 List&lt;User&gt; list = ordersMapperCustom.findUserAndItemsResultMap(); System.out.println(list); sqlSession.close(); &#125; 测试： 我去，竟然报错了，但是不要怕，通过查看报错信息可以知道我忘记在 User.java 中加入 orderlist 属性了，接下来我加上去，并加上 getter 和 setter 方法。 12345678//用户创建的订单列表 private List&lt;Orders&gt; ordersList; public List&lt;Orders&gt; getOrdersList() &#123; return ordersList; &#125; public void setOrdersList(List&lt;Orders&gt; ordersList) &#123; this.ordersList = ordersList; &#125; 再次测试就能成功了。 多对多查询总结将查询用户购买的商品信息明细清单，（用户名、用户地址、购买商品名称、购买商品时间、购买商品数量） 针对上边的需求就使用resultType将查询到的记录映射到一个扩展的pojo中，很简单实现明细清单的功能。 一对多是多对多的特例，如下需求： 查询用户购买的商品信息，用户和商品的关系是多对多关系。 需求1： 查询字段：用户账号、用户名称、用户性别、商品名称、商品价格(最常见) 企业开发中常见明细列表，用户购买商品明细列表， 使用resultType将上边查询列映射到pojo输出。 需求2： 查询字段：用户账号、用户名称、购买商品数量、商品明细（鼠标移上显示明细） 使用resultMap将用户购买的商品明细列表映射到user对象中。 总结： 使用resultMap是针对那些对查询结果映射有特殊要求的功能，，比如特殊要求映射成list中包括多个list。 ResultMap 总结resultType：作用： 将查询结果按照sql列名pojo属性名一致性映射到pojo中。 场合： 常见一些明细记录的展示，比如用户购买商品明细，将关联查询信息全部展示在页面时，此时可直接使用resultType将每一条记录映射到pojo中，在前端页面遍历list（list中是pojo）即可。 resultMap： 使用association和collection完成一对一和一对多高级映射（对结果有特殊的映射要求）。 association：作用： 将关联查询信息映射到一个pojo对象中。 场合： 为了方便查询关联信息可以使用association将关联订单信息映射为用户对象的pojo属性中，比如：查询订单及关联用户信息。使用resultType无法将查询结果映射到pojo对象的pojo属性中，根据对结果集查询遍历的需要选择使用resultType还是resultMap。 collection：作用： 将关联查询信息映射到一个list集合中。 场合： 为了方便查询遍历关联信息可以使用collection将关联信息映射到list集合中，比如：查询用户权限范围模块及模块下的菜单，可使用collection将模块映射到模块list中，将菜单列表映射到模块对象的菜单list属性中，这样的作的目的也是方便对查询结果集进行遍历查询。如果使用resultType无法将查询结果映射到list集合中。","tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://yoursite.com/tags/Mybatis/"},{"name":"SpringMVC","slug":"SpringMVC","permalink":"http://yoursite.com/tags/SpringMVC/"}]},{"title":"通过项目逐步深入了解Mybatis（四）","date":"2017-03-28T10:55:50.711Z","path":"2017/03/28/通过项目逐步深入了解Mybatis(四)/","text":"相关阅读： 1、通过项目逐步深入了解Mybatis&lt;一&gt; 2、通过项目逐步深入了解Mybatis&lt;二&gt; 3、通过项目逐步深入了解Mybatis&lt;三&gt; 本项目所有代码及文档都托管在 Github地址：https://github.com/zhisheng17/mybatis 延迟加载什么是延迟加载？resultMap可以实现高级映射（使用association、collection实现一对一及一对多映射），association、collection具备延迟加载功能。需求：如果查询订单并且关联查询用户信息。如果先查询订单信息即可满足要求，当我们需要查询用户信息时再查询用户信息。把对用户信息的按需去查询就是延迟加载。 延迟加载：先从单表查询、需要时再从关联表去关联查询，大大提高 数据库性能，因为查询单表要比关联查询多张表速度要快。 打开延迟加载开关在mybatis核心配置文件中配置： lazyLoadingEnabled、aggressiveLazyLoading 设置项 描述 允许值 默认值 lazyLoadingEnabled 全局性设置懒加载。如果设为‘false’，则所有相关联的都会被初始化加载。 true \\ false false aggressiveLazyLoading 当设置为‘true’的时候，懒加载的对象可能被任何懒属性全部加载。否则，每个属性都按需加载。 true \\ false true 1234&lt;settings&gt; &lt;setting name=\"lazyLoadingEnabled\" value=\"true\"/&gt; &lt;setting name=\"aggressiveLazyLoading\" value=\"false\"/&gt;&lt;/settings&gt; 使用 association 实现延迟加载需求：查询订单并且关联查询用户信息 Mapper.xml需要定义两个 mapper 的方法对应的 statement。 1、只查询订单信息 SQL 语句： select * from orders 在查询订单的 statement 中使用 association 去延迟加载（执行）下边的 statement (关联查询用户信息) 1234&lt;!--查询订单并且关联查询用户信息，关联用户信息需要通过 association 延迟加载--&gt; &lt;select id=\"findOrdersUserLazyLoading\" resultMap=\"OrdersUserLazyLoadingResultMap\"&gt; select * from orders &lt;/select&gt; 2、关联查询用户信息 通过上面查询订单信息中的 user_id 来关联查询用户信息。使用 UserMapper.xml 中的 findUserById SQL语句：select * from user where id = user_id 123&lt;select id=\"findUserById\" parameterType=\"int\" resultType=\"user\"&gt; select * from user where id = #&#123;value&#125; &lt;/select&gt; 上边先去执行 findOrdersUserLazyLoading，当需要去查询用户的时候再去执行 findUserById ，通过 resultMap的定义将延迟加载执行配置起来。也就是通过 resultMap 去加载 UserMapper.xml 文件中的 select = findUserById 延迟加载的 resultMap1234567891011121314151617181920&lt;!--定义 关联用户信息（通过 association 延迟加载）的resultMap--&gt; &lt;resultMap id=\"OrdersUserLazyLoadingResultMap\" type=\"cn.zhisheng.mybatis.po.Orders\"&gt; &lt;!--对订单信息映射--&gt; &lt;id column=\"id\" property=\"id\"/&gt; &lt;result column=\"user_id\" property=\"userId\"/&gt; &lt;result column=\"number\" property=\"number\"/&gt; &lt;result column=\"createtime\" property=\"createtime\"/&gt; &lt;result column=\"note\" property=\"note\"/&gt; &lt;!-- 实现对用户信息进行延迟加载 select：指定延迟加载需要执行的statement的id（是根据user_id查询用户信息的statement） 要使用userMapper.xml中findUserById完成根据用户id(user_id)用户信息的查询，如果findUserById不在本mapper中需要前边加namespace column：订单信息中关联用户信息查询的列，是user_id 关联查询的sql理解为： SELECT orders.*, (SELECT username FROM USER WHERE orders.user_id = user.id)username, (SELECT sex FROM USER WHERE orders.user_id = user.id)sex FROM orders--&gt; &lt;association property=\"user\" javaType=\"cn.zhisheng.mybatis.po.User\" select=\"cn.zhisheng.mybatis.mapper.UserMapper.findUserById\" column=\"user_id\"&gt; &lt;/association&gt; &lt;/resultMap&gt; OrderMapperCustom.java1public List&lt;Orders&gt; findOrdersUserLazyLoading() throws Exception; 测试代码：1234567891011121314151617@Test public void testFindOrdersUserLazyLoading() throws Exception &#123; SqlSession sqlSession = sqlSessionFactory.openSession(); //创建OrdersMapperCustom对象,mybatis自动生成代理对象 OrdersMapperCustom ordersMapperCustom = sqlSession.getMapper(OrdersMapperCustom.class); //查询订单信息 List&lt;Orders&gt; list = ordersMapperCustom.findOrdersUserLazyLoading(); //遍历所查询的的订单信息 for (Orders orders : list) &#123; //查询用户信息 User user = orders.getUser(); System.out.println(user); &#125; sqlSession.close(); &#125; 测试结果： 整个延迟加载的思路： 1、执行上边mapper方法（findOrdersUserLazyLoading），内部去调用cn.zhisheng.mybatis.mapper.OrdersMapperCustom 中的 findOrdersUserLazyLoading 只查询 orders 信息（单表）。 2、在程序中去遍历上一步骤查询出的 List，当我们调用 Orders 中的 getUser 方法时，开始进行延迟加载。 3、延迟加载，去调用 UserMapper.xml 中 findUserbyId 这个方法获取用户信息。 思考：不使用 mybatis 提供的 association 及 collection 中的延迟加载功能，如何实现延迟加载？？ 实现方法如下： 定义两个mapper方法： 1、查询订单列表 2、根据用户id查询用户信息 实现思路： 先去查询第一个mapper方法，获取订单信息列表 在程序中（service），按需去调用第二个mapper方法去查询用户信息。 总之： 使用延迟加载方法，先去查询 简单的 sql（最好单表，也可以关联查询），再去按需要加载关联查询的其它信息。 一对多延迟加载上面的那个案例是一对一延迟加载，那么如果我们想一对多进行延迟加载呢，其实也是很简单的。 一对多延迟加载的方法同一对一延迟加载，在collection标签中配置select内容。 延迟加载总结：作用： 当需要查询关联信息时再去数据库查询，默认不去关联查询，提高数据库性能。只有使用resultMap支持延迟加载设置。 场合： 当只有部分记录需要关联查询其它信息时，此时可按需延迟加载，需要关联查询时再向数据库发出sql，以提高数据库性能。 当全部需要关联查询信息时，此时不用延迟加载，直接将关联查询信息全部返回即可，可使用resultType或resultMap完成映射。 查询缓存什么是查询缓存？mybatis提供查询缓存，用于减轻数据压力，提高数据库性能。 mybaits提供一级缓存，和二级缓存。 一级缓存是SqlSession级别的缓存。在操作数据库时需要构造 sqlSession对象，在对象中有一个数据结构（HashMap）用于存储缓存数据。不同的sqlSession之间的缓存数据区域（HashMap）是互相不影响的。 二级缓存是mapper级别的缓存，多个SqlSession去操作同一个Mapper的sql语句，多个SqlSession可以共用二级缓存，二级缓存是跨SqlSession的。 为什么要用缓存？ 如果缓存中有数据就不用从数据库中获取，大大提高系统性能。 一级缓存工作原理： 第一次发起查询用户id为1的用户信息，先去找缓存中是否有id为1的用户信息，如果没有，从数据库查询用户信息。 得到用户信息，将用户信息存储到一级缓存中。 如果sqlSession去执行commit操作（执行插入、更新、删除），清空SqlSession中的一级缓存，这样做的目的为了让缓存中存储的是最新的信息，避免脏读。 第二次发起查询用户id为1的用户信息，先去找缓存中是否有id为1的用户信息，缓存中有，直接从缓存中获取用户信息。 一级缓存测试 Mybatis 默认支持一级缓存，不需要在配置文件中配置。 所以我们直接按照上面的步骤进行测试： 123456789101112131415//一级缓存测试 @Test public void testCache1() throws Exception &#123; SqlSession sqlSession = sqlSessionFactory.openSession(); //创建UserMapper对象,mybatis自动生成代理对象 UserMapper userMapper = sqlSession.getMapper(UserMapper.class); //查询使用的是同一个session //第一次发起请求，查询Id 为1的用户信息 User user1 = userMapper.findUserById(1); System.out.println(user1); //第二次发起请求，查询Id 为1的用户信息 User user2 = userMapper.findUserById(1); System.out.println(user2); sqlSession.close(); &#125; 通过结果可以看出第二次没有发出sql查询请求， 所以我们需要在中间执行 commit 操作 123456789//如果sqlSession去执行commit操作（执行插入、更新、删除），// 清空SqlSession中的一级缓存，这样做的目的为了让缓存中存储的是最新的信息，避免脏读。//更新user1的信息，user1.setUsername(\"李飞\");//user1.setSex(\"男\");//user1.setAddress(\"北京\");userMapper.updateUserById(user1);//提交事务,才会去清空缓存sqlSession.commit(); 测试 一级缓存应用 正式开发，是将 mybatis 和 spring 进行整合开发，事务控制在 service 中。 一个 service 方法中包括很多 mapper 方法调用。 service{ //开始执行时，开启事务，创建SqlSession对象 //第一次调用mapper的方法findUserById(1) //第二次调用mapper的方法findUserById(1)，从一级缓存中取数据 //方法结束，sqlSession关闭 } 如果是执行两次service调用查询相同的用户信息，不走一级缓存，因为session方法结束，sqlSession就关闭，一级缓存就清空。 二级缓存原理 首先开启mybatis的二级缓存。 sqlSession1去查询用户id为1的用户信息，查询到用户信息会将查询数据存储到二级缓存中。 如果SqlSession3去执行相同 mapper下sql，执行commit提交，清空该 mapper下的二级缓存区域的数据。 sqlSession2去查询用户id为1的用户信息，去缓存中找是否存在数据，如果存在直接从缓存中取出数据。 二级缓存与一级缓存区别，二级缓存的范围更大，多个sqlSession可以共享一个UserMapper的二级缓存区域。 UserMapper有一个二级缓存区域（按namespace分） ，其它mapper也有自己的二级缓存区域（按namespace分）。 每一个namespace的mapper都有一个二缓存区域，两个mapper的namespace如果相同，这两个mapper执行sql查询到数据将存在相同的二级缓存区域中。 开启二级缓存： mybaits的二级缓存是mapper范围级别，除了在SqlMapConfig.xml设置二级缓存的总开关，还要在具体的mapper.xml中开启二级缓存 在 SqlMapConfig.xml 开启二级开关 12&lt;!-- 开启二级缓存 --&gt;&lt;setting name=\"cacheEnabled\" value=\"true\"/&gt; 然后在你的 Mapper 映射文件中添加一行： ，表示此 mapper 开启二级缓存。 调用 pojo 类实现序列化接口： 二级缓存需要查询结果映射的pojo对象实现java.io.Serializable接口实现序列化和反序列化操作（因为二级缓存数据存储介质多种多样，在内存不一样），注意如果存在父类、成员pojo都需要实现序列化接口。 12public class Orders implements Serializablepublic class User implements Serializable 测试 12345678910111213141516171819202122232425262728293031323334//二级缓存测试 @Test public void testCache2() throws Exception &#123; SqlSession sqlSession1 = sqlSessionFactory.openSession(); SqlSession sqlSession2 = sqlSessionFactory.openSession(); SqlSession sqlSession3 = sqlSessionFactory.openSession(); //创建UserMapper对象,mybatis自动生成代理对象 UserMapper userMapper1 = sqlSession1.getMapper(UserMapper.class); //sqlSession1 执行查询 写入缓存(第一次查询请求) User user1 = userMapper1.findUserById(1); System.out.println(user1); sqlSession1.close(); //sqlSession3 执行提交 清空缓存 UserMapper userMapper3 = sqlSession3.getMapper(UserMapper.class); User user3 = userMapper3.findUserById(1); user3.setSex(\"女\"); user3.setAddress(\"山东济南\"); user3.setUsername(\"崔建\"); userMapper3.updateUserById(user3); //提交事务，清空缓存 sqlSession3.commit(); sqlSession3.close(); //sqlSession2 执行查询(第二次查询请求) UserMapper userMapper2 = sqlSession2.getMapper(UserMapper.class); User user2 = userMapper2.findUserById(1); System.out.println(user2); sqlSession2.close(); &#125; 结果： useCache 配置 在 statement 中设置 useCache=false 可以禁用当前 select 语句的二级缓存，即每次查询都会发出sql去查询，默认情况是true，即该sql使用二级缓存。 1&lt;select id=\"findUserById\" parameterType=\"int\" resultType=\"user\" useCache=\"false\"&gt; 总结：针对每次查询都需要最新的数据sql，要设置成useCache=false，禁用二级缓存。 刷新缓存（清空缓存） 在mapper的同一个namespace中，如果有其它insert、update、delete操作数据后需要刷新缓存，如果不执行刷新缓存会出现脏读。 设置statement配置中的flushCache=”true” 属性，默认情况下为true即刷新缓存，如果改成false则不会刷新。使用缓存时如果手动修改数据库表中的查询数据会出现脏读。 如下： 1&lt;insert id=\"insetrUser\" parameterType=\"cn.zhisheng.mybatis.po.User\" flushCache=\"true\"&gt; 一般下执行完commit操作都需要刷新缓存，flushCache=true表示刷新缓存，这样可以避免数据库脏读。 Mybatis Cache参数flushInterval（刷新间隔）可以被设置为任意的正整数，而且它们代表一个合理的毫秒形式的时间段。默认情况是不设置，也就是没有刷新间隔，缓存仅仅调用语句时刷新。 size（引用数目）可以被设置为任意正整数，要记住你缓存的对象数目和你运行环境的可用内存资源数目。默认值是1024。 readOnly（只读）属性可以被设置为true或false。只读的缓存会给所有调用者返回缓存对象的相同实例。因此这些对象不能被修改。这提供了很重要的性能优势。可读写的缓存会返回缓存对象的拷贝（通过序列化）。这会慢一些，但是安全，因此默认是false。 如下例子： 1&lt;cache eviction=\"FIFO\" flushInterval=\"60000\" size=\"512\" readOnly=\"true\"/&gt; 这个更高级的配置创建了一个 FIFO 缓存,并每隔 60 秒刷新,存数结果对象或列表的 512 个引用,而且返回的对象被认为是只读的,因此在不同线程中的调用者之间修改它们会导致冲突。可用的收回策略有, 默认的是 LRU: LRU – 最近最少使用的:移除最长时间不被使用的对象。 FIFO – 先进先出:按对象进入缓存的顺序来移除它们。 SOFT – 软引用:移除基于垃圾回收器状态和软引用规则的对象。 WEAK – 弱引用:更积极地移除基于垃圾收集器状态和弱引用规则的对象。 Mybatis 整合 ehcacheehcache 是一个分布式缓存框架。 分布缓存 我们系统为了提高系统并发，性能、一般对系统进行分布式部署（集群部署方式） 不使用分布缓存，缓存的数据在各各服务单独存储，不方便系统 开发。所以要使用分布式缓存对缓存数据进行集中管理。 mybatis无法实现分布式缓存，需要和其它分布式缓存框架进行整合。 整合方法 mybatis 提供了一个二级缓存 cache 接口（org.apache.ibatis.cache 下的 Cache），如果要实现自己的缓存逻辑，实现cache接口开发即可。 12345678910import java.util.concurrent.locks.ReadWriteLock;public interface Cache &#123; String getId(); void putObject(Object var1, Object var2); Object getObject(Object var1); Object removeObject(Object var1); void clear(); int getSize(); ReadWriteLock getReadWriteLock();&#125; mybatis和ehcache整合，mybatis 和 ehcache 整合包中提供了一个 cache 接口的实现类(org.apache.ibatis.cache.impl 下的 PerpetualCache)。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package org.apache.ibatis.cache.impl;import java.util.HashMap;import java.util.Map;import java.util.concurrent.locks.ReadWriteLock;import org.apache.ibatis.cache.Cache;import org.apache.ibatis.cache.CacheException;public class PerpetualCache implements Cache &#123; private String id; private Map&lt;Object, Object&gt; cache = new HashMap(); public PerpetualCache(String id) &#123; this.id = id; &#125; public String getId() &#123; return this.id; &#125; public int getSize() &#123; return this.cache.size(); &#125; public void putObject(Object key, Object value) &#123; this.cache.put(key, value); &#125; public Object getObject(Object key) &#123; return this.cache.get(key); &#125; public Object removeObject(Object key) &#123; return this.cache.remove(key); &#125; public void clear() &#123; this.cache.clear(); &#125; public ReadWriteLock getReadWriteLock() &#123; return null; &#125; public boolean equals(Object o) &#123; if(this.getId() == null) &#123; throw new CacheException(\"Cache instances require an ID.\"); &#125; else if(this == o) &#123; return true; &#125; else if(!(o instanceof Cache)) &#123; return false; &#125; else &#123; Cache otherCache = (Cache)o; return this.getId().equals(otherCache.getId()); &#125; &#125; public int hashCode() &#123; if(this.getId() == null) &#123; throw new CacheException(\"Cache instances require an ID.\"); &#125; else &#123; return this.getId().hashCode(); &#125; &#125;&#125; 通过实现 Cache 接口可以实现 mybatis 缓存数据通过其它缓存数据库整合，mybatis 的特长是sql操作，缓存数据的管理不是 mybatis 的特长，为了提高缓存的性能将 mybatis 和第三方的缓存数据库整合，比如 ehcache、memcache、redis等。 引入依赖包 ehcache-core-2.6.5.jar 和 mybatis-ehcache-1.0.2.jar 引入缓存配置文件 classpath下添加：ehcache.xml 内容如下： 1234567891011121314&lt;ehcache xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:noNamespaceSchemaLocation=\"http://ehcache.org/ehcache.xsd\"&gt; &lt;diskStore path=\"C:\\JetBrains\\IDEAProject\\ehcache\" /&gt; &lt;defaultCache maxElementsInMemory=\"1000\" maxElementsOnDisk=\"10000000\" eternal=\"false\" overflowToDisk=\"false\" timeToIdleSeconds=\"120\" timeToLiveSeconds=\"120\" diskExpiryThreadIntervalSeconds=\"120\" memoryStoreEvictionPolicy=\"LRU\"&gt; &lt;/defaultCache&gt;&lt;/ehcache&gt; 属性说明： diskStore：指定数据在磁盘中的存储位置。 defaultCache：当借助 CacheManager.add(“demoCache”) 创建Cache时，EhCache 便会采用指定的的管理策略 以下属性是必须的： maxElementsInMemory - 在内存中缓存的element的最大数目 maxElementsOnDisk - 在磁盘上缓存的element的最大数目，若是0表示无穷大 eternal - 设定缓存的elements是否永远不过期。如果为true，则缓存的数据始终有效，如果为false那么还要根据timeToIdleSeconds，timeToLiveSeconds判断 overflowToDisk- 设定当内存缓存溢出的时候是否将过期的element缓存到磁盘上 以下属性是可选的： timeToIdleSeconds - 当缓存在EhCache中的数据前后两次访问的时间超过timeToIdleSeconds的属性取值时，这些数据便会删除，默认值是0,也就是可闲置时间无穷大 timeToLiveSeconds - 缓存element的有效生命期，默认是0.,也就是element存活时间无穷大 diskSpoolBufferSizeMB 这个参数设置DiskStore(磁盘缓存)的缓存区大小.默认是30MB.每个Cache都应该有自己的一个缓冲区. diskPersistent- 在VM重启的时候是否启用磁盘保存EhCache中的数据，默认是false。 diskExpiryThreadIntervalSeconds - 磁盘缓存的清理线程运行间隔，默认是120秒。每个120s，相应的线程会进行一次EhCache中数据的清理工作 memoryStoreEvictionPolicy - 当内存缓存达到最大，有新的element加入的时候， 移除缓存中element的策略。默认是LRU（最近最少使用），可选的有LFU（最不常使用）和FIFO（先进先出） 开启ehcache缓存 EhcacheCache 是ehcache对Cache接口的实现；修改mapper.xml文件，在cache中指定EhcacheCache。 根据需求调整缓存参数： 123456789&lt;cache type=\"org.mybatis.caches.ehcache.EhcacheCache\" &gt; &lt;property name=\"timeToIdleSeconds\" value=\"3600\"/&gt; &lt;property name=\"timeToLiveSeconds\" value=\"3600\"/&gt; &lt;!-- 同ehcache参数maxElementsInMemory --&gt; &lt;property name=\"maxEntriesLocalHeap\" value=\"1000\"/&gt; &lt;!-- 同ehcache参数maxElementsOnDisk --&gt; &lt;property name=\"maxEntriesLocalDisk\" value=\"10000000\"/&gt; &lt;property name=\"memoryStoreEvictionPolicy\" value=\"LRU\"/&gt; &lt;/cache&gt; 测试 ：(这命中率就代表成功将ehcache 与 mybatis 整合了) 应用场景对于访问多的查询请求且用户对查询结果实时性要求不高，此时可采用 mybatis 二级缓存技术降低数据库访问量，提高访问速度，业务场景比如：耗时较高的统计分析sql、电话账单查询sql等。 实现方法如下：通过设置刷新间隔时间，由 mybatis 每隔一段时间自动清空缓存，根据数据变化频率设置缓存刷新间隔 flushInterval，比如设置为30分钟、60分钟、24小时等，根据需求而定。 局限性mybatis 二级缓存对细粒度的数据级别的缓存实现不好，比如如下需求：对商品信息进行缓存，由于商品信息查询访问量大，但是要求用户每次都能查询最新的商品信息，此时如果使用 mybatis 的二级缓存就无法实现当一个商品变化时只刷新该商品的缓存信息而不刷新其它商品的信息，因为 mybaits 的二级缓存区域以 mapper 为单位划分，当一个商品信息变化会将所有商品信息的缓存数据全部清空。解决此类问题需要在业务层根据需求对数据有针对性缓存。","tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://yoursite.com/tags/Mybatis/"},{"name":"SpringMVC","slug":"SpringMVC","permalink":"http://yoursite.com/tags/SpringMVC/"}]},{"title":"奇怪的Java题：为什么128 == 128返回为False，而127 == 127会返回为True?","date":"2017-03-28T10:55:36.199Z","path":"2017/03/28/奇怪的Java题：为什么128 == 128返回为False，而127 == 127会返回为True-/","text":"这是我们今天要讨论的话题，因为我觉得它非常的有趣。 如果你运行如下代码： 12345678910class A&#123; public static void main(String[] args) &#123; Integer a = 128, b = 128; System.out.println(a == b); Integer c = 127, d = 127; System.out.println(c == d); &#125;&#125; 你会得到如下结果： 12falsetrue 我们知道，如果两个引用指向同一个对象，那么==就成立；反之，如果两个引用指向的不是同一个对象，那么==就不成立，即便两个引用的内容是一样的。因此，结果就会出现false。 这是非常有趣的地方。如果你查看Integer.java类，你会找到IntegerCache.java这个内部私有类，它为-128到127之间的所有整数对象提供缓存。 这个东西为那些数值比较小的整数提供内部缓存，当进行如此声明时： 1Integer c = 127 它的内部就是这样的： 1Integer var3 = Integer.valueOf(127); 其实我通过将A.class文件反编译后，代码如下图： 如果我们观察valueOf()类函数，我们可以看到： 12345public static Integer valueOf(int i) &#123; if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i); &#125; 通过看源码能够知道，整数类型在-128～127之间时，会使用缓存，造成的效果就是，如果已经创建了一个相同的整数，使用valueOf创建第二次时，不会使用new关键字，而用已经缓存的对象。所以使用valueOf方法创建两次对象，若对应的数值相同，且数值在-128～127之间时，两个对象都指向同一个地址。 因此。。。 1Integer c = 127, d = 127; 两者指向同样的对象。 这就是为什么下面这段代码的结果为true了： 1System.out.println(c == d); 现在你可能会问，为什么会为-128到127之间的所有整数设置缓存？ 这是因为在这个范围内的小数值整数在日常生活中的使用频率要比其它的大得多，多次使用相同的底层对象这一特性可以通过该设置进行有效的内存优化。你可以使用reflection API任意使用这个功能。 运行下面的这段代码，你就会明白它的神奇所在了。 12345678910111213public static void main(String[] args) throws NoSuchFieldException, IllegalAccessException &#123; Class cache = Integer.class.getDeclaredClasses()[0]; Field myCache = cache.getDeclaredField(&quot;cache&quot;); myCache.setAccessible(true); Integer[] newCache = (Integer[]) myCache.get(cache); newCache[132] = newCache[133]; int a = 2; int b = a + a; System.out.printf(&quot;%d + %d = %d&quot;, a, a, b); // &#125; 打印结果竟然是： 12 + 2 = 5 我们再次看一下反汇编代码： 是不是又和上面的是同一个问题呢？ 但是结果为什么是 2 + 2 = 5 呢？ 我们继续去看一下 Integer 源码，去深入了解 Integer 缓存机制，下面截个图： 根据源码可以发现最后修改 Integer 缓存上限时候的方法有点小瑕疵。我们看看Api给我们怎么建议的一段话：1the size of the cache may be controlled by the &#123;@code -XX:AutoBoxCacheMax=&lt;size&gt;&#125; option. 原来我们只需要：运行时设置 -XX:AutoBoxCacheMax=133 就OK。 参考文章： 奇怪的Java题：为什么1000 == 1000返回为False，而100 == 100会返回为True?","tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"}]},{"title":"通过项目逐步深入了解Spring MVC（一）","date":"2017-03-28T10:55:16.943Z","path":"2017/03/28/通过项目逐步深入了解Spring MVC（一）/","text":"相关阅读：本文档和项目代码地址：https://github.com/zhisheng17/springmvc 了解 Spring： Spring 官网：http://spring.io/ 一个好的东西一般都会有一个好的文档解释说明，如果你英语还行，建议还是看官方文档。 Spring MVC基础知识什么是Spring MVC？ Spring MVC框架原理（掌握） ​ 前端控制器、处理器映射器、处理器适配器、试图解析器Spring MVC 入门程序 ​ 目的：对前端控制器、处理器映射器、处理器适配器、试图解析器学习 ​ 非注解的处理器映射器、处理器适配器 ​ 注解的处理器映射器、处理器适配器（掌握） Spring MVC 和 Mybatis 整合（掌握） Spring MVC 注解开发：（掌握） ​ 常用的注解学习 ​ 参数绑定（简单类型，pojo类型、集合类型） ​ 自定义的参数绑定（掌握） Spring MVC 和 Struts2区别 Spring MVC高级应用参数绑定（集合类型） 数据回显 上传图片 json 数据交互 RESTful 支持 拦截器 Spring MVC 框架什么是Spring MVC？springmvc是spring框架的一个模块，springmvc和spring无需通过中间整合层进行整合。springmvc是一个基于mvc的web框架。 Web MVCMVC 设计模式在 B/S 系统下应用： 1、 用户发起request请求至控制器(Controller) 控制接收用户请求的数据，委托给模型进行处理 2、 控制器通过模型(Model)处理数据并得到处理结果 模型通常是指业务逻辑 3、 模型处理结果返回给控制器 4、 控制器将模型数据在视图(View)中展示 web中模型无法将数据直接在视图上显示，需要通过控制器完成。如果在C/S应用中模型是可以将数据在视图中展示的。 5、 控制器将视图response响应给用户 通过视图展示给用户要的数据或处理结果。 Spring MVC 框架 第一步：发起请求到前端控制器(DispatcherServlet) 第二步：前端控制器请求HandlerMapping查找 Handler 可以根据xml配置、注解进行查找 第三步：处理器映射器HandlerMapping向前端控制器返回Handler 第四步：前端控制器调用处理器适配器去执行Handler 第五步：处理器适配器去执行Handler 第六步：Handler执行完成给适配器返回ModelAndView 第七步：处理器适配器向前端控制器返回ModelAndView ModelAndView是springmvc框架的一个底层对象，包括Model和view 第八步：前端控制器请求视图解析器去进行视图解析 根据逻辑视图名解析成真正的视图(jsp) 第九步：视图解析器向前端控制器返回View 第十步：前端控制器进行视图渲染 视图渲染将模型数据(在ModelAndView对象中)填充到request域 第十一步：前端控制器向用户响应结果 组件： 1、前端控制器DispatcherServlet（不需要程序员开发） 作用接收请求，响应结果，相当于转发器，中央处理器。 有了DispatcherServlet减少了其它组件之间的耦合度。 2、处理器映射器HandlerMapping(不需要程序员开发) 作用：根据请求的url查找Handler 3、处理器适配器HandlerAdapter 作用：按照特定规则（HandlerAdapter要求的规则）去执行Handler 4、处理器Handler(需要程序员开发) 注意：编写Handler时按照HandlerAdapter的要求去做，这样适配器才可以去正确执行Handler 5、视图解析器View resolver(不需要程序员开发) 作用：进行视图解析，根据逻辑视图名解析成真正的视图（view） 6、视图View(需要程序员开发jsp) View是一个接口，实现类支持不同的View类型（jsp、freemarker、pdf…）","tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"Spring MVC","slug":"Spring-MVC","permalink":"http://yoursite.com/tags/Spring-MVC/"}]},{"title":"Spring MVC+Hibernate JPA搭建的博客系统项目中所遇到的坑","date":"2017-03-28T10:55:02.647Z","path":"2017/03/28/Spring MVC+Hibernate JPA搭建的博客系统项目中所遇到的坑/","text":"项目代码地址：https://github.com/zhisheng17/springmvc最近在学习 Spring MVC ，其中在做一个简单的博客系统demo，是使用 SpringMVC 集成 Spring Data JPA（由 Hibernate JPA 提供），来进行强大的数据库访问。结果其中遇到的坑不 是一点点啊，我差点崩溃了，其中最大的原因就是由于 Hibernate JPA 中的bug了，反正一开始 还不知道是这个问题，导致折腾了快一天的时间。想想都可怕啊。 mvc-dispatch-servlet.xml代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:mvc=\"http://www.springframework.org/schema/mvc\" xmlns:jpa=\"http://www.springframework.org/schema/data/jpa\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd http://www.springframework.org/schema/data/jpa http://www.springframework.org/schema/data/jpa/spring-jpa.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd\"&gt; &lt;!--指明 controller 所在包，并扫描其中的注解--&gt; &lt;context:component-scan base-package=\"cn.zhisheng.controller\"/&gt; &lt;!-- 静态资源(js、image等)的访问 --&gt; &lt;mvc:default-servlet-handler/&gt; &lt;!-- 开启注解 --&gt; &lt;mvc:annotation-driven/&gt; &lt;!--ViewResolver 视图解析器--&gt; &lt;!--用于支持Servlet、JSP视图解析--&gt; &lt;bean id=\"jspViewResolver\" class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\"&gt; &lt;property name=\"viewClass\" value=\"org.springframework.web.servlet.view.JstlView\"/&gt; &lt;property name=\"prefix\" value=\"/WEB-INF/pages/\"/&gt; &lt;property name=\"suffix\" value=\".jsp\"/&gt; &lt;/bean&gt; &lt;!-- 表示JPA Repository所在的包 --&gt; &lt;jpa:repositories base-package=\"cn.zhisheng.repository\"/&gt; &lt;bean id=\"entityManagerFactory\" class=\"org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean\"&gt; &lt;property name=\"persistenceUnitName\" value=\"defaultPersistenceUnit\"/&gt; &lt;property name=\"packagesToScan\" value=\"cn.zhisheng.model\" /&gt; &lt;property name=\"jpaVendorAdapter\"&gt; &lt;bean class=\"org.springframework.orm.jpa.vendor.HibernateJpaVendorAdapter\"/&gt; &lt;/property&gt; &lt;property name=\"jpaProperties\"&gt; &lt;props&gt; &lt;prop key=\"hibernate.connection.driver_class\"&gt;com.mysql.jdbc.Driver&lt;/prop&gt; &lt;prop key=\"hibernate.connection.url\"&gt;jdbc:mysql://localhost:3306/springdemo?useSSL=false&lt;/prop&gt; &lt;prop key=\"hibernate.connection.username\"&gt;root&lt;/prop&gt; &lt;prop key=\"hibernate.connection.password\"&gt;root&lt;/prop&gt; &lt;prop key=\"hibernate.show_sql\"&gt;false&lt;/prop&gt; &lt;prop key=\"hibernate.connection.useUnicode\"&gt;true&lt;/prop&gt; &lt;prop key=\"hibernate.connection.characterEncoding\"&gt;UTF-8&lt;/prop&gt; &lt;prop key=\"hibernate.format_sql\"&gt;true&lt;/prop&gt; &lt;prop key=\"hibernate.use_sql_comments\"&gt;true&lt;/prop&gt; &lt;prop key=\"hibernate.hbm2ddl.auto\"&gt;update&lt;/prop&gt; &lt;prop key=\"hibernate.connection.autoReconnect\"&gt;true&lt;/prop&gt; &lt;prop key=\"hibernate.dialect\"&gt;org.hibernate.dialect.MySQL5Dialect&lt;/prop&gt; &lt;prop key=\"connection.autoReconnectForPools\"&gt;true&lt;/prop&gt; &lt;prop key=\"connection.is-connection-validation-required\"&gt;true&lt;/prop&gt; &lt;prop key=\"hibernate.c3p0.validate\"&gt;true&lt;/prop&gt; &lt;prop key=\"hibernate.connection.provider_class\"&gt;org.hibernate.service.jdbc.connections.internal.C3P0ConnectionProvider&lt;/prop&gt; &lt;prop key=\"hibernate.c3p0.min_size\"&gt;5&lt;/prop&gt; &lt;prop key=\"hibernate.c3p0.max_size\"&gt;600&lt;/prop&gt; &lt;prop key=\"hibernate.c3p0.timeout\"&gt;1800&lt;/prop&gt; &lt;prop key=\"hibernate.c3p0.max_statements\"&gt;50&lt;/prop&gt; &lt;prop key=\"hibernate.c3p0.preferredTestQuery\"&gt;SELECT 1;&lt;/prop&gt; &lt;prop key=\"hibernate.c3p0.testConnectionOnCheckout\"&gt;true&lt;/prop&gt; &lt;prop key=\"hibernate.c3p0.idle_test_period\"&gt;3000&lt;/prop&gt; &lt;prop key=\"javax.persistence.validation.mode\"&gt;none&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!-- 事务管理 --&gt; &lt;bean id=\"transactionManager\" class=\"org.springframework.orm.jpa.JpaTransactionManager\"&gt; &lt;property name=\"entityManagerFactory\" ref=\"entityManagerFactory\"/&gt; &lt;/bean&gt; &lt;!-- 开启事务管理注解 --&gt; &lt;tx:annotation-driven transaction-manager=\"transactionManager\"/&gt;&lt;/beans&gt; pom.xml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.zhisheng&lt;/groupId&gt; &lt;artifactId&gt;springmvc&lt;/artifactId&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;name&gt;springmvc Maven Webapp&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;properties&gt; &lt;spring.version&gt;4.2.6.RELEASE&lt;/spring.version&gt; &lt;hibernate.version&gt;5.1.0.Final&lt;/hibernate.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.data&lt;/groupId&gt; &lt;artifactId&gt;spring-data-jpa&lt;/artifactId&gt; &lt;version&gt;1.10.1.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-entitymanager&lt;/artifactId&gt; &lt;version&gt;$&#123;hibernate.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-c3p0&lt;/artifactId&gt; &lt;version&gt;$&#123;hibernate.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.mchange&lt;/groupId&gt; &lt;artifactId&gt;c3p0&lt;/artifactId&gt; &lt;version&gt;0.9.5.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.39&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;finalName&gt;springmvc&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 一开始我是用默认的在resources文件里面生成了persistence.xml配置文件进行数据库配置的，后来由于用那种方法，碰到的问题有很多，自己搞了好几个个小时都没弄好，只好换种方法，没想到竟然还是这种效果（泪崩），看来是不治标也不治本。 无奈，只好硬刚了，碰到错误，百度+google，看了大量的的解决方法，都是没用，慢慢的我所加的jar包越来越多，用maven管理的依赖的也变得多起来了，但终究是不能够解决问题的。 其实这时我看了这么多的博客和解决方法，我已经知道了是 Hibernate JPA 的bug问题，途中自己也换了一些版本，还是没能解决办法。 最后在吃完完晚饭后，又折腾了快三小时，终于找到可靠有用的解决方案了。 运行成功后，我当时就激动起来了。马丹，老子终于将你解决了。 所以在这里立马就将自己这次的血崩历史纪录下来。 下面写下遇到的问题：（其中有些可能还不记得写了） java.lang.ClassNotFoundException: javax.persistence.EntityManager java.lang.NoSuchMethodError: javax.persistence.JoinColumn.foreignKey()Ljavax/persistence/ForeignKey; javax.persistence.PersistenceException: No Persistence provider for EntityManager named defaultPersistenceUnit javax.persistence.PersistenceException: No Persistence provider for EntityManager named defaultPersi java.lang.NoClassDefFoundError: org/hibernate/ejb/HibernatePersistence java.lang.NoClassDefFoundError: org/slf4j/LoggerFactory java.lang.ClassNotFoundException: org.hibernate.MappingException NoSuchMethodError: javax.persistence.xxx 等，还有几个，忘记了。。 首先通过报错信息可以知道有些是因为jar包的问题，但是并不是光是缺少jar包的问题，很大的原 因就是因为jar包的版本不同，刚好那个jar包又是有问题的（自身有bug）。 就比如错误： java.lang.NoSuchMethodError: javax.persistence.JoinColumn.foreignKey()Ljavax/persistence/ForeignKey; 就是因为JAVAEE6.0中的 javax.persistence.jar与 hibernate4.3.8中的hibernate-jpa-2.1-api-1.0.0.Final.jar冲突 JoinColumn.foreignKey() was introduced with JPA 2.1, which was not implemented by Hibernate 4 until version 4.3. If you’re using an older version of Hibernate 4 then try upgrading to 4.3.x. If you’re already using Hibernate 4.3 then make sure you’re also using JPA 2.1 to make sure the API and implementation match up. 图片来自 : http://stackoverflow.com/questions/24588860/error-javax-persistence-joincolumn-foreignkeyljavax-persistence-foreignkey-wi I finally solved this similar problem, there was an old version(hibernate-jpa-2.0-api-1.0.0-Final.jar) in my lib folder which I guess has been preventing maven dependency from loading. So after I manually deleted it and added (hibernate-jpa-2.1-api-1.0.0-Final.jar) everything started to work. 意思大概就是： 因为JAVAEE6.0中的 javax.persistence.jar与 hibernate4.3.8中的hibernate-jpa-2.1-api-1.0.0.Final.jar冲突 ，我们在pom文件下添加依赖后，竟然没发现在 springmvc（项目名称）\\target\\springmvc（项目名称）\\WEB-INF\\lib 下看到 javax.persistence.jar 文件，结果竟然在 springmvc\\lib下找到他了。 解决办法就是在 pom文件和 mvc-dispatcher-servlet.xml 都配置好的情况下，将 springmvc\\lib下的 javax.persistence.jar 删除。 最后再说一句：Though the error drove almost crazy, hold on, you wil get smile ！ Fighting","tags":[{"name":"Bootstrap","slug":"Bootstrap","permalink":"http://yoursite.com/tags/Bootstrap/"},{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"MySQL","slug":"MySQL","permalink":"http://yoursite.com/tags/MySQL/"},{"name":"Spring","slug":"Spring","permalink":"http://yoursite.com/tags/Spring/"},{"name":"Spring MVC","slug":"Spring-MVC","permalink":"http://yoursite.com/tags/Spring-MVC/"},{"name":"Hibernate JPA","slug":"Hibernate-JPA","permalink":"http://yoursite.com/tags/Hibernate-JPA/"}]},{"title":"Spring MVC + Hibernate JPA + Bootstrap 搭建的博客系统 Demo","date":"2017-03-28T10:54:40.743Z","path":"2017/03/28/Spring MVC + Hibernate JPA + Bootstrap 搭建的博客系统/","text":"相关阅读：1、Spring MVC+Hibernate JPA+ Bootstrap 搭建的博客系统项目中所遇到的坑 由于整个系统不是很难，这里就不详细介绍了，我相信看源码的话，应该能够看得懂。 源码地址：https://github.com/zhisheng17/springmvc数据库：springdemo.sql 下面给出下整个系统的截图吧，觉得不错，可以给个 star ，哈哈！后续继续在这个项目中加入新的项目。 截图：首页 用户管理模块 用户列表 添加用户 用户信息详情 更新用户信息 删除用户 博客管理模块 博客列表 博客详情 添加博客 更新博客 删除博客","tags":[{"name":"Bootstrap","slug":"Bootstrap","permalink":"http://yoursite.com/tags/Bootstrap/"},{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"MySQL","slug":"MySQL","permalink":"http://yoursite.com/tags/MySQL/"},{"name":"Spring","slug":"Spring","permalink":"http://yoursite.com/tags/Spring/"},{"name":"Spring MVC","slug":"Spring-MVC","permalink":"http://yoursite.com/tags/Spring-MVC/"},{"name":"Hibernate JPA","slug":"Hibernate-JPA","permalink":"http://yoursite.com/tags/Hibernate-JPA/"}]},{"title":"Java连接Oracle数据库的三种连接方式","date":"2017-03-28T10:54:21.861Z","path":"2017/03/28/Java连接Oracle数据库的三种连接方式/","text":"背景：这两天在学习Oracle数据库，这里就总结下自己上课所学的知识，同时记录下来，方便整理当天所学下的知识，也同时方便日后自己查询。 SQL语句的话，这里我就不多讲了，感觉和其他的数据库（MySQL、SQL Server）都是类似，区别不大。 今天在这里就写下 Java 连接 Oracle 数据库的三种连接方式。 工具： Oracle Database 10g Express Edition cmd命令窗口 IDEA 2016.1.3 ojdbc6_g.jar（数据库驱动包） jdk 1.8 创建数据库表：首先在本地写好创建的数据库表的创建代码后，然后粘贴在cmd命令窗口下，即可创建成功。（前提是进入安装好了oracle，进入了用户，然后在当前用户下创建这个表） 部门表：tb1_dept （含有id name city三个属性） 12345create table tb1_dept( id number(5) primary key, name varchar2(10) not null, city varchar2(10) not null); 插入数据：然后同样写好插入数据的sql语句，这里我就写三条数据。 123insert into tb1_dept(id, name, city) values(1,&apos;java&apos;, &apos;南昌&apos;);insert into tb1_dept(id, name, city) values(2,&apos;c&apos;, &apos;上海&apos;);insert into tb1_dept(id, name, city) values(3,&apos;java&apos;, &apos;南昌&apos;); 好，数据库表已经创建好了，接下来我们需要准备的是数据库驱动包。 这里我用的是 ojdbc6_g.jar 驱动包。 接下来先了解一些基础知识： JDBC的六大步骤：这里我们就按照jdbc的这六大步骤执行下去： 注册驱动 获取连接 获取执行sql语句对象 执行sql语句 处理结果集 关闭资源 URL：统一资源定位器 oracle URL： jdbc:oracle:thin:@localhost:1521:XE jdbc:oracle:thin:@127.0.0.1:1521:XE MySQL URL：jdbc:mysql://localhost:3306/数据库名称 thin：小型驱动，驱动方式 @localhost 本机ip地址 127.0.0.1 XE：数据库的名字 ipconfig：ip地址查询 URI：统一资源标识符 URN：用特定命名空间的名字标识资源 如果你不知道 URL、 URI、URN三者的区别的话，那么你可以参考下面我推荐的一篇文章。 你知道URL、URI和URN三者之间的区别吗？ 三种连接方式代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586package cn.zhisheng.test.jdbc;import oracle.jdbc.driver.OracleDriver;import java.sql.*;import java.util.Properties;/** * Created by 10412 on 2016/12/27. * JDBC的六大步骤 * JAVA连接Oracle的三种方式 */public class JdbcTest&#123; public static void main(String[] args) &#123; Connection connect = null; Statement statement = null; ResultSet resultSet = null; try &#123; //第一步：注册驱动 //第一种方式：类加载(常用) //Class.forName(\"oracle.jdbc.OracleDriver\"); //第二种方式：利用Driver对象 Driver driver = new OracleDriver(); DriverManager.deregisterDriver(driver); //第三种方式:利用系统参数 需在idea中配置program arguments为下面的参数 //-Djdbc.drivers = oracle.jdbc.OracleDriver //第二步：获取连接 //第一种方式：利用DriverManager（常用） //connect = DriverManager.getConnection(\"jdbc:oracle:thin:@localhost:1521:XE\", \"你的oracle数据库用户名\", \"用户名密码\"); //第二种方式：直接使用Driver Properties pro = new Properties(); pro.put(\"user\", \"你的oracle数据库用户名\"); pro.put(\"password\", \"用户名密码\"); connect = driver.connect(\"jdbc:oracle:thin:@localhost:1521:XE\", pro); //测试connect正确与否 System.out.println(connect); //第三步：获取执行sql语句对象 //第一种方式:statement //statement = connect.createStatement(); //第二种方式：PreStatement PreparedStatement preState = connect.prepareStatement(\"select * from tb1_dept where id = ?\"); //第四步：执行sql语句 //第一种方式： //resultSet = statement.executeQuery(\"select * from tb1_dept\"); //第二种方式： preState.setInt(1, 2);//1是指sql语句中第一个？, 2是指第一个？的values值 //resultSet = preState.executeQuery(); //执行查询语句 //查询任何语句，如果有结果集，返回true，没有的话返回false,注意如果是插入一条数据的话，虽然是没有结果集，返回false，但是却能成功的插入一条数据 boolean execute = preState.execute(); System.out.println(execute); //第五步：处理结果集 while (resultSet.next()) &#123; int id = resultSet.getInt(\"id\"); String name = resultSet.getString(\"name\"); String city = resultSet.getString(\"city\"); System.out.println(id+\" \"+name+\" \"+city); //打印输出结果集 &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;finally &#123; //第六步：关闭资源 try &#123; if (resultSet!=null) resultSet.close(); if (statement!=null) statement.close(); if (connect!=null) connect.close(); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 注解：1、 第一步：注册驱动 中的第三种方法 利用系统参数 需在idea中配置program arguments为下面的参数 这里我说一下怎么在IDEA中的配置方式吧 运行截图： OK ! 下篇文章将写 JDBC 的封装。","tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/tags/数据库/"},{"name":"Oracle","slug":"Oracle","permalink":"http://yoursite.com/tags/Oracle/"}]},{"title":"Java读取文件","date":"2017-03-28T10:54:05.735Z","path":"2017/03/28/java读取文件/","text":"以字节为单位读取文件 以字符为单位读取文件 以行为单位读取文件 随机读取文件内容 ReadFromFile.java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263package cn.zhisheng.io;import java.io.*;/** * java读取文件 * Created by 10412 on 2016/12/29. */public class ReadFromFile&#123; /** * 以字节为单位读取文件，常用于读二进制文件，如图片、声音、影像等文件 * @param fileName 文件名 */ public static void readFileByBytes(String fileName) &#123; File file = new File(fileName); InputStream in = null; try &#123; System.out.println(\"以字节为单位读取文件内容，一次读取一个字节\"); //一次读一个字节 in = new FileInputStream(file); int tempbyte; while ((tempbyte = in.read()) != -1) &#123; System.out.println(tempbyte); &#125; in.close(); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); return; &#125; try &#123; System.out.println(\"以字节为单位读取文件内容，一次读取多个字节\"); //一次读取多个字节 byte[] tempbytes = new byte[100]; int byteread = 0; in = new FileInputStream(fileName); ReadFromFile.showAvailableBytes(in); // 读入多个字节到字节数组中，byteread为一次读入的字节数 while ((byteread = in.read(tempbytes)) != -1) &#123; System.out.write(tempbytes, 0, byteread); &#125; &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;finally &#123; if (in != null) &#123; try &#123; in.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; /** * 以字符为单位读取文件，常用于读文本，数字等类型的文件 * @param fileName 文件名 */ public static void readFileByChars(String fileName) &#123; File file = new File(fileName); Reader reader = null; try &#123; System.out.println(\"以字符为单位读取文件内容，一次读一个字符：\"); // 一次读一个字符 reader = new InputStreamReader(new FileInputStream(file)); int tempchar; while ((tempchar = reader.read()) != -1) &#123; // 对于windows下，\\r\\n这两个字符在一起时，表示一个换行。 // 但如果这两个字符分开显示时，会换两次行。 // 因此，屏蔽掉\\r，或者屏蔽\\n。否则，将会多出很多空行。 if (((char)tempchar) != '\\r') &#123; System.out.print((char) tempchar); &#125; &#125; reader.close(); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; try &#123; System.out.println(\"以字符为单位读取文件内容，一次读多个字符：\"); //一次读多个字符 char[] tempchars = new char[30]; int charread = 0; reader = new InputStreamReader(new FileInputStream(fileName)); // 读入多个字符到字符数组中，charread为一次读取字符数 while ((charread = reader.read(tempchars)) != -1) &#123; // 同样屏蔽掉\\r不显示 if ((charread == tempchars.length) &amp;&amp; (tempchars[tempchars.length - 1]) != '\\r') &#123; System.out.print(tempchars); &#125; else &#123; for (int i = 0; i &lt; charread; i++ ) &#123; if (tempchars[i] == '\\r') &#123; continue; &#125; else &#123; System.out.print(tempchars[i]); &#125; &#125; &#125; &#125; &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;finally &#123; if (reader != null) &#123; try &#123; reader.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; /** * 以行为单位读取文件，常用于读面向行的格式化文件 * @param fileName 文件名 */ public static void readFileByLines(String fileName) &#123; File file = new File(fileName); BufferedReader reader =null; try &#123; System.out.println(\"以行为单位读取文件内容，一次读一整行：\"); reader = new BufferedReader(new FileReader(file)); String tempString = null; int line = 1; // 一次读入一行，直到读入null为文件结束 while ((tempString = reader.readLine()) != null) &#123; // 显示行号 System.out.println(\"line \"+line+\": \"+tempString); line++; &#125; &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;finally &#123; if (reader != null) &#123; try &#123; reader.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; /** * 随机读取文件内容 * @param fileName 文件名 */ public static void readFileBRandomAccess(String fileName) &#123; RandomAccessFile randomFile = null; try &#123; System.out.println(\"随机读取一段文件内容：\"); // 打开一个随机访问文件流，按只读方式 randomFile = new RandomAccessFile(fileName, \"r\"); // 文件长度，字节数 long fileLength = randomFile.length(); // 读文件的起始位置 int beginIndex = (fileLength &gt; 4) ? 4 : 0; // 将读文件的开始位置移到beginIndex位置 randomFile.seek(beginIndex); byte[] bytes = new byte[10]; int byteread = 0; // 一次读10个字节，如果文件内容不足10个字节，则读剩下的字节。 // 将一次读取的字节数赋给byteread while ((byteread = randomFile.read(bytes)) != -1) &#123; System.out.write(bytes, 0, byteread); &#125; &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;finally &#123; if (randomFile != null) try &#123; randomFile.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; /** * 显示输入流中剩余的字节数 * @param in */ public static void showAvailableBytes(InputStream in) &#123; try &#123; System.out.println(\"当前字节流输入流中剩余的字节数为:\"+in.available()); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; public static void main(String[] args) &#123; String fileName = \"C:\\\\Users\\\\10412\\\\Desktop\\\\1.txt\"; //文本文件 //String fileName = \"C:\\\\Users\\\\10412\\\\Desktop\\\\sp20161227_204413.png\"; //图片文件 //readFileByBytes(fileName); //readFileByChars(fileName); //readFileByLines(fileName); readFileBRandomAccess(fileName); &#125;&#125; 文件追加内容AppendToFile.java12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576package cn.zhisheng.io;import java.io.FileNotFoundException;import java.io.FileWriter;import java.io.IOException;import java.io.RandomAccessFile;/** * 追加内容到文件尾部 * Created by 10412 on 2016/12/29. */public class AppendToFile&#123; /** * 第一种方法追加文件：使用RandomAccessFile * @param fileName 文件名 * @param content 追加内容 */ public static void appendMethod1(String fileName, String content) &#123; try &#123; // 打开一个随机访问文件流，按读写方式 RandomAccessFile randomFile = new RandomAccessFile(fileName, \"rw\"); // 文件长度，字节数 long fileLength = randomFile.length(); //将写文件指针移到文件尾 randomFile.seek(fileLength); randomFile.writeBytes(content); randomFile.close(); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; /** * 第二种方法追加文件：使用FileWriter * @param fileName 文件名 * @param content 追加内容 */ public static void appendMethod2(String fileName, String content) &#123; try &#123; //打开一个写文件器，构造函数中的第二个参数true表示以追加形式写文件 FileWriter writer = new FileWriter(fileName, true); writer.write(content); writer.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; public static void main(String[] args) &#123; String fileName = \"C:\\\\Users\\\\10412\\\\Desktop\\\\1.txt\"; //文本文件 String content = \"new append!\"; //按方法1追加文件// AppendToFile.appendMethod1(fileName, content);// AppendToFile.appendMethod1(fileName, \"\\new append. 第一种方法\\n\"); //按照方法2追加文件 AppendToFile.appendMethod2(fileName, content); AppendToFile.appendMethod2(fileName, \"\\nnew append. 第二种方法\\n\"); //显示文件内容 ReadFromFile.readFileByLines(fileName); &#125;&#125;","tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"文件","slug":"文件","permalink":"http://yoursite.com/tags/文件/"}]},{"title":"Bootstrap入门需掌握的知识点（二）","date":"2017-03-28T10:53:39.319Z","path":"2017/03/28/Bootstrap入门需掌握的知识点（二）/","text":"相关阅读：Bootstrap入门需掌握的知识点（一）表格基本实例为任意 &lt;table&gt; 标签添加 .table 类可以为其赋予基本的样式 — 少量的内补（padding）和水平方向的分隔线。 123&lt;table class=&quot;table&quot;&gt; ...&lt;/table&gt; 条纹状表格通过 .table-striped 类可以给 &lt;tbody&gt; 之内的每一行增加斑马条纹样式。 123&lt;table class=\"table table-striped\"&gt; ...&lt;/table&gt; 带边框的表格添加 .table-bordered 类为表格和其中的每个单元格增加边框。 123&lt;table class=\"table table-bordered\"&gt; ...&lt;/table&gt; 鼠标悬停通过添加 .table-hover 类可以让 中的每一行对鼠标悬停状态作出响应。 123&lt;table class=\"table table-hover\"&gt; ...&lt;/table&gt; 状态类通过这些状态类可以为行或单元格设置颜色。 Class 描述 .active 鼠标悬停在行或单元格上时所设置的颜色 .success 标识成功或积极的动作 .info 标识普通的提示信息或动作 .warning 标识警告或需要用户注意 .danger 标识危险或潜在的带来负面影响的动作 123456789101112131415&lt;!-- On rows --&gt;&lt;tr class=\"active\"&gt;...&lt;/tr&gt;&lt;tr class=\"success\"&gt;...&lt;/tr&gt;&lt;tr class=\"warning\"&gt;...&lt;/tr&gt;&lt;tr class=\"danger\"&gt;...&lt;/tr&gt;&lt;tr class=\"info\"&gt;...&lt;/tr&gt;&lt;!-- On cells (`td` or `th`) --&gt;&lt;tr&gt; &lt;td class=\"active\"&gt;...&lt;/td&gt; &lt;td class=\"success\"&gt;...&lt;/td&gt; &lt;td class=\"warning\"&gt;...&lt;/td&gt; &lt;td class=\"danger\"&gt;...&lt;/td&gt; &lt;td class=\"info\"&gt;...&lt;/td&gt;&lt;/tr&gt; 响应式表格将任何 .table 元素包裹在 .table-responsive 元素内，即可创建响应式表格，其会在小屏幕设备上（小于768px）水平滚动。当屏幕大于 768px 宽度时，水平滚动条消失。 12345&lt;div class=\"table-responsive\"&gt; &lt;table class=\"table\"&gt; ... &lt;/table&gt;&lt;/div&gt; 表单基本实例单独的表单控件会被自动赋予一些全局样式。所有设置了 .form-control 类的 &lt;input&gt;、&lt;textarea&gt; 和 &lt;select&gt; 元素都将被默认设置宽度属性为 width: 100%;。 将 label 元素和前面提到的控件包裹在 .form-group 中可以获得最好的排列。 123456789101112131415161718192021&lt;form role=\"form\"&gt; &lt;div class=\"form-group\"&gt; &lt;label for=\"exampleInputEmail1\"&gt;Email address&lt;/label&gt; &lt;input type=\"email\" class=\"form-control\" id=\"exampleInputEmail1\" placeholder=\"Enter email\"&gt; &lt;/div&gt; &lt;div class=\"form-group\"&gt; &lt;label for=\"exampleInputPassword1\"&gt;Password&lt;/label&gt; &lt;input type=\"password\" class=\"form-control\" id=\"exampleInputPassword1\" placeholder=\"Password\"&gt; &lt;/div&gt; &lt;div class=\"form-group\"&gt; &lt;label for=\"exampleInputFile\"&gt;File input&lt;/label&gt; &lt;input type=\"file\" id=\"exampleInputFile\"&gt; &lt;p class=\"help-block\"&gt;Example block-level help text here.&lt;/p&gt; &lt;/div&gt; &lt;div class=\"checkbox\"&gt; &lt;label&gt; &lt;input type=\"checkbox\"&gt; Check me out &lt;/label&gt; &lt;/div&gt; &lt;button type=\"submit\" class=\"btn btn-default\"&gt;Submit&lt;/button&gt;&lt;/form&gt; 注意：不要将表单组直接和输入框组混合使用，建议将输入框组嵌套到表单组中使用。 内联表单为 &lt;form&gt; 元素添加 .form-inline 类可使其内容左对齐并且表现为 inline-block 级别的控件。只适用于视口（viewport）至少在 768px 宽度时（视口宽度再小的话就会使表单折叠）。 注意： 需要手动设置宽度在 Bootstrap 中，输入框和单选/多选框控件默认被设置为 width: 100%; 宽度。在内联表单，我们将这些元素的宽度设置为 width: auto;，因此，多个控件可以排列在同一行。根据你的布局需求，可能需要一些额外的定制化组件。 一定要添加 label 标签如果你没有为每个输入控件设置 label 标签，屏幕阅读器将无法正确识别。对于这些内联表单，你可以通过为label 设置 .sr-only 类将其隐藏。 12345678910111213141516171819202122&lt;form class=\"form-inline\" role=\"form\"&gt; &lt;div class=\"form-group\"&gt; &lt;label class=\"sr-only\" for=\"exampleInputEmail2\"&gt;Email address&lt;/label&gt; &lt;input type=\"email\" class=\"form-control\" id=\"exampleInputEmail2\" placeholder=\"Enter email\"&gt; &lt;/div&gt; &lt;div class=\"form-group\"&gt; &lt;div class=\"input-group\"&gt; &lt;div class=\"input-group-addon\"&gt;@&lt;/div&gt; &lt;input class=\"form-control\" type=\"email\" placeholder=\"Enter email\"&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=\"form-group\"&gt; &lt;label class=\"sr-only\" for=\"exampleInputPassword2\"&gt;Password&lt;/label&gt; &lt;input type=\"password\" class=\"form-control\" id=\"exampleInputPassword2\" placeholder=\"Password\"&gt; &lt;/div&gt; &lt;div class=\"checkbox\"&gt; &lt;label&gt; &lt;input type=\"checkbox\"&gt; Remember me &lt;/label&gt; &lt;/div&gt; &lt;button type=\"submit\" class=\"btn btn-default\"&gt;Sign in&lt;/button&gt;&lt;/form&gt; 水平排列的表单通过为表单添加 .form-horizontal 类，并联合使用 Bootstrap 预置的栅格类，可以将 label 标签和控件组水平并排布局。这样做将改变 .form-group 的行为，使其表现为栅格系统中的行（row），因此就无需再额外添加 .row 了。 12345678910111213141516171819202122232425262728&lt;form class=\"form-horizontal\" role=\"form\"&gt; &lt;div class=\"form-group\"&gt; &lt;label for=\"inputEmail3\" class=\"col-sm-2 control-label\"&gt;Email&lt;/label&gt; &lt;div class=\"col-sm-10\"&gt; &lt;input type=\"email\" class=\"form-control\" id=\"inputEmail3\" placeholder=\"Email\"&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=\"form-group\"&gt; &lt;label for=\"inputPassword3\" class=\"col-sm-2 control-label\"&gt;Password&lt;/label&gt; &lt;div class=\"col-sm-10\"&gt; &lt;input type=\"password\" class=\"form-control\" id=\"inputPassword3\" placeholder=\"Password\"&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=\"form-group\"&gt; &lt;div class=\"col-sm-offset-2 col-sm-10\"&gt; &lt;div class=\"checkbox\"&gt; &lt;label&gt; &lt;input type=\"checkbox\"&gt; Remember me &lt;/label&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=\"form-group\"&gt; &lt;div class=\"col-sm-offset-2 col-sm-10\"&gt; &lt;button type=\"submit\" class=\"btn btn-default\"&gt;Sign in&lt;/button&gt; &lt;/div&gt; &lt;/div&gt;&lt;/form&gt; 被支持的控件表单布局实例中展示了其所支持的标准表单控件。 1、输入框包括大部分表单控件、文本输入域控件，还支持所有 HTML5 类型的输入控件：text、password、datetime、datetime-local、date、month、time、week、number、email、url、search、tel 和 color。 1&lt;input type=\"text\" class=\"form-control\" placeholder=\"Text input\"&gt; 如需在文本输入域 &lt;input&gt; 前面或后面添加文本内容或按钮控件，请参考输入控件组。 2、文本域支持多行文本的表单控件。可根据需要改变 rows 属性。 1&lt;textarea class=\"form-control\" rows=\"3\"&gt;&lt;/textarea&gt; 3、多选和单选框多选框（checkbox）用于选择列表中的一个或多个选项，而单选框（radio）用于从多个选项中只选择一个。 设置了 disabled 属性的单选或多选框都能被赋予合适的样式。对于和多选或单选框联合使用的 &lt;label&gt; 标签，如果也希望将悬停于上方的鼠标设置为“禁止点击”的样式，请将 .disabled 类赋予 .radio、.radio-inline、.checkbox 、.checkbox-inline 或 &lt;fieldset&gt;。 12345678910111213141516171819202122232425262728293031&lt;div class=\"checkbox\"&gt; &lt;label&gt; &lt;input type=\"checkbox\" value=\"\"&gt; Option one is this and that&amp;mdash;be sure to include why it's great &lt;/label&gt;&lt;/div&gt;&lt;div class=\"checkbox disabled\"&gt; &lt;label&gt; &lt;input type=\"checkbox\" value=\"\" disabled&gt; Option two is disabled &lt;/label&gt;&lt;/div&gt;&lt;div class=\"radio\"&gt; &lt;label&gt; &lt;input type=\"radio\" name=\"optionsRadios\" id=\"optionsRadios1\" value=\"option1\" checked&gt; Option one is this and that&amp;mdash;be sure to include why it's great &lt;/label&gt;&lt;/div&gt;&lt;div class=\"radio\"&gt; &lt;label&gt; &lt;input type=\"radio\" name=\"optionsRadios\" id=\"optionsRadios2\" value=\"option2\"&gt; Option two can be something else and selecting it will deselect option one &lt;/label&gt;&lt;/div&gt;&lt;div class=\"radio disabled\"&gt; &lt;label&gt; &lt;input type=\"radio\" name=\"optionsRadios\" id=\"optionsRadios3\" value=\"option3\" disabled&gt; Option three is disabled &lt;/label&gt;&lt;/div&gt; 内联单选和多选框通过将 .checkbox-inline 或 .radio-inline 类应用到一系列的多选框（checkbox）或单选框（radio）控件上，可以使这些控件排列在一行。 12345678910111213141516171819&lt;label class=\"checkbox-inline\"&gt; &lt;input type=\"checkbox\" id=\"inlineCheckbox1\" value=\"option1\"&gt; 1&lt;/label&gt;&lt;label class=\"checkbox-inline\"&gt; &lt;input type=\"checkbox\" id=\"inlineCheckbox2\" value=\"option2\"&gt; 2&lt;/label&gt;&lt;label class=\"checkbox-inline\"&gt; &lt;input type=\"checkbox\" id=\"inlineCheckbox3\" value=\"option3\"&gt; 3&lt;/label&gt;&lt;label class=\"radio-inline\"&gt; &lt;input type=\"radio\" name=\"inlineRadioOptions\" id=\"inlineRadio1\" value=\"option1\"&gt; 1&lt;/label&gt;&lt;label class=\"radio-inline\"&gt; &lt;input type=\"radio\" name=\"inlineRadioOptions\" id=\"inlineRadio2\" value=\"option2\"&gt; 2&lt;/label&gt;&lt;label class=\"radio-inline\"&gt; &lt;input type=\"radio\" name=\"inlineRadioOptions\" id=\"inlineRadio3\" value=\"option3\"&gt; 3&lt;/label&gt; 复选框 12345678910&lt;div class=\"checkbox\"&gt; &lt;label&gt; &lt;input type=\"checkbox\" id=\"blankCheckbox\" value=\"option1\"&gt; &lt;/label&gt;&lt;/div&gt;&lt;div class=\"radio\"&gt; &lt;label&gt; &lt;input type=\"radio\" name=\"blankRadio\" id=\"blankRadio1\" value=\"option1\"&gt; &lt;/label&gt;&lt;/div&gt; 下拉列表（select）使用默认选项或添加 multiple 属性可以同时显示多个选项。 123456789101112131415&lt;select class=\"form-control\"&gt; &lt;option&gt;1&lt;/option&gt; &lt;option&gt;2&lt;/option&gt; &lt;option&gt;3&lt;/option&gt; &lt;option&gt;4&lt;/option&gt; &lt;option&gt;5&lt;/option&gt;&lt;/select&gt;&lt;select multiple class=\"form-control\"&gt; &lt;option&gt;1&lt;/option&gt; &lt;option&gt;2&lt;/option&gt; &lt;option&gt;3&lt;/option&gt; &lt;option&gt;4&lt;/option&gt; &lt;option&gt;5&lt;/option&gt;&lt;/select&gt; 静态控件如果需要在表单中将一行纯文本和 label 元素放置于同一行，为 &lt;p&gt; 元素添加 .form-control-static 类即可。 1234567891011121314&lt;form class=\"form-horizontal\" role=\"form\"&gt; &lt;div class=\"form-group\"&gt; &lt;label class=\"col-sm-2 control-label\"&gt;Email&lt;/label&gt; &lt;div class=\"col-sm-10\"&gt; &lt;p class=\"form-control-static\"&gt;email@example.com&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=\"form-group\"&gt; &lt;label for=\"inputPassword\" class=\"col-sm-2 control-label\"&gt;Password&lt;/label&gt; &lt;div class=\"col-sm-10\"&gt; &lt;input type=\"password\" class=\"form-control\" id=\"inputPassword\" placeholder=\"Password\"&gt; &lt;/div&gt; &lt;/div&gt;&lt;/form&gt; 1234567891011&lt;form class=\"form-inline\" role=\"form\"&gt; &lt;div class=\"form-group\"&gt; &lt;label class=\"sr-only\"&gt;Email&lt;/label&gt; &lt;p class=\"form-control-static\"&gt;email@example.com&lt;/p&gt; &lt;/div&gt; &lt;div class=\"form-group\"&gt; &lt;label for=\"inputPassword2\" class=\"sr-only\"&gt;Password&lt;/label&gt; &lt;input type=\"password\" class=\"form-control\" id=\"inputPassword2\" placeholder=\"Password\"&gt; &lt;/div&gt; &lt;button type=\"submit\" class=\"btn btn-default\"&gt;Confirm identity&lt;/button&gt;&lt;/form&gt; 输入框焦点我们将某些表单控件的默认 outline 样式移除，然后对 :focus 状态赋予 box-shadow 属性。 被禁用的输入框为输入框设置 disabled 属性可以防止用户输入，并能对外观做一些修改，使其更直观。 1&lt;input class=\"form-control\" id=\"disabledInput\" type=\"text\" placeholder=\"Disabled input here...\" disabled&gt; 1234567891011121314151617181920&lt;form role=\"form\"&gt; &lt;fieldset disabled&gt; &lt;div class=\"form-group\"&gt; &lt;label for=\"disabledTextInput\"&gt;Disabled input&lt;/label&gt; &lt;input type=\"text\" id=\"disabledTextInput\" class=\"form-control\" placeholder=\"Disabled input\"&gt; &lt;/div&gt; &lt;div class=\"form-group\"&gt; &lt;label for=\"disabledSelect\"&gt;Disabled select menu&lt;/label&gt; &lt;select id=\"disabledSelect\" class=\"form-control\"&gt; &lt;option&gt;Disabled select&lt;/option&gt; &lt;/select&gt; &lt;/div&gt; &lt;div class=\"checkbox\"&gt; &lt;label&gt; &lt;input type=\"checkbox\"&gt; Can't check this &lt;/label&gt; &lt;/div&gt; &lt;button type=\"submit\" class=\"btn btn-primary\"&gt;Submit&lt;/button&gt; &lt;/fieldset&gt;&lt;/form&gt; 只读输入框为输入框设置 readonly 属性可以禁止用户输入，并且输入框的样式也是禁用状态。 1&lt;input class=\"form-control\" type=\"text\" placeholder=\"Readonly input here…\" readonly&gt; 校验状态Bootstrap 对表单控件的校验状态，如 error、warning 和 success 状态，都定义了样式。使用时，添加 .has-warning、.has-error 或 .has-success 类到这些控件的父元素即可。任何包含在此元素之内的 .control-label、.form-control 和 .help-block 元素都将接受这些校验状态的样式。 123456789101112131415161718192021222324252627282930313233343536&lt;div class=\"form-group has-success\"&gt; &lt;label class=\"control-label\" for=\"inputSuccess1\"&gt;Input with success&lt;/label&gt; &lt;input type=\"text\" class=\"form-control\" id=\"inputSuccess1\"&gt;&lt;/div&gt;&lt;div class=\"form-group has-warning\"&gt; &lt;label class=\"control-label\" for=\"inputWarning1\"&gt;Input with warning&lt;/label&gt; &lt;input type=\"text\" class=\"form-control\" id=\"inputWarning1\"&gt;&lt;/div&gt;&lt;div class=\"form-group has-error\"&gt; &lt;label class=\"control-label\" for=\"inputError1\"&gt;Input with error&lt;/label&gt; &lt;input type=\"text\" class=\"form-control\" id=\"inputError1\"&gt;&lt;/div&gt;&lt;div class=\"has-success\"&gt; &lt;div class=\"checkbox\"&gt; &lt;label&gt; &lt;input type=\"checkbox\" id=\"checkboxSuccess\" value=\"option1\"&gt; Checkbox with success &lt;/label&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class=\"has-warning\"&gt; &lt;div class=\"checkbox\"&gt; &lt;label&gt; &lt;input type=\"checkbox\" id=\"checkboxWarning\" value=\"option1\"&gt; Checkbox with warning &lt;/label&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class=\"has-error\"&gt; &lt;div class=\"checkbox\"&gt; &lt;label&gt; &lt;input type=\"checkbox\" id=\"checkboxError\" value=\"option1\"&gt; Checkbox with error &lt;/label&gt; &lt;/div&gt;&lt;/div&gt; 添加额外的图标你还可以针对校验状态为输入框添加额外的图标。只需设置相应的 .has-feedback 类并添加正确的图标即可。 Feedback icons only work with textual &lt;input class=&quot;form-control&quot;&gt; elements. 图标、label 和输入控件组对于不带有 label 标签的输入框以及右侧带有附加组件的输入框组，需要手动为其图标定位。为了让所有用户都能访问你的网站，我们强烈建议为所有输入框添加 label 标签。如果你不希望将 label 标签展示出来，可以通过添加 sr-only 类来实现。如果的确不能添加 label 标签，请调整图标的 top 值。对于输入框组，请根据你的实际情况调整 right 值。 123456789101112131415&lt;div class=\"form-group has-success has-feedback\"&gt; &lt;label class=\"control-label\" for=\"inputSuccess2\"&gt;Input with success&lt;/label&gt; &lt;input type=\"text\" class=\"form-control\" id=\"inputSuccess2\"&gt; &lt;span class=\"glyphicon glyphicon-ok form-control-feedback\"&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=\"form-group has-warning has-feedback\"&gt; &lt;label class=\"control-label\" for=\"inputWarning2\"&gt;Input with warning&lt;/label&gt; &lt;input type=\"text\" class=\"form-control\" id=\"inputWarning2\"&gt; &lt;span class=\"glyphicon glyphicon-warning-sign form-control-feedback\"&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=\"form-group has-error has-feedback\"&gt; &lt;label class=\"control-label\" for=\"inputError2\"&gt;Input with error&lt;/label&gt; &lt;input type=\"text\" class=\"form-control\" id=\"inputError2\"&gt; &lt;span class=\"glyphicon glyphicon-remove form-control-feedback\"&gt;&lt;/span&gt;&lt;/div&gt; 控件尺寸通过 .input-lg 类似的类可以为控件设置高度，通过 .col-lg-* 类似的类可以为控件设置宽度。 高度尺寸创建大一些或小一些的表单控件以匹配按钮尺寸。 1234567&lt;input class=\"form-control input-lg\" type=\"text\" placeholder=\".input-lg\"&gt;&lt;input class=\"form-control\" type=\"text\" placeholder=\"Default input\"&gt;&lt;input class=\"form-control input-sm\" type=\"text\" placeholder=\".input-sm\"&gt;&lt;select class=\"form-control input-lg\"&gt;...&lt;/select&gt;&lt;select class=\"form-control\"&gt;...&lt;/select&gt;&lt;select class=\"form-control input-sm\"&gt;...&lt;/select&gt; 按钮预定义样式使用下面列出的类可以快速创建一个带有预定义样式的按钮。 1234567891011121314151617181920&lt;!-- Standard button --&gt;&lt;button type=\"button\" class=\"btn btn-default\"&gt;Default&lt;/button&gt;&lt;!-- Provides extra visual weight and identifies the primary action in a set of buttons --&gt;&lt;button type=\"button\" class=\"btn btn-primary\"&gt;Primary&lt;/button&gt;&lt;!-- Indicates a successful or positive action --&gt;&lt;button type=\"button\" class=\"btn btn-success\"&gt;Success&lt;/button&gt;&lt;!-- Contextual button for informational alert messages --&gt;&lt;button type=\"button\" class=\"btn btn-info\"&gt;Info&lt;/button&gt;&lt;!-- Indicates caution should be taken with this action --&gt;&lt;button type=\"button\" class=\"btn btn-warning\"&gt;Warning&lt;/button&gt;&lt;!-- Indicates a dangerous or potentially negative action --&gt;&lt;button type=\"button\" class=\"btn btn-danger\"&gt;Danger&lt;/button&gt;&lt;!-- Deemphasize a button by making it look like a link while maintaining button behavior --&gt;&lt;button type=\"button\" class=\"btn btn-link\"&gt;Link&lt;/button&gt; 尺寸需要让按钮具有不同尺寸吗？使用 .btn-lg、.btn-sm 或 .btn-xs 可以获得不同尺寸的按钮。 12345678910111213141516&lt;p&gt; &lt;button type=\"button\" class=\"btn btn-primary btn-lg\"&gt;Large button&lt;/button&gt; &lt;button type=\"button\" class=\"btn btn-default btn-lg\"&gt;Large button&lt;/button&gt;&lt;/p&gt;&lt;p&gt; &lt;button type=\"button\" class=\"btn btn-primary\"&gt;Default button&lt;/button&gt; &lt;button type=\"button\" class=\"btn btn-default\"&gt;Default button&lt;/button&gt;&lt;/p&gt;&lt;p&gt; &lt;button type=\"button\" class=\"btn btn-primary btn-sm\"&gt;Small button&lt;/button&gt; &lt;button type=\"button\" class=\"btn btn-default btn-sm\"&gt;Small button&lt;/button&gt;&lt;/p&gt;&lt;p&gt; &lt;button type=\"button\" class=\"btn btn-primary btn-xs\"&gt;Extra small button&lt;/button&gt; &lt;button type=\"button\" class=\"btn btn-default btn-xs\"&gt;Extra small button&lt;/button&gt;&lt;/p&gt; 通过给按钮添加 .btn-block 类可以将其拉伸至父元素100%的宽度，而且按钮也变为了块级（block）元素。 12&lt;button type=\"button\" class=\"btn btn-primary btn-lg btn-block\"&gt;Block level button&lt;/button&gt;&lt;button type=\"button\" class=\"btn btn-default btn-lg btn-block\"&gt;Block level button&lt;/button&gt; 激活状态当按钮处于激活状态时，其表现为被按压下去（底色更深、边框夜色更深、向内投射阴影）。对于 &lt;button&gt; 元素，是通过 :active 状态实现的。对于 &lt;a&gt;元素，是通过 .active 类实现的。然而，你还可以将 .active 应用到 &lt;button&gt;上，并通过编程的方式使其处于激活状态。 button 元素由于 :active 是伪状态，因此无需额外添加，但是在需要让其表现出同样外观的时候可以添加 .active 类。 12&lt;button type=\"button\" class=\"btn btn-primary btn-lg active\"&gt;Primary button&lt;/button&gt;&lt;button type=\"button\" class=\"btn btn-default btn-lg active\"&gt;Button&lt;/button&gt; 链接（&lt;a&gt;）元素可以为基于 &lt;a&gt;元素创建的按钮添加 .active 类。 12&lt;a href=\"#\" class=\"btn btn-primary btn-lg active\" role=\"button\"&gt;Primary link&lt;/a&gt;&lt;a href=\"#\" class=\"btn btn-default btn-lg active\" role=\"button\"&gt;Link&lt;/a&gt; 按钮类为 &lt;a&gt;、&lt;button&gt; 或 &lt;input&gt; 元素应用按钮类 1234&lt;a class=\"btn btn-default\" href=\"#\" role=\"button\"&gt;Link&lt;/a&gt;&lt;button class=\"btn btn-default\" type=\"submit\"&gt;Button&lt;/button&gt;&lt;input class=\"btn btn-default\" type=\"button\" value=\"Input\"&gt;&lt;input class=\"btn btn-default\" type=\"submit\" value=\"Submit\"&gt; 图片响应式图片在 Bootstrap 版本 3 中，通过为图片添加 .img-responsive 类可以让图片支持响应式布局。其实质是为图片设置了 max-width: 100%; 和 height: auto; 属性，从而让图片在其父元素中更好的缩放。 1&lt;img src=\"...\" class=\"img-responsive\" alt=\"Responsive image\"&gt; 图片形状通过为 &lt;img&gt; 元素添加以下相应的类，可以让图片呈现不同的形状。 123&lt;img src=&quot;...&quot; alt=&quot;...&quot; class=&quot;img-rounded&quot;&gt;&lt;img src=&quot;...&quot; alt=&quot;...&quot; class=&quot;img-circle&quot;&gt;&lt;img src=&quot;...&quot; alt=&quot;...&quot; class=&quot;img-thumbnail&quot;&gt;","tags":[{"name":"前端","slug":"前端","permalink":"http://yoursite.com/tags/前端/"},{"name":"Bootstrap","slug":"Bootstrap","permalink":"http://yoursite.com/tags/Bootstrap/"}]},{"title":"Bootstrap入门需掌握的知识点（一）","date":"2017-03-28T10:53:23.615Z","path":"2017/03/28/Bootstrap入门需掌握的知识点（一）/","text":"BootstrapBootstrap中文网：http://www.bootcss.com/ 1.什么是 Bootstrap？ 官方介绍：简洁、直观、强悍的前端开发框架，让web开发更迅速、简单。 Bootstrap 下载 Bootstrap3下载地址：http://v3.bootcss.com/getting-started/#download Bootstrap 文件目录结构 1234567891011121314151617dist -css -bootstrap.css -bootstrap.css.map -bootstrap.min.css（常用） -bootstrap-theme.css -bootstrap-theme.css.map -bootstrap-theme.min.css -fonts -glyphicons-halflings-regular.eot -glyphicons-halflings-regular.svg -glyphicons-halflings-regular.ttf -glyphicons-halflings-regular.woff -js -bootstrap.js -bootstrap.min.js（常用） -npm.js Bootstrap 依赖 要想使用 Bootstrap ，那么必须先引入 jQuery（jquery.min.js）文件。 5.使用 Bootstrap 压缩版本适于实际应用，未压缩版本适于开发调试过程 直接引用官网下载下来的文件。 使用 Bootstrap 中文网提供的免费 CDN 服务。 1234567891011&lt;!-- 新 Bootstrap 核心 CSS 文件 --&gt;&lt;link rel=\"stylesheet\" href=\"http://cdn.bootcss.com/bootstrap/3.3.0/css/bootstrap.min.css\"&gt;&lt;!-- 可选的Bootstrap主题文件（一般不用引入） --&gt;&lt;link rel=\"stylesheet\" href=\"http://cdn.bootcss.com/bootstrap/3.3.0/css/bootstrap-theme.min.css\"&gt;&lt;!-- jQuery文件。务必在bootstrap.min.js 之前引入 --&gt;&lt;script src=\"http://cdn.bootcss.com/jquery/1.11.1/jquery.min.js\"&gt;&lt;/script&gt;&lt;!-- 最新的 Bootstrap 核心 JavaScript 文件 --&gt;&lt;script src=\"http://cdn.bootcss.com/bootstrap/3.3.0/js/bootstrap.min.js\"&gt;&lt;/script&gt; Bootstrap 基本模板 123456789101112131415161718192021222324252627&lt;!DOCTYPE html&gt;&lt;html lang=\"zh-cn\"&gt; &lt;head&gt; &lt;meta charset=\"utf-8\"&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"&gt; &lt;title&gt;Bootstrap 基本模板&lt;/title&gt; &lt;!-- Bootstrap --&gt; &lt;link href=\"css/bootstrap.min.css\" rel=\"stylesheet\"&gt; &lt;!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries --&gt; &lt;!-- WARNING: Respond.js doesn't work if you view the page via file:// --&gt; &lt;!--[if lt IE 9]&gt; &lt;script src=\"http://cdn.bootcss.com/html5shiv/3.7.2/html5shiv.min.js\"&gt;&lt;/script&gt; &lt;script src=\"http://cdn.bootcss.com/respond.js/1.4.2/respond.min.js\"&gt;&lt;/script&gt; &lt;![endif]--&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;你好，世界！&lt;/h1&gt; &lt;!-- jQuery (necessary for Bootstrap's JavaScript plugins) --&gt; &lt;script src=\"http://cdn.bootcss.com/jquery/1.11.1/jquery.min.js\"&gt;&lt;/script&gt; &lt;!-- Include all compiled plugins (below), or include individual files as needed --&gt; &lt;script src=\"js/bootstrap.min.js\"&gt;&lt;/script&gt; &lt;/body&gt;&lt;/html&gt; Bootstrap 实例精选：http://v3.bootcss.com/getting-started/#examples 全局 CSS 样式HTML5 文档类型Bootstrap 使用到的某些 HTML 元素和 CSS 属性需要将页面设置为 HTML5 文档类型。 1234&lt;!DOCTYPE html&gt;&lt;html lang=\"zh-CN\"&gt; ...&lt;/html&gt; 移动设备优先在 bootstrap3 中移动设备优先考虑的。为了保证适当的绘制和触屏缩放，需要在&lt;head&gt;之中添加 viewport 元数据标签。 1&lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"&gt; 在移动设备浏览器上，可以通过视口 viewport 设置meta属性为user-scalable=no可以禁用其缩放（zooming）功能，这样后用户只能滚动屏幕。（看情况而定） 1&lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1, maximum-scala=1, user-scalable=no\"&gt; 排版与链接Bootstrap 排版、链接样式设置了基本的全局样式。分别是： 为 body 元素设置 background-color: #fff; 使用 @font-family-base、@font-size-base 和 @line-height-base a变量作为排版的基本参数 为所有链接设置了基本颜色 @link-color ，并且当链接处于 :hover 状态时才添加下划线 这些样式都能在 scaffolding.less 文件中找到对应的源码。 Normalize.css为了增强跨浏览器表现的一致性，bootstrap使用了 Normalize.css，这是由 Nicolas Gallagher 和 Jonathan Neal 维护的一个CSS 重置样式库。 布局容器Bootstrap 需要为页面内容和栅格系统包裹一个 .container 容器。Bootstrap提供了两个作此用处的类。注意，由于 padding等属性的原因，这两种容器类不能互相嵌套。 .container 类用于固定宽度并支持响应式布局的容器。 123&lt;div class=\"container\"&gt; ...&lt;/div&gt; .container-fluid 类用于 100% 宽度，占据全部视口（viewport）的容器。 123&lt;div class=\"container-fluid\"&gt; ...&lt;/div&gt; 栅格系统Bootstrap 提供了一套响应式、移动设备优先的流式栅格系统，随着屏幕或视口（viewport）尺寸的增加，系统会自动分为最多12列。它包含了易于使用的预定义类，还有强大的mixin 用于生成更具语义的布局。 简介栅格系统用于通过一系列的行（row）与列（column）的组合来创建页面布局，你的内容就可以放入这些创建好的布局中。下面就介绍一下 Bootstrap 栅格系统的工作原理： “行（row）”必须包含在 .container （固定宽度）或 .container-fluid （100% 宽度）中，以便为其赋予合适的排列（aligment）和内补（padding）。 通过“行（row）”在水平方向创建一组“列（column）”。 你的内容应当放置于“列（column）”内，并且，只有“列（column）”可以作为行（row）”的直接子元素。 类似 .row 和 .col-xs-4 这种预定义的类，可以用来快速创建栅格布局。Bootstrap 源码中定义的 mixin 也可以用来创建语义化的布局。 通过为“列（column）”设置 padding 属性，从而创建列与列之间的间隔（gutter）。通过为 .row 元素设置负值margin 从而抵消掉为 .container 元素设置的 padding，也就间接为“行（row）”所包含的“列（column）”抵消掉了padding。 The negative margin is why the examples below are outdented. It’s so that content within grid columns is lined up with non-grid content. Grid columns are created by specifying the number of twelve available columns you wish to span. For example, three equal columns would use three .col-xs-4. 如果一“行（row）”中包含了的“列（column）”大于 12，多余的“列（column）”所在的元素将被作为一个整体另起一行排列。 Grid classes apply to devices with screen widths greater than or equal to the breakpoint sizes, and override grid classes targeted at smaller devices. Therefore, applying any .col-md- class to an element will not only affect its styling on medium devices but also on large devices if a .col-lg- class is not present. 通过研究后面的实例，可以将这些原理应用到你的代码中。 媒体查询在栅格系统中，我们在 Less 文件中使用以下媒体查询（media query）来创建关键的分界点阈值。 1234567891011/* 超小屏幕（手机，小于 768px） *//* 没有任何媒体查询相关的代码，因为这在 Bootstrap 中是默认的（还记得 Bootstrap 是移动设备优先的吗？） *//* 小屏幕（平板，大于等于 768px） */@media (min-width: @screen-sm-min) &#123; ... &#125;/* 中等屏幕（桌面显示器，大于等于 992px） */@media (min-width: @screen-md-min) &#123; ... &#125;/* 大屏幕（大桌面显示器，大于等于 1200px） */@media (min-width: @screen-lg-min) &#123; ... &#125; 偶尔也会在媒体查询代码中包含 max-width 从而将 CSS 的影响限制在更小范围的屏幕大小之内 1234@media (max-width: @screen-xs-max) &#123; ... &#125;@media (min-width: @screen-sm-min) and (max-width: @screen-sm-max) &#123; ... &#125;@media (min-width: @screen-md-min) and (max-width: @screen-md-max) &#123; ... &#125;@media (min-width: @screen-lg-min) &#123; ... &#125; 栅格参数通过下表可以详细查看 Bootstrap 的栅格系统是如何在多种屏幕设备上工作的。 超小屏幕 手机 (&lt;768px) 小屏幕 平板 (≥768px) 中等屏幕 桌面显示器 (≥992px) 大屏幕 大桌面显示器 (≥1200px) 栅格系统行为 总是水平排列 开始是堆叠在一起的，当大于这些阈值时将变为水平排列C 同左 同左 .container 最大宽度 None （自动） 750px 970px 1170px 类前缀 .col-xs- .col-sm- .col-md- .col-lg- 列（column）数 12 12 12 12 最大列（column）宽 自动 ~62px ~81px ~97px 槽（gutter）宽 30px （每列左右均有 15px） 同左 同左 同左 可嵌套 是 是 是 是 偏移（Offsets） 是 是 是 是 列排序 是 是 是 是 实例：从堆叠到水平排列使用单一的一组 .col-md-* 栅格类，就可以创建一个基本的栅格系统，在手机和平板设备上一开始是堆叠在一起的（超小屏幕到小屏幕这一范围），在桌面（中等）屏幕设备上变为水平排列。所有“列（column）必须放在 ” .row 内。 123456789101112131415161718192021222324252627&lt;div class=\"row\"&gt; &lt;div class=\"col-md-1\"&gt;.col-md-1&lt;/div&gt; &lt;div class=\"col-md-1\"&gt;.col-md-1&lt;/div&gt; &lt;div class=\"col-md-1\"&gt;.col-md-1&lt;/div&gt; &lt;div class=\"col-md-1\"&gt;.col-md-1&lt;/div&gt; &lt;div class=\"col-md-1\"&gt;.col-md-1&lt;/div&gt; &lt;div class=\"col-md-1\"&gt;.col-md-1&lt;/div&gt; &lt;div class=\"col-md-1\"&gt;.col-md-1&lt;/div&gt; &lt;div class=\"col-md-1\"&gt;.col-md-1&lt;/div&gt; &lt;div class=\"col-md-1\"&gt;.col-md-1&lt;/div&gt; &lt;div class=\"col-md-1\"&gt;.col-md-1&lt;/div&gt; &lt;div class=\"col-md-1\"&gt;.col-md-1&lt;/div&gt; &lt;div class=\"col-md-1\"&gt;.col-md-1&lt;/div&gt;&lt;/div&gt;&lt;div class=\"row\"&gt; &lt;div class=\"col-md-8\"&gt;.col-md-8&lt;/div&gt; &lt;div class=\"col-md-4\"&gt;.col-md-4&lt;/div&gt;&lt;/div&gt;&lt;div class=\"row\"&gt; &lt;div class=\"col-md-4\"&gt;.col-md-4&lt;/div&gt; &lt;div class=\"col-md-4\"&gt;.col-md-4&lt;/div&gt; &lt;div class=\"col-md-4\"&gt;.col-md-4&lt;/div&gt;&lt;/div&gt;&lt;div class=\"row\"&gt; &lt;div class=\"col-md-6\"&gt;.col-md-6&lt;/div&gt; &lt;div class=\"col-md-6\"&gt;.col-md-6&lt;/div&gt;&lt;/div&gt; 实例：移动设备和桌面屏幕是否不希望在小屏幕设备上所有列都堆叠在一起？那就使用针对超小屏幕和中等屏幕设备所定义的类吧，即 .col-xs-*和 .col-md-*。请看下面的实例，研究一下这些是如何工作的。 123456789101112131415161718&lt;!-- Stack the columns on mobile by making one full-width and the other half-width --&gt;&lt;div class=\"row\"&gt; &lt;div class=\"col-xs-12 col-md-8\"&gt;.col-xs-12 .col-md-8&lt;/div&gt; &lt;div class=\"col-xs-6 col-md-4\"&gt;.col-xs-6 .col-md-4&lt;/div&gt;&lt;/div&gt;&lt;!-- Columns start at 50% wide on mobile and bump up to 33.3% wide on desktop --&gt;&lt;div class=\"row\"&gt; &lt;div class=\"col-xs-6 col-md-4\"&gt;.col-xs-6 .col-md-4&lt;/div&gt; &lt;div class=\"col-xs-6 col-md-4\"&gt;.col-xs-6 .col-md-4&lt;/div&gt; &lt;div class=\"col-xs-6 col-md-4\"&gt;.col-xs-6 .col-md-4&lt;/div&gt;&lt;/div&gt;&lt;!-- Columns are always 50% wide, on mobile and desktop --&gt;&lt;div class=\"row\"&gt; &lt;div class=\"col-xs-6\"&gt;.col-xs-6&lt;/div&gt; &lt;div class=\"col-xs-6\"&gt;.col-xs-6&lt;/div&gt;&lt;/div&gt; 排版标题HTML 中的所有标题标签，到 均可使用。另外，还提供了 .h1 到 .h6 类，为的是给内联（inline）属性的文本赋予标题的样式 123456&lt;h1&gt;h1. Bootstrap heading&lt;/h1&gt;&lt;h2&gt;h2. Bootstrap heading&lt;/h2&gt;&lt;h3&gt;h3. Bootstrap heading&lt;/h3&gt;&lt;h4&gt;h4. Bootstrap heading&lt;/h4&gt;&lt;h5&gt;h5. Bootstrap heading&lt;/h5&gt;&lt;h6&gt;h6. Bootstrap heading&lt;/h6&gt; 在标题内还可以包含 &lt;small&gt; 标签或赋予 .small 类的元素，可以用来标记副标题。 123456&lt;h1&gt;h1. Bootstrap heading &lt;small&gt;Secondary text&lt;/small&gt;&lt;/h1&gt;&lt;h2&gt;h2. Bootstrap heading &lt;small&gt;Secondary text&lt;/small&gt;&lt;/h2&gt;&lt;h3&gt;h3. Bootstrap heading &lt;small&gt;Secondary text&lt;/small&gt;&lt;/h3&gt;&lt;h4&gt;h4. Bootstrap heading &lt;small&gt;Secondary text&lt;/small&gt;&lt;/h4&gt;&lt;h5&gt;h5. Bootstrap heading &lt;small&gt;Secondary text&lt;/small&gt;&lt;/h5&gt;&lt;h6&gt;h6. Bootstrap heading &lt;small&gt;Secondary text&lt;/small&gt;&lt;/h6&gt; 页面主体Bootstrap 将全局 font-size 设置为 14px，line-height 设置为 1.428。这些属性直接赋予 元素和所有段落元素。另外， （段落）元素还被设置了等于 1/2 行高（即 10px）的底部外边距（margin）。 中心内容通过添加 .lead 类可以让段落突出显示。 1&lt;p class=\"lead\"&gt;...&lt;/p&gt; 使用 Less 工具构建variables.less 文件中定义的两个 Less 变量决定了排版尺寸：@font-size-base 和 @line-height-base。第一个变量定义了全局 font-size 基准，第二个变量是 line-height 基准。我们使用这些变量和一些简单的公式计算出其它所有页面元素的 margin、 padding 和 line-height。自定义这些变量即可改变 Bootstrap 的默认样式 内联文本元素标记文本为了高亮文本，可以使用 &lt;mark&gt; 标签 1You can use the mark tag to &lt;mark&gt;highlight&lt;/mark&gt; text. 被删除的文本对于被删除的文本，可以使用 &lt;del&gt; 标签。 1&lt;del&gt;This line of text is meant to be treated as deleted text.&lt;/del&gt; 无用文本对于无用文本可以使用 &lt;s&gt; 标签。 1&lt;s&gt;This line of text is meant to be treated as no longer accurate.&lt;/s&gt; 插入文本而外插入文本使用 &lt;ins&gt; 标签 1&lt;ins&gt;This line of text is meant to be treated as an addition to the document.&lt;/ins&gt; 带下划线的文本为文本添加下划线，使用 &lt;u&gt; 标签。 1&lt;u&gt;This line of text will render as underlined&lt;/u&gt; 小号文本使用标签 &lt;small&gt; 着重强调使用标签 &lt;strong&gt; 标签 斜体使用 &lt;em&gt; 标签 文本对齐 12345&lt;p class=\"text-left\"&gt;Left aligned text.&lt;/p&gt;&lt;p class=\"text-center\"&gt;Center aligned text.&lt;/p&gt;&lt;p class=\"text-right\"&gt;Right aligned text.&lt;/p&gt;&lt;p class=\"text-justify\"&gt;Justified text.&lt;/p&gt;&lt;p class=\"text-nowrap\"&gt;No wrap text.&lt;/p&gt; 改变大小写 123&lt;p class=\"text-lowercase\"&gt;Lowercased text.&lt;/p&gt;&lt;p class=\"text-uppercase\"&gt;Uppercased text.&lt;/p&gt;&lt;p class=\"text-capitalize\"&gt;Capitalized text.&lt;/p&gt; 引用在你的文档中引用其他的来源，可以使用 &lt;blockquote&gt; 来表示引用样式。对于直接引用，建议使用 &lt;p&gt; 标签。 123&lt;blockquote&gt; &lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Integer posuere erat a ante.&lt;/p&gt;&lt;/blockquote&gt; 列表无序列表排列顺序无关紧要的一列元素。 123&lt;ul&gt; &lt;li&gt;...&lt;/li&gt;&lt;/ul&gt; 有序列表顺序至关重要的一组元素 123&lt;ol&gt; &lt;li&gt;...&lt;/li&gt;&lt;/ol&gt; 代码内联代码1For example, &lt;code&gt;&amp;lt;section&amp;gt;&lt;/code&gt; should be wrapped as inline. 用户输入通过 kbd 标签标记用户通过键盘输入的内容。 12To switch directories, type &lt;kbd&gt;cd&lt;/kbd&gt; followed by the name of the directory.&lt;br&gt;To edit settings, press &lt;kbd&gt;&lt;kbd&gt;ctrl&lt;/kbd&gt; + &lt;kbd&gt;,&lt;/kbd&gt;&lt;/kbd&gt; 代码块多行代码可以使用 &lt;pre&gt; 标签。为了正确的展示代码，注意将尖括号做转义处理。 变量通过 &lt;var&gt; 标签标记变量 程序输出通过 &lt;samp&gt; 标签来标记程序输出的内容 期待后面的文章！","tags":[{"name":"前端","slug":"前端","permalink":"http://yoursite.com/tags/前端/"},{"name":"Bootstrap","slug":"Bootstrap","permalink":"http://yoursite.com/tags/Bootstrap/"}]},{"title":"字符串","date":"2017-03-28T10:51:42.735Z","path":"2017/03/28/【字符串】字符串逆序/","text":"题目一：如果一个字符串 str ，把字符串 str 前面的任意部分挪到后面去形成的字符串叫做 str 的旋转词。比如 str = “ 1234 ” ， 那么 str 的旋转词有 “ 1234 ” ， “ 2341 ” ， “ 3412 ” ， “ 4123 ” 。给定两个字符串 a 和 b ，请判断 a 和 b 是否互为旋转词？举例： a = “ cdab “ , b = “ abcd “ 。返回 true。 a = “ 1ab2 “ , b = “ ab12 “ 。返回 false。 a = “ 2ab1 “ , b= “ ab12 “ 。 返回 true。 思路：最优解时间复杂度为 O(N) 先判断字符串 a 和 b 是否长度相等。 如果长度相等，生成 a + a 的大字符串。 然后判断大字符串中是否包含 b 字符串。（使用 kmp 算法判断）如果大字符串中包含字符串 b ，那么字符串 a 和 b 就互为旋转词。 举例： a = “ 1234 “ a + a = “ 12341234 “ 很明显发现，如果字符串 a 的长度为 N，在 a + a 的大字符串中，任意一个长度为 N 的子串都是 a 的旋转词。 题目二：给定一个字符串 a， 请在单词间做逆序调整。 举例： “ pig loves dog “ 逆序成 “ dog loves pig “ 。 “ I’m a student. “ 逆序成 “ student. a I’m “ 思路： 实现将字符串局部所有字符逆序的函数 f 利用 f 将字符串所有字符逆序 找到逆序后的字符串中每一个单词的区域，利用 f 将每一个单词的区域逆序 题目三：给定一个字符串 a 和一个整数 i。N为字符串的长度，i 为 a 中的位置，将 a [ 0 … i ] 移到右侧，a [ i + 1 … N - 1 ]移到左侧。 举例： a = “ ABCDE “ ，i = 2 。将 str 调整为 “ DEABC “ 。 要求：时间复杂度为 O(N)，额外空间复杂度为 O(1)。 思路： 先将 a[ 0 … i ] 部分的字符逆序 再将 a[ i + 1 … N - 1 ] 部分的字符逆序 最后将整体的字符 a 逆序 题目四：给定一个字符串类型的数组 strs，请找到一种拼接顺序，使得将所有的字符串拼接起来组成的大字符串是所有可能性中字典顺序最小的，并返回这个字符串。 举例： strs = [ “ abc “ , “ de “ ]，可以拼接成 “ abcde “，也可以拼接成 “ deabc “，但是前者的字典顺序更小，所以返回 “ abcde “ 。 strs = [ “ b “, “ ba “ ], 可以拼接成 “ bba “, 也可以拼接成 “ bab “,但是后者的字典顺序更小，所以返回 “ bab “。 思路：最优解的时间复杂度O(N*logN)，其实质是一种排序的实现。 方案二中是比较两个字符串彼此拼接后的字典顺序，所以能成功。","tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://yoursite.com/tags/数据结构/"},{"name":"算法","slug":"算法","permalink":"http://yoursite.com/tags/算法/"},{"name":"字符串","slug":"字符串","permalink":"http://yoursite.com/tags/字符串/"}]},{"title":"【字符串】判断两字符串是否互为旋转词？","date":"2017-03-28T10:49:25.536Z","path":"2017/03/28/【字符串】判断两字符串是否互为旋转词？/","text":"相关阅读：字符串逆序问题的解决方法题目： 如果对于一个字符串A，将A的前面任意一部分挪到后边去形成的字符串称为A的旋转词。 比如A=”12345”,A的旋转词有”12345”,”23451”,”34512”,”45123”和”51234”。 对于两个字符串A和B，请判断A和B是否互为旋转词。 给定两个字符串A和B及他们的长度lena，lenb，请返回一个bool值，代表他们是否互为旋转词。 测试样例： “cdab”,4,”abcd”,4 返回：true 通过代码： 1234567891011121314import java.util.*;public class Rotation&#123; public static boolean chkRotation(String A, int lena, String B, int lenb) &#123; // write code here if (lena != lenb)&#123; return false; &#125;else &#123; String str = A + A; return str.contains(B); &#125; &#125;&#125; 也可以使用 indexOf。 其区别是： contains 是找指定字符串是否包含一个字符串，返回值的 boolean 类型，即只有 true 和 false indexOf 有多个重载，但无论哪个，都是做一定的匹配，然后把匹配的第一个字符的位置返回，返回的是 int 类型，如果没找到，那么返回 -1 稍微再深究一下的我看了下 contains 的源码，结果发现他调用的是 indexOf 方法。 源码如下： 1234567891011/** * Returns true if and only if this string contains the specified * sequence of char values. * * @param s the sequence to search for * @return true if this string contains &#123;@code s&#125;, false otherwise * @since 1.5 */ public boolean contains(CharSequence s) &#123; return indexOf(s.toString()) &gt; -1; &#125; 意思就是如上面的区别所说的，他只有两个返回值 true 和 false。 于是我们继续看一下 indexOf 方法的源码： 1234567891011121314151617/** * Returns the index within this string of the first occurrence of the * specified substring. * * &lt;p&gt;The returned index is the smallest value &lt;i&gt;k&lt;/i&gt; for which: * &lt;blockquote&gt;&lt;pre&gt; * this.startsWith(str, &lt;i&gt;k&lt;/i&gt;) * &lt;/pre&gt;&lt;/blockquote&gt; * If no such value of &lt;i&gt;k&lt;/i&gt; exists, then &#123;@code -1&#125; is returned. * * @param str the substring to search for. * @return the index of the first occurrence of the specified substring, * or &#123;@code -1&#125; if there is no such occurrence. public int indexOf(String str) &#123; return indexOf(str, 0); &#125; 继续可以发现他又调用了 indexOf 的两个参数方法，只不过索引是 0 。 然后我继续看带有两个参数的 indexOf 方法源码如下： 123456789101112131415161718192021/** * Returns the index within this string of the first occurrence of the * specified substring, starting at the specified index. * * &lt;p&gt;The returned index is the smallest value &lt;i&gt;k&lt;/i&gt; for which: * &lt;blockquote&gt;&lt;pre&gt; * &lt;i&gt;k&lt;/i&gt; &amp;gt;= fromIndex &#123;@code &amp;&amp;&#125; this.startsWith(str, &lt;i&gt;k&lt;/i&gt;) * &lt;/pre&gt;&lt;/blockquote&gt; * If no such value of &lt;i&gt;k&lt;/i&gt; exists, then &#123;@code -1&#125; is returned. * * @param str the substring to search for. * @param fromIndex the index from which to start the search. * @return the index of the first occurrence of the specified substring, * starting at the specified index, * or &#123;@code -1&#125; if there is no such occurrence. */ public int indexOf(String str, int fromIndex) &#123; return indexOf(value, 0, value.length, str.value, 0, str.value.length, fromIndex); &#125; 哈哈，发现他又调用了 indexOf 的方法，这次终于我们可以看到最后的 查找算法 如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * Code shared by String and StringBuffer to do searches. The * source is the character array being searched, and the target * is the string being searched for. * * @param source the characters being searched. * @param sourceOffset offset of the source string. * @param sourceCount count of the source string. * @param target the characters being searched for. * @param targetOffset offset of the target string. * @param targetCount count of the target string. * @param fromIndex the index to begin searching from. */static int indexOf(char[] source, int sourceOffset, int sourceCount, char[] target, int targetOffset, int targetCount, int fromIndex) &#123; if (fromIndex &gt;= sourceCount) &#123; return (targetCount == 0 ? sourceCount : -1); &#125; if (fromIndex &lt; 0) &#123; fromIndex = 0; &#125; if (targetCount == 0) &#123; return fromIndex; &#125; char first = target[targetOffset]; int max = sourceOffset + (sourceCount - targetCount); for (int i = sourceOffset + fromIndex; i &lt;= max; i++) &#123; /* Look for first character. */ if (source[i] != first) &#123; while (++i &lt;= max &amp;&amp; source[i] != first); &#125; /* Found first character, now look at the rest of v2 */ if (i &lt;= max) &#123; int j = i + 1; int end = j + targetCount - 1; for (int k = targetOffset + 1; j &lt; end &amp;&amp; source[j] == target[k]; j++, k++); if (j == end) &#123; /* Found whole string. */ return i - sourceOffset; &#125; &#125; &#125; return -1;&#125; 总结：遇到这种问题多查看源码，想深入就得从底层做起！","tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://yoursite.com/tags/数据结构/"},{"name":"算法","slug":"算法","permalink":"http://yoursite.com/tags/算法/"},{"name":"字符串","slug":"字符串","permalink":"http://yoursite.com/tags/字符串/"},{"name":"旋转词","slug":"旋转词","permalink":"http://yoursite.com/tags/旋转词/"}]},{"title":"程序访问文件的几种方式","date":"2017-03-28T10:47:04.592Z","path":"2017/03/28/程序访问文件的几种方式/","text":"IO程序访问文件的几种方式 读取和写入文件 I/O 操作都调用操作系统提供的接口。因为磁盘设备是由操作系统管理的，应用程序要访问物理设备只能通过系统调用的方式来工作。读和写分别对应 read() 和 write() 两个系统调用。而只要是系统调用就可能存在内核空间地址和用户空间地址切换的问题，这也是为什么操作系统为了保护系统本身的运行安全而将内核程序运行使用的内存空间和用户程序运行的内存空间进行隔离造成的。虽然这样可以保证内核程序运行的安全性，但是也存在数据可能需要从内核空间向用户空间复制的问题。 如果遇到非常耗时的操作，如磁盘 I/O， 数据从磁盘复制到内核空间，然后又从内核空间复制到用户空间，将会非常缓慢。这时操作系统为了加速 I/O 访问，在内核空间使用缓存机制，也就是将从磁盘读取的文件按照一定的组织方式进行缓存，如果用户程序访问的是同一段磁盘地址的空间数据，那么操作系统将从内核缓存中直接取出返回给用户程序，这样就可以减小 I/O 的响应时间。 1. 标准访问文件的方式标准访问文件的方式就是当应用程序调用 read() 接口时，操作系统检查在内核的高速缓存中有没有需要的数据，如果已经缓存了，那么就直接从缓存中返回，如果没有，则从磁盘中读取，然后缓存在操作系统的缓存中。 写入的方式是，用户的应用程序调用 write() 接口将数据从用户地址空间复制到内核地址空间的缓存中。这时对用户程序来说写操作就已经完成了，至于什么时候再写到磁盘中由操作系统决定，除非显示地调用 sync 同步命令。 标准访问文件的方式如下图所示： 2. 直接 I/O 的方式直接 I/O 方式就是应用程序直接访问磁盘数据，而不经过操作系统内核数据缓冲区，这样做的目的就是减少一次从内核缓冲区到用户程序缓存的数据复制。此种方式通常是在对数据的缓存管理由应用程序实现的数据库管理系统中。如在数据库管理系统中，系统明确的知道应该缓存哪些数据，应该失效哪些数据，还可以对一些热点的数据进行预加载，提前将热点数据加载到内存，可以加速数据的访问效率。在这些情况下，如果是由操作系统进行缓存，则很难做到，因为操作系统并不知道哪些是热点数据，哪些数据是访问一次后再也不会访问了，操作系统就是简单的缓存最近一次从磁盘读取的数据。 但是直接 I/O 也有负面的影响，如果访问的数据不再应用程序缓存中，则每次数据的加载都需要从磁盘读取，样加载的话速度非常的慢，通常是直接 I/O 与 异步 I/O 结合使用，会得到较好的性能。 直接 I/O 的方式如下图所示： 3. 同步访问文件的方式同步访问文件的方式就是数据的读取和写入都是同步操作的，它与标准访问文件的方式不同的是，只有当数据被成功写到磁盘时才返回给应用程序成功的标志。 这种访问文件的方式性能比较差，只有在一些数据安全性要求比较高的场景中才会使用，而且通常这种方式的硬件都是定制的。 同步访问文件的方式如下图所示： 4. 异步访问文件的方式异步访问文件的方式就是当访问数据的线程发出请求之后，线程会接着去处理其他事情，而不是阻塞等待，当请求的数据返回后继续处理下面的操作。这种方式可以明显的提高应用程序的效率，但是不会改变访问文件的效率。 异步访问文件的方式如下图所示： 5. 内存映射的方式内存映射的方式是指操作系统将内存中的某一块区域与磁盘中的文件关联起来，当要访问内存中的一段数据时，转换为访问文件的某一段数据。这种方式的目的同样是减少数据从内核空间缓存到用户空间缓存的数据复制操作，因为这两个空间的数据是共享的。 内存映射的方式如下图所示： 注：以上参考书籍《深入分析Java Web 技术内幕修订版》许令波，更多精彩知识还请看原书。","tags":[{"name":"IO","slug":"IO","permalink":"http://yoursite.com/tags/IO/"}]},{"title":"Java NIO 系列教程","date":"2017-03-28T10:44:23.057Z","path":"2017/03/28/Java NIO 系列教程/","text":"Java NIO（New IO）是从Java 1.4版本开始引入的一个新的IO API，可以替代标准的Java IO API。 Java NIO提供了与标准IO不同的IO工作方式： Channels and Buffers（通道和缓冲区）：标准的IO基于字节流和字符流进行操作的，而NIO是基于通道（Channel）和缓冲区（Buffer）进行操作，数据总是从通道读取到缓冲区中，或者从缓冲区写入到通道中。 Asynchronous IO（异步IO）：Java NIO可以让你异步的使用IO，例如：当线程从通道读取数据到缓冲区时，线程还是可以进行其他事情。当数据被写入到缓冲区时，线程可以继续处理它。从缓冲区写入通道也类似。 Selectors（选择器）：Java NIO引入了选择器的概念，选择器用于监听多个通道的事件（比如：连接打开，数据到达）。因此，单个的线程可以监听多个数据通道。 下面就来详细介绍Java NIO的相关知识。 1、Java NIO 概述Java NIO 由以下几个核心部分组成： Channels Buffers Selectors 虽然 Java NIO 中除此之外还有很多类和组件，但在我看来，Channel，Buffer 和 Selector 构成了核心的 API。其它组件，如 Pipe 和 FileLock，只不过是与三个核心组件共同使用的工具类。因此，在概述中我将集中在这三个组件上。其它组件会在单独的章节中讲到。 Channel 和 Buffer基本上，所有的 IO 在NIO 中都从一个 Channel 开始。Channel 有点象流。 数据可以从 Channel 读到 Buffer 中，也可以从 Buffer 写到 Channel 中。这里有个图示： Channel 和 Buffer 有好几种类型。下面是 JAVA NIO 中的一些主要 Channel 的实现： FileChannel DatagramChannel SocketChannel ServerSocketChannel 正如你所看到的，这些通道涵盖了 UDP 和 TCP 网络 IO，以及文件 IO。 与这些类一起的有一些有趣的接口，但为简单起见，我尽量在概述中不提到它们。本教程其它章节与它们相关的地方我会进行解释。 以下是 Java NIO 里关键的 Buffer 实现： ByteBuffer CharBuffer DoubleBuffer FloatBuffer IntBuffer LongBuffer ShortBuffer 这些 Buffer 覆盖了你能通过 IO 发送的基本数据类型：byte, short, int, long, float, double 和 char。 Java NIO 还有个 MappedByteBuffer，用于表示内存映射文件， 我也不打算在概述中说明。 SelectorSelector 允许单线程处理多个 Channel。如果你的应用打开了多个连接（通道），但每个连接的流量都很低，使用 Selector 就会很方便。例如，在一个聊天服务器中。 这是在一个单线程中使用一个 Selector 处理3个 Channel 的图示： 要使用 Selector，得向 Selector 注册 Channel，然后调用它的 select() 方法。这个方法会一直阻塞到某个注册的通道有事件就绪。一旦这个方法返回，线程就可以处理这些事件，事件的例子有如新连接进来，数据接收等。 2、ChannelJava NIO 的通道类似流，但又有些不同： 既可以从通道中读取数据，又可以写数据到通道。但流的读写通常是单向的。 通道可以异步地读写。 通道中的数据总是要先读到一个 Buffer，或者总是要从一个 Buffer 中写入。 正如上面所说，从通道读取数据到缓冲区，从缓冲区写入数据到通道。如下图所示： Channel 的实现这些是 Java NIO 中最重要的通道的实现： FileChannel DatagramChannel SocketChannel ServerSocketChannel FileChannel 从文件中读写数据。 DatagramChannel 能通过 UDP 读写网络中的数据。 SocketChannel 能通过 TCP 读写网络中的数据。 ServerSocketChannel 可以监听新进来的 TCP 连接，像 Web 服务器那样。对每一个新进来的连接都会创建一个 SocketChannel。 基本的 Channel 示例下面是一个使用 FileChannel 读取数据到 Buffer 中的示例： 12345678910111213141516171819RandomAccessFile aFile = new RandomAccessFile(&quot;data/nio-data.txt&quot;, &quot;rw&quot;);FileChannel inChannel = aFile.getChannel();ByteBuffer buf = ByteBuffer.allocate(48);int bytesRead = inChannel.read(buf);while (bytesRead != -1) &#123;System.out.println(&quot;Read &quot; + bytesRead);buf.flip();while(buf.hasRemaining())&#123;System.out.print((char) buf.get());&#125;buf.clear();bytesRead = inChannel.read(buf);&#125;aFile.close(); 注意 buf.flip() 的调用，首先读取数据到Buffer，然后反转Buffer,接着再从Buffer中读取数据。下一节会深入讲解Buffer的更多细节。 3、BufferJava NIO 中的 Buffer 用于和 NIO 通道进行交互。如你所知，数据是从通道读入缓冲区，从缓冲区写入到通道中的。 缓冲区本质上是一块可以写入数据，然后可以从中读取数据的内存。这块内存被包装成 NIO Buffer 对象，并提供了一组方法，用来方便的访问该块内存。 Buffer 的基本用法使用 Buffer 读写数据一般遵循以下四个步骤： 写入数据到 Buffer 调用 flip() 方法 从 Buffer 中读取数据 调用 clear() 方法或者 compact() 方法 当向 buffer 写入数据时，buffer 会记录下写了多少数据。一旦要读取数据，需要先通过 flip() 方法将 Buffer 从写模式切换到读模式。在读模式下，可以读取之前写入到 buffer 的所有数据。 一旦读完了所有的数据，就需要清空缓冲区，让它可以再次被写入。有两种方式能清空缓冲区：调用 clear() 或 compact() 方法。clear() 方法会清空整个缓冲区。compact() 方法只会清除已经读过的数据，任何未读的数据都被移到缓冲区的起始处，新写入的数据将放到缓冲区未读数据的后面。 下面是一个使用Buffer的例子： 12345678910111213141516171819RandomAccessFile aFile = new RandomAccessFile(&quot;data/nio-data.txt&quot;, &quot;rw&quot;);FileChannel inChannel = aFile.getChannel();//create buffer with capacity of 48 bytesByteBuffer buf = ByteBuffer.allocate(48);int bytesRead = inChannel.read(buf); //read into buffer.while (bytesRead != -1) &#123; buf.flip(); //make buffer ready for read while(buf.hasRemaining())&#123; System.out.print((char) buf.get()); // read 1 byte at a time &#125; buf.clear(); //make buffer ready for writing bytesRead = inChannel.read(buf);&#125;aFile.close(); Buffer 的 capacity、 position 和 limit缓冲区本质上是一块可以写入数据，然后可以从中读取数据的内存。这块内存被包装成 NIO Buffer 对象，并提供了一组方法，用来方便的访问该块内存。 为了理解 Buffer 的工作原理，需要熟悉它的三个属性： capacity position limit position 和 limit 的含义取决于 Buffer 处在读模式还是写模式。不管 Buffer 处在什么模式，capacity 的含义总是一样的。 这里有一个关于 capacity，position 和 limit 在读写模式中的说明，详细的解释在插图后面。 capacity 作为一个内存块，Buffer 有一个固定的大小值，也叫“capacity”.你只能往里写 capacity 个byte、long，char 等类型。一旦 Buffer 满了，需要将其清空（通过读数据或者清除数据）才能继续写数据往里写数据。 position 当你写数据到 Buffer 中时，position 表示当前的位置。初始的 position 值为 0。当一个 byte、long 等数据写到 Buffer 后， position 会向前移动到下一个可插入数据的 Buffer 单元。position 最大可为 capacity – 1. 当读取数据时，也是从某个特定位置读。当将 Buffer 从写模式切换到读模式，position 会被重置为 0. 当从 Buffer 的 position 处读取数据时，position 向前移动到下一个可读的位置。 limit 在写模式下，Buffer 的 limit 表示你最多能往 Buffer 里写多少数据。 写模式下，limit 等于Buffer 的 capacity。 当切换 Buffer 到读模式时， limit 表示你最多能读到多少数据。因此，当切换 Buffer 到读模式时，limit 会被设置成写模式下的 position 值。换句话说，你能读到之前写入的所有数据（limit被设置成已写数据的数量，这个值在写模式下就是 position） Buffer的类型Java NIO 有以下Buffer类型 ByteBuffer MappedByteBuffer CharBuffer DoubleBuffer FloatBuffer IntBuffer LongBuffer ShortBuffer 如你所见，这些Buffer类型代表了不同的数据类型。换句话说，就是可以通过char，short，int，long，float 或 double类型来操作缓冲区中的字节。 MappedByteBuffer 有些特别，在涉及它的专门章节中再讲。 Buffer 的分配要想获得一个 Buffer 对象首先要进行分配。 每一个 Buffer 类都有一个 allocate 方法。下面是一个分配48字节 capacity 的 ByteBuffer 的例子。 1ByteBuffer buf = ByteBuffer.allocate(48); 这是分配一个可存储1024个字符的 CharBuffer： 1CharBuffer buf = CharBuffer.allocate(1024); 向 Buffer 中写数据写数据到 Buffer 有两种方式： 从 Channel 写到 Buffer。 通过 Buffer 的 put() 方法写到 Buffer 里。 从 Channel 写到 Buffer 的例子： 1int bytesRead = inChannel.read(buf); //read into buffer. 通过put方法写Buffer的例子： 1buf.put(127); put 方法有很多版本，允许你以不同的方式把数据写入到 Buffer 中。例如， 写到一个指定的位置，或者把一个字节数组写入到 Buffer。 更多Buffer实现的细节参考JavaDoc。 flip() 方法 flip() 方法将 Buffer 从写模式切换到读模式。调用 flip() 方法会将 position 设回 0，并将 limit 设置成之前 position 的值。 换句话说，position 现在用于标记读的位置，limit 表示之前写进了多少个 byte、char等 —— 现在能读取多少个byte、char等。 从Buffer中读取数据从Buffer中读取数据有两种方式： 从Buffer读取数据到Channel。 使用get()方法从Buffer中读取数据。 从Buffer读取数据到Channel的例子： 12//read from buffer into channel.int bytesWritten = inChannel.write(buf); 使用get()方法从Buffer中读取数据的例子 1byte aByte = buf.get(); get方法有很多版本，允许你以不同的方式从Buffer中读取数据。例如，从指定position读取，或者从Buffer中读取数据到字节数组。更多Buffer实现的细节参考JavaDoc。 rewind()方法Buffer.rewind()将position设回0，所以你可以重读Buffer中的所有数据。limit保持不变，仍然表示能从Buffer中读取多少个元素（byte、char等）。 clear()与compact()方法一旦读完Buffer中的数据，需要让Buffer准备好再次被写入。可以通过clear()或compact()方法来完成。 如果调用的是clear()方法，position将被设回0，limit被设置成 capacity的值。换句话说，Buffer 被清空了。Buffer中的数据并未清除，只是这些标记告诉我们可以从哪里开始往Buffer里写数据。 如果Buffer中有一些未读的数据，调用clear()方法，数据将“被遗忘”，意味着不再有任何标记会告诉你哪些数据被读过，哪些还没有。 如果Buffer中仍有未读的数据，且后续还需要这些数据，但是此时想要先先写些数据，那么使用compact()方法。 compact()方法将所有未读的数据拷贝到Buffer起始处。然后将position设到最后一个未读元素正后面。limit属性依然像clear()方法一样，设置成capacity。现在Buffer准备好写数据了，但是不会覆盖未读的数据。 mark()与reset()方法通过调用Buffer.mark()方法，可以标记Buffer中的一个特定position。之后可以通过调用Buffer.reset()方法恢复到这个position。例如： 123buffer.mark();//call buffer.get() a couple of times, e.g. during parsing.buffer.reset(); //set position back to mark. equals()与compareTo()方法可以使用equals()和compareTo()方法两个Buffer。 equals() 当满足下列条件时，表示两个Buffer相等： 有相同的类型（byte、char、int等）。 Buffer中剩余的byte、char等的个数相等。 Buffer中所有剩余的byte、char等都相同。 如你所见，equals只是比较Buffer的一部分，不是每一个在它里面的元素都比较。实际上，它只比较Buffer中的剩余元素。 compareTo()方法 compareTo()方法比较两个Buffer的剩余元素(byte、char等)， 如果满足下列条件，则认为一个Buffer“小于”另一个Buffer： 第一个不相等的元素小于另一个Buffer中对应的元素 。 所有元素都相等，但第一个Buffer比另一个先耗尽(第一个Buffer的元素个数比另一个少)。 （译注：剩余元素是从 position到limit之间的元素） 4、Scatter/GatherJava NIO 开始支持 scatter/gather，scatter/gather 用于描述从 Channel（译者注：Channel 在中文经常翻译为通道）中读取或者写入到 Channel 的操作。 分散（scatter）从 Channel 中读取是指在读操作时将读取的数据写入多个 buffer 中。因此，Channel 将从 Channel 中读取的数据“分散（scatter）”到多个Buffer中。 聚集（gather）写入Channel是指在写操作时将多个buffer的数据写入同一个Channel，因此，Channel 将多个Buffer中的数据“聚集（gather）”后发送到Channel。 scatter / gather经常用于需要将传输的数据分开处理的场合，例如传输一个由消息头和消息体组成的消息，你可能会将消息体和消息头分散到不同的buffer中，这样你可以方便的处理消息头和消息体。 Scattering ReadsScattering Reads是指数据从一个channel读取到多个buffer中。如下图描述： 代码示例如下： 123456ByteBuffer header = ByteBuffer.allocate(128);ByteBuffer body = ByteBuffer.allocate(1024);ByteBuffer[] bufferArray = &#123; header, body &#125;;channel.read(bufferArray); 注意buffer首先被插入到数组，然后再将数组作为channel.read() 的输入参数。read()方法按照buffer在数组中的顺序将从channel中读取的数据写入到buffer，当一个buffer被写满后，channel紧接着向另一个buffer中写。 Scattering Reads在移动下一个buffer前，必须填满当前的buffer，这也意味着它不适用于动态消息(译者注：消息大小不固定)。换句话说，如果存在消息头和消息体，消息头必须完成填充（例如 128byte），Scattering Reads才能正常工作。 Gathering WritesGathering Writes是指数据从多个buffer写入到同一个channel。如下图描述： 代码示例如下： 12345678ByteBuffer header = ByteBuffer.allocate(128);ByteBuffer body = ByteBuffer.allocate(1024);//write data into buffersByteBuffer[] bufferArray = &#123; header, body &#125;;channel.write(bufferArray); buffers数组是write()方法的入参，write()方法会按照buffer在数组中的顺序，将数据写入到channel，注意只有position和limit之间的数据才会被写入。因此，如果一个buffer的容量为128byte，但是仅仅包含58byte的数据，那么这58byte的数据将被写入到channel中。因此与Scattering Reads相反，Gathering Writes能较好的处理动态消息。 5、通道之间的数据传输在Java NIO中，如果两个通道中有一个是FileChannel，那你可以直接将数据从一个channel（译者注：channel中文常译作通道）传输到另外一个channel。 transferFrom()FileChannel的transferFrom()方法可以将数据从源通道传输到FileChannel中（译者注：这个方法在JDK文档中的解释为将字节从给定的可读取字节通道传输到此通道的文件中）。 下面是一个简单的例子： 12345678910RandomAccessFile fromFile = new RandomAccessFile(&quot;fromFile.txt&quot;, &quot;rw&quot;);FileChannel fromChannel = fromFile.getChannel();RandomAccessFile toFile = new RandomAccessFile(&quot;toFile.txt&quot;, &quot;rw&quot;);FileChannel toChannel = toFile.getChannel();long position = 0;long count = fromChannel.size();toChannel.transferFrom(position, count, fromChannel); 方法的输入参数position表示从position处开始向目标文件写入数据，count表示最多传输的字节数。如果源通道的剩余空间小于 count 个字节，则所传输的字节数要小于请求的字节数。 此外要注意，在SoketChannel的实现中，SocketChannel只会传输此刻准备好的数据（可能不足count字节）。因此，SocketChannel可能不会将请求的所有数据(count个字节)全部传输到FileChannel中。 transferTo()transferTo()方法将数据从FileChannel传输到其他的channel中。 下面是一个简单的例子： 12345678910RandomAccessFile fromFile = new RandomAccessFile(&quot;fromFile.txt&quot;, &quot;rw&quot;);FileChannel fromChannel = fromFile.getChannel();RandomAccessFile toFile = new RandomAccessFile(&quot;toFile.txt&quot;, &quot;rw&quot;);FileChannel toChannel = toFile.getChannel();long position = 0;long count = fromChannel.size();fromChannel.transferTo(position, count, toChannel); 是不是发现这个例子和前面那个例子特别相似？除了调用方法的FileChannel对象不一样外，其他的都一样。 上面所说的关于SocketChannel的问题在transferTo()方法中同样存在。SocketChannel会一直传输数据直到目标buffer被填满。 6、SelectorSelector（选择器）是Java NIO中能够检测一到多个NIO通道，并能够知晓通道是否为诸如读写事件做好准备的组件。这样，一个单独的线程可以管理多个channel，从而管理多个网络连接。 为什么使用Selector?仅用单个线程来处理多个Channels的好处是，只需要更少的线程来处理通道。事实上，可以只用一个线程处理所有的通道。对于操作系统来说，线程之间上下文切换的开销很大，而且每个线程都要占用系统的一些资源（如内存）。因此，使用的线程越少越好。 但是，需要记住，现代的操作系统和CPU在多任务方面表现的越来越好，所以多线程的开销随着时间的推移，变得越来越小了。实际上，如果一个CPU有多个内核，不使用多任务可能是在浪费CPU能力。不管怎么说，关于那种设计的讨论应该放在另一篇不同的文章中。在这里，只要知道使用Selector能够处理多个通道就足够了。 下面是单线程使用一个Selector处理3个channel的示例图： Selector的创建通过调用Selector.open()方法创建一个Selector，如下： 1Selector selector = Selector.open(); 向Selector注册通道为了将Channel和Selector配合使用，必须将channel注册到selector上。通过SelectableChannel.register()方法来实现，如下： 123channel.configureBlocking(false);SelectionKey key = channel.register(selector, Selectionkey.OP_READ); 与Selector一起使用时，Channel必须处于非阻塞模式下。这意味着不能将FileChannel与Selector一起使用，因为FileChannel不能切换到非阻塞模式。而套接字通道都可以。 注意register()方法的第二个参数。这是一个“interest集合”，意思是在通过Selector监听Channel时对什么事件感兴趣。可以监听四种不同类型的事件： Connect Accept Read Write 通道触发了一个事件意思是该事件已经就绪。所以，某个channel成功连接到另一个服务器称为“连接就绪”。一个server socket channel准备好接收新进入的连接称为“接收就绪”。一个有数据可读的通道可以说是“读就绪”。等待写数据的通道可以说是“写就绪”。 这四种事件用SelectionKey的四个常量来表示： SelectionKey.OP_CONNECT SelectionKey.OP_ACCEPT SelectionKey.OP_READ SelectionKey.OP_WRITE 如果你对不止一种事件感兴趣，那么可以用“位或”操作符将常量连接起来，如下： 1int interestSet = SelectionKey.OP_READ | SelectionKey.OP_WRITE; 在下面还会继续提到interest集合。 SelectionKey在上一小节中，当向Selector注册Channel时，register()方法会返回一个SelectionKey对象。这个对象包含了一些你感兴趣的属性： interest集合 ready集合 Channel Selector 附加的对象（可选）下面我会描述这些属性。 interest集合就像向Selector注册通道一节中所描述的，interest集合是你所选择的感兴趣的事件集合。可以通过SelectionKey读写interest集合，像这样： 123456int interestSet = selectionKey.interestOps();boolean isInterestedInAccept = (interestSet &amp; SelectionKey.OP_ACCEPT) == SelectionKey.OP_ACCEPT；boolean isInterestedInConnect = interestSet &amp; SelectionKey.OP_CONNECT;boolean isInterestedInRead = interestSet &amp; SelectionKey.OP_READ;boolean isInterestedInWrite = interestSet &amp; SelectionKey.OP_WRITE; 可以看到，用“位与”操作interest 集合和给定的SelectionKey常量，可以确定某个确定的事件是否在interest 集合中。 ready集合ready 集合是通道已经准备就绪的操作的集合。在一次选择(Selection)之后，你会首先访问这个ready set。Selection将在下一小节进行解释。可以这样访问ready集合： 1int readySet = selectionKey.readyOps(); 可以用像检测interest集合那样的方法，来检测channel中什么事件或操作已经就绪。但是，也可以使用以下四个方法，它们都会返回一个布尔类型： 1234selectionKey.isAcceptable();selectionKey.isConnectable();selectionKey.isReadable();selectionKey.isWritable(); Channel + Selector从SelectionKey访问Channel和Selector很简单。如下： 12Channel channel = selectionKey.channel();Selector selector = selectionKey.selector(); 附加的对象可以将一个对象或者更多信息附着到SelectionKey上，这样就能方便的识别某个给定的通道。例如，可以附加 与通道一起使用的Buffer，或是包含聚集数据的某个对象。使用方法如下： 12selectionKey.attach(theObject);Object attachedObj = selectionKey.attachment(); 还可以在用register()方法向Selector注册Channel的时候附加对象。如： 1SelectionKey key = channel.register(selector, SelectionKey.OP_READ, theObject); 通过Selector选择通道一旦向Selector注册了一或多个通道，就可以调用几个重载的select()方法。这些方法返回你所感兴趣的事件（如连接、接受、读或写）已经准备就绪的那些通道。换句话说，如果你对“读就绪”的通道感兴趣，select()方法会返回读事件已经就绪的那些通道。 下面是select()方法： int select() int select(long timeout) int selectNow() select()阻塞到至少有一个通道在你注册的事件上就绪了。 select(long timeout)和select()一样，除了最长会阻塞timeout毫秒(参数)。 selectNow()不会阻塞，不管什么通道就绪都立刻返回（译者注：此方法执行非阻塞的选择操作。如果自从前一次选择操作后，没有通道变成可选择的，则此方法直接返回零。）。 select()方法返回的int值表示有多少通道已经就绪。亦即，自上次调用select()方法后有多少通道变成就绪状态。如果调用select()方法，因为有一个通道变成就绪状态，返回了1，若再次调用select()方法，如果另一个通道就绪了，它会再次返回1。如果对第一个就绪的channel没有做任何操作，现在就有两个就绪的通道，但在每次select()方法调用之间，只有一个通道就绪了。 selectedKeys()一旦调用了select()方法，并且返回值表明有一个或更多个通道就绪了，然后可以通过调用selector的selectedKeys()方法，访问“已选择键集（selected key set）”中的就绪通道。如下所示： 当像Selector注册Channel时，Channel.register()方法会返回一个SelectionKey 对象。这个对象代表了注册到该Selector的通道。可以通过SelectionKey的selectedKeySet()方法访问这些对象。 可以遍历这个已选择的键集合来访问就绪的通道。如下： 123456789101112131415Set selectedKeys = selector.selectedKeys();Iterator keyIterator = selectedKeys.iterator();while(keyIterator.hasNext()) &#123; SelectionKey key = keyIterator.next(); if(key.isAcceptable()) &#123; // a connection was accepted by a ServerSocketChannel. &#125; else if (key.isConnectable()) &#123; // a connection was established with a remote server. &#125; else if (key.isReadable()) &#123; // a channel is ready for reading &#125; else if (key.isWritable()) &#123; // a channel is ready for writing &#125; keyIterator.remove();&#125; 这个循环遍历已选择键集中的每个键，并检测各个键所对应的通道的就绪事件。 注意每次迭代末尾的keyIterator.remove()调用。Selector不会自己从已选择键集中移除SelectionKey实例。必须在处理完通道时自己移除。下次该通道变成就绪时，Selector会再次将其放入已选择键集中。 SelectionKey.channel()方法返回的通道需要转型成你要处理的类型，如ServerSocketChannel或SocketChannel等。 wakeUp()某个线程调用select()方法后阻塞了，即使没有通道已经就绪，也有办法让其从select()方法返回。只要让其它线程在第一个线程调用select()方法的那个对象上调用Selector.wakeup()方法即可。阻塞在select()方法上的线程会立马返回。 如果有其它线程调用了wakeup()方法，但当前没有线程阻塞在select()方法上，下个调用select()方法的线程会立即“醒来（wake up）”。 close()用完Selector后调用其close()方法会关闭该Selector，且使注册到该Selector上的所有SelectionKey实例无效。通道本身并不会关闭。 完整的示例这里有一个完整的示例，打开一个Selector，注册一个通道注册到这个Selector上(通道的初始化过程略去),然后持续监控这个Selector的四种事件（接受，连接，读，写）是否就绪。 12345678910111213141516171819202122Selector selector = Selector.open();channel.configureBlocking(false);SelectionKey key = channel.register(selector, SelectionKey.OP_READ);while(true) &#123; int readyChannels = selector.select(); if(readyChannels == 0) continue; Set selectedKeys = selector.selectedKeys(); Iterator keyIterator = selectedKeys.iterator(); while(keyIterator.hasNext()) &#123; SelectionKey key = keyIterator.next(); if(key.isAcceptable()) &#123; // a connection was accepted by a ServerSocketChannel. &#125; else if (key.isConnectable()) &#123; // a connection was established with a remote server. &#125; else if (key.isReadable()) &#123; // a channel is ready for reading &#125; else if (key.isWritable()) &#123; // a channel is ready for writing &#125; keyIterator.remove(); &#125;&#125; 7、FileChannelJava NIO中的FileChannel是一个连接到文件的通道。可以通过文件通道读写文件。 FileChannel无法设置为非阻塞模式，它总是运行在阻塞模式下。 打开FileChannel在使用FileChannel之前，必须先打开它。但是，我们无法直接打开一个FileChannel，需要通过使用一个InputStream、OutputStream或RandomAccessFile来获取一个FileChannel实例。下面是通过RandomAccessFile打开FileChannel的示例： 12RandomAccessFile aFile = new RandomAccessFile(&quot;data/nio-data.txt&quot;, &quot;rw&quot;);FileChannel inChannel = aFile.getChannel(); 从FileChannel读取数据调用多个read()方法之一从FileChannel中读取数据。如： 12ByteBuffer buf = ByteBuffer.allocate(48);int bytesRead = inChannel.read(buf); 首先，分配一个Buffer。从FileChannel中读取的数据将被读到Buffer中。 然后，调用FileChannel.read()方法。该方法将数据从FileChannel读取到Buffer中。read()方法返回的int值表示了有多少字节被读到了Buffer中。如果返回-1，表示到了文件末尾。 向FileChannel写数据使用FileChannel.write()方法向FileChannel写数据，该方法的参数是一个Buffer。如： 1234567891011String newData = &quot;New String to write to file...&quot; + System.currentTimeMillis();ByteBuffer buf = ByteBuffer.allocate(48);buf.clear();buf.put(newData.getBytes());buf.flip();while(buf.hasRemaining()) &#123; channel.write(buf);&#125; 注意FileChannel.write()是在while循环中调用的。因为无法保证write()方法一次能向FileChannel写入多少字节，因此需要重复调用write()方法，直到Buffer中已经没有尚未写入通道的字节。 关闭FileChannel用完FileChannel后必须将其关闭。如：1channel.close(); FileChannel的position方法有时可能需要在FileChannel的某个特定位置进行数据的读/写操作。可以通过调用position()方法获取FileChannel的当前位置。 也可以通过调用position(long pos)方法设置FileChannel的当前位置。 这里有两个例子:12long pos = channel.position();channel.position(pos +123); 如果将位置设置在文件结束符之后，然后试图从文件通道中读取数据，读方法将返回-1 —— 文件结束标志。 如果将位置设置在文件结束符之后，然后向通道中写数据，文件将撑大到当前位置并写入数据。这可能导致“文件空洞”，磁盘上物理文件中写入的数据间有空隙。 FileChannel的size方法FileChannel实例的size()方法将返回该实例所关联文件的大小。如:1long fileSize = channel.size(); FileChannel的truncate方法可以使用FileChannel.truncate()方法截取一个文件。截取文件时，文件将中指定长度后面的部分将被删除。如：1channel.truncate(1024); 这个例子截取文件的前1024个字节。 FileChannel的force方法FileChannel.force()方法将通道里尚未写入磁盘的数据强制写到磁盘上。出于性能方面的考虑，操作系统会将数据缓存在内存中，所以无法保证写入到FileChannel里的数据一定会即时写到磁盘上。要保证这一点，需要调用force()方法。 force()方法有一个boolean类型的参数，指明是否同时将文件元数据（权限信息等）写到磁盘上。 下面的例子同时将文件数据和元数据强制写到磁盘上： 查看源代码打印帮助1channel.force(true); 8、SocketChannelJava NIO中的SocketChannel是一个连接到TCP网络套接字的通道。可以通过以下2种方式创建SocketChannel： 打开一个SocketChannel并连接到互联网上的某台服务器。一个新连接到达ServerSocketChannel时，会创建一个SocketChannel。 打开 SocketChannel下面是SocketChannel的打开方式： 12SocketChannel socketChannel = SocketChannel.open();socketChannel.connect(new InetSocketAddress(&quot;http://jenkov.com&quot;, 80)); 关闭 SocketChannel 当用完SocketChannel之后调用SocketChannel.close()关闭SocketChannel： 1socketChannel.close(); 从 SocketChannel 读取数据要从SocketChannel中读取数据，调用一个read()的方法之一。以下是例子： 12ByteBuffer buf = ByteBuffer.allocate(48);int bytesRead = socketChannel.read(buf); 首先，分配一个Buffer。从SocketChannel读取到的数据将会放到这个Buffer中。 然后，调用SocketChannel.read()。该方法将数据从SocketChannel 读到Buffer中。read()方法返回的int值表示读了多少字节进Buffer里。如果返回的是-1，表示已经读到了流的末尾（连接关闭了）。 写入 SocketChannel写数据到SocketChannel用的是SocketChannel.write()方法，该方法以一个Buffer作为参数。示例如下： 1234567891011String newData = &quot;New String to write to file...&quot; + System.currentTimeMillis();ByteBuffer buf = ByteBuffer.allocate(48);buf.clear();buf.put(newData.getBytes());buf.flip();while(buf.hasRemaining()) &#123; channel.write(buf);&#125; 注意SocketChannel.write()方法的调用是在一个while循环中的。Write()方法无法保证能写多少字节到SocketChannel。所以，我们重复调用write()直到Buffer没有要写的字节为止。 非阻塞模式可以设置 SocketChannel 为非阻塞模式（non-blocking mode）.设置之后，就可以在异步模式下调用connect(), read() 和write()了。 connect()如果SocketChannel在非阻塞模式下，此时调用connect()，该方法可能在连接建立之前就返回了。为了确定连接是否建立，可以调用finishConnect()的方法。像这样： 123456socketChannel.configureBlocking(false);socketChannel.connect(new InetSocketAddress(&quot;http://jenkov.com&quot;, 80));while(! socketChannel.finishConnect() )&#123; //wait, or do something else...&#125; write()非阻塞模式下，write()方法在尚未写出任何内容时可能就返回了。所以需要在循环中调用write()。前面已经有例子了，这里就不赘述了。 read()非阻塞模式下,read()方法在尚未读取到任何数据时可能就返回了。所以需要关注它的int返回值，它会告诉你读取了多少字节。 非阻塞模式与选择器非阻塞模式与选择器搭配会工作的更好，通过将一或多个SocketChannel注册到Selector，可以询问选择器哪个通道已经准备好了读取，写入等。Selector与SocketChannel的搭配使用会在后面详讲。 9、ServerSocketChannelJava NIO中的 ServerSocketChannel 是一个可以监听新进来的TCP连接的通道, 就像标准IO中的ServerSocket一样。ServerSocketChannel类在 java.nio.channels包中。 这里有个例子： 12345678910ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();serverSocketChannel.socket().bind(new InetSocketAddress(9999));while(true)&#123; SocketChannel socketChannel = serverSocketChannel.accept(); //do something with socketChannel...&#125; 打开 ServerSocketChannel通过调用 ServerSocketChannel.open() 方法来打开ServerSocketChannel.如： 1ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); 关闭 ServerSocketChannel通过调用ServerSocketChannel.close() 方法来关闭ServerSocketChannel. 如： 1serverSocketChannel.close(); 监听新进来的连接通过 ServerSocketChannel.accept() 方法监听新进来的连接。当 accept()方法返回的时候,它返回一个包含新进来的连接的 SocketChannel。因此, accept()方法会一直阻塞到有新连接到达。 通常不会仅仅只监听一个连接,在while循环中调用 accept()方法. 如下面的例子： 123456while(true)&#123; SocketChannel socketChannel = serverSocketChannel.accept(); //do something with socketChannel...&#125; 当然,也可以在while循环中使用除了true以外的其它退出准则。 非阻塞模式ServerSocketChannel可以设置成非阻塞模式。在非阻塞模式下，accept() 方法会立刻返回，如果还没有新进来的连接,返回的将是null。 因此，需要检查返回的SocketChannel是否是null.如： 12345678910111213ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();serverSocketChannel.socket().bind(new InetSocketAddress(9999));serverSocketChannel.configureBlocking(false);while(true)&#123; SocketChannel socketChannel = serverSocketChannel.accept(); if(socketChannel != null)&#123; //do something with socketChannel... &#125;&#125; 10、Java NIO DatagramChannelJava NIO中的DatagramChannel是一个能收发UDP包的通道。因为UDP是无连接的网络协议，所以不能像其它通道那样读取和写入。它发送和接收的是数据包。 打开 DatagramChannel下面是 DatagramChannel 的打开方式： 12DatagramChannel channel = DatagramChannel.open();channel.socket().bind(new InetSocketAddress(9999)); 这个例子打开的 DatagramChannel可以在UDP端口9999上接收数据包。 接收数据通过receive()方法从DatagramChannel接收数据，如： 123ByteBuffer buf = ByteBuffer.allocate(48);buf.clear();channel.receive(buf); receive()方法会将接收到的数据包内容复制到指定的Buffer. 如果Buffer容不下收到的数据，多出的数据将被丢弃。 发送数据通过send()方法从DatagramChannel发送数据，如: 12345678String newData = &quot;New String to write to file...&quot; + System.currentTimeMillis();ByteBuffer buf = ByteBuffer.allocate(48);buf.clear();buf.put(newData.getBytes());buf.flip();int bytesSent = channel.send(buf, new InetSocketAddress(&quot;jenkov.com&quot;, 80)); 这个例子发送一串字符到”jenkov.com”服务器的UDP端口80。 因为服务端并没有监控这个端口，所以什么也不会发生。也不会通知你发出的数据包是否已收到，因为UDP在数据传送方面没有任何保证。 连接到特定的地址可以将DatagramChannel“连接”到网络中的特定地址的。由于UDP是无连接的，连接到特定地址并不会像TCP通道那样创建一个真正的连接。而是锁住DatagramChannel ，让其只能从特定地址收发数据。 这里有个例子: 1channel.connect(new InetSocketAddress(&quot;jenkov.com&quot;, 80)); 当连接后，也可以使用read()和write()方法，就像在用传统的通道一样。只是在数据传送方面没有任何保证。这里有几个例子： 12int bytesRead = channel.read(buf);int bytesWritten = channel.write(but); 11、PipeJava NIO 管道是2个线程之间的单向数据连接。Pipe有一个source通道和一个sink通道。数据会被写到sink通道，从source通道读取。 这里是Pipe原理的图示： 创建管道通过Pipe.open()方法打开管道。例如： 1Pipe pipe = Pipe.open(); 向管道写数据要向管道写数据，需要访问sink通道。像这样： 1Pipe.SinkChannel sinkChannel = pipe.sink(); 通过调用SinkChannel的write()方法，将数据写入SinkChannel,像这样： 12345678910String newData = &quot;New String to write to file...&quot; + System.currentTimeMillis();ByteBuffer buf = ByteBuffer.allocate(48);buf.clear();buf.put(newData.getBytes());buf.flip();while(buf.hasRemaining()) &#123; sinkChannel.write(buf);&#125; 从管道读取数据从读取管道的数据，需要访问source通道，像这样： 1Pipe.SourceChannel sourceChannel = pipe.source(); 调用source通道的read()方法来读取数据，像这样： 123ByteBuffer buf = ByteBuffer.allocate(48);int bytesRead = sourceChannel.read(buf); read()方法返回的int值会告诉我们多少字节被读进了缓冲区。 12、Java NIO与IO的对比当学习了Java NIO和IO的API后，一个问题马上涌入脑海： 我应该何时使用IO，何时使用NIO呢？在本文中，我会尽量清晰地解析Java NIO和IO的差异、它们的使用场景，以及它们如何影响您的代码设计。 Java NIO和IO的主要区别下表总结了Java NIO和IO之间的主要差别，我会更详细地描述表中每部分的差异。 IO NIO Stream oriented Buffer oriented Blocking IO Non blocking IO 无 Selectors 面向流与面向缓冲Java NIO和IO之间第一个最大的区别是，IO是面向流的，NIO是面向缓冲区的。 Java IO面向流意味着每次从流中读一个或多个字节，直至读取所有字节，它们没有被缓存在任何地方。此外，它不能前后移动流中的数据。如果需要前后移动从流中读取的数据，需要先将它缓存到一个缓冲区。 Java NIO的缓冲导向方法略有不同。数据读取到一个它稍后处理的缓冲区，需要时可在缓冲区中前后移动。这就增加了处理过程中的灵活性。但是，还需要检查是否该缓冲区中包含所有您需要处理的数据。而且，需确保当更多的数据读入缓冲区时，不要覆盖缓冲区里尚未处理的数据。 阻塞与非阻塞IOJava IO的各种流是阻塞的。这意味着，当一个线程调用read() 或 write()时，该线程被阻塞，直到有一些数据被读取，或数据完全写入。该线程在此期间不能再干任何事情了。 Java NIO的非阻塞模式，使一个线程从某通道发送请求读取数据，但是它仅能得到目前可用的数据，如果目前没有数据可用时，就什么都不会获取。而不是保持线程阻塞，所以直至数据变的可以读取之前，该线程可以继续做其他的事情。 非阻塞写也是如此。一个线程请求写入一些数据到某通道，但不需要等待它完全写入，这个线程同时可以去做别的事情。 线程通常将非阻塞IO的空闲时间用于在其它通道上执行IO操作，所以一个单独的线程现在可以管理多个输入和输出通道（channel）。 选择器（Selectors）Java NIO的选择器允许一个单独的线程来监视多个输入通道，你可以注册多个通道使用一个选择器，然后使用一个单独的线程来“选择”通道：这些通道里已经有可以处理的输入，或者选择已准备写入的通道。这种选择机制，使得一个单独的线程很容易来管理多个通道。 NIO和IO如何影响应用程序的设计无论您选择IO或NIO工具箱，可能会影响您应用程序设计的以下几个方面： 对NIO或IO类的API调用。 数据处理。 用来处理数据的线程数。 API调用当然，使用NIO的API调用时看起来与使用IO时有所不同，但这并不意外，因为并不是仅从一个InputStream逐字节读取，而是数据必须先读入缓冲区再处理。 数据处理使用纯粹的NIO设计相较IO设计，数据处理也受到影响。 在IO设计中，我们从InputStream或 Reader逐字节读取数据。假设你正在处理一基于行的文本数据流，例如： 1234Name: AnnaAge: 25Email: anna@mailserver.comPhone: 1234567890 该文本行的流可以这样处理： 1234567InputStream input = … ; // get the InputStream from the client socketBufferedReader reader = new BufferedReader(new InputStreamReader(input));String nameLine = reader.readLine();String ageLine = reader.readLine();String emailLine = reader.readLine();String phoneLine = reader.readLine(); 请注意处理状态由程序执行多久决定。换句话说，一旦reader.readLine()方法返回，你就知道肯定文本行就已读完， readline()阻塞直到整行读完，这就是原因。你也知道此行包含名称；同样，第二个readline()调用返回的时候，你知道这行包含年龄等。 正如你可以看到，该处理程序仅在有新数据读入时运行，并知道每步的数据是什么。一旦正在运行的线程已处理过读入的某些数据，该线程不会再回退数据（大多如此）。下图也说明了这条原则： 上图：从一个阻塞的流中读数据 而一个NIO的实现会有所不同，下面是一个简单的例子： 123ByteBuffer buffer = ByteBuffer.allocate(48);int bytesRead = inChannel.read(buffer); 注意第二行，从通道读取字节到ByteBuffer。当这个方法调用返回时，你不知道你所需的所有数据是否在缓冲区内。你所知道的是，该缓冲区包含一些字节，这使得处理有点困难。假设第一次 read(buffer)调用后，读入缓冲区的数据只有半行，例如，“Name:An”，你能处理数据吗？显然不能，需要等待，直到整行数据读入缓存，在此之前，对数据的任何处理毫无意义。 所以，你怎么知道是否该缓冲区包含足够的数据可以处理呢？好了，你不知道。发现的方法只能查看缓冲区中的数据。其结果是，在你知道所有数据都在缓冲区里之前，你必须检查几次缓冲区的数据。这不仅效率低下，而且可以使程序设计方案杂乱不堪。例如： 12345ByteBuffer buffer = ByteBuffer.allocate(48);int bytesRead = inChannel.read(buffer);while(! bufferFull(bytesRead) ) &#123;bytesRead = inChannel.read(buffer);&#125; bufferFull()方法必须跟踪有多少数据读入缓冲区，并返回真或假，这取决于缓冲区是否已满。换句话说，如果缓冲区准备好被处理，那么表示缓冲区满了。 bufferFull()方法扫描缓冲区，但必须保持在bufferFull（）方法被调用之前状态相同。如果没有，下一个读入缓冲区的数据可能无法读到正确的位置。这是不可能的，但却是需要注意的又一问题。 如果缓冲区已满，它可以被处理。如果它不满，并且在你的实际案例中有意义，你或许能处理其中的部分数据。但是许多情况下并非如此。下图展示了“缓冲区数据循环就绪”： 上图：从一个通道里读数据，直到所有的数据都读到缓冲区里 总结NIO可让您只使用一个（或几个）单线程管理多个通道（网络连接或文件），但付出的代价是解析数据可能会比从一个阻塞流中读取数据更复杂。 如果需要管理同时打开的成千上万个连接，这些连接每次只是发送少量的数据，例如聊天服务器，实现NIO的服务器可能是一个优势。同样，如果你需要维持许多打开的连接到其他计算机上，如P2P网络中，使用一个单独的线程来管理你所有出站连接，可能是一个优势。一个线程多个连接的设计方案如下图所示： 上图：单线程管理多个连接 如果你有少量的连接使用非常高的带宽，一次发送大量的数据，也许典型的IO服务器实现可能非常契合。下图说明了一个典型的IO服务器设计： 上图：一个典型的IO服务器设计：一个连接通过一个线程处理 注明：文章转载自 NIO|并发编程网，二次转载请务必注明原出处！","tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"NIO","slug":"NIO","permalink":"http://yoursite.com/tags/NIO/"}]},{"title":"JVM性能调优监控工具jps、jstack、jmap、jhat、jstat等使用详解","date":"2017-03-28T10:40:34.793Z","path":"2017/03/28/JVM性能调优监控工具jps、jstack、jmap、jhat、jstat等使用详解/","text":"javap 和 javac javac -verbose 类名.java java -verbose 类名 javap -c 类名 javap -verbose 类名 javap -help用法: javap 其中, 可能的选项包括: -help –help -? 输出此用法消息 -version 版本信息 -v -verbose 输出附加信息 -l 输出行号和本地变量表 -public 仅显示公共类和成员 -protected 显示受保护的/公共类和成员 -package 显示程序包/受保护的/公共类 和成员 (默认) -p -private 显示所有类和成员 -c 对代码进行反汇编 -s 输出内部类型签名 -sysinfo 显示正在处理的类的 系统信息 (路径, 大小, 日期, MD5 散列) -constants 显示最终常量 -classpath 指定查找用户类文件的位置 -cp 指定查找用户类文件的位置 -bootclasspath 覆盖引导类文件的位置 javac -help用法: javac 其中, 可能的选项包括: -g 生成所有调试信息 -g:none 不生成任何调试信息 -g:{lines,vars,source} 只生成某些调试信息 -nowarn 不生成任何警告 -verbose 输出有关编译器正在执行的操作的消息 -deprecation 输出使用已过时的 API 的源位置 -classpath &lt;路径&gt; 指定查找用户类文件和注释处理程序的位置 -cp &lt;路径&gt; 指定查找用户类文件和注释处理程序的位置 -sourcepath &lt;路径&gt; 指定查找输入源文件的位置 -bootclasspath &lt;路径&gt; 覆盖引导类文件的位置 -extdirs &lt;目录&gt; 覆盖所安装扩展的位置 -endorseddirs &lt;目录&gt; 覆盖签名的标准路径的位置 -proc:{none,only} 控制是否执行注释处理和/或编译。 -processor [,,…] 要运行的注释处理程序的名称; 绕过默认的搜索进程 -processorpath &lt;路径&gt; 指定查找注释处理程序的位置 -parameters 生成元数据以用于方法参数的反射 -d &lt;目录&gt; 指定放置生成的类文件的位置 -s &lt;目录&gt; 指定放置生成的源文件的位置 -h &lt;目录&gt; 指定放置生成的本机标头文件的位置 -implicit:{none,class} 指定是否为隐式引用文件生成类文件 -encoding &lt;编码&gt; 指定源文件使用的字符编码 -source &lt;发行版&gt; 提供与指定发行版的源兼容性 -target &lt;发行版&gt; 生成特定 VM 版本的类文件 -profile &lt;配置文件&gt; 请确保使用的 API 在指定的配置文件中可用 -version 版本信息 -help 输出标准选项的提要 -A关键字[=值] 传递给注释处理程序的选项 -X 输出非标准选项的提要 -J&lt;标记&gt; 直接将 &lt;标记&gt; 传递给运行时系统 -Werror 出现警告时终止编译 @&lt;文件名&gt; 从文件读取选项和文件名 jps用来查看基于HotSpot的JVM里面中，所有具有访问权限的Java进程的具体状态, 包括进程ID，进程启动的路径及启动参数等等，与unix上的ps类似，只不过jps是用来显示java进程，可以把jps理解为ps的一个子集。 使用jps时，如果没有指定hostid，它只会显示本地环境中所有的Java进程；如果指定了hostid，它就会显示指定hostid上面的java进程，不过这需要远程服务上开启了jstatd服务。 jps -helpusage: jps [-help] jps [-q] [-mlvV] [&lt;hostid&gt;] Definitions: &lt;hostid&gt;: &lt;hostname&gt;[:&lt;port&gt;] -q：忽略输出的类名、Jar名以及传递给main方法的参数，只输出pid。 -m：输出传递给main方法的参数，如果是内嵌的JVM则输出为null。 -l：输出完全的包名，应用主类名，jar的完全路径名 -v：输出传给jvm的参数 -V：输出通过标记的文件传递给JVM的参数（.hotspotrc文件，或者是通过参数-XX:Flags=指定的文件）。 -J 用于传递jvm选项到由javac调用的java加载器中，例如，“-J-Xms48m”将把启动内存设置为48M，使用-J选项可以非常方便的向基于Java的开发的底层虚拟机应用程序传递参数。 jstackjstack用于打印出给定的java进程ID或core file或远程调试服务的Java堆栈信息，如果是在64位机器上，需要指定选项”-J-d64”，Windows的jstack使用方式只支持以下的这种方式： jstack [-l] pid 如果java程序崩溃生成core文件，jstack工具可以用来获得core文件的java stack和native stack的信息，从而可以轻松地知道java程序是如何崩溃和在程序何处发生问题。另外，jstack工具还可以附属到正在运行的java程序中，看到当时运行的java程序的java stack和native stack的信息, 如果现在运行的java程序呈现hung的状态，jstack是非常有用的。 jstack -helpUsage: jstack [-l] &lt;pid&gt; (to connect to running process) jstack -F [-m] [-l] &lt;pid&gt; (to connect to a hung process) jstack [-m] [-l] &lt;executable&gt; &lt;core&gt; (to connect to a core file) jstack [-m] [-l] [server_id@]&lt;remote server IP or hostname&gt; (to connect to a remote debug server) Options: -F to force a thread dump. Use when jstack &lt;pid&gt; does not respond (process is hung)(当’jstack [-l] pid’没有相应的时候强制打印栈信息) -m to print both java and native frames (mixed mode)(打印java和native c/c++框架的所有栈信息.) -l long listing. Prints additional information about locks (长列表. 打印关于锁的附加信息,例如属于java.util.concurrent的ownable synchronizers列表.) -h or -help to print this help message (打印帮助信息) jstatJstat 用于监控基于HotSpot的JVM，对其堆的使用情况进行实时的命令行的统计，使用jstat我们可以对指定的JVM做如下监控： 类的加载及卸载情况 查看新生代、老生代及持久代的容量及使用情况 查看新生代、老生代及持久代的垃圾收集情况，包括垃圾回收的次数及垃圾回收所占用的时间 查看新生代中Eden区及Survior区中容量及分配情况等 jstat -help Usage: jstat -help|-options jstat -&lt;option&gt; [-t] [-h&lt;lines&gt;] &lt;vmid&gt; [&lt;interval&gt; [&lt;count&gt;]] Definitions:&gt; An option reported by the -options option Virtual Machine Identifier. A vmid takes the following form: [@[:]] Where is the local vm identifier for the target Java virtual machine, typically a process id; is the name of the host running the target Java virtual machine; and is the port number for the rmiregistry on the target host. See the jvmstat documentation for a more complete description of the Virtual Machine Identifier. Number of samples between header lines. Sampling interval. The following forms are allowed: [“ms”|”s”] Where is an integer and the suffix specifies the units as milliseconds(“ms”) or seconds(“s”). The default units are “ms”. Number of samples to take before terminating. -J Pass directly to the runtime system. 参考文章1、jstat命令详解 2、jstat命令(Java Virtual Machine Statistics Monitoring Tool) 3、http://docs.oracle.com/javase/1.5.0/docs/tooldocs/share/jstat.html#class_option jmap打印出某个java进程（使用pid）内存内的，所有‘对象’的情况（如：产生那些对象，及其数量）。 可以输出所有内存中对象的工具，甚至可以将VM 中的heap，以二进制输出成文本。使用方法 jmap -histo pid 如果连用SHELL jmap -histo pid&gt;a.log 可以将其保存到文本中去，在一段时间后，使用文本对比工具，可以对比出GC回收了哪些对象。 jmap -dump:format=b,file=outfile 3024 可以将3024进程的内存heap输出出来到outfile文件里，再配合MAT（内存分析工具(Memory Analysis Tool），使用参见：http://blog.csdn.net/fenglibing/archive/2011/04/02/6298326.aspx）或与jhat (Java Heap Analysis Tool)一起使用，能够以图像的形式直观的展示当前内存是否有问题。 64位机上使用需要使用如下方式： jmap -J-d64 -heap pid jmap -helpUsage: jmap [option] &lt;pid&gt; (to connect to running process) jmap [option] &lt;executable &lt;core&gt; (to connect to a core file) jmap [option] [server_id@]&lt;remote server IP or hostname&gt; (to connect to remote debug server) where is one of: &lt;none&gt; to print same info as Solaris pmap -heap to print java heap summary -histo[:live] to print histogram of java object heap; if the &quot;live&quot; suboption is specified, only count live objects -clstats to print class loader statistics -finalizerinfo to print information on objects awaiting finalization -dump:&lt;dump-options&gt; to dump java heap in hprof binary format dump-options: live dump only live objects; if not specified, all objects in the heap are dumped. format=b binary format file=&lt;file&gt; dump heap to &lt;file&gt; Example: jmap -dump:live,format=b,file=heap.bin &lt;pid&gt; -F force. Use with -dump:&lt;dump-options&gt; &lt;pid&gt; or -histo to force a heap dump or histogram when &lt;pid&gt; does not respond. The &quot;live&quot; suboption is not supported in this mode. -h | -help to print this help message -J&lt;flag&gt; to pass &lt;flag&gt; directly to the runtime system 参数说明 1)、options： executable Java executable from which the core dump was produced.(可能是产生core dump的java可执行程序) core 将被打印信息的core dump文件 remote-hostname-or-IP 远程debug服务的主机名或ip server-id 唯一id,假如一台主机上多个远程debug服务 2）、基本参数： -dump:[live,]format=b,file= 使用hprof二进制形式,输出jvm的heap内容到文件=. live子选项是可选的，假如指定live选项,那么只输出活的对象到文件. -finalizerinfo 打印正等候回收的对象的信息. -heap 打印heap的概要信息，GC使用的算法，heap的配置及wise heap的使用情况. -histo[:live] 打印每个class的实例数目,内存占用,类全名信息. VM的内部类名字开头会加上前缀”*”. 如果live子参数加上后,只统计活的对象数量. -permstat 打印classload和jvm heap长久层的信息. 包含每个classloader的名字,活泼性,地址,父classloader和加载的class数量. 另外,内部String的数量和占用内存数也会打印出来. -F 强迫.在pid没有相应的时候使用-dump或者-histo参数. 在这个模式下,live子参数无效. -h | -help 打印辅助信息 -J 传递参数给jmap启动的jvm. pid 需要被打印配相信息的java进程id,创业与打工的区别 - 博文预览,可以用jps查问. jinfojinfo 可以输出并修改运行时的java 进程的opts。 用处比较简单，用于输出JAVA系统参数及命令行参数。 用法是 jinfo -opt pid 如：查看2788的MaxPerm大小可以用 jinfo -flag MaxPermSize 2788。 jinfo -help Usage: jinfo [option] &lt;pid&gt; (to connect to running process) jinfo [option] &lt;executable &lt;core&gt; (to connect to a core file) jinfo [option] [server_id@]&lt;remote server IP or hostname&gt; (to connect to remote debug server) where is one of: -flag &lt;name&gt; to print the value of the named VM flag -flag [+|-]&lt;name&gt; to enable or disable the named VM flag -flag &lt;name&gt;=&lt;value&gt; to set the named VM flag to the given value -flags to print VM flags -sysprops to print Java system properties &lt;no option&gt; to print both of the above -h | -help to print this help message jconsole一个java GUI监视工具，可以以图表化的形式显示各种数据。并可通过远程连接监视远程的服务器VM。用java写的GUI程序，用来监控VM，并可监控远程的VM，非常易用，而且功能非常强。命令行里打 jconsole，选则进程就可以了。 需要注意的就是在运行jconsole之前，必须要先设置环境变量DISPLAY，否则会报错误，Linux下设置环境变量如下： export DISPLAY=:0.0 可以这里选择查看本地进程的状况，还是远程进程的状况 通过这张图可以看到内存、线程、类及CPU使用的一些情况。 jvisualvm参考文章： 程序员必备利器—Java程序性能分析工具Java VisualVM（Visual GC） jhat用于对JAVA heap进行离线分析的工具，他可以对不同虚拟机中导出的heap信息文件进行分析，如Linux上导出的文件可以拿到WINDOWS上进行分析，可以查找诸如内存方面的问题，使用方式可以查看这篇文章： jhat命令 不过jhat和MAT比较起来，就没有MAT那么直观了，MAT是以图形界面的方式展现结果，MAT的使用方式可以参看文章： MAT(Memory Analyzer Tool)工具入门介绍 Usage:jhat [-stack ] [-refs ] [-port ] [-baseline ] [-debug ] [-version] [-h|-help] -J&lt;flag&gt; Pass &lt;flag&gt; directly to the runtime system. For example, -J-mx512m to use a maximum heap size of 512MB -stack false: Turn off tracking object allocation call stack. -refs false: Turn off tracking of references to objects -port &lt;port&gt;: Set the port for the HTTP server. Defaults to 7000 -exclude &lt;file&gt;: Specify a file that lists data members that should be excluded from the reachableFrom query. -baseline &lt;file&gt;: Specify a baseline object dump. Objects in both heap dumps with the same ID and same class will be marked as not being &quot;new&quot;. -debug &lt;int&gt;: Set debug level. 0: No debug output 1: Debug hprof file parsing 2: Debug hprof file parsing, no server -version Report version number -h|-help Print this help and exit &lt;file&gt; The file to read jdb用来对core文件和正在运行的Java进程进行实时地调试，里面包含了丰富的命令帮助您进行调试，它的功能和Sun studio里面所带的dbx非常相似，但 jdb是专门用来针对Java应用程序的。 jstatdjstatd是一个基于RMI（Remove Method Invocation）的服务程序，它用于监控基于HotSpot的JVM中资源的创建及销毁，并且提供了一个远程接口允许远程的监控工具连接到本地的JVM执行命令。 jstatd是基于RMI的，所以在运行jstatd的服务器上必须存在RMI注册中心，如果没有通过选项”-p port”指定要连接的端口，jstatd会尝试连接RMI注册中心的默认端口。 用法： jstatd [-nr] [-p port] [-n rminame] -nr 如果RMI注册中心没有找到，不会创建一个内部的RMI注册中心。 -p port RMI注册中心的端口号，默认为1099。 -n rminame 默认为JStatRemoteHost；如果同一台主机上同时运行了多个jstatd服务，rminame可以用于唯一确定一个jstatd服务；这里需要注意一下，如果开启了这个选项，那么监控客户端远程连接时，必须同时指定hostid及vmid，才可以唯一确定要连接的服务，这个可以参看jps章节中列出远程服务器上Java进程的示例。 -J 用于传递jvm选项到由javac调用的java加载器中，例如，“-J-Xms48m”将把启动内存设置为48M，使用-J选项可以非常方便的向基于Java的开发的底层虚拟机应用程序传递参数。 参考文章 JDK内置工具使用","tags":[{"name":"JVM","slug":"JVM","permalink":"http://yoursite.com/tags/JVM/"},{"name":"性能调优工具","slug":"性能调优工具","permalink":"http://yoursite.com/tags/性能调优工具/"}]},{"title":"详解 Filter 过滤器","date":"2017-03-26T17:03:48.417Z","path":"2017/03/27/详解 Filter 过滤器/","text":"1、简介 Filter也称之为过滤器，它是Servlet技术中最实用的技术，WEB开发人员通过Filter技术，对web服务器管理的所有web资源：例如Jsp, Servlet, 静态图片文件或静态 html 文件等进行拦截，从而实现一些特殊的功能。例如实现URL级别的权限访问控制、过滤敏感词汇、压缩响应信息等一些高级功能。 它主要用于对用户请求进行预处理，也可以对HttpServletResponse 进行后处理。使用Filter 的完整流程：Filter 对用户请求进行预处理，接着将请求交给Servlet 进行处理并生成响应，最后Filter 再对服务器响应进行后处理。 Filter功能： 在HttpServletRequest 到达 Servlet 之前，拦截客户的 HttpServletRequest 。 根据需要检查 HttpServletRequest ，也可以修改HttpServletRequest 头和数据。 在HttpServletResponse 到达客户端之前，拦截HttpServletResponse 。 根据需要检查 HttpServletResponse ，也可以修改HttpServletResponse头和数据。 2、如何实现拦截 Filter接口中有一个doFilter方法，当开发人员编写好Filter，并配置对哪个web资源进行拦截后，WEB服务器每次在调用web资源的service方法之前，都会先调用一下filter的doFilter方法，因此，在该方法内编写代码可达到如下目的： 调用目标资源之前，让一段代码执行。 是否调用目标资源（即是否让用户访问web资源）。 web服务器在调用doFilter方法时，会传递一个filterChain对象进来，filterChain对象是filter接口中最重要的一个对象，它也提供了一个doFilter方法，开发人员可以根据需求决定是否调用此方法，调用该方法，则web服务器就会调用web资源的service方法，即web资源就会被访问，否则web资源不会被访问。 3、Filter开发两步走 编写java类实现Filter接口，并实现其doFilter方法。 在 web.xml 文件中使用和元素对编写的filter类进行注册，并设置它所能拦截的资源。 web.xml配置各节点介绍： 12345678910111213141516&lt;filter-name&gt;用于为过滤器指定一个名字，该元素的内容不能为空。&lt;filter-class&gt;元素用于指定过滤器的完整的限定类名。&lt;init-param&gt;元素用于为过滤器指定初始化参数，它的子元素&lt;param-name&gt;指定参数的名字，&lt;param-value&gt;指定参数的值。在过滤器中，可以使用FilterConfig接口对象来访问初始化参数。&lt;filter-mapping&gt;元素用于设置一个 Filter 所负责拦截的资源。一个Filter拦截的资源可通过两种方式来指定：Servlet 名称和资源访问的请求路径&lt;filter-name&gt;子元素用于设置filter的注册名称。该值必须是在&lt;filter&gt;元素中声明过的过滤器的名字&lt;url-pattern&gt;设置 filter 所拦截的请求路径(过滤器关联的URL样式)&lt;servlet-name&gt;指定过滤器所拦截的Servlet名称。&lt;dispatcher&gt;指定过滤器所拦截的资源被 Servlet 容器调用的方式，可以是REQUEST,INCLUDE,FORWARD和ERROR之一，默认REQUEST。用户可以设置多个&lt;dispatcher&gt; 子元素用来指定 Filter 对资源的多种调用方式进行拦截。&lt;dispatcher&gt; 子元素可以设置的值及其意义：REQUEST：当用户直接访问页面时，Web容器将会调用过滤器。如果目标资源是通过RequestDispatcher的include()或forward()方法访问时，那么该过滤器就不会被调用。INCLUDE：如果目标资源是通过RequestDispatcher的include()方法访问时，那么该过滤器将被调用。除此之外，该过滤器不会被调用。FORWARD：如果目标资源是通过RequestDispatcher的forward()方法访问时，那么该过滤器将被调用，除此之外，该过滤器不会被调用。ERROR：如果目标资源是通过声明式异常处理机制调用时，那么该过滤器将被调用。除此之外，过滤器不会被调用。 4、Filter链 在一个web应用中，可以开发编写多个Filter，这些Filter组合起来称之为一个Filter链。 web服务器根据Filter在web.xml文件中的注册顺序，决定先调用哪个Filter，当第一个Filter的doFilter方法被调用时，web服务器会创建一个代表Filter链的FilterChain对象传递给该方法。在doFilter方法中，开发人员如果调用了FilterChain对象的doFilter方法，则web服务器会检查FilterChain对象中是否还有filter，如果有，则调用第2个filter，如果没有，则调用目标资源。 多个过滤器执行顺序 一个目标资源可以指定多个过滤器，过滤器的执行顺序是在web.xml文件中的部署顺序： 12345678910111213141516&lt;filter&gt; &lt;filter-name&gt;myFilter1&lt;/filter-name&gt; &lt;filter-class&gt;cn.cloud.filter.MyFilter1&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;myFilter1&lt;/filter-name&gt; &lt;url-pattern&gt;/index.jsp&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;filter&gt; &lt;filter-name&gt;myFilter2&lt;/filter-name&gt; &lt;filter-class&gt;cn. cloud.filter.MyFilter2&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;myFilter2&lt;/filter-name&gt; &lt;url-pattern&gt;/index.jsp&lt;/url-pattern&gt; &lt;/filter-mapping&gt; MyFilter1 12345678public class MyFilter1 extends HttpFilter &#123; public void doFilter(HttpServletRequest request, HttpServletResponse response, FilterChain chain) throws IOException, ServletException &#123; System.out.println(\"filter1 start...\"); chain.doFilter(request, response);//放行，执行MyFilter2的doFilter()方法 System.out.println(\"filter1 end...\"); &#125;&#125; MyFilter2 12345678public class MyFilter2 extends HttpFilter &#123; public void doFilter(HttpServletRequest request, HttpServletResponse response, FilterChain chain) throws IOException, ServletException &#123; System.out.println(\"filter2 start...\"); chain.doFilter(request, response);//放行，执行目标资源 System.out.println(\"filter2 end...\"); &#125;&#125; 12345&lt;body&gt; This is my JSP page. &lt;br&gt; &lt;h1&gt;index.jsp&lt;/h1&gt; &lt;%System.out.println(\"index.jsp\"); %&gt; &lt;/body&gt; 当有用户访问index.jsp页面时，输出结果如下： 12345filter1 start...filter2 start...index.jspfilter2 end...filter1 end... 5、Filter的生命周期 1public void init(FilterConfig filterConfig) throws ServletException;//初始化 和我们编写的Servlet程序一样，Filter的创建和销毁由WEB服务器负责。 web 应用程序启动时，web 服务器将创建Filter 的实例对象，并调用其init方法，读取web.xml配置，完成对象的初始化功能，从而为后续的用户请求作好拦截的准备工作（filter对象只会创建一次，init方法也只会执行一次）。开发人员通过init方法的参数，可获得代表当前filter配置信息的FilterConfig对象。 1public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException;//拦截请求 这个方法完成实际的过滤操作。当客户请求访问与过滤器关联的URL（目标资源）的时候，Servlet过滤器将先执行doFilter方法。FilterChain参数用于访问后续过滤器。 1public void destroy();//销毁 服务器在创建Filter对象之后，把Filter放到缓存中一直使用（会驻留在内存），通常不会销毁它，当web应用移除或服务器停止时才销毁Filter对象。在Web容器卸载 Filter 对象之前被调用。该方法在Filter的生命周期中仅执行一次。在这个方法中，可以释放过滤器使用的资源。 6、FilterConfig接口 用户在配置filter时，可以使用为filter配置一些初始化参数，当web容器实例化Filter对象，调用其init方法时，会把封装了filter初始化参数的filterConfig对象传递进来。因此开发人员在编写filter时，通过filterConfig对象的方法，就可获得以下内容： 1234String getFilterName();//得到filter的名称；与&lt;filter-name&gt;元素对应。String getInitParameter(String name);//返回在部署描述中指定名称的初始化参数的值。如果不存在返回null，与&lt;init-param&gt;元素对应.Enumeration getInitParameterNames();//返回过滤器的所有初始化参数的名字的枚举集合。public ServletContext getServletContext();//返回Servlet上下文对象的引用。 7、FilterChain doFilter()方法的参数中有一个类型为FilterChain的参数，它只有一个方法：doFilter(ServletRequest,ServletResponse) doFilter() 方法的放行，让请求流访问目标资源！其实调用该方法的意思是，当前 Filter 放行了，但不代表其他过滤器也放行。一个目标资源上，可能部署了多个过滤器，所以调用 FilterChain 类的 doFilter() 方法表示的是执行下一个过滤器的 doFilter() 方法，或者是执行目标资源！ 如果当前过滤器是最后一个过滤器，那么调用 chain.doFilter() 方法表示执行目标资源，而不是最后一个过滤器，那么 chain.doFilter() 表示执行下一个过滤器的 doFilter() 方法。 8、过滤器的应用场景 执行目标资源之前做预处理工作，例如设置编码，这种试通常都会放行，只是在目标资源执行之前做一些准备工作； 通过条件判断是否放行，例如校验当前用户是否已经登录，或者用户IP是否已经被禁用； 在目标资源执行后，做一些后续的特殊处理工作，例如把目标资源输出的数据进行处理 设置目标资源 在web.xml文件中部署Filter时，可以通过“*”来执行目标资源： 1234&lt;filter-mapping&gt; &lt;filter-name&gt;myfilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; 特性与Servlet完全相同！通过这一特性，可以在用户访问敏感资源时，执行过滤器，例如：/admin/*，可以把所有管理员才能访问的资源放到/admin路径下，这时可以通过过滤器来校验用户身份。 还可以为指定目标资源为某个Servlet，例如： 12345678910111213141516&lt;servlet&gt; &lt;servlet-name&gt;myservlet&lt;/servlet-name&gt; &lt;servlet-class&gt;cn.cloud.servlet.MyServlet&lt;/servlet-class&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;myservlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/abc&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;filter&gt; &lt;filter-name&gt;myfilter&lt;/filter-name&gt; &lt;filter-class&gt;cn.cloud.filter.MyFilter&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;myfilter&lt;/filter-name&gt; &lt;servlet-name&gt;myservlet&lt;/servlet-name&gt; &lt;/filter-mapping&gt; 当用户访问http://localhost:8080/filtertest/abc时，会执行名字为myservlet的Servlet，这时会执行过滤器。 9、四种拦截方式 写一个过滤器，指定过滤的资源为b.jsp，然后在浏览器中直接访问b.jsp，会发现过滤器执行了.但是，当在a.jsp中request.getRequestDispathcer(“/b.jsp”).forward(request,response)时，就不会再执行过滤器了！也就是说，默认情况下，只能直接访问目标资源才会执行过滤器，而forward执行目标资源，不会执行过滤器！ 12345678public class MyFilter extends HttpFilter &#123; public void doFilter(HttpServletRequest request, HttpServletResponse response, FilterChain chain) throws IOException, ServletException &#123; System.out.println(\"myfilter...\"); chain.doFilter(request, response); &#125;&#125; 12345678&lt;filter&gt; &lt;filter-name&gt;myfilter&lt;/filter-name&gt; &lt;filter-class&gt;cn.itcast.filter.MyFilter&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;myfilter&lt;/filter-name&gt; &lt;url-pattern&gt;/b.jsp&lt;/url-pattern&gt; &lt;/filter-mapping&gt; 123&lt;body&gt; &lt;h1&gt;b.jsp&lt;/h1&gt; &lt;/body&gt; 12345&lt;h1&gt;a.jsp&lt;/h1&gt; &lt;% request.getRequestDispatcher(\"/b.jsp\").forward(request, response); %&gt; &lt;/body&gt; 在浏览器输入： http://localhost:8080/filtertest/b.jsp 直接访问b.jsp时，会执行过滤器内容； http://localhost:8080/filtertest/a.jsp 访问a.jsp，但a.jsp会forward到b.jsp，这时就不会执行过滤器！ 过滤器有四种拦截方式！分别是：REQUEST、FORWARD、INCLUDE、ERROR。 REQUEST：直接访问目标资源时执行过滤器。包括：在地址栏中直接访问、表单提交、超链接、重定向，只要在地址栏中可以看到目标资源的路径，就是REQUEST FORWARD：转发访问执行过滤器。包括RequestDispatcher#forward()方法、标签都是转发访问 INCLUDE：包含访问执行过滤器。包括RequestDispatcher#include()方法、标签都是包含访问 ERROR：当目标资源在web.xml中配置为中时，并且真的出现了异常，转发到目标资源时，会执行过滤器。 可以在中添加0~n个子元素，来说明当前访问的拦截方式。 如： 123456&lt;filter-mapping&gt; &lt;filter-name&gt;myfilter&lt;/filter-name&gt; &lt;url-pattern&gt;/b.jsp&lt;/url-pattern&gt; &lt;dispatcher&gt;REQUEST&lt;/dispatcher&gt; &lt;dispatcher&gt;FORWARD&lt;/dispatcher&gt; &lt;/filter-mapping&gt; 最为常用的就是REQUEST和FORWARD两种拦截方式，而INCLUDE和ERROR都比较少用！其中INCLUDE比较好理解，ERROR方式不易理解，下面给出ERROR拦截方式的例子： 123456789&lt;filter-mapping&gt; &lt;filter-name&gt;myfilter&lt;/filter-name&gt; &lt;url-pattern&gt;/b.jsp&lt;/url-pattern&gt; &lt;dispatcher&gt;ERROR&lt;/dispatcher&gt; &lt;/filter-mapping&gt; &lt;error-page&gt; &lt;error-code&gt;500&lt;/error-code&gt; &lt;location&gt;/b.jsp&lt;/location&gt; &lt;/error-page&gt; 1234567&lt;body&gt; &lt;h1&gt;a.jsp&lt;/h1&gt; &lt;% if(true) throw new RuntimeException(\"嘻嘻~\"); %&gt; &lt;/body&gt; 10、Filter使用案例 1、使用Filter验证用户登录安全控制 前段时间参与维护一个项目，用户退出系统后，再去地址栏访问历史，根据url，仍然能够进入系统响应页面。我去检查一下发现对请求未进行过滤验证用户登录。添加一个filter搞定问题！ 先在web.xml配置 123456789101112131415161718192021222324&lt;filter&gt; &lt;filter-name&gt;SessionFilter&lt;/filter-name&gt; &lt;filter-class&gt;com.action.login.SessionFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;logonStrings&lt;/param-name&gt;&lt;!-- 对登录页面不进行过滤 --&gt; &lt;param-value&gt;/project/index.jsp;login.do&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;includeStrings&lt;/param-name&gt;&lt;!-- 只对指定过滤参数后缀进行过滤 --&gt; &lt;param-value&gt;.do;.jsp&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;redirectPath&lt;/param-name&gt;&lt;!-- 未通过跳转到登录界面 --&gt; &lt;param-value&gt;/index.jsp&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;disabletestfilter&lt;/param-name&gt;&lt;!-- Y:过滤无效 --&gt; &lt;param-value&gt;N&lt;/param-value&gt; &lt;/init-param&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;SessionFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt; 接着编写FilterServlet： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576package com.action.login;import java.io.IOException;import javax.servlet.Filter;import javax.servlet.FilterChain;import javax.servlet.FilterConfig;import javax.servlet.ServletException;import javax.servlet.ServletRequest;import javax.servlet.ServletResponse;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import javax.servlet.http.HttpServletResponseWrapper;/** * 判断用户是否登录,未登录则退出系统 */public class SessionFilter implements Filter &#123; public FilterConfig config; public void destroy() &#123; this.config = null; &#125; public static boolean isContains(String container, String[] regx) &#123; boolean result = false; for (int i = 0; i &lt; regx.length; i++) &#123; if (container.indexOf(regx[i]) != -1) &#123; return true; &#125; &#125; return result; &#125; public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123; HttpServletRequest hrequest = (HttpServletRequest)request; HttpServletResponseWrapper wrapper = new HttpServletResponseWrapper((HttpServletResponse) response); String logonStrings = config.getInitParameter(\"logonStrings\"); // 登录登陆页面 String includeStrings = config.getInitParameter(\"includeStrings\"); // 过滤资源后缀参数 String redirectPath = hrequest.getContextPath() + config.getInitParameter(\"redirectPath\");// 没有登陆转向页面 String disabletestfilter = config.getInitParameter(\"disabletestfilter\");// 过滤器是否有效 if (disabletestfilter.toUpperCase().equals(\"Y\")) &#123; // 过滤无效 chain.doFilter(request, response); return; &#125; String[] logonList = logonStrings.split(\";\"); String[] includeList = includeStrings.split(\";\"); if (!this.isContains(hrequest.getRequestURI(), includeList)) &#123;// 只对指定过滤参数后缀进行过滤 chain.doFilter(request, response); return; &#125; if (this.isContains(hrequest.getRequestURI(), logonList)) &#123;// 对登录页面不进行过滤 chain.doFilter(request, response); return; &#125; String user = ( String ) hrequest.getSession().getAttribute(\"useronly\");//判断用户是否登录 if (user == null) &#123; wrapper.sendRedirect(redirectPath); return; &#125;else &#123; chain.doFilter(request, response); return; &#125; &#125; public void init(FilterConfig filterConfig) throws ServletException &#123; config = filterConfig; &#125;&#125; 这样既可完成对用户所有请求，均要经过这个Filter进行验证用户登录。 2、防止中文乱码过滤器 项目使用spring框架时。当前台JSP页面和JAVA代码中使用了不同的字符集进行编码的时候就会出现表单提交的数据或者上传/下载中文名称文件出现乱码的问题，那就可以使用这个过滤器。 12345678910111213141516&lt;filter&gt; &lt;filter-name&gt;encoding&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt;&lt;!--用来指定一个具体的字符集--&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;forceEncoding&lt;/param-name&gt;&lt;!--true：无论request是否指定了字符集，都是用encoding；false：如果request已指定一个字符集，则不使用encoding--&gt; &lt;param-value&gt;false&lt;/param-value&gt; &lt;/init-param&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;encoding&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt; 3、Spring+Hibernate的OpenSessionInViewFilter控制session的开关 当 hibernate+spring 配合使用的时候，如果设置了lazy=true（延迟加载）,那么在读取数据的时候，当读取了父数据后，hibernate 会自动关闭 session，这样，当要使用与之关联数据、子数据的时候，系统会抛出lazyinit的错误，这时就需要使用 spring 提供的 OpenSessionInViewFilter 过滤器。 OpenSessionInViewFilter主要是保持 Session 状态直到 request 将全部页面发送到客户端，直到请求结束后才关闭 session，这样就可以解决延迟加载带来的问题。 注意：OpenSessionInViewFilter 配置要写在struts2的配置前面。因为 tomcat 容器在加载过滤器的时候是按照顺序加载的，如果配置文件先写的是 struts2 的过滤器配置，然后才是 OpenSessionInViewFilter 过滤器配置，所以加载的顺序导致，action 在获得数据的时候 session 并没有被 spring 管理。 1234567891011121314151617&lt;!-- lazy loading enabled in spring --&gt;&lt;filter&gt; &lt;filter-name&gt;OpenSessionInViewFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.orm.hibernate3.support.OpenSessionInViewFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;sessionFactoryBeanName&lt;/param-name&gt;&lt;!-- 可缺省。默认是从spring容器中找id为sessionFactory的bean，如果id不为sessionFactory，则需要配置如下，此处SessionFactory为spring容器中的bean。 --&gt; &lt;param-value&gt;sessionFactory&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;singleSession&lt;/param-name&gt;&lt;!-- singleSession默认为true,若设为false则等于没用OpenSessionInView --&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;OpenSessionInViewFilter&lt;/filter-name&gt; &lt;url-pattern&gt;*.do&lt;/url-pattern&gt;&lt;/filter-mapping&gt; 4、Struts2的web.xml配置 项目中使用Struts2同样需要在web.xml配置过滤器，用来截取请求，转到Struts2的Action进行处理。 注意：如果在2.1.3以前的Struts2版本，过滤器使用org.apache.struts2.dispatcher.FilterDispatcher。否则使用org.apache.struts2.dispatcher.ng.filter.StrutsPrepareAndExecuteFilter。从Struts2.1.3开始，将废弃ActionContextCleanUp过滤器，而在StrutsPrepareAndExecuteFilter过滤器中包含相应的功能。 三个初始化参数配置： config参数：指定要加载的配置文件。逗号分割。 actionPackages参数：指定Action类所在的包空间。逗号分割。 configProviders参数：自定义配置文件提供者，需要实现ConfigurationProvider接口类。逗号分割。 123456789&lt;!-- struts 2.x filter --&gt;&lt;filter&gt; &lt;filter-name&gt;struts2&lt;/filter-name&gt; &lt;filter-class&gt;org.apache.struts2.dispatcher.ng.filter.StrutsPrepareAndExecuteFilter&lt;/filter-class&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;struts2&lt;/filter-name&gt; &lt;url-pattern&gt;*.do&lt;/url-pattern&gt;&lt;/filter-mapping&gt;","tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"Filter过滤器","slug":"Filter过滤器","permalink":"http://yoursite.com/tags/Filter过滤器/"}]},{"title":"Pyspider框架 —— Python爬虫实战之爬取 V2EX 网站帖子","date":"2017-03-26T17:01:51.117Z","path":"2017/03/27/Pyspider框架 —— Python爬虫实战之爬取 V2EX 网站帖子/","text":"背景： PySpider：一个国人编写的强大的网络爬虫系统并带有强大的WebUI。采用Python语言编写，分布式架构，支持多种数据库后端，强大的WebUI支持脚本编辑器，任务监视器，项目管理器以及结果查看器。在线示例： http://demo.pyspider.org/ 官方文档： http://docs.pyspider.org/en/latest/ Github : https://github.com/binux/pyspider 本文爬虫代码 Github 地址：https://github.com/zhisheng17/Python-Projects/blob/master/v2ex/V2EX.py 说了这么多，我们还是来看正文吧！ 前提: 你已经安装好了Pyspider 和 MySQL-python（保存数据） 如果你还没安装的话，请看看我的前一篇文章，防止你也走弯路。 Pyspider 框架学习时走过的一些坑 HTTP 599: SSL certificate problem: unable to get local issuer certificate错误 我所遇到的一些错误： 首先，本爬虫目标：使用 Pyspider 框架爬取 V2EX 网站的帖子中的问题和内容，然后将爬取的数据保存在本地。 V2EX 中大部分的帖子查看是不需要登录的，当然也有些帖子是需要登陆后才能够查看的。（因为后来爬取的时候发现一直 error ，查看具体原因后才知道是需要登录的才可以查看那些帖子的）所以我觉得没必要用到 Cookie，当然如果你非得要登录，那也很简单，简单地方法就是添加你登录后的 cookie 了。 我们在 https://www.v2ex.com/ 扫了一遍，发现并没有一个列表能包含所有的帖子，只能退而求其次，通过抓取分类下的所有的标签列表页，来遍历所有的帖子： https://www.v2ex.com/?tab=tech 然后是 https://www.v2ex.com/go/programmer 最后每个帖子的详情地址是 （举例）： https://www.v2ex.com/t/314683#reply1 创建一个项目 在 pyspider 的 dashboard 的右下角，点击 “Create” 按钮 替换 on_start 函数的 self.crawl 的 URL： 123@every(minutes=24 * 60) def on_start(self): self.crawl(&apos;https://www.v2ex.com/&apos;, callback=self.index_page, validate_cert=False) self.crawl 告诉 pyspider 抓取指定页面，然后使用 callback 函数对结果进行解析。 @every) 修饰器，表示 on_start 每天会执行一次，这样就能抓到最新的帖子了。 validate_cert=False 一定要这样，否则会报 HTTP 599: SSL certificate problem: unable to get local issuer certificate错误 首页： 点击绿色的 run 执行，你会看到 follows 上面有一个红色的 1，切换到 follows 面板，点击绿色的播放按钮： 第二张截图一开始是出现这个问题了，解决办法看前面写的文章，后来问题就不再会出现了。 Tab 列表页 : 在 tab 列表页 中，我们需要提取出所有的主题列表页 的 URL。你可能已经发现了，sample handler 已经提取了非常多大的 URL 代码：1234@config(age=10 * 24 * 60 * 60) def index_page(self, response): for each in response.doc(&apos;a[href^=&quot;https://www.v2ex.com/?tab=&quot;]&apos;).items(): self.crawl(each.attr.href, callback=self.tab_page, validate_cert=False) 由于帖子列表页和 tab列表页长的并不一样，在这里新建了一个 callback 为 self.tab_page @config(age=10 24 60 * 60) 在这表示我们认为 10 天内页面有效，不会再次进行更新抓取 Go列表页 : 代码： 1234@config(age=10 * 24 * 60 * 60) def tab_page(self, response): for each in response.doc(&apos;a[href^=&quot;https://www.v2ex.com/go/&quot;]&apos;).items(): self.crawl(each.attr.href, callback=self.board_page, validate_cert=False) 帖子详情页（T）: 你可以看到结果里面出现了一些reply的东西，对于这些我们是可以不需要的，我们可以去掉。 同时我们还需要让他自己实现自动翻页功能。 代码：123456789@config(age=10 * 24 * 60 * 60) def board_page(self, response): for each in response.doc(&apos;a[href^=&quot;https://www.v2ex.com/t/&quot;]&apos;).items(): url = each.attr.href if url.find(&apos;#reply&apos;)&gt;0: url = url[0:url.find(&apos;#&apos;)] self.crawl(url, callback=self.detail_page, validate_cert=False) for each in response.doc(&apos;a.page_normal&apos;).items(): self.crawl(each.attr.href, callback=self.board_page, validate_cert=False) #实现自动翻页功能 去掉后的运行截图： 实现自动翻页后的截图： 此时我们已经可以匹配了所有的帖子的 url 了。 点击每个帖子后面的按钮就可以查看帖子具体详情了。 代码： 12345678910@config(priority=2) def detail_page(self, response): title = response.doc(&apos;h1&apos;).text() content = response.doc(&apos;div.topic_content&apos;).html().replace(&apos;&quot;&apos;, &apos;\\\\&quot;&apos;) self.add_question(title, content) #插入数据库 return &#123; &quot;url&quot;: response.url, &quot;title&quot;: title, &quot;content&quot;: content, &#125; 插入数据库的话，需要我们在之前定义一个add_question函数。 123456789101112131415#连接数据库def __init__(self): self.db = MySQLdb.connect(&apos;localhost&apos;, &apos;root&apos;, &apos;root&apos;, &apos;wenda&apos;, charset=&apos;utf8&apos;) def add_question(self, title, content): try: cursor = self.db.cursor() sql = &apos;insert into question(title, content, user_id, created_date, comment_count) values (&quot;%s&quot;,&quot;%s&quot;,%d, %s, 0)&apos; % (title, content, random.randint(1, 10) , &apos;now()&apos;); #插入数据库的SQL语句 print sql cursor.execute(sql) print cursor.lastrowid self.db.commit() except Exception, e: print e self.db.rollback() 查看爬虫运行结果： 先debug下，再调成running。pyspider框架在windows下的bug 设置跑的速度，建议不要跑的太快，否则很容易被发现是爬虫的，人家就会把你的IP给封掉的 查看运行工作 查看爬取下来的内容 然后再本地数据库GUI软件上查询下就可以看到数据已经保存到本地了。 自己需要用的话就可以导入出来了。 在开头我就告诉大家爬虫的代码了，如果详细的看看那个project，你就会找到我上传的爬取数据了。（仅供学习使用，切勿商用！） 当然你还会看到其他的爬虫代码的了，如果你觉得不错可以给个 Star，或者你也感兴趣的话，你可以fork我的项目，和我一起学习，这个项目长期更新下去。 最后： 代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869# created by 10412# !/usr/bin/env python# -*- encoding: utf-8 -*-# Created on 2016-10-20 20:43:00# Project: V2EXfrom pyspider.libs.base_handler import *import reimport randomimport MySQLdbclass Handler(BaseHandler): crawl_config = &#123; &#125; def __init__(self): self.db = MySQLdb.connect(&apos;localhost&apos;, &apos;root&apos;, &apos;root&apos;, &apos;wenda&apos;, charset=&apos;utf8&apos;) def add_question(self, title, content): try: cursor = self.db.cursor() sql = &apos;insert into question(title, content, user_id, created_date, comment_count) values (&quot;%s&quot;,&quot;%s&quot;,%d, %s, 0)&apos; % (title, content, random.randint(1, 10) , &apos;now()&apos;); print sql cursor.execute(sql) print cursor.lastrowid self.db.commit() except Exception, e: print e self.db.rollback() @every(minutes=24 * 60) def on_start(self): self.crawl(&apos;https://www.v2ex.com/&apos;, callback=self.index_page, validate_cert=False) @config(age=10 * 24 * 60 * 60) def index_page(self, response): for each in response.doc(&apos;a[href^=&quot;https://www.v2ex.com/?tab=&quot;]&apos;).items(): self.crawl(each.attr.href, callback=self.tab_page, validate_cert=False) @config(age=10 * 24 * 60 * 60) def tab_page(self, response): for each in response.doc(&apos;a[href^=&quot;https://www.v2ex.com/go/&quot;]&apos;).items(): self.crawl(each.attr.href, callback=self.board_page, validate_cert=False) @config(age=10 * 24 * 60 * 60) def board_page(self, response): for each in response.doc(&apos;a[href^=&quot;https://www.v2ex.com/t/&quot;]&apos;).items(): url = each.attr.href if url.find(&apos;#reply&apos;)&gt;0: url = url[0:url.find(&apos;#&apos;)] self.crawl(url, callback=self.detail_page, validate_cert=False) for each in response.doc(&apos;a.page_normal&apos;).items(): self.crawl(each.attr.href, callback=self.board_page, validate_cert=False) @config(priority=2) def detail_page(self, response): title = response.doc(&apos;h1&apos;).text() content = response.doc(&apos;div.topic_content&apos;).html().replace(&apos;&quot;&apos;, &apos;\\\\&quot;&apos;) self.add_question(title, content) #插入数据库 return &#123; &quot;url&quot;: response.url, &quot;title&quot;: title, &quot;content&quot;: content, &#125;","tags":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/tags/Python/"},{"name":"爬虫","slug":"爬虫","permalink":"http://yoursite.com/tags/爬虫/"},{"name":"Pyspider","slug":"Pyspider","permalink":"http://yoursite.com/tags/Pyspider/"}]},{"title":"深入分析 Java Web 中的中文编码问题","date":"2017-03-26T16:39:33.504Z","path":"2017/03/27/深入分析 Java Web 中的中文编码问题/","text":"背景： 编码问题一直困扰着程序开发人员，尤其是在 Java 中更加明显，因为 Java 是跨平台的语言，在不同平台的编码之间的切换较多。接下来将介绍 Java 编码问题出现的根本原因；在 Java 中经常遇到的几种编码格式的区别；在 Java 中经常需要编码的场景；出现中文问题的原因分析；在开发 Java Web 中可能存在编码的几个地方；一个 HTTP 请求怎么控制编码格式；如何避免出现中文编码问题等。 1、几种常见的编码格式1.1 为什么要编码 在计算机中存储信息的最小单元是 1 个字节，即 8 个 bit， 所以能表示的字符范围是 0 ~ 255 个。 要表示的符号太多，无法用 1 个字节来完全表示。 1.2 如何翻译计算机中提供多种翻译方式，常见的有 ASCII、ISO-8859-1、GB2312、GBK、UTF-8、UTF-16等。这些都规定了转化的规则，按照这个规则就可以让计算机正确的表示我们的字符。下面介绍这几种编码格式： ASCII 码 总共有 128 个，用 1 个字节的低 7 位表示， 0 ~ 31 是控制字符如换行、回车、删除等，32 ~ 126 是打印字符，可以通过键盘输入并且能够显示出来。 ISO-8859-1 128 个字符显然是不够用的，所以 ISO 组织在 ASCII 的基础上扩展，他们是 ISO-8859-1 至 ISO-8859-15，前者涵盖大多数字符，应用最广。ISO-8859-1 仍是单字节编码，它总归能表示 256 个字符。 GB2312 它是双字节编码，总的编码范围是 A1 ~ F7，其中 A1 ~ A9 是符号区，总共包含 682 个符号；B0 ~ F7 是汉字区，包含 6763 个汉字。 GBk GBK 为《汉字内码扩展规范》，为 GB2312 的扩展，它的编码范围是 8140 ~ FEFE（去掉XX7F），总共有 23940 个码位，能表示 21003 个汉字，和 GB2312的编码兼容，不会有乱码。 UTF-16 它具体定义了 Unicode 字符在计算机中的存取方法。UTF-16 用两个字节来表示 Unicode 的转化格式，它采用定长的表示方法，即不论什么字符用两个字节表示。两个字节是 16 个 bit，所以叫 UTF-16。它表示字符非常方便，没两个字节表示一个字符，这就大大简化了字符串操作。 UTF-8 虽说 UTF-16 统一采用两个字节表示一个字符很简单方便，但是很大一部分字符用一个字节就可以表示，如果用两个字节表示，存储空间放大了一倍，在网络带宽有限的情况下会增加网络传输的流量。UTF-8 采用了一种变长技术，每个编码区域有不同的字码长度不同类型的字符可以由 1 ~ 6 个字节组成。 UTF-8 有以下编码规则： 如果是 1 个字节，最高位（第 8 位）为 0，则表示这是一个 ASCII 字符（00 ~ 7F） 如果是 1 个字节，以 11 开头，则连续的 1 的个数暗示这个字符的字节数 如果是 1 个字节，以 10 开头，表示它不是首字节，则需要向前查找才能得到当前字符的首字节 ​ 2、在 Java 中需要编码的场景2.1 在 I/O 操作中存在的编码 如上图：Reader 类是在 Java 的 I/O 中读取符的父类，而 InputStream 类是读字节的父类， InputStreamReader 类就是关联字节到字符的桥梁，它负责在 I/O 过程中处理读取字节到字符的转换，而对具体字节到字符的解码实现，它又委托 StreamDecoder 去做，在 StreamDecoder 解码过程中必须由用户指定 Charset 编码格式。值得注意的是，如果你没有指定 Charset，则将使用本地环境中默认的字符集，如在中文环境中将使用 GBK 编码。 如下面一段代码，实现了文件的读写功能： 12345678910111213141516171819202122232425String file = \"c:/stream.txt\";String charset = \"UTF-8\";// 写字符换转成字节流FileOutputStream outputStream = new FileOutputStream(file);OutputStreamWriter writer = new OutputStreamWriter(outputStream, charset);try &#123; writer.write(\"这是要保存的中文字符\");&#125; finally &#123; writer.close();&#125;// 读取字节转换成字符FileInputStream inputStream = new FileInputStream(file);InputStreamReader reader = new InputStreamReader(inputStream, charset);StringBuffer buffer = new StringBuffer();char[] buf = new char[64];int count = 0;try &#123; while ((count = reader.read(buf)) != -1) &#123; buffer.append(buffer, 0, count); &#125;&#125; finally &#123; reader.close();&#125; 在我们的应用程序中涉及 I/O 操作时，只要注意指定统一的编解码 Charset 字符集，一般不会出现乱码问题。 2.2 在内存操作中的编码在内存中进行从字符到字节的数据类型转换。 1、String 类提供字符串转换到字节的方法，也支持将字节转换成字符串的构造函数。 123String s = \"字符串\"；byte[] b = s.getBytes(\"UTF-8\");String n = new String(b, \"UTF-8\"); 2、Charset 提供 encode 与 decode，分别对应 char[] 到 byte[] 的编码 和 byte[] 到 char[] 的解码。 123Charset charset = Charset.forName(\"UTF-8\");ByteBuffer byteBuffer = charset.encode(string);CharBuffer charBuffer = charset.decode(byteBuffer); … 3、在 Java 中如何编解码Java 编码类图 首先根据指定的 charsetName 通过 Charset.forName(charsetName) 设置 Charset 类，然后根据 Charset 创建 CharsetEncoder 对象，再调用 CharsetEncoder.encode 对字符串进行编码，不同的编码类型都会对应到一个类中，实际的编码过程是在这些类中完成的。下面是 String. getBytes(charsetName) 编码过程的时序图 Java 编码时序图 从上图可以看出根据 charsetName 找到 Charset 类，然后根据这个字符集编码生成 CharsetEncoder，这个类是所有字符编码的父类，针对不同的字符编码集在其子类中定义了如何实现编码，有了 CharsetEncoder 对象后就可以调用 encode 方法去实现编码了。这个是 String.getBytes 编码方法，其它的如 StreamEncoder 中也是类似的方式。 经常会出现中文变成“？”很可能就是错误的使用了 ISO-8859-1 这个编码导致的。中文字符经过 ISO-8859-1 编码会丢失信息，通常我们称之为“黑洞”，它会把不认识的字符吸收掉。由于现在大部分基础的 Java 框架或系统默认的字符集编码都是 ISO-8859-1，所以很容易出现乱码问题，后面将会分析不同的乱码形式是怎么出现的。 几种编码格式的比较对中文字符后面四种编码格式都能处理，GB2312 与 GBK 编码规则类似，但是 GBK 范围更大，它能处理所有汉字字符，所以 GB2312 与 GBK 比较应该选择 GBK。UTF-16 与 UTF-8 都是处理 Unicode 编码，它们的编码规则不太相同，相对来说 UTF-16 编码效率最高，字符到字节相互转换更简单，进行字符串操作也更好。它适合在本地磁盘和内存之间使用，可以进行字符和字节之间快速切换，如 Java 的内存编码就是采用 UTF-16 编码。但是它不适合在网络之间传输，因为网络传输容易损坏字节流，一旦字节流损坏将很难恢复，想比较而言 UTF-8 更适合网络传输，对 ASCII 字符采用单字节存储，另外单个字符损坏也不会影响后面其它字符，在编码效率上介于 GBK 和 UTF-16 之间，所以 UTF-8 在编码效率上和编码安全性上做了平衡，是理想的中文编码方式。 4、在 Java Web 中涉及的编解码对于使用中文来说，有 I/O 的地方就会涉及到编码，前面已经提到了 I/O 操作会引起编码，而大部分 I/O 引起的乱码都是网络 I/O，因为现在几乎所有的应用程序都涉及到网络操作，而数据经过网络传输都是以字节为单位的，所以所有的数据都必须能够被序列化为字节。在 Java 中数据被序列化必须继承 Serializable 接口。 一段文本它的实际大小应该怎么计算，我曾经碰到过一个问题：就是要想办法压缩 Cookie 大小，减少网络传输量，当时有选择不同的压缩算法，发现压缩后字符数是减少了，但是并没有减少字节数。所谓的压缩只是将多个单字节字符通过编码转变成一个多字节字符。减少的是 String.length()，而并没有减少最终的字节数。例如将“ab”两个字符通过某种编码转变成一个奇怪的字符，虽然字符数从两个变成一个，但是如果采用 UTF-8 编码这个奇怪的字符最后经过编码可能又会变成三个或更多的字节。同样的道理比如整型数字 1234567 如果当成字符来存储，采用 UTF-8 来编码占用 7 个 byte，采用 UTF-16 编码将会占用 14 个 byte，但是把它当成 int 型数字来存储只需要 4 个 byte 来存储。所以看一段文本的大小，看字符本身的长度是没有意义的，即使是一样的字符采用不同的编码最终存储的大小也会不同，所以从字符到字节一定要看编码类型。 我们能够看到的汉字都是以字符形式出现的，例如在 Java 中“淘宝”两个字符，它在计算机中的数值 10 进制是 28120 和 23453，16 进制是 6bd8 和 5d9d，也就是这两个字符是由这两个数字唯一表示的。Java 中一个 char 是 16 个 bit 相当于两个字节，所以两个汉字用 char 表示在内存中占用相当于四个字节的空间。 这两个问题搞清楚后，我们看一下 Java Web 中那些地方可能会存在编码转换？ 用户从浏览器端发起一个 HTTP 请求，需要存在编码的地方是 URL、Cookie、Parameter。服务器端接受到 HTTP 请求后要解析 HTTP 协议，其中 URI、Cookie 和 POST 表单参数需要解码，服务器端可能还需要读取数据库中的数据，本地或网络中其它地方的文本文件，这些数据都可能存在编码问题，当 Servlet 处理完所有请求的数据后，需要将这些数据再编码通过 Socket 发送到用户请求的浏览器里，再经过浏览器解码成为文本。这些过程如下图所示： 一次 HTTP 请求的编码示例 4.1 URL 的编解码用户提交一个 URL，这个 URL 中可能存在中文，因此需要编码，如何对这个 URL 进行编码？根据什么规则来编码？有如何来解码？如下图一个 URL： 上图中以 Tomcat 作为 Servlet Engine 为例，它们分别对应到下面这些配置文件中：Port 对应在 Tomcat 的 中配置，而 Context Path 在 中配置，Servlet Path 在 Web 应用的 web.xml 中的 1234&lt;servlet-mapping&gt; &lt;servlet-name&gt;junshanExample&lt;/servlet-name&gt; &lt;url-pattern&gt;/servlets/servlet/*&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; 中配置，PathInfo 是我们请求的具体的 Servlet，QueryString 是要传递的参数，注意这里是在浏览器里直接输入 URL 所以是通过 Get 方法请求的，如果是 POST 方法请求的话，QueryString 将通过表单方式提交到服务器端。 上图中 PathInfo 和 QueryString 出现了中文，当我们在浏览器中直接输入这个 URL 时，在浏览器端和服务端会如何编码和解析这个 URL 呢？为了验证浏览器是怎么编码 URL 的我选择的是360极速浏览器并通过 Postman 插件观察我们请求的 URL 的实际的内容，以下是 URL： HTTP://localhost:8080/examples/servlets/servlet/君山?author=君山 君山的编码结果是：e5 90 9b e5 b1 b1，和《深入分析 Java Web 技术内幕》中的结果不一样，这是因为我使用的浏览器和插件和原作者是有区别的，那么这些浏览器之间的默认编码是不一样的，原文中的结果是： 君山的编码结果分别是：e5 90 9b e5 b1 b1，be fd c9 bd，查阅上一届的编码可知，PathInfo 是 UTF-8 编码而 QueryString 是经过 GBK 编码，至于为什么会有“%”？查阅 URL 的编码规范 RFC3986 可知浏览器编码 URL 是将非 ASCII 字符按照某种编码格式编码成 16 进制数字然后将每个 16 进制表示的字节前加上“%”，所以最终的 URL 就成了上图的格式了。 从上面测试结果可知浏览器对 PathInfo 和 QueryString 的编码是不一样的，不同浏览器对 PathInfo 也可能不一样，这就对服务器的解码造成很大的困难，下面我们以 Tomcat 为例看一下，Tomcat 接受到这个 URL 是如何解码的。 解析请求的 URL 是在 org.apache.coyote.HTTP11.InternalInputBuffer 的 parseRequestLine 方法中，这个方法把传过来的 URL 的 byte[] 设置到 org.apache.coyote.Request 的相应的属性中。这里的 URL 仍然是 byte 格式，转成 char 是在 org.apache.catalina.connector.CoyoteAdapter 的 convertURI 方法中完成的： 12345678910111213141516171819202122232425262728293031323334protected void convertURI(MessageBytes uri, Request request) throws Exception &#123; ByteChunk bc = uri.getByteChunk(); int length = bc.getLength(); CharChunk cc = uri.getCharChunk(); cc.allocate(length, -1); String enc = connector.getURIEncoding(); if (enc != null) &#123; B2CConverter conv = request.getURIConverter(); try &#123; if (conv == null) &#123; conv = new B2CConverter(enc); request.setURIConverter(conv); &#125; &#125; catch (IOException e) &#123;...&#125; if (conv != null) &#123; try &#123; conv.convert(bc, cc, cc.getBuffer().length - cc.getEnd()); uri.setChars(cc.getBuffer(), cc.getStart(), cc.getLength()); return; &#125; catch (IOException e) &#123;...&#125; &#125; &#125; // Default encoding: fast conversion byte[] bbuf = bc.getBuffer(); char[] cbuf = cc.getBuffer(); int start = bc.getStart(); for (int i = 0; i &lt; length; i++) &#123; cbuf[i] = (char) (bbuf[i + start] &amp; 0xff); &#125; uri.setChars(cbuf, 0, length); &#125; 从上面的代码中可以知道对 URL 的 URI 部分进行解码的字符集是在 connector 的 中定义的，如果没有定义，那么将以默认编码 ISO-8859-1 解析。所以如果有中文 URL 时最好把 URIEncoding 设置成 UTF-8 编码。 QueryString 又如何解析？ GET 方式 HTTP 请求的 QueryString 与 POST 方式 HTTP 请求的表单参数都是作为 Parameters 保存，都是通过 request.getParameter 获取参数值。对它们的解码是在 request.getParameter 方法第一次被调用时进行的。request.getParameter 方法被调用时将会调用 org.apache.catalina.connector.Request 的 parseParameters 方法。这个方法将会对 GET 和 POST 方式传递的参数进行解码，但是它们的解码字符集有可能不一样。POST 表单的解码将在后面介绍，QueryString 的解码字符集是在哪定义的呢？它本身是通过 HTTP 的 Header 传到服务端的，并且也在 URL 中，是否和 URI 的解码字符集一样呢？从前面浏览器对 PathInfo 和 QueryString 的编码采取不同的编码格式不同可以猜测到解码字符集肯定也不会是一致的。的确是这样 QueryString 的解码字符集要么是 Header 中 ContentType 中定义的 Charset 要么就是默认的 ISO-8859-1，要使用 ContentType 中定义的编码就要设置 connector 的 中的 useBodyEncodingForURI 设置为 true。这个配置项的名字有点让人产生混淆，它并不是对整个 URI 都采用 BodyEncoding 进行解码而仅仅是对 QueryString 使用 BodyEncoding 解码，这一点还要特别注意。 从上面的 URL 编码和解码过程来看，比较复杂，而且编码和解码并不是我们在应用程序中能完全控制的，所以在我们的应用程序中应该尽量避免在 URL 中使用非 ASCII 字符，不然很可能会碰到乱码问题，当然在我们的服务器端最好设置 中的 URIEncoding 和 useBodyEncodingForURI 两个参数。 4.2 HTTP Header 的编解码当客户端发起一个 HTTP 请求除了上面的 URL 外还可能会在 Header 中传递其它参数如 Cookie、redirectPath 等，这些用户设置的值很可能也会存在编码问题，Tomcat 对它们又是怎么解码的呢？ 对 Header 中的项进行解码也是在调用 request.getHeader 是进行的，如果请求的 Header 项没有解码则调用 MessageBytes 的 toString 方法，这个方法将从 byte 到 char 的转化使用的默认编码也是 ISO-8859-1，而我们也不能设置 Header 的其它解码格式，所以如果你设置 Header 中有非 ASCII 字符解码肯定会有乱码。 我们在添加 Header 时也是同样的道理，不要在 Header 中传递非 ASCII 字符，如果一定要传递的话，我们可以先将这些字符用 org.apache.catalina.util.URLEncoder 编码然后再添加到 Header 中，这样在浏览器到服务器的传递过程中就不会丢失信息了，如果我们要访问这些项时再按照相应的字符集解码就好了。 4.3 POST 表单的编解码在前面提到了 POST 表单提交的参数的解码是在第一次调用 request.getParameter 发生的，POST 表单参数传递方式与 QueryString 不同，它是通过 HTTP 的 BODY 传递到服务端的。当我们在页面上点击 submit 按钮时浏览器首先将根据 ContentType 的 Charset 编码格式对表单填的参数进行编码然后提交到服务器端，在服务器端同样也是用 ContentType 中字符集进行解码。所以通过 POST 表单提交的参数一般不会出现问题，而且这个字符集编码是我们自己设置的，可以通过 request.setCharacterEncoding(charset) 来设置。 另外针对 multipart/form-data 类型的参数，也就是上传的文件编码同样也是使用 ContentType 定义的字符集编码，值得注意的地方是上传文件是用字节流的方式传输到服务器的本地临时目录，这个过程并没有涉及到字符编码，而真正编码是在将文件内容添加到 parameters 中，如果用这个编码不能编码时将会用默认编码 ISO-8859-1 来编码。 4.4 HTTP BODY 的编解码当用户请求的资源已经成功获取后，这些内容将通过 Response 返回给客户端浏览器，这个过程先要经过编码再到浏览器进行解码。这个过程的编解码字符集可以通过 response.setCharacterEncoding 来设置，它将会覆盖 request.getCharacterEncoding 的值，并且通过 Header 的 Content-Type 返回客户端，浏览器接受到返回的 socket 流时将通过 Content-Type 的 charset 来解码，如果返回的 HTTP Header 中 Content-Type 没有设置 charset，那么浏览器将根据 Html 的 中的 charset 来解码。如果也没有定义的话，那么浏览器将使用默认的编码来解码。 4.5 其它需要编码的地方除了 URL 和参数编码问题外，在服务端还有很多地方可能存在编码，如可能需要读取 xml、velocity 模版引擎、JSP 或者从数据库读取数据等。xml 文件可以通过设置头来制定编码格式 1&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; Velocity 模版设置编码格式： 1services.VelocityService.input.encoding=UTF-8 JSP 设置编码格式： 1&lt;%@page contentType=&quot;text/html; charset=UTF-8&quot;%&gt; 访问数据库都是通过客户端 JDBC 驱动来完成，用 JDBC 来存取数据要和数据的内置编码保持一致，可以通过设置 JDBC URL 来制定如 MySQL：url=”jdbc:mysql://localhost:3306/DB?useUnicode=true&amp;characterEncoding=GBK”。 5、常见问题分析下面看一下，当我们碰到一些乱码时，应该怎么处理这些问题？出现乱码问题唯一的原因都是在 char 到 byte 或 byte 到 char 转换中编码和解码的字符集不一致导致的，由于往往一次操作涉及到多次编解码，所以出现乱码时很难查找到底是哪个环节出现了问题，下面就几种常见的现象进行分析。 5.1 中文变成了看不懂的字符例如，字符串“淘！我喜欢！”变成了“Ì Ô £ ¡Î Ò Ï²»¶ £ ¡”编码过程如下图所示： 字符串在解码时所用的字符集与编码字符集不一致导致汉字变成了看不懂的乱码，而且是一个汉字字符变成两个乱码字符。 5.2 一个汉字变成一个问号例如，字符串“淘！我喜欢！”变成了“？？？？？？”编码过程如下图所示: 将中文和中文符号经过不支持中文的 ISO-8859-1 编码后，所有字符变成了“？”，这是因为用 ISO-8859-1 进行编解码时遇到不在码值范围内的字符时统一用 3f 表示，这也就是通常所说的“黑洞”，所有 ISO-8859-1 不认识的字符都变成了“？”。 5.3 一个汉字变成两个问号例如，字符串“淘！我喜欢！”变成了“？？？？？？？？？？？？”编码过程如下图所示: 这种情况比较复杂，中文经过多次编码，但是其中有一次编码或者解码不对仍然会出现中文字符变成“？”现象，出现这种情况要仔细查看中间的编码环节，找出出现编码错误的地方。 5.4 一种不正常的正确编码还有一种情况是在我们通过 request.getParameter 获取参数值时，当我们直接调用 String value = request.getParameter(name); 会出现乱码，但是如果用下面的方式 String value = String(request.getParameter(name).getBytes(&quot; ISO-8859-1&quot;), &quot;GBK&quot;); 解析时取得的 value 会是正确的汉字字符，这种情况是怎么造成的呢？ 看下如所示： 这种情况是这样的，ISO-8859-1 字符集的编码范围是 0000-00FF，正好和一个字节的编码范围相对应。这种特性保证了使用 ISO-8859-1 进行编码和解码可以保持编码数值“不变”。虽然中文字符在经过网络传输时，被错误地“拆”成了两个欧洲字符，但由于输出时也是用 ISO-8859-1，结果被“拆”开的中文字的两半又被合并在一起，从而又刚好组成了一个正确的汉字。虽然最终能取得正确的汉字，但是还是不建议用这种不正常的方式取得参数值，因为这中间增加了一次额外的编码与解码，这种情况出现乱码时因为 Tomcat 的配置文件中 useBodyEncodingForURI 配置项没有设置为”true”，从而造成第一次解析式用 ISO-8859-1 来解析才造成乱码的。 6、总结本文首先总结了几种常见编码格式的区别，然后介绍了支持中文的几种编码格式，并比较了它们的使用场景。接着介绍了 Java 那些地方会涉及到编码问题，已经 Java 中如何对编码的支持。并以网络 I/O 为例重点介绍了 HTTP 请求中的存在编码的地方，以及 Tomcat 对 HTTP 协议的解析，最后分析了我们平常遇到的乱码问题出现的原因。 综上所述，要解决中文问题，首先要搞清楚哪些地方会引起字符到字节的编码以及字节到字符的解码，最常见的地方就是读取会存储数据到磁盘，或者数据要经过网络传输。然后针对这些地方搞清楚操作这些数据的框架的或系统是如何控制编码的，正确设置编码格式，避免使用软件默认的或者是操作系统平台默认的编码格式。 注明：文章大部分参考书籍《深入 Java Web 技术内幕》第三章，自己有删减，二次转载请也务必注明此出处。","tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"编码","slug":"编码","permalink":"http://yoursite.com/tags/编码/"}]},{"title":"详细深入分析 Java ClassLoader 工作机制","date":"2017-03-26T13:27:57.101Z","path":"2017/03/26/详细深入分析 Java ClassLoader 工作机制/","text":"什么是 ClassLoader ？大家都知道，当我们写好一个 Java 程序之后，不是管是 C/S 还是 B/S 应用，都是由若干个 .class 文件组织而成的一个完整的 Java 应用程序，当程序在运行时，即会调用该程序的一个入口函数来调用系统的相关功能，而这些功能都被封装在不同的 class 文件当中，所以经常要从这个 class 文件中要调用另外一个 class 文件中的方法，如果另外一个文件不存在的，则会引发系统异常。而程序在启动的时候，并不会一次性加载程序所要用的所有class文件，而是根据程序的需要，通过Java的类加载机制（ClassLoader）来动态加载某个 class 文件到内存当中的，从而只有 class 文件被载入到了内存之后，才能被其它 class 所引用。所以 ClassLoader 就是用来动态加载 class 文件到内存当中用的。 ClassLoader 作用： 负责将 Class 加载到 JVM 中 审查每个类由谁加载（父优先的等级加载机制） 将 Class 字节码重新解析成 JVM 统一要求的对象格式 1、ClassLoader 类结构分析为了更好的理解类的加载机制，我们来深入研究一下 ClassLoader 和他的方法。 public abstract class ClassLoader ClassLoader类是一个抽象类，sun公司是这么解释这个类的： 1234567/** * A class loader is an object that is responsible for loading classes. The * class ClassLoader is an abstract class. Given the binary name of a class, a class loader should attempt to * locate or generate data that constitutes a definition for the class. A * typical strategy is to transform the name into a file name and then read a * &quot;class file&quot; of that name from a file system.**/ 大致意思如下： class loader 是一个负责加载 classes 的对象，ClassLoader 类是一个抽象类，需要给出类的二进制名称，class loader 尝试定位或者产生一个 class 的数据，一个典型的策略是把二进制名字转换成文件名然后到文件系统中找到该文件。 以下是 ClassLoader 常用到的几个方法及其重载方法： ClassLoader defineClass(byte[], int, int) 把字节数组 b中的内容转换成 Java 类，返回的结果是java.lang.Class类的实例。这个方法被声明为final的 findClass(String name) 查找名称为 name的类，返回的结果是java.lang.Class类的实例 loadClass(String name) 加载名称为 name的类，返回的结果是java.lang.Class类的实例 resolveClass(Class&lt;?&gt;) 链接指定的 Java 类 其中 defineClass 方法用来将 byte 字节流解析成 JVM 能够识别的 Class 对象，有了这个方法意味着我们不仅仅可以通过 class 文件实例化对象，还可以通过其他方式实例化对象，如果我们通过网络接收到一个类的字节码，拿到这个字节码流直接创建类的 Class 对象形式实例化对象。如果直接调用这个方法生成类的 Class 对象，这个类的 Class 对象还没有 resolve ，这个 resolve 将会在这个对象真正实例化时才进行。 接下来我们看loadClass方法的实现方式： 123456789101112131415161718192021222324252627282930313233343536protected Class&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException &#123; synchronized (getClassLoadingLock(name)) &#123; // First, check if the class has already been loaded Class c = findLoadedClass(name); if (c == null) &#123; long t0 = System.nanoTime(); try &#123; if (parent != null) &#123; c = parent.loadClass(name, false); &#125; else &#123; c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // ClassNotFoundException thrown if class not found // from the non-null parent class loader &#125; if (c == null) &#123; // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125; &#125; 该方法大概意思： 使用指定的二进制名称来加载类，这个方法的默认实现按照以下顺序查找类： 调用findLoadedClass(String) 方法检查这个类是否被加载过 使用父加载器调用 loadClass(String) 方法，如果父加载器为 Null，类加载器装载虚拟机内置的加载器调用 findClass(String) 方法装载类， 如果，按照以上的步骤成功的找到对应的类，并且该方法接收的 resolve 参数的值为 true,那么就调用resolveClass(Class) 方法来处理类。 ClassLoader 的子类最好覆盖 findClass(String) 而不是这个方法。 除非被重写，这个方法默认在整个装载过程中都是同步的（线程安全的）。 2、ClassLoader 的等级加载机制Java默认提供的三个ClassLoader BootStrap ClassLoader：称为启动类加载器，是Java类加载层次中最顶层的类加载器，负责加载JDK中的核心类库，如：rt.jar、resources.jar、charsets.jar等，可通过如下程序获得该类加载器从哪些地方加载了相关的jar或class文件： 12345678910public class BootStrapTest&#123; public static void main(String[] args) &#123; URL[] urls = sun.misc.Launcher.getBootstrapClassPath().getURLs(); for (int i = 0; i &lt; urls.length; i++) &#123; System.out.println(urls[i].toExternalForm()); &#125; &#125;&#125; 以下内容是上述程序从本机JDK环境所获得的结果： 其实上述结果也是通过查找 sun.boot.class.path 这个系统属性所得知的。 1System.out.println(System.getProperty(\"sun.boot.class.path\")); 1打印结果：C:\\Java\\jdk1.8.0_60\\jre\\lib\\resources.jar;C:\\Java\\jdk1.8.0_60\\jre\\lib\\rt.jar;C:\\Java\\jdk1.8.0_60\\jre\\lib\\sunrsasign.jar;C:\\Java\\jdk1.8.0_60\\jre\\lib\\jsse.jar;C:\\Java\\jdk1.8.0_60\\jre\\lib\\jce.jar;C:\\Java\\jdk1.8.0_60\\jre\\lib\\charsets.jar;C:\\Java\\jdk1.8.0_60\\jre\\lib\\jfr.jar;C:\\Java\\jdk1.8.0_60\\jre\\classes Extension ClassLoader：称为扩展类加载器，负责加载Java的扩展类库，Java 虚拟机的实现会提供一个扩展库目录。该类加载器在此目录里面查找并加载 Java 类。默认加载JAVA_HOME/jre/lib/ext/目下的所有jar。 App ClassLoader：称为系统类加载器，负责加载应用程序classpath目录下的所有jar和class文件。一般来说，Java 应用的类都是由它来完成加载的。可以通过 ClassLoader.getSystemClassLoader()来获取它。 ​ 除了系统提供的类加载器以外，开发人员可以通过继承java.lang.ClassLoader类的方式实现自己的类加载器，以满足一些特殊的需求。 除了引导类加载器之外，所有的类加载器都有一个父类加载器。 给出的 getParent()方法可以得到。对于系统提供的类加载器来说，系统类加载器的父类加载器是扩展类加载器，而扩展类加载器的父类加载器是引导类加载器；对于开发人员编写的类加载器来说，其父类加载器是加载此类加载器 Java 类的类加载器。因为类加载器 Java 类如同其它的 Java 类一样，也是要由类加载器来加载的。一般来说，开发人员编写的类加载器的父类加载器是系统类加载器。类加载器通过这种方式组织起来，形成树状结构。树的根节点就是引导类加载器。 ​ ClassLoader加载类的原理1. 原理介绍ClassLoader使用的是双亲委托模型来搜索类的，每个ClassLoader实例都有一个父类加载器的引用（不是继承的关系，是一个包含的关系），虚拟机内置的类加载器（Bootstrap ClassLoader）本身没有父类加载器，但可以用作其它ClassLoader实例的的父类加载器。当一个ClassLoader实例需要加载某个类时，它会试图亲自搜索某个类之前，先把这个任务委托给它的父类加载器，这个过程是由上至下依次检查的，首先由最顶层的类加载器Bootstrap ClassLoader试图加载，如果没加载到，则把任务转交给Extension ClassLoader试图加载，如果也没加载到，则转交给App ClassLoader进行加载，如果它也没有加载得到的话，则返回给委托的发起者，由它到指定的文件系统或网络等URL中加载该类。如果它们都没有加载到这个类时，则抛出ClassNotFoundException异常。否则将这个找到的类生成一个类的定义，并将它加载到内存当中，最后返回这个类在内存中的Class实例对象。 2、为什么要使用双亲委托这种模型呢？因为这样可以避免重复加载，当父亲已经加载了该类的时候，就没有必要 ClassLoader再加载一次。考虑到安全因素，我们试想一下，如果不使用这种委托模式，那我们就可以随时使用自定义的String来动态替代java核心api中定义的类型，这样会存在非常大的安全隐患，而双亲委托的方式，就可以避免这种情况，因为String已经在启动时就被引导类加载器（Bootstrcp ClassLoader）加载，所以用户自定义的ClassLoader永远也无法加载一个自己写的String，除非你改变JDK中ClassLoader搜索类的默认算法。 3、 但是JVM在搜索类的时候，又是如何判定两个class是相同的呢？JVM在判定两个class是否相同时，不仅要判断两个类名是否相同，而且要判断是否由同一个类加载器实例加载的。只有两者同时满足的情况下，JVM才认为这两个class是相同的。就算两个class是同一份class字节码，如果被两个不同的ClassLoader实例所加载，JVM也会认为它们是两个不同class。比如网络上的一个Java类org.classloader.simple.NetClassLoaderSimple，javac编译之后生成字节码文件NetClassLoaderSimple.class，ClassLoaderA和ClassLoaderB这两个类加载器并读取了NetClassLoaderSimple.class文件，并分别定义出了java.lang.Class实例来表示这个类，对于JVM来说，它们是两个不同的实例对象，但它们确实是同一份字节码文件，如果试图将这个Class实例生成具体的对象进行转换时，就会抛运行时异常java.lang.ClassCaseException，提示这是两个不同的类型。现在通过实例来验证上述所描述的是否正确：1）、在web服务器上建一个org.classloader.simple.NetClassLoaderSimple.java类 1234567public class NetClassLoaderSimple&#123; private NetClassLoaderSimple instance; public void setNetClassLoaderSimple(Object object)&#123; this.instance = (NetClassLoaderSimple)object; &#125;&#125; org.classloader.simple.NetClassLoaderSimple类的setNetClassLoaderSimple方法接收一个Object类型参数，并将它强制转换成org.classloader.simple.NetClassLoaderSimple类型。 2）、测试两个class是否相同 NetWorkClassLoader.java 12345678910111213141516171819202122package classloader;public class NewworkClassLoaderTest &#123; public static void main(String[] args) &#123; try &#123; //测试加载网络中的class文件 String rootUrl = &quot;http://localhost:8080/httpweb/classes&quot;; String className = &quot;org.classloader.simple.NetClassLoaderSimple&quot;; NetworkClassLoader ncl1 = new NetworkClassLoader(rootUrl); NetworkClassLoader ncl2 = new NetworkClassLoader(rootUrl); Class&lt;?&gt; clazz1 = ncl1.loadClass(className); Class&lt;?&gt; clazz2 = ncl2.loadClass(className); Object obj1 = clazz1.newInstance(); Object obj2 = clazz2.newInstance(); clazz1.getMethod(&quot;setNetClassLoaderSimple&quot;, Object.class).invoke(obj1, obj2); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 首先获得网络上一个class文件的二进制名称，然后通过自定义的类加载器NetworkClassLoader创建两个实例，并根据网络地址分别加载这份class，并得到这两个ClassLoader实例加载后生成的Class实例clazz1和clazz2，最后将这两个Class实例分别生成具体的实例对象obj1和obj2，再通过反射调用clazz1中的setNetClassLoaderSimple方法。 3）、查看测试结果 结论：从结果中可以看出，运行时抛出了java.lang.ClassCastException异常。虽然两个对象obj1和 obj2的类的名字相同，但是这两个类是由不同的类加载器实例来加载的，所以JVM认为它们就是两个不同的类。 了解了这一点之后，就可以理解代理模式的设计动机了。代理模式是为了保证 Java 核心库的类型安全。所有 Java 应用都至少需要引用 java.lang.Object类，也就是说在运行的时候，java.lang.Object这个类需要被加载到 Java 虚拟机中。如果这个加载过程由 Java 应用自己的类加载器来完成的话，很可能就存在多个版本的 java.lang.Object类，而且这些类之间是不兼容的。通过代理模式，对于 Java 核心库的类的加载工作由引导类加载器来统一完成，保证了Java 应用所使用的都是同一个版本的 Java 核心库的类，是互相兼容的。 不同的类加载器为相同名称的类创建了额外的名称空间。相同名称的类可以并存在 Java 虚拟机中，只需要用不同的类加载器来加载它们即可。不同类加载器加载的类之间是不兼容的，这就相当于在 Java 虚拟机内部创建了一个个相互隔离的 Java 类空间。 ClassLoader的体系架构： 类加载器的树状组织结构测试一： 1234567891011public class ClassLoaderTree&#123; public static void main(String[] args) &#123; ClassLoader loader = ClassLoaderTree.class.getClassLoader(); while (loader!=null)&#123; System.out.println(loader.toString()); loader = loader.getParent(); &#125; System.out.println(loader); &#125;&#125; 每个 Java 类都维护着一个指向定义它的类加载器的引用，通过 getClassLoader()方法就可以获取到此引用。代码中通过递归调用 getParent()方法来输出全部的父类加载器。 结果是： 第一个输出的是ClassLoaderTree类的类加载器，即系统类加载器。它是sun.misc.Launcher$AppClassLoader类的实例；第二个输出的是扩展类加载器，是sun.misc.Launcher$ExtClassLoader类的实例。需要注意的是这里并没有输出引导类加载器，这是由于有些 JDK 的实现对于父类加载器是引导类加载器的情况，getParent()方法返回 null。第三行结果说明：ExtClassLoader的类加器是Bootstrap ClassLoader，因为Bootstrap ClassLoader不是一个普通的Java类，所以ExtClassLoader的parent=null，所以第三行的打印结果为null就是这个原因。 测试二： 将ClassLoaderTree.class打包成ClassLoaderTree.jar，放到Extension ClassLoader的加载目录下（JAVA_HOME/jre/lib/ext），然后重新运行这个程序，得到的结果会是什么样呢？ 此处我在 IDEA 中的运行结果还和上面的一样，与文章 深入分析Java ClassLoader原理 中的有差距，具体原因未弄清楚，还希望读者能够亲自测试。 那文章中的结果是： 打印结果分析：为什么第一行的结果是ExtClassLoader呢？ 因为 ClassLoader 的委托模型机制，当我们要用 ClassLoaderTest.class 这个类的时候，AppClassLoader 在试图加载之前，先委托给 Bootstrcp ClassLoader，Bootstracp ClassLoader 发现自己没找到，它就告诉 ExtClassLoader，兄弟，我这里没有这个类，你去加载看看，然后 Extension ClassLoader 拿着这个类去它指定的类路径（JAVA_HOME/jre/lib/ext）试图加载，唉，它发现在ClassLoaderTest.jar 这样一个文件中包含 ClassLoaderTest.class 这样的一个文件，然后它把找到的这个类加载到内存当中，并生成这个类的 Class 实例对象，最后把这个实例返回。所以 ClassLoaderTest.class 的类加载器是 ExtClassLoader。 第二行的结果为null，是因为ExtClassLoader的父类加载器是Bootstrap ClassLoader。 JVM加载class文件的两种方法； 隐式加载， 程序在运行过程中当碰到通过new 等方式生成对象时，隐式调用类装载器加载对应的类到jvm中。 显式加载， 通过class.forname()、this.getClass.getClassLoader().loadClass()等方法显式加载需要的类，或者我们自己实现的 ClassLoader 的 findlass() 方法。 下面介绍下 class.forName的加载类方法： Class.forName是一个静态方法，同样可以用来加载类。该方法有两种形式：Class.forName(String name,boolean initialize, ClassLoader loader)和Class.forName(String className)。第一种形式的参数 name表示的是类的全名；initialize表示是否初始化类；loader表示加载时使用的类加载器。第二种形式则相当于设置了参数 initialize的值为 true，loader的值为当前类的类加载器。Class.forName的一个很常见的用法是在加载数据库驱动的时候。如Class.forName(&quot;org.apache.derby.jdbc.EmbeddedDriver&quot;)用来加载 Apache Derby 数据库的驱动。 类加载的动态性体现：一个应用程序总是由n多个类组成，Java程序启动时，并不是一次把所有的类全部加载后再运行，它总是先把保证程序运行的基础类一次性加载到jvm中，其它类等到jvm用到的时候再加载，这样的好处是节省了内存的开销，因为java最早就是为嵌入式系统而设计的，内存宝贵，这是一种可以理解的机制，而用到时再加载这也是java动态性的一种体现。 3、如何加载 class 文件 第一阶段找到 .class 文件并把这个文件包含的字节码加载到内存中。 第二阶段中分三步，字节码验证；class 类数据结构分析及相应的内存分配；最后的符号表的链接。 第三阶段是类中静态属性和初始化赋值，以及静态块的执行等。 3.1 、加载字节码到内存。。 3.2 、验证与分析 字节码验证，类装入器对于类的字节码要做很多检测，以确保格式正确，行为正确。 类装备，准备代表每个类中定义的字段、方法和实现接口所必须的数据结构。 解析，装入器装入类所引用的其他所有类。 4、常见加载类错误分析4.1 、 ClassNotFoundExecptionClassNotFoundExecption 异常是平常碰到的最多的。这个异常通常发生在显示加载类的时候。 12345678910public class ClassNotFoundExceptionTest&#123; public static void main(String[] args) &#123; try &#123; Class.forName(&quot;NotFoundClass&quot;); &#125;catch (ClassNotFoundException e)&#123; e.printStackTrace(); &#125; &#125;&#125; 显示加载一个类通常有： 通过类 Class 中的 forName() 方法 通过类 ClassLoader 中的 loadClass() 方法 通过类 ClassLoader 中的 findSystemClass() 方法 出现这种错误其实就是当 JVM 要加载指定文件的字节码到内存时，并没有找到这个文件对应的字节码，也就是这个文件并不存在。解决方法就是检查在当前的 classpath 目录下有没有指定的文件。 4.2 、 NoClassDefFoundError在JavaDoc中对NoClassDefFoundError的产生可能的情况就是使用new关键字、属性引用某个类、继承了某个接口或者类，以及方法的某个参数中引用了某个类，这时就会触发JVM或者类加载器实例尝试加载类型的定义，但是该定义却没有找到，影响了执行路径。换句话说，在编译时这个类是能够被找到的，但是在执行时却没有找到。 解决这个错误的方法就是确保每个类引用的类都在当前的classpath下面。 4.3 、 UnsatisfiedLinkError该错误通常是在 JVM 启动的时候，如果 JVM 中的某个 lib 删除了，就有可能报这个错误。 12345678910public class UnsatisfiedLinkErrorTest&#123; public native void nativeMethod(); static &#123; System.loadLibrary(\"NoLib\"); &#125; public static void main(String[] args) &#123; new UnsatisfiedLinkErrorTest().nativeMethod(); //解析native标识的方法时JVM找不到对应的库文件 &#125;&#125; 4.4 、 ClassCastException该错误通常出现强制类型转换时出现这个错误。 123456789101112public class ClassCastExceptionTest&#123; public static Map m = new HashMap()&#123; &#123; put(\"a\", \"2\"); &#125; &#125;; public static void main(String[] args) &#123; Integer integer = (Integer) m.get(\"a\"); //将m强制转换成Integer类型 System.out.println(integer); &#125;&#125; 注意：JVM 在做类型转换时的规则： 对于普通对象，对象必须是目标类的实例或目标类的子类的实例。如果目标类是接口，那么会把它当作实现了该接口的一个子类。 对于数组类型，目标类必须是数组类型或 java.lang.Object、java.lang.Cloneable、java.io.Serializable。 如果不满足上面的规则，JVM 就会报错，有两种方式可避免错误： 在容器类型中显式的指明这个容器所包含的对象类型。 先通过 instanceof 检查是不是目标类型，然后再进行强制类型的转换。 上面代码中改成如下就可以避免错误了： 4.5 、 ExceptionInInitializerError12345678910public class ExceptionInInitializerErrorTest&#123; public static Map m = new HashMap()&#123;&#123; m.put(\"a\", \"2\"); &#125;&#125;; public static void main(String[] args) &#123; Integer integer = (Integer) m.get(\"a\"); System.out.println(integer); &#125;&#125; 在初始化这个类时，给静态属性 m 赋值时出现了异常导致抛出错误 ExceptionInInitializerError。 4.6 NoSuchMethodErrorNoSuchMethodError代表这个类型确实存在，但是一个不正确的版本被加载了。为了解决这个问题我们可以使用 ‘­verbose:class’ 来判断该JVM加载的到底是哪个版本。 4.7 LinkageError有时候事情会变得更糟，和 ClassCastException 本质一样，加载自不同位置的相同类在同一段逻辑（比如：方法）中交互时，会出现 LinkageError 。 LinkageError 需要观察哪个类被不同的类加载器加载了，在哪个方法或者调用处发生（交汇）的，然后才能想解决方法，解决方法无外乎两种。第一，还是不同的类加载器加载，但是相互不再交汇影响，这里需要针对发生问题的地方做一些改动，比如更换实现方式，避免出现上述问题；第二，冲突的类需要由一个Parent类加载器进行加载。LinkageError 和ClassCastException 本质是一样的，加载自不同类加载器的类型，在同一个类的方法或者调用中出现，如果有转型操作那么就会抛 ClassCastException ，如果是直接的方法调用处的参数或者返回值解析，那么就会产生 LinkageError 。 5、常用的 ClassLoader 分析。。参见书籍《深入分析Java Web技术内幕》 6、如何实现自己的 ClassLoaderClassLoader 能够完成的事情有以下情况： 在自定义路径下查找自定义的class类文件。 对我们自己要加载的类做特殊处理。 可以定义类的实现机制。 虽然在绝大多数情况下，系统默认提供的类加载器实现已经可以满足需求。但是在某些情况下，您还是需要为应用开发出自己的类加载器。比如您的应用通过网络来传输 Java 类的字节代码，为了保证安全性，这些字节代码经过了加密处理。这个时候您就需要自己的类加载器来从某个网络地址上读取加密后的字节代码，接着进行解密和验证，最后定义出要在 Java 虚拟机中运行的类来。 定义自已的类加载器分为两步：1、继承java.lang.ClassLoader2、重写父类的findClass方法 6.1 、文件系统类加载器加载存储在文件系统上的 Java 字节代码。 123456789101112131415161718192021222324252627282930313233343536373839404142public class FileSystemClassLoader extends ClassLoader&#123; private String rootDir; public FileSystemClassLoader(String rootDir)&#123; this.rootDir = rootDir; &#125; protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; byte[] classData = getClassData(name); if (classData == null)&#123; throw new ClassNotFoundException(); &#125; else &#123; return defineClass(name, classData, 0, classData.length); &#125; &#125; private byte[] getClassData(String className) &#123; String path = classNameToPath(className); try &#123; InputStream ins = new FileInputStream(path); ByteArrayOutputStream baos = new ByteArrayOutputStream(); int bufferSize = 4096; byte[] buffer = new byte[bufferSize]; int bytesNumRead = 0; while ((bytesNumRead = ins.read(buffer)) != -1)&#123; baos.write(buffer, 0, bytesNumRead); &#125; return baos.toByteArray(); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return null; &#125; private String classNameToPath(String className) &#123; return rootDir + File.separatorChar + className.replace('.', File.separatorChar) + \".class\"; &#125;&#125; 类 FileSystemClassLoader继承自类java.lang.ClassLoader。java.lang.ClassLoader类的方法loadClass()封装了前面提到的代理模式的实现。该方法会首先调用 findLoadedClass()方法来检查该类是否已经被加载过；如果没有加载过的话，会调用父类加载器的loadClass()方法来尝试加载该类；如果父类加载器无法加载该类的话，就调用 findClass()方法来查找该类。因此，为了保证类加载器都正确实现代理模式，在开发自己的类加载器时，最好不要覆写 loadClass()方法，而是覆写findClass()方法。 类 FileSystemClassLoader的 findClass()方法首先根据类的全名在硬盘上查找类的字节代码文件（.class 文件），然后读取该文件内容，最后通过 defineClass()方法来把这些字节代码转换成 java.lang.Class类的实例。 6.2 、 网络类加载器一个网络类加载器来说明如何通过类加载器来实现组件的动态更新。即基本的场景是：Java 字节代码（.class）文件存放在服务器上，客户端通过网络的方式获取字节代码并执行。当有版本更新的时候，只需要替换掉服务器上保存的文件即可。通过类加载器可以比较简单的实现这种需求。 类 NetworkClassLoader 负责通过网络下载 Java 类字节代码并定义出 Java 类。它的实现与FileSystemClassLoader 类似。在通过 NetworkClassLoader 加载了某个版本的类之后，一般有两种做法来使用它。第一种做法是使用 Java 反射 API。另外一种做法是使用接口。需要注意的是，并不能直接在客户端代码中引用从服务器上下载的类，因为客户端代码的类加载器找不到这些类。使用 Java 反射 API 可以直接调用 Java 类的方法。而使用接口的做法则是把接口的类放在客户端中，从服务器上加载实现此接口的不同版本的类。在客户端通过相同的接口来使用这些实现类。 网络类加载器的代码：ClassLoader 7、类加载器与Web容器对于运行在 Java EE™容器中的 Web 应用来说，类加载器的实现方式与一般的 Java 应用有所不同。不同的 Web 容器的实现方式也会有所不同。以 Apache Tomcat 来说，每个Web 应用都有一个对应的类加载器实例。该类加载器也使用代理模式，所不同的是它是首先尝试去加载某个类，如果找不到再代理给父类加载器。这与一般类加载器的顺序是相反的。这是 Java Servlet 规范中的推荐做法，其目的是使得Web 应用自己的类的优先级高于 Web 容器提供的类。这种代理模式的一个例外是：Java 核心库的类是不在查找范围之内的。这也是为了保证 Java 核心库的类型安全。 绝大多数情况下，Web 应用的开发人员不需要考虑与类加载器相关的细节。下面给出几条简单的原则： 每个 Web 应用自己的 Java 类文件和使用的库的 jar 包，分别放在 WEB-INF/classes和 WEB-INF/lib目录下面。 多个应用共享的 Java 类文件和 jar 包，分别放在 Web 容器指定的由所有 Web 应用共享的目录下面。 当出现找不到类的错误时，检查当前类的类加载器和当前线程的上下文类加载器是否正确 8、总结本篇文章详细深入的介绍了 ClassLoader 的工作机制，还写了如何自己实现所需的 ClassLoader 。 参考资料1、深度分析 Java 的 ClassLoader 机制（源码级别） 2、深入浅出ClassLoader 3、深入探讨 Java 类加载器 4、深入分析Java ClassLoader原理 5、《深入分析 Java Web 技术内幕》修订版 —— 深入分析 ClassLoader 工作机制","tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"http://yoursite.com/tags/JVM/"},{"name":"类加载机制","slug":"类加载机制","permalink":"http://yoursite.com/tags/类加载机制/"}]}]